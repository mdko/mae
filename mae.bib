
@inproceedings{darais_galois_2015,
	title = {Galois transformers and modular abstract interpreters: reusable metatheory for program analysis},
	isbn = {978-1-4503-3689-5},
	shorttitle = {Galois transformers and modular abstract interpreters},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814308},
	doi = {10.1145/2814270.2814308},
	language = {en},
	urldate = {2017-07-18},
	publisher = {ACM Press},
	author = {Darais, David and Might, Matthew and Van Horn, David},
	year = {2015},
	pages = {552--571},
	file = {Darais et al_2015_Galois transformers and modular abstract interpreters - reusable metatheory for.pdf:/home/michael/Dropbox/zotero-pdfs/D/Darais et al_2015_Galois transformers and modular abstract interpreters - reusable metatheory for.pdf:application/pdf}
}

@inproceedings{petersen_type_2003,
	address = {New York, NY, USA},
	series = {{POPL} '03},
	title = {A {Type} {Theory} for {Memory} {Allocation} and {Data} {Layout}},
	isbn = {978-1-58113-628-9},
	url = {http://doi.acm.org/10.1145/604131.604147},
	doi = {10.1145/604131.604147},
	abstract = {Ordered type theory is an extension of linear type theory in which variables in the context may be neither dropped nor re-ordered. This restriction gives rise to a natural notion of adjacency. We show that a language based on ordered types can use this property to give an exact account of the layout of data in memory. The fuse constructor from ordered logic describes adjacency of values in memory, and the mobility modal describes pointers into the heap. We choose a particular allocation model based on a common implementation scheme for copying garbage collection and show how this permits us to separate out the allocation and initialization of memory locations in such a way as to account for optimizations such as the coalescing of multiple calls to the allocator.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Petersen, Leaf and Harper, Robert and Crary, Karl and Pfenning, Frank},
	year = {2003},
	keywords = {data representation, memory management, ordered logic, type theory, MAE},
	pages = {172--184},
	file = {Petersen et al_2003_A Type Theory for Memory Allocation and Data Layout.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petersen et al_2003_A Type Theory for Memory Allocation and Data Layout.pdf:application/pdf}
}

@inproceedings{clarke_ownership_2002,
	address = {New York, NY, USA},
	series = {{OOPSLA} '02},
	title = {Ownership, {Encapsulation} and the {Disjointness} of {Type} and {Effect}},
	isbn = {978-1-58113-471-1},
	url = {http://doi.acm.org/10.1145/582419.582447},
	doi = {10.1145/582419.582447},
	abstract = {Ownership types provide a statically enforceable notion of object-level encapsulation. We extend ownership types with computational effects to support reasoning about object-oriented programs. The ensuing system provides both access control and effects reporting. Based on this type system, we codify two formal systems for reasoning about aliasing and the disjointness of computational effects. The first can be used to prove that evaluation of two expressions will never lead to aliases, while the latter can be used to show the non-interference of two expressions.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Clarke, Dave and Drossopoulou, Sophia},
	year = {2002},
	keywords = {aliasing, encapsulation, ownership types, type-and-effects systems},
	pages = {292--310},
	file = {Clarke_Drossopoulou_2002_Ownership, Encapsulation and the Disjointness of Type and Effect.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke_Drossopoulou_2002_Ownership, Encapsulation and the Disjointness of Type and Effect.pdf:application/pdf}
}

@inproceedings{minsky_towards_1996,
	title = {Towards alias-free pointers},
	url = {https://link.springer.com/chapter/10.1007/BFb0053062},
	urldate = {2017-08-08},
	booktitle = {European {Conference} on {Object}-{Oriented} {Programming}},
	publisher = {Springer},
	author = {Minsky, Naftaly H.},
	year = {1996},
	pages = {189--209},
	file = {Minsky_1996_Towards alias-free pointers.pdf:/home/michael/Dropbox/zotero-pdfs/M/Minsky_1996_Towards alias-free pointers.pdf:application/pdf}
}

@inproceedings{deline_enforcing_2001,
	address = {New York, NY, USA},
	series = {{PLDI} '01},
	title = {Enforcing {High}-level {Protocols} in {Low}-level {Software}},
	isbn = {978-1-58113-414-8},
	url = {http://doi.acm.org/10.1145/378795.378811},
	doi = {10.1145/378795.378811},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2001 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {DeLine, Robert and Fähndrich, Manuel},
	year = {2001},
	pages = {59--69},
	file = {DeLine_Fahndrich_2001_Enforcing High-level Protocols in Low-level Software.pdf:/home/michael/Dropbox/zotero-pdfs/D/DeLine_Fahndrich_2001_Enforcing High-level Protocols in Low-level Software.pdf:application/pdf;DeLine_Fahndrich_2001_Enforcing High-level Protocols in Low-level Software.pdf:/home/michael/Dropbox/zotero-pdfs/D/DeLine_Fahndrich_2001_Enforcing High-level Protocols in Low-level Software.pdf:application/pdf}
}

@article{lampson_report_1977,
	title = {Report on the programming language {Euclid}},
	volume = {12},
	url = {http://dl.acm.org/citation.cfm?id=971189},
	number = {2},
	urldate = {2017-08-08},
	journal = {ACM Sigplan Notices},
	author = {Lampson, Butler W. and Horning, James Jay and London, Ralph L. and Mitchell, James G. and Popek, Gerald J.},
	year = {1977},
	pages = {1--79},
	file = {Lampson et al_1977_Report on the programming language Euclid.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lampson et al_1977_Report on the programming language Euclid.pdf:application/pdf}
}

@techreport{grossman_formal_2001,
	title = {Formal {Type} {Soundness} for {Cyclone}’s {Region} {System}},
	url = {http://dl.acm.org/citation.cfm?id=512563},
	urldate = {2017-08-08},
	author = {Grossman, Dan and Morrisett, Greg and Jim, Trevor and Hicks, Michael and Wang, Yanling and Cheney, James},
	year = {2001},
	file = {Grossman et al_2001_Formal Type Soundness for Cyclone’s Region System.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grossman et al_2001_Formal Type Soundness for Cyclone’s Region System.pdf:application/pdf}
}

@article{bruce_comparing_1999,
	title = {Comparing {Object} {Encodings}},
	volume = {155},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/S0890540199928298},
	doi = {10.1006/inco.1999.2829},
	abstract = {Recent years have seen the development of several foundational models for statically typed object-oriented programming. But despite their intuitive similarity, differences in the technical machinery used to formulate the various proposals have made them difficult to compare. Using the typed lambda-calculus Fω{\textless}: as a common basis, we now offer a detailed comparison of four models: (1) a recursive-record encoding similar to the ones used by Cardelli, Reddy, Cook, and others; (2) Hofmann, Pierce, and Turner's existential encoding; (3) Bruce's model based on existential and recursive types; and (4) Abadi, Cardelli, and Viswanathan's type-theoretic encoding of a calculus of primitive objects.},
	number = {1},
	urldate = {2017-08-08},
	journal = {Information and Computation},
	author = {Bruce, Kim B. and Cardelli, Luca and Pierce, Benjamin C.},
	month = nov,
	year = {1999},
	pages = {108--133},
	file = {Bruce et al_1999_Comparing Object Encodings.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bruce et al_1999_Comparing Object Encodings.pdf:application/pdf;ScienceDirect Snapshot:/home/michael/Zotero/storage/IRVXRU42/S0890540199928298.html:text/html}
}

@inproceedings{lucassen_polymorphic_1988,
	address = {New York, NY, USA},
	series = {{POPL} '88},
	title = {Polymorphic {Effect} {Systems}},
	isbn = {978-0-89791-252-5},
	url = {http://doi.acm.org/10.1145/73560.73564},
	doi = {10.1145/73560.73564},
	abstract = {We present a new approach to programming languages for parallel computers that uses an effect system to discover expression scheduling constraints. This effect system is part of a 'kinded' type system with three base kinds: types, which describe the value that an expression may return; effects, which describe the side-effects that an expression may have; and regions, which describe the area of the store in which side-effects may occur. Types, effects and regions are collectively called descriptions.
Expressions can be abstracted over any kind of description variable -- this permits type, effect and region polymorphism. Unobservable side-effects can be masked by the effect system; an effect soundness property guarantees that the effects computed statically by the effect system are a conservative approximation of the actual side-effects that a given expression may have.
The effect system we describe performs certain kinds of side-effect analysis that were not previously feasible. Experimental data from the programming language FX indicate that an effect system can be used effectively to compile programs for parallel computers.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Lucassen, J. M. and Gifford, D. K.},
	year = {1988},
	pages = {47--57},
	file = {Lucassen_Gifford_1988_Polymorphic Effect Systems.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lucassen_Gifford_1988_Polymorphic Effect Systems.pdf:application/pdf}
}

@inproceedings{grossman_region-based_2002,
	address = {New York, NY, USA},
	series = {{PLDI} '02},
	title = {Region-based {Memory} {Management} in {Cyclone}},
	isbn = {978-1-58113-463-6},
	url = {http://doi.acm.org/10.1145/512529.512563},
	doi = {10.1145/512529.512563},
	abstract = {Cyclone is a type-safe programming language derived from C. The primary design goal of Cyclone is to let programmers control data representation and memory management without sacrificing type-safety. In this paper, we focus on the region-based memory management of Cyclone and its static typing discipline. The design incorporates several advancements, including support for region subtyping and a coherent integration with stack allocation and a garbage collector. To support separate compilation, Cyclone requires programmers to write some explicit region annotations, but a combination of default annotations, local type inference, and a novel treatment of region effects reduces this burden. As a result, we integrate C idioms in a region-based framework. In our experience, porting legacy C to Cyclone has required altering about 8\% of the code; of the changes, only 6\% (of the 8\%) were region annotations.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2002 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Grossman, Dan and Morrisett, Greg and Jim, Trevor and Hicks, Michael and Wang, Yanling and Cheney, James},
	year = {2002},
	keywords = {TYPES},
	pages = {282--293},
	file = {Grossman et al_2002_Region-based Memory Management in Cyclone.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grossman et al_2002_Region-based Memory Management in Cyclone.pdf:application/pdf}
}

@inproceedings{levy_ownership_2015,
	address = {New York, NY, USA},
	series = {{PLOS} '15},
	title = {Ownership is {Theft}: {Experiences} {Building} an {Embedded} {OS} in {Rust}},
	isbn = {978-1-4503-3942-1},
	shorttitle = {Ownership is {Theft}},
	url = {http://doi.acm.org/10.1145/2818302.2818306},
	doi = {10.1145/2818302.2818306},
	abstract = {Rust, a new systems programming language, provides compile-time memory safety checks to help eliminate runtime bugs that manifest from improper memory management. This feature is advantageous for operating system development, and especially for embedded OS development, where recovery and debugging are particularly challenging. However, embedded platforms are highly event-based, and Rust's memory safety mechanisms largely presume threads. In our experience developing an operating system for embedded systems in Rust, we have found that Rust's ownership model prevents otherwise safe resource sharing common in the embedded domain, conflicts with the reality of hardware resources, and hinders using closures for programming asynchronously. We describe these experiences and how they relate to memory safety as well as illustrate our workarounds that preserve the safety guarantees to the largest extent possible. In addition, we draw from our experience to propose a new language extension to Rust that would enable it to provide better memory safety tools for event-driven platforms.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 8th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Levy, Amit and Andersen, Michael P. and Campbell, Bradford and Culler, David and Dutta, Prabal and Ghena, Branden and Levis, Philip and Pannuto, Pat},
	year = {2015},
	keywords = {embedded operating systems, linear types, ownership, rust, RUST},
	pages = {21--26},
	file = {Levy et al_2015_Ownership is Theft.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levy et al_2015_Ownership is Theft.pdf:application/pdf;LEVY-ANDERSEN-CAMPBELL_ownership-is-theft-experiences-building-an-embedded-os-in-rust_2017_plos.pdf:/home/michael/Zotero/storage/WUEVECFD/LEVY-ANDERSEN-CAMPBELL_ownership-is-theft-experiences-building-an-embedded-os-in-rust_2017_plos.pdf:application/pdf}
}

@inproceedings{boyapati_ownership_2002,
	address = {New York, NY, USA},
	series = {{OOPSLA} '02},
	title = {Ownership {Types} for {Safe} {Programming}: {Preventing} {Data} {Races} and {Deadlocks}},
	isbn = {978-1-58113-471-1},
	shorttitle = {Ownership {Types} for {Safe} {Programming}},
	url = {http://doi.acm.org/10.1145/582419.582440},
	doi = {10.1145/582419.582440},
	abstract = {This paper presents a new static type system for multithreaded programs; well-typed programs in our system are guaranteed to be free of data races and deadlocks. Our type system allows programmers to partition the locks into a fixed number of equivalence classes and specify a partial order among the equivalence classes. The type checker then statically verifies that whenever a thread holds more than one lock, the thread acquires the locks in the descending order.Our system also allows programmers to use recursive tree-based data structures to describe the partial order. For example, programmers can specify that nodes in a tree must be locked in the tree order. Our system allows mutations to the data structure that change the partial order at runtime. The type checker statically verifies that the mutations do not introduce cycles in the partial order, and that the changing of the partial order does not lead to deadlocks. We do not know of any other sound static system for preventing deadlocks that allows changes to the partial order at runtime.Our system uses a variant of ownership types to prevent data races and deadlocks. Ownership types provide a statically enforceable way of specifying object encapsulation. Ownership types are useful for preventing data races and deadlocks because the lock that protects an object can also protect its encapsulated objects. This paper describes how to use our type system to statically enforce object encapsulation as well as prevent data races and deadlocks. The paper also contains a detailed discussion of different ownership type systems and the encapsulation guarantees they provide.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Boyapati, Chandrasekhar and Lee, Robert and Rinard, Martin},
	year = {2002},
	keywords = {encapsulation, ownership types, data races, deadlocks, TO-READ},
	pages = {211--230},
	file = {Boyapati et al_2002_Ownership Types for Safe Programming.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyapati et al_2002_Ownership Types for Safe Programming.pdf:application/pdf}
}

@article{tofte_region-based_1997,
	title = {Region-{Based} {Memory} {Management}},
	volume = {132},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/S0890540196926139},
	doi = {10.1006/inco.1996.2613},
	abstract = {This paper describes a memory management discipline for programs that perform dynamic memory allocation and de-allocation. At runtime, all values are put intoregions. The store consists of a stack of regions. All points of region allocation and de-allocation are inferred automatically, using a type and effect based program analysis. The scheme does not assume the presence of a garbage collector. The scheme was first presented in 1994 (M. Tofte and J.-P. Talpin,in“Proceedings of the 21st ACM SIGPLAN–SIGACT Symposium on Principles of Programming Languages,” pp. 188–201); subsequently, it has been tested in The ML Kit with Regions, a region-based, garbage-collection free implementation of the Standard ML Core language, which includes recursive datatypes, higher-order functions and updatable references L. Birkedal, M. Tofte, and M. Vejlstrup, (1996),in“Proceedings of the 23 rd ACM SIGPLAN–SIGACT Symposium on Principles of Programming Languages,” pp. 171–183. This paper defines a region-based dynamic semantics for a skeletal programming language extracted from Standard ML. We present the inference system which specifies where regions can be allocated and de-allocated and a detailed proof that the system is sound with respect to a standard semantics. We conclude by giving some advice on how to write programs that run well on a stack of regions, based on practical experience with the ML Kit.},
	number = {2},
	urldate = {2017-08-08},
	journal = {Information and Computation},
	author = {Tofte, Mads and Talpin, Jean-Pierre},
	month = feb,
	year = {1997},
	keywords = {TO-READ, TYPES},
	pages = {109--176},
	file = {ScienceDirect Snapshot:/home/michael/Zotero/storage/L8SA2ZYJ/S0890540196926139.html:text/html;Tofte_Talpin_1997_Region-Based Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte_Talpin_1997_Region-Based Memory Management.pdf:application/pdf}
}

@inproceedings{jim_cyclone:_2002,
	title = {Cyclone: {A} {Safe} {Dialect} of {C}.},
	url = {https://www.usenix.org/legacy/events/usenix02/full_papers/jim/jim_html/},
	urldate = {2017-08-08},
	booktitle = {{USENIX} {Annual} {Technical} {Conference}, {General} {Track}},
	author = {Jim, Trevor and Morrisett, J. Gregory and Grossman, Dan and Hicks, Michael W. and Cheney, James and Wang, Yanling},
	year = {2002},
	keywords = {MAE},
	pages = {275--288},
	file = {Jim et al_2002_Cyclone.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jim et al_2002_Cyclone.pdf:application/pdf}
}

@inproceedings{clarke_ownership_1998,
	address = {New York, NY, USA},
	series = {{OOPSLA} '98},
	title = {Ownership {Types} for {Flexible} {Alias} {Protection}},
	isbn = {978-1-58113-005-8},
	url = {http://doi.acm.org/10.1145/286936.286947},
	doi = {10.1145/286936.286947},
	abstract = {Object-oriented programming languages allow inter-object aliasing. Although necessary to construct linked data structures and networks of interacting objects, aliasing is problematic in that an aggregate object's state can change via an alias to one of its components, without the aggregate being aware of any aliasing.Ownership types form a static type system that indicates object ownership. This provides a flexible mechanism to limit the visibility of object references and restrict access paths to objects, thus controlling a system's dynamic topology. The type system is shown to be sound, and the specific aliasing properties that a system's object graph satisfies are formulated and proven invariant for well-typed programs.},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Clarke, David G. and Potter, John M. and Noble, James},
	year = {1998},
	keywords = {ownership, alias protection, containment, programming language design, representation exposure, sharing, TO-READ},
	pages = {48--64},
	file = {Clarke et al_1998_Ownership Types for Flexible Alias Protection.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke et al_1998_Ownership Types for Flexible Alias Protection.pdf:application/pdf}
}

@inproceedings{clarke_simple_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Simple {Ownership} {Types} for {Object} {Containment}},
	isbn = {978-3-540-42206-8 978-3-540-45337-6},
	url = {https://link.springer.com/chapter/10.1007/3-540-45337-7_4},
	doi = {10.1007/3-540-45337-7_4},
	abstract = {Containment of objects is a natural concept that has been poorly supported in object-oriented programming languages. For a predefined set of ownership contexts, this paper presents a type system that enforces certain containment relationships for run-time objects. A fixed ordering relationship is presumed between the owners.The formalisation of ownership types has developed from our work with flexible alias protection together with an investigation of structural properties of object graphs based on dominator trees. Our general ownership type system permits fresh ownership contexts to be created at run-time. Here we present a simplified system in which the ownership contexts are predefined. This is powerful enough to express and enforce constraints about a system’s high-level structure.Our formal system is presented in an imperative variant of the object calculus. We present type preservation and soundness results. Furthermore we highlight how these type theoretic results establish a containment invariant for objects, in which access to contained objects is only permitted via their owners. In effect, the predefined ownership ordering restricts the permissible inter-object reference structure.},
	language = {en},
	booktitle = {{ECOOP} 2001 — {Object}-{Oriented} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Clarke, David G. and Noble, James and Potter, John M.},
	month = jun,
	year = {2001},
	pages = {53--76},
	file = {Clarke et al_2001_Simple Ownership Types for Object Containment.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke et al_2001_Simple Ownership Types for Object Containment.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/W48SGV6K/10.html:text/html}
}

@inproceedings{boyapati_parameterized_2001,
	address = {New York, NY, USA},
	series = {{OOPSLA} '01},
	title = {A {Parameterized} {Type} {System} for {Race}-free {Java} {Programs}},
	isbn = {978-1-58113-335-6},
	url = {http://doi.acm.org/10.1145/504282.504287},
	doi = {10.1145/504282.504287},
	abstract = {This paper presents a new static type system for multithreaded programs; any well-typed program in our system is free of data races. Our type system is significantly more expressive than previous such type systems. In particular, our system lets programmers write generic code to implement a class, then create different objects of the same class that have different objects of the same class that have different protection mechanisms. This flexibility enables programmers to reduce the number of unnecessary synchronizationoperations in a program without risking data races. We also support default types which reduce the burden of writing extra type annotations. Our experience indicates that our system provides a promising approach to make multithreaded programs more reliable and efficient},
	urldate = {2017-08-08},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Boyapati, Chandrasekhar and Rinard, Martin},
	year = {2001},
	pages = {56--69},
	file = {Boyapati_Rinard_2001_A Parameterized Type System for Race-free Java Programs.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyapati_Rinard_2001_A Parameterized Type System for Race-free Java Programs.pdf:application/pdf}
}

@article{morrisett_system_1999,
	title = {From {System} {F} to {Typed} {Assembly} {Language}},
	volume = {21},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/319301.319345},
	doi = {10.1145/319301.319345},
	abstract = {We motivate the design of typed assembly language (TAL) and present a type-preserving ttranslation from Systemn F to TAL. The typed assembly language we pressent is based on a conventional RISC assembly language, but its static type sytem provides support for enforcing high-level language abstratctions, such as closures, tuples, and user-defined abstract data types. The type system ensures that well-typed programs cannot violatet these abstractionsl In addition, the typing constructs admit many low-level compiler optimiztaions. Our translation to TAL is specified as a sequence of type-preserving transformations, including CPS and closure conversion phases; type-correct source programs are mapped to type-correct assembly language. A key contribution is an approach to polymorphic   closure conversion that is considerably simpler than previous work. The compiler and typed assembly lanugage provide a fully automatic way to produce certified code, suitable for use in systems where unstrusted and potentially malicious code must be checked for safety before execution.},
	number = {3},
	urldate = {2017-08-09},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Morrisett, Greg and Walker, David and Crary, Karl and Glew, Neal},
	month = may,
	year = {1999},
	keywords = {certified code, closure conversion, secure extensible systems, type-directed compilation, typed assembly language, typed intermediate languages},
	pages = {527--568},
	file = {Morrisett et al_1999_From System F to Typed Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/M/Morrisett et al_1999_From System F to Typed Assembly Language.pdf:application/pdf}
}

@inproceedings{colby_certifying_2000,
	address = {New York, NY, USA},
	series = {{PLDI} '00},
	title = {A {Certifying} {Compiler} for {Java}},
	isbn = {978-1-58113-199-4},
	url = {http://doi.acm.org/10.1145/349299.349315},
	doi = {10.1145/349299.349315},
	abstract = {This paper presents the initial results of a project to determine if
the techniques of  proof-carrying code and 
certifying compilers can be applied to programming languages of realistic size and complexity. The experiment shows that: (1) it is possible to implement a certifying native-code compiler for a large subset of the Java programming language; (2) the compiler is freely able to apply many standard local and global optimizations; and (3) the PCC binaries it produces are of reasonable size and can be rapidly checked for type safety by a small proof-checker. This paper also presents further evidence that PCC provides several advantages for compiler development. In particular, generating proofs of the target code helps to identify compiler bugs, many of which would have been difficult to discover by testing.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2000 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Colby, Christopher and Lee, Peter and Necula, George C. and Blau, Fred and Plesko, Mark and Cline, Kenneth},
	year = {2000},
	pages = {95--107},
	file = {Colby et al_2000_A Certifying Compiler for Java.pdf:/home/michael/Dropbox/zotero-pdfs/C/Colby et al_2000_A Certifying Compiler for Java.pdf:application/pdf}
}

@inproceedings{crary_talx86:_1999,
	title = {{TALx}86: {A} realistic typed assembly language},
	shorttitle = {{TALx}86},
	url = {http://www.cis.upenn.edu/~stevez/papers/MCGG99.pdf},
	urldate = {2017-08-09},
	booktitle = {1999 {ACM} {SIGPLAN} {Workshop} on {Compiler} {Support} for {System} {Software} {Atlanta}, {GA}, {USA}},
	author = {Crary, K. and Glew, Neal and Grossman, Dan and Samuels, Richard and Smith, F. and Walker, D. and Weirich, S. and Zdancewic, S.},
	year = {1999},
	pages = {25--35},
	file = {Crary et al_1999_TALx86.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary et al_1999_TALx86.pdf:application/pdf}
}

@inproceedings{necula_design_1998,
	address = {New York, NY, USA},
	series = {{PLDI} '98},
	title = {The {Design} and {Implementation} of a {Certifying} {Compiler}},
	isbn = {978-0-89791-987-6},
	url = {http://doi.acm.org/10.1145/277650.277752},
	doi = {10.1145/277650.277752},
	abstract = {This paper presents the design and implementation of a compiler that translates programs written in a type-safe subset of the C programming language into highly optimized DEC Alpha assembly language programs, and a certifier that automatically checks the type safety and memory safety of any assembly language program produced by the compiler. The result of the certifier is either a formal proof of type safety or a counterexample pointing to a potential violation of the type system by the target program. The ensemble of the compiler and the certifier is called a certifying compiler.Several advantages of certifying compilation over previous approaches can be claimed. The notion of a certifying compiler is significantly easier to employ than a formal compiler verification, in part because it is generally easier to verify the correctness of the result of a computation than to prove the correctness of the computation itself. Also, the approach can be applied even to highly optimizing compilers, as demonstrated by the fact that our compiler generates target code, for a range of realistic C programs, which is competitive with both the cc and gcc compilers with all optimizations enabled. The certifier also drastically improves the effectiveness of compiler testing because, for each test case, it statically signals compilation errors that might otherwise require many executions to detect. Finally, this approach is a practical way to produce the safety proofs for a Proof-Carrying Code system, and thus may be useful in a system for safe mobile code.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1998 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Necula, George C. and Lee, Peter},
	year = {1998},
	pages = {333--344},
	file = {Necula_Lee_1998_The Design and Implementation of a Certifying Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/N/Necula_Lee_1998_The Design and Implementation of a Certifying Compiler.pdf:application/pdf}
}

@inproceedings{shao_zhong_overview_1997,
	title = {An {Overview} of the {FLINT}/{ML} {Compiler}},
	url = {http://flint.cs.yale.edu/flint/publications/tic97.pdf},
	doi = {10.1.1.54.9101},
	abstract = {The FLINT project at Yale aims to build a state-of-the-art systems environment for modern typesafe languages. One important component of the FLINT system is a high-performance type-directed compiler for SML'97 (extended with higher-order modules). The FLINT/ML compiler provides several new capabilities that are not available in other type-based compilers: ffl type-directed compilation is carried over across the higher-order module boundaries; ffl recursive and mutable data objects can use unboxed representations without incurring expensive runtime cost on heavily polymorphic code; ffl parameterized modules (functors) can be selectively specialized, just as normal polymorphic functions; ffl new type representations are used to reduce the cost of type manipulation thus the compilation time. This paper gives an overview of these novel aspects, and a preliminary report on the current status of the implementation.},
	urldate = {2017-08-09},
	booktitle = {Proc. 1997 {ACM} {SIGPLAN} {Workshop} on {Types} in {Compilation}},
	author = {Shao, Zhong},
	year = {1997},
	file = {Shao, Zhong_1997_An Overview of the FLINT-ML Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shao, Zhong_1997_An Overview of the FLINT-ML Compiler.pdf:application/pdf}
}

@inproceedings{tarditi_til:_1996,
	address = {New York, NY, USA},
	series = {{PLDI} '96},
	title = {{TIL}: {A} {Type}-directed {Optimizing} {Compiler} for {ML}},
	isbn = {978-0-89791-795-7},
	shorttitle = {{TIL}},
	url = {http://doi.acm.org/10.1145/231379.231414},
	doi = {10.1145/231379.231414},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1996 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Tarditi, D. and Morrisett, G. and Cheng, P. and Stone, C. and Harper, R. and Lee, P.},
	year = {1996},
	pages = {181--192},
	file = {Tarditi et al_1996_TIL - A Type-directed Optimizing Compiler for ML.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tarditi et al_1996_TIL - A Type-directed Optimizing Compiler for ML.pdf:application/pdf}
}

@article{polakow_natural_1999,
	title = {Natural deduction for intuitionistic non-commutative linear logic},
	url = {http://link.springer.com/content/pdf/10.1007/3-540-48959-2.pdf#page=307},
	urldate = {2017-08-09},
	journal = {Lecture notes in computer science},
	author = {Polakow, Jeff and Pfenning, Frank},
	year = {1999},
	pages = {295--309},
	file = {Polakow_Pfenning_1999_Natural deduction for intuitionistic non-commutative linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/P/Polakow_Pfenning_1999_Natural deduction for intuitionistic non-commutative linear logic.pdf:application/pdf}
}

@article{polakow_relating_1999,
	title = {Relating {Natural} {Deduction} and {Sequent} {Calculus} for {Intuitionistic} {Non}-{Commutative} {Linear} {Logic}},
	volume = {20},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066104800884},
	doi = {http://dx.doi.org/10.1016/S1571-0661(04)80088-4},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Polakow, Jeff and Pfenning, Frank},
	year = {1999},
	pages = {449 -- 466},
	file = {Polakow_Pfenning_1999_Relating Natural Deduction and Sequent Calculus for Intuitionistic.pdf:/home/michael/Dropbox/zotero-pdfs/P/Polakow_Pfenning_1999_Relating Natural Deduction and Sequent Calculus for Intuitionistic.pdf:application/pdf}
}

@article{polakow_properties_2000,
	title = {Properties of terms in continuation-passing style in an ordered logical framework},
	url = {http://repository.cmu.edu/compsci/1234/},
	urldate = {2017-08-09},
	author = {Polakow, Jeff and Pfenning, Frank},
	year = {2000},
	file = {Polakow_Pfenning_2000_Properties of terms in continuation-passing style in an ordered logical.pdf:/home/michael/Dropbox/zotero-pdfs/P/Polakow_Pfenning_2000_Properties of terms in continuation-passing style in an ordered logical.pdf:application/pdf}
}

@book{polakow_ordered_2001,
	title = {Ordered linear logic and applications},
	url = {http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/2001/CMU-CS-01-152.pdf},
	urldate = {2017-08-09},
	publisher = {Carnegie Mellon University Pittsburgh},
	author = {Polakow, Jeff and Pfenning, Frank},
	year = {2001},
	file = {Polakow_Pfenning_2001_Ordered linear logic and applications.pdf:/home/michael/Dropbox/zotero-pdfs/P/Polakow_Pfenning_2001_Ordered linear logic and applications.pdf:application/pdf}
}

@article{pfenning_judgmental_2001,
	title = {A judgmental reconstruction of modal logic},
	volume = {11},
	issn = {0960-1295, 1469-8072},
	url = {http://www.journals.cambridge.org/abstract_S0960129501003322},
	doi = {10.1017/S0960129501003322},
	language = {en},
	number = {04},
	urldate = {2017-08-09},
	journal = {Mathematical Structures in Computer Science},
	author = {Pfenning, Frank and Davies, Rowan},
	month = aug,
	year = {2001},
	file = {Pfenning_Davies_2001_A judgmental reconstruction of modal logic.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_Davies_2001_A judgmental reconstruction of modal logic.pdf:application/pdf}
}

@inproceedings{xi_eliminating_1998,
	address = {New York, NY, USA},
	series = {{PLDI} '98},
	title = {Eliminating {Array} {Bound} {Checking} {Through} {Dependent} {Types}},
	isbn = {978-0-89791-987-6},
	url = {http://doi.acm.org/10.1145/277650.277732},
	doi = {10.1145/277650.277732},
	abstract = {We present a type-based approach to eliminating array bound checking and list tag checking by conservatively extending Standard ML with a restricted form of dependent types. This enables the programmer to capture more invariants through types while type-checking remains decidable in theory and can still be performed efficiently in practice. We illustrate our approach through concrete examples and present the result of our preliminary experiments which support support the feasibility and effectiveness of our approach.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1998 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Xi, Hongwei and Pfenning, Frank},
	year = {1998},
	pages = {249--257},
	file = {Xi_Pfenning_1998_Eliminating Array Bound Checking Through Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xi_Pfenning_1998_Eliminating Array Bound Checking Through Dependent Types.pdf:application/pdf}
}

@inproceedings{minamide_functional_1998,
	address = {New York, NY, USA},
	series = {{POPL} '98},
	title = {A {Functional} {Representation} of {Data} {Structures} with a {Hole}},
	isbn = {978-0-89791-979-1},
	url = {http://doi.acm.org/10.1145/268946.268953},
	doi = {10.1145/268946.268953},
	abstract = {Data structures with a hole, in other words data structures with an uninitialized field, are useful to write efficient programs: they enable us to construct functional data structures flexibly and write functions such as append and map as tail recursive functions. In this paper we present an approach to introducing data structures with a hole into call-by-value functional programming languages like ML. Data structures with a hole are formalized as a new form of ¿-abstraction called hole abstraction. The novel features of hole abstraction are that expressions inside hole abstraction are evaluated and application is implemented by destructive update of a hole. We present a simply typed call-by-value ¿-calculus extended with hole abstractions. Then we show a compilation method of hole abstraction and prove correctness of the compilation.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Minamide, Yasuhiko},
	year = {1998},
	pages = {75--84},
	file = {Minamide_1998_A Functional Representation of Data Structures with a Hole.pdf:/home/michael/Dropbox/zotero-pdfs/M/Minamide_1998_A Functional Representation of Data Structures with a Hole.pdf:application/pdf}
}

@article{chirimar_reference_1996,
	title = {Reference counting as a computational interpretation of linear logic},
	volume = {6},
	doi = {10.1017/S0956796800001660},
	number = {2},
	journal = {Journal of Functional Programming},
	author = {Chirimar, Jawahar and Gunter, Carl A. and Riecke, Jon G.},
	year = {1996},
	pages = {195--244},
	file = {Chirimar et al_1996_Reference counting as a computational interpretation of linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chirimar et al_1996_Reference counting as a computational interpretation of linear logic.pdf:application/pdf}
}

@misc{igarashi_garbage_2000,
	title = {Garbage {Collection} {Based} on a {Linear} {Type} {System}},
	url = {http://reports-archive.adm.cs.cmu.edu/anon/anon/usr0/ftp/home/ftp/2000/CMU-CS-00-161F.pdf},
	urldate = {2017-08-09},
	author = {Igarashi, Atsushi and Kobayashi, Naoki},
	year = {2000},
	file = {Igarashi_Kobayashi_2000_Garbage Collection Based on a Linear Type System.pdf:/home/michael/Dropbox/zotero-pdfs/I/Igarashi_Kobayashi_2000_Garbage Collection Based on a Linear Type System.pdf:application/pdf}
}

@inproceedings{kobayashi_quasi-linear_1999,
	address = {New York, NY, USA},
	series = {{POPL} '99},
	title = {Quasi-linear {Types}},
	isbn = {978-1-58113-095-9},
	url = {http://doi.acm.org/10.1145/292540.292546},
	doi = {10.1145/292540.292546},
	abstract = {Linear types (types of values that can be used just once) have been drawing a great deal of attention because they are useful for memory management, in-place update of data structures, etc.: an obvious advantage is that a value of a linear type can be immediately deallocated after being used. However, the linear types have not been applied so widely in practice, probably because linear values (values of linear types) in the traditional sense do not so often appear in actual programs. In order to increase the applicability of linear types, we relax the condition of linearity by extending the types with information on an evaluation order and simple dataflow information. The extended type system, called a quasi-linear type system, is formalized and its correctness is proved. We have implemented a prototype type inference system for the core-ML that can automatically find out which value is linear in the relaxed sense. Promising results were obtained from preliminary experiments with the prototype system.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kobayashi, Naoki},
	year = {1999},
	pages = {29--42},
	file = {Kobayashi_1999_Quasi-linear Types.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kobayashi_1999_Quasi-linear Types.pdf:application/pdf}
}

@article{turner_operational_1999,
	title = {Operational interpretations of linear logic},
	volume = {227},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397599000547},
	doi = {http://dx.doi.org/10.1016/S0304-3975(99)00054-7},
	number = {1},
	journal = {Theoretical Computer Science},
	author = {Turner, David N. and Wadler, Philip},
	year = {1999},
	keywords = {Memory management},
	pages = {231 -- 248},
	file = {Turner_Wadler_1999_Operational interpretations of linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turner_Wadler_1999_Operational interpretations of linear logic.pdf:application/pdf}
}

@techreport{petersen_type_2002,
	title = {A type theory for memory allocation and data layout [extended version]},
	url = {http://dl.acm.org/citation.cfm?id=604147},
	urldate = {2017-08-09},
	institution = {ACM},
	author = {Petersen, Leaf and Harper, Robert and Crary, Karl and Pfenning, Frank},
	year = {2002},
	pages = {172--184},
	file = {Petersen et al_2002_A type theory for memory allocation and data layout [extended version].pdf:/home/michael/Dropbox/zotero-pdfs/P/Petersen et al_2002_A type theory for memory allocation and data layout [extended version].pdf:application/pdf}
}

@inproceedings{aiken_better_1995,
	address = {New York, NY, USA},
	series = {{PLDI} '95},
	title = {Better {Static} {Memory} {Management}: {Improving} {Region}-based {Analysis} of {Higher}-order {Languages}},
	isbn = {978-0-89791-697-4},
	shorttitle = {Better {Static} {Memory} {Management}},
	url = {http://doi.acm.org/10.1145/207110.207137},
	doi = {10.1145/207110.207137},
	abstract = {Static memory management replaces runtime garbage collection with compile-time annotations that make all memory allocation and deallocation explicit in a program. We improve upon the Tofte/Talpin region-based scheme for compile-time memory management[TT94]. In the Tofte/Talpin approach, all values, including closures, are stored in regions. Region lifetimes coincide with lexical scope, thus forming a runtime stack of regions and eliminating the need for garbage collection. We relax the requirement that region lifetimes be lexical. Rather, regions are allocated late and deallocated as early as possible by explicit memory operations. The placement of allocation and deallocation annotations is determined by solving a system of constraints that expresses all possible annotations. Experiments show that our approach reduces memory requirements significantly, in some cases asymptotically.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1995 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Aiken, Alexander and Fähndrich, Manuel and Levien, Raph},
	year = {1995},
	pages = {174--185},
	file = {Aiken et al_1995_Better Static Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/A/Aiken et al_1995_Better Static Memory Management - Improving Region-based Analysis of.pdf:application/pdf}
}

@inproceedings{jespersen_session_2015,
	address = {New York, NY, USA},
	series = {{WGP} 2015},
	title = {Session {Types} for {Rust}},
	isbn = {978-1-4503-3810-3},
	url = {http://doi.acm.org/10.1145/2808098.2808100},
	doi = {10.1145/2808098.2808100},
	abstract = {We present a library for specifying session types implemented in Rust, and discuss practical use cases through examples and demonstrate how session types may be used in a large-scale application. Specifically we adapt parts of the ad-hoc communication patterns in the Servo browser engine to use session typed channels. Session types provide a protocol abstraction, expanding on traditional typed communication channels, to ensure that communication takes place according to a specified protocol. Thus, the library allows us to provide compile-time guarantees of adherence to a specific protocol without incurring significant run-time penalties.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 11th {ACM} {SIGPLAN} {Workshop} on {Generic} {Programming}},
	publisher = {ACM},
	author = {Jespersen, Thomas Bracht Laumann and Munksgaard, Philip and Larsen, Ken Friis},
	year = {2015},
	keywords = {concurrency, generic types, Rust, Session types, RUST},
	pages = {13--22},
	file = {Jespersen et al_2015_Session Types for Rust.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jespersen et al_2015_Session Types for Rust.pdf:application/pdf;Jespersen et al_2015_Session Types for Rust.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jespersen et al_2015_Session Types for Rust.pdf:application/pdf}
}

@inproceedings{wadler_how_1989,
	address = {New York, NY, USA},
	series = {{POPL} '89},
	title = {How to {Make} {Ad}-hoc {Polymorphism} {Less} {Ad} {Hoc}},
	isbn = {978-0-89791-294-5},
	url = {http://doi.acm.org/10.1145/75277.75283},
	doi = {10.1145/75277.75283},
	abstract = {This paper presents type classes, a new approach to ad-hoc polymorphism. Type classes permit overloading of arithmetic operators such as multiplication, and generalise the “eqtype variables” of Standard ML. Type classes extend the Hindley/Milner polymorphic type system, and provide a new approach to issues that arise in object-oriented programming, bounded type quantification, and abstract data types. This paper provides an informal introduction to type classes, and defines them formally by means of type inference rules.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Wadler, P. and Blott, S.},
	year = {1989},
	keywords = {TYPES},
	pages = {60--76},
	file = {Wadler_Blott_1989_How to Make Ad-hoc Polymorphism Less Ad Hoc.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_Blott_1989_How to Make Ad-hoc Polymorphism Less Ad Hoc.pdf:application/pdf}
}

@incollection{floyd_assigning_1993,
	title = {Assigning meanings to programs},
	url = {https://link.springer.com/chapter/10.1007/978-94-011-1793-7_4},
	urldate = {2017-08-09},
	booktitle = {Program {Verification}},
	publisher = {Springer},
	author = {Floyd, Robert W.},
	year = {1993},
	pages = {65--81},
	file = {Floyd_1993_Assigning meanings to programs.pdf:/home/michael/Dropbox/zotero-pdfs/F/Floyd_1993_Assigning meanings to programs.pdf:application/pdf}
}

@inproceedings{xi_dependently_2001,
	address = {New York, NY, USA},
	series = {{ICFP} '01},
	title = {A {Dependently} {Typed} {Assembly} {Language}},
	isbn = {978-1-58113-415-5},
	url = {http://doi.acm.org/10.1145/507635.507657},
	doi = {10.1145/507635.507657},
	abstract = {We present a dependently typed assembly language (DTAL) in which the type system supports the use of a restricted form of dependent types, reaping some benefits of dependent types at the assembly level. DTAL improves upon TAL , enabling certain important compiler optimizations such as run-time array bound check elimination and tag check elimination. Also, DTAL formally addresses the issue of representing sum types at assembly level, making it suitable for handling not only datatypes in ML but also dependent datatypes in Dependent ML (DML).},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Sixth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Xi, Hongwei and Harper, Robert},
	year = {2001},
	keywords = {TO-READ, typed assembly},
	pages = {169--180},
	file = {Xi_Harper_2001_A Dependently Typed Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xi_Harper_2001_A Dependently Typed Assembly Language.pdf:application/pdf}
}

@techreport{scott_outline_1970,
	title = {Outline of a {Mathematical} {Theory} of {Computation}},
	url = {http://ropas.snu.ac.kr/~kwang/520/readings/sco70.pdf},
	number = {PRG02},
	urldate = {2017-08-09},
	institution = {OUCL},
	author = {Scott, Dana},
	year = {1970},
	file = {Scott_1970_Outline of a Mathematical Theory of Computation.pdf:/home/michael/Dropbox/zotero-pdfs/S/Scott_1970_Outline of a Mathematical Theory of Computation.pdf:application/pdf}
}

@article{mccarthy_recursive_1960,
	title = {Recursive {Functions} of {Symbolic} {Expressions} and {Their} {Computation} by {Machine}, {Part} {I}},
	volume = {3},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/367177.367199},
	doi = {10.1145/367177.367199},
	number = {4},
	urldate = {2017-08-09},
	journal = {Commun. ACM},
	author = {McCarthy, John},
	month = apr,
	year = {1960},
	keywords = {classic-PL},
	pages = {184--195},
	file = {McCarthy_1960_Recursive Functions of Symbolic Expressions and Their Computation by Machine,.pdf:/home/michael/Dropbox/zotero-pdfs/M/McCarthy_1960_Recursive Functions of Symbolic Expressions and Their Computation by Machine,.pdf:application/pdf}
}

@inproceedings{toro_customizable_2015,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2015},
	title = {Customizable {Gradual} {Polymorphic} {Effects} for {Scala}},
	isbn = {978-1-4503-3689-5},
	url = {http://doi.acm.org/10.1145/2814270.2814315},
	doi = {10.1145/2814270.2814315},
	abstract = {Despite their obvious advantages in terms of static reasoning, the adoption of effect systems is still rather limited in practice. Recent advances such as generic effect systems, lightweight effect polymorphism, and gradual effect checking, all represent promising steps towards making effect systems suitable for widespread use. However, no existing system combines these approaches: the theory of gradual polymorphic effects has not been developed, and there are no implementations of gradual effect checking. In addition, a limiting factor in the adoption of effect systems is their unsuitability for localized and customized effect disciplines. This paper addresses these issues by presenting the first implementation of gradual effect checking, for Scala, which supports both effect polymorphism and a domain-specific language called Effscript to declaratively define and customize effect disciplines. We report on the theory, implementation, and practical application of the system.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Toro, Matías and Tanter, Éric},
	year = {2015},
	keywords = {effect polymorphism, effscript, gradual typing, Scala, Type-and-effect systems},
	pages = {935--953},
	file = {Toro_Tanter_2015_Customizable Gradual Polymorphic Effects for Scala.pdf:/home/michael/Dropbox/zotero-pdfs/T/Toro_Tanter_2015_Customizable Gradual Polymorphic Effects for Scala.pdf:application/pdf}
}

@inproceedings{alur_synthesis_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Synthesis {Through} {Unification}},
	isbn = {978-3-319-21667-6 978-3-319-21668-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-21668-3_10},
	doi = {10.1007/978-3-319-21668-3_10},
	abstract = {Given a specification and a set of candidate programs (program space), the program synthesis problem is to find a candidate program that satisfies the specification. We present the synthesis through unification (STUN) approach, which is an extension of the counter-example guided inductive synthesis (CEGIS) approach. In CEGIS, the synthesizer maintains a subset S of inputs and a candidate program 𝙿𝚛𝚘𝚐Prog{\textbackslash}mathtt \{Prog\} that is correct for S. The synthesizer repeatedly checks if there exists a counterexample input c such that the execution of 𝙿𝚛𝚘𝚐Prog{\textbackslash}mathtt \{Prog\} is incorrect on c. If so, the synthesizer enlarges S to include c, and picks a program from the program space that is correct for the new set S.The STUN approach extends CEGIS with the idea that given a program 𝙿𝚛𝚘𝚐Prog{\textbackslash}mathtt \{Prog\} that is correct for a subset of inputs, the synthesizer can try to find a program 𝙿𝚛𝚘𝚐′Prog′{\textbackslash}mathtt \{Prog\}' that is correct for the rest of the inputs. If 𝙿𝚛𝚘𝚐Prog{\textbackslash}mathtt \{Prog\} and 𝙿𝚛𝚘𝚐′Prog′{\textbackslash}mathtt \{Prog\}' can be unified into a program in the program space, then a solution has been found. We present a generic synthesis procedure based on the STUN approach and specialize it for three different domains by providing the appropriate unification operators. We implemented these specializations in prototype tools, and we show that our tools often performs significantly better on standard benchmarks than a tool based on a pure CEGIS approach.},
	language = {en},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Cham},
	author = {Alur, Rajeev and Černý, Pavol and Radhakrishna, Arjun},
	month = jul,
	year = {2015},
	pages = {163--179},
	file = {Alur et al_2015_Synthesis Through Unification.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alur et al_2015_Synthesis Through Unification.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/4D7D9KKK/978-3-319-21668-3_10.html:text/html}
}

@inproceedings{terei_safe_2012,
	address = {New York, NY, USA},
	series = {Haskell '12},
	title = {Safe {Haskell}},
	isbn = {978-1-4503-1574-6},
	url = {http://doi.acm.org/10.1145/2364506.2364524},
	doi = {10.1145/2364506.2364524},
	abstract = {Though Haskell is predominantly type-safe, implementations contain a few loopholes through which code can bypass typing and module encapsulation. This paper presents Safe Haskell, a language extension that closes these loopholes. Safe Haskell makes it possible to confine and safely execute untrusted, possibly malicious code. By strictly enforcing types, Safe Haskell allows a variety of different policies from API sandboxing to information-flow control to be implemented easily as monads. Safe Haskell is aimed to be as unobtrusive as possible. It enforces properties that programmers tend to meet already by convention. We describe the design of Safe Haskell and an implementation (currently shipping with GHC) that infers safety for code that lies in a safe subset of the language. We use Safe Haskell to implement an online Haskell interpreter that can securely execute arbitrary untrusted code with no overhead. The use of Safe Haskell greatly simplifies this task and allows the use of a large body of existing code and tools.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2012 {Haskell} {Symposium}},
	publisher = {ACM},
	author = {Terei, David and Marlow, Simon and Peyton Jones, Simon and Mazières, David},
	year = {2012},
	keywords = {haskell, security, type safety},
	pages = {137--148},
	file = {Terei et al_2012_Safe Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/T/Terei et al_2012_Safe Haskell.pdf:application/pdf}
}

@book{milner_definition_1997,
	address = {Cambridge, Mass},
	title = {The definition of standard {ML}: revised},
	isbn = {978-0-262-63181-5},
	shorttitle = {The definition of standard {ML}},
	publisher = {MIT Press},
	editor = {Milner, R.},
	year = {1997},
	keywords = {ML (Computer program language)},
	file = {Milner_1997_The definition of standard ML - revised.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_1997_The definition of standard ML - revised.pdf:application/pdf}
}

@inproceedings{prasad_prudent_2016,
	address = {New York, NY, USA},
	series = {{ASPLOS} '16},
	title = {Prudent {Memory} {Reclamation} in {Procrastination}-{Based} {Synchronization}},
	isbn = {978-1-4503-4091-5},
	url = {http://doi.acm.org/10.1145/2872362.2872405},
	doi = {10.1145/2872362.2872405},
	abstract = {Procrastination is the fundamental technique used in synchronization mechanisms such as Read-Copy-Update (RCU) where writers, in order to synchronize with readers, defer the freeing of an object until there are no readers referring to the object. The synchronization mechanism determines when the deferred object is safe to reclaim and when it is actually reclaimed. Hence, such memory reclamations are completely oblivious of the memory allocator state. This induces poor memory allocator performance, for instance, when the reclamations are ill-timed. Furthermore, deferred objects provide hints about the future that inform memory regions that are about to be freed. Although useful, hints are not exploited as deferred objects are not visible to memory allocators. We introduce Prudence, a dynamic memory allocator, that is tightly integrated with the synchronization mechanism to ensure visibility of deferred objects to the memory allocator. Such an integration enables Prudence to (i) identify the safe time to reclaim deferred objects' memory, (ii) have an inclusive view of the allocated, free and about-to-be-freed objects, and (iii) exploit optimizations based on the hints about the future during important state transitions. Our evaluation in the Linux kernel shows that Prudence integrated with RCU performs 3.9X to 28X better in micro-benchmarks compared to SLUB, a recent memory allocator in the Linux kernel. It also improves the overall performance perceptibly (4\%-18\%) for a mix of widely used synthetic and application benchmarks. Further, it performs better (up to 98\%) in terms of object hits in caches, object cache churns, slab churns, peak memory usage and total fragmentation, when compared with the SLUB allocator.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Prasad, Aravinda and Gopinath, K.},
	year = {2016},
	keywords = {dynamic memory allocator, memory reclamation, read-copy-update (RCU)},
	pages = {99--112},
	file = {Prasad_Gopinath_2016_Prudent Memory Reclamation in Procrastination-Based Synchronization.pdf:/home/michael/Dropbox/zotero-pdfs/P/Prasad_Gopinath_2016_Prudent Memory Reclamation in Procrastination-Based Synchronization.pdf:application/pdf}
}

@inproceedings{hardekopf_ant_2007,
	address = {New York, NY, USA},
	series = {{PLDI} '07},
	title = {The {Ant} and the {Grasshopper}: {Fast} and {Accurate} {Pointer} {Analysis} for {Millions} of {Lines} of {Code}},
	isbn = {978-1-59593-633-2},
	shorttitle = {The {Ant} and the {Grasshopper}},
	url = {http://doi.acm.org/10.1145/1250734.1250767},
	doi = {10.1145/1250734.1250767},
	abstract = {Pointer information is a prerequisite for most program analyses, and the quality of this information can greatly affect their precision and performance. Inclusion-based (i.e. Andersen-style) pointer analysis is an important point in the space of pointer analyses, offering a potential sweet-spot in the trade-off between precision and performance. However, current techniques for inclusion-based pointer analysis can have difficulties delivering on this potential. We introduce and evaluate two novel techniques for inclusion-based pointer analysis---one lazy, one eager1---that significantly improve upon the current state-of-the-art without impacting precision. These techniques focus on the problem of online cycle detection, a critical optimization for scaling such analyses. Using a suite of six open-source C programs, which range in size from 169K to 2.17M LOC, we compare our techniques against the three best inclusion-based analyses--described by Heintze and Tardieu [11], by Pearce et al. [21], and by Berndl et al. [4]. The combination of our two techniques results in an algorithm which is on average 3.2 xfaster than Heintze and Tardieu's algorithm, 6.4 xfaster than Pearce et al.'s algorithm, and 20.6 faster than Berndl et al.'s algorithm. We also investigate the use of different data structures to represent points-to sets, examining the impact on both performance and memory consumption. We compare a sparse-bitmap implementation used in the GCC compiler with a BDD-based implementation, and we find that the BDD implementation is on average 2x slower than using sparse bitmaps but uses 5.5x less memory.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 28th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Hardekopf, Ben and Lin, Calvin},
	year = {2007},
	keywords = {analysis, pointer},
	pages = {290--299},
	file = {Hardekopf_Lin_2007_The Ant and the Grasshopper - Fast and Accurate Pointer Analysis for Millions of.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hardekopf_Lin_2007_The Ant and the Grasshopper - Fast and Accurate Pointer Analysis for Millions of.pdf:application/pdf}
}

@book{barr_category_1990,
	title = {Category theory for computing science},
	volume = {1},
	url = {http://www.emis.ams.org/journals/TAC/reprints/articles/22/tr22.pdf},
	urldate = {2017-08-09},
	publisher = {Prentice Hall New York},
	author = {Barr, Michael and Wells, Charles},
	year = {1990},
	file = {Barr_Wells_1990_Category theory for computing science.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barr_Wells_1990_Category theory for computing science.pdf:application/pdf}
}

@inproceedings{wadler_taste_1993,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A taste of linear logic},
	isbn = {978-3-540-57182-7 978-3-540-47927-7},
	url = {https://link.springer.com/chapter/10.1007/3-540-57182-5_12},
	doi = {10.1007/3-540-57182-5_12},
	abstract = {This tutorial paper provides an introduction to intuitionistic logic and linear logic, and shows how they correspond to type systems for functional languages via the notion of ‘Propositions as Types”. The presentation of linear logic is simplified by basing it on the Logic of Unity. An application to the array update problem is briefly discussed.},
	language = {en},
	booktitle = {Mathematical {Foundations} of {Computer} {Science} 1993},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Wadler, Philip},
	month = aug,
	year = {1993},
	pages = {185--210},
	file = {Snapshot:/home/michael/Zotero/storage/W6RGT58L/3-540-57182-5_12.html:text/html;Wadler_1993_A taste of linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_1993_A taste of linear logic.pdf:application/pdf;wadler_a-taste-of-linear-logic_1993_mfcs.pdf:/home/michael/Zotero/storage/E7XM5MLV/wadler_a-taste-of-linear-logic_1993_mfcs.pdf:application/pdf}
}

@inproceedings{boston_probability_2015,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2015},
	title = {Probability {Type} {Inference} for {Flexible} {Approximate} {Programming}},
	isbn = {978-1-4503-3689-5},
	url = {http://doi.acm.org/10.1145/2814270.2814301},
	doi = {10.1145/2814270.2814301},
	abstract = {In approximate computing, programs gain efficiency by allowing occasional errors. Controlling the probabilistic effects of this approximation remains a key challenge. We propose a new approach where programmers use a type system to communicate high-level constraints on the degree of approximation. A combination of type inference, code specialization, and optional dynamic tracking makes the system expressive and convenient. The core type system captures the probability that each operation exhibits an error and bounds the probability that each expression deviates from its correct value. Solver-aided type inference lets the programmer specify the correctness probability on only some variables—program outputs, for example—and automatically fills in other types to meet these specifications. An optional dynamic type helps cope with complex run-time behavior where static approaches are insufficient. Together, these features interact to yield a high degree of programmer control while offering a strong soundness guarantee. We use existing approximate-computing benchmarks to show how our language, DECAF, maintains a low annotation burden. Our constraint-based approach can encode hardware details, such as finite degrees of reliability, so we also use DECAF to examine implications for approximate hardware design. We find that multi-level architectures can offer advantages over simpler two-level machines and that solver-aided optimization improves efficiency.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Boston, Brett and Sampson, Adrian and Grossman, Dan and Ceze, Luis},
	year = {2015},
	keywords = {approximate computing, type inference},
	pages = {470--487},
	file = {Boston et al_2015_Probability Type Inference for Flexible Approximate Programming.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boston et al_2015_Probability Type Inference for Flexible Approximate Programming.pdf:application/pdf}
}

@inproceedings{dhawan_architectural_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {Architectural {Support} for {Software}-{Defined} {Metadata} {Processing}},
	isbn = {978-1-4503-2835-7},
	url = {http://doi.acm.org/10.1145/2694344.2694383},
	doi = {10.1145/2694344.2694383},
	abstract = {Optimized hardware for propagating and checking software-programmable metadata tags can achieve low runtime overhead. We generalize prior work on hardware tagging by considering a generic architecture that supports software-defined policies over metadata of arbitrary size and complexity; we introduce several novel microarchitectural optimizations that keep the overhead of this rich processing low. Our model thus achieves the efficiency of previous hardware-based approaches with the flexibility of the software-based ones. We demonstrate this by using it to enforce four diverse safety and security policies---spatial and temporal memory safety, taint tracking, control-flow integrity, and code and data separation---plus a composite policy that enforces all of them simultaneously. Experiments on SPEC CPU2006 benchmarks with a PUMP-enhanced RISC processor show modest impact on runtime (typically under 10\%) and power ceiling (less than 10\%), in return for some increase in energy usage (typically under 60\%) and area for on-chip memory structures (110\%).},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Dhawan, Udit and Hritcu, Catalin and Rubin, Raphael and Vasilakis, Nikos and Chiricescu, Silviu and Smith, Jonathan M. and Knight, Jr., Thomas F. and Pierce, Benjamin C. and DeHon, Andre},
	year = {2015},
	keywords = {security, CFI, memory safety, metadata, tagged architecture, taint tracking},
	pages = {487--502},
	file = {Dhawan et al_2015_Architectural Support for Software-Defined Metadata Processing.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dhawan et al_2015_Architectural Support for Software-Defined Metadata Processing.pdf:application/pdf}
}

@article{hudak_gentle_1992,
	title = {A gentle introduction to {Haskell}},
	volume = {27},
	url = {http://dl.acm.org/citation.cfm?id=130698},
	number = {5},
	urldate = {2017-08-09},
	journal = {ACM Sigplan Notices},
	author = {Hudak, Paul and Fasel, Joseph H.},
	year = {1992},
	pages = {1--52},
	file = {Hudak_Fasel_1992_A gentle introduction to Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hudak_Fasel_1992_A gentle introduction to Haskell.pdf:application/pdf}
}

@article{swamy_safe_2006,
	title = {Safe manual memory management in {Cyclone}},
	volume = {62},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642306000785},
	number = {2},
	urldate = {2017-08-09},
	journal = {Science of Computer Programming},
	author = {Swamy, Nikhil and Hicks, Michael and Morrisett, Greg and Grossman, Dan and Jim, Trevor},
	year = {2006},
	keywords = {TYPES},
	pages = {122--144},
	file = {Swamy et al_2006_Safe manual memory management in Cyclone.pdf:/home/michael/Dropbox/zotero-pdfs/S/Swamy et al_2006_Safe manual memory management in Cyclone.pdf:application/pdf}
}

@article{lampson_note_1973,
	title = {A {Note} on the {Confinement} {Problem}},
	volume = {16},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/362375.362389},
	doi = {10.1145/362375.362389},
	abstract = {onfining a program during its execution so that it cannot transmit information to any other program except its caller. A set of examples attempts to stake out the boundaries of the problem. Necessary conditions for a solution are stated and informally justified.},
	number = {10},
	urldate = {2017-08-09},
	journal = {Commun. ACM},
	author = {Lampson, Butler W.},
	month = oct,
	year = {1973},
	keywords = {security, confinement, leakage of data, privacy, proprietary program, protection},
	pages = {613--615},
	file = {Lampson_1973_A Note on the Confinement Problem.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lampson_1973_A Note on the Confinement Problem.pdf:application/pdf}
}

@incollection{cousot_patrick_semantic_1981,
	title = {Semantic {Foundations} of {Program} {Analysis}},
	url = {http://cs.nyu.edu/~pcousot/publications.www/Cousot-81-PFA-ch10-p303-342.pdf},
	abstract = {A program defines a dynamic discrete system that is a transition relation on states. In section 4, we set-up general mathematical methods useful in the task of analyzing the behavior of dynamic discrete systems. In order to make this mathematically demanding sections self-contained, lattice-theoretical theorems on fixed points of isotone or continuous maps are first introduced in a separate subsection. The main result of section 4 shows that the predicates characterizing the descendants of the entry states, the ascendants of the exit states, the states which lead to an error, and the states which cause the system to diverge are the least or greatest solution to forward or backward fixed point equations. This result is completed by the proof that whenever a forward equation (corresponding to postconditions) is needed, a backward equation (corresponding to preconditions) can be used instead, and vice-versa. Finally we show that when a set of states of the dynamic discrete system is partitioned, the forward and backward equation can be decomposed into a system of equations. Numerous examples of applications are given which provide for a very concise presentation and justification of classical or innovative program proving methods. Section 5 tailors the general mathematical techniques previously set up for analyzing the behavior of a deterministic discrete dynamic system to suit the particular case when the system is a program. Two main theorems make explicit the syntactic construction rules for obtaining the systems of semantic backward or forward equations from the text of a program. The facts that the extreme fixed points of these systems of semantic equations can lead to complete information about program behavior and that the backward and forward approaches are equivalent are illustrated on the simple introductory example.
In the second part we briefly survey our joint work with Radhia Cousot on the automatic synthesis of approximate invariant assertions for programs. Because of well-known insolvability problems, the semantics equations which have been used in section 5 for program analysis cannot be algorithmically solved. hence we must limit ourselves to constructive methods which automatically compute approximate solutions? Such approximate information about the program behavior is often useful, e.g., in program verification systems, program debugging systems, optimizing compilers, etc. Approximate solutions to the semantic equations can be obtained by first simplifying these equations and next solving the simplified equations associated with the program text, using any chaotic iteration technique. In section 6.2 we show that when the exact solution to the simplified equations is obtained only after an infinite number of iteration steps, the convergence of the iterates can be sped up using an extrapolation technique based on a widening or narrowing operator. A hierarchy of examples illustrates the approximate program analysis method.},
	urldate = {2017-08-09},
	booktitle = {Program {Flow} {Analysis}: {Theory} and {Applications}},
	publisher = {Prentice-Hall, Inc. Englewood Cliffs, New Jersey},
	author = {Cousot, Patrick},
	year = {1981},
	pages = {303--342},
	file = {Cousot, Patrick_1981_Semantic Foundations of Program Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cousot, Patrick_1981_Semantic Foundations of Program Analysis.pdf:application/pdf}
}

@inproceedings{tuch_os_2005,
	title = {{OS} {Verification}-{Now}!},
	url = {https://www.usenix.org/legacy/events/hotos05/final_papers/full_papers/tuch/tuch_html/},
	urldate = {2017-08-09},
	booktitle = {{HotOS}},
	author = {Tuch, Harvey and Klein, Gerwin and Heiser, Gernot},
	year = {2005},
	file = {Tuch et al_2005_OS Verification-Now!.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tuch et al_2005_OS Verification-Now!.pdf:application/pdf}
}

@article{rosendahl_introduction_1995,
	title = {Introduction to abstract interpretation},
	url = {https://pdfs.semanticscholar.org/a146/81d13a14b1255a9ef537982561eef61f4e46.pdf},
	urldate = {2017-08-09},
	journal = {Computer Science University of Copenhagen},
	author = {Rosendahl, Mads},
	year = {1995},
	file = {Rosendahl_1995_Introduction to abstract interpretation.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosendahl_1995_Introduction to abstract interpretation.pdf:application/pdf}
}

@article{moura_coroutines_2004,
	title = {Coroutines in lua},
	volume = {10},
	abstract = {Abstract: After a period of oblivion, a renewal of interest in coroutines is being observed. However, most current implementations of coroutine mechanisms are restricted, and motivated by particular uses. The convenience of providing true coroutines as a general control abstraction is disregarded. This paper presents and discusses the coroutine facilities provided by the language Lua, a full implementation of the concept of asymmetric coroutines. It also shows that this powerful construct supports easy and succint implementations of useful control behaviors.},
	journal = {Journal of Universal Computer Science},
	author = {Moura, Ana Lúcia De and Rodriguez, Noemi and Ierusalimschy, Roberto},
	year = {2004},
	pages = {925},
	file = {Citeseer - Snapshot:/home/michael/Zotero/storage/ENGE9TP2/summary.html:text/html;Moura et al_2004_Coroutines in lua.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moura et al_2004_Coroutines in lua.pdf:application/pdf}
}

@techreport{hoare_hints_1973,
	address = {Stanford, CA, USA},
	title = {Hints on {Programming} {Language} {Design}.},
	abstract = {This paper (based on a keynote address presented at the SIGACT/SIGPLAN Symposium on Principles of Programming Languages, Boston, October 1-3, 1973) presents the view that a programming language is a tool which should assist the programmer in the most difficult aspects of his art, namely program design, documentation, and debugging. It discusses the objective criteria for evaluating a language design, and illustrates them by application to language features of both high level languages and machine code programming. It concludes with an annotated reading list, recommended for all intending language designers.},
	institution = {Stanford University},
	author = {Hoare, C. A. R.},
	year = {1973},
	file = {Hoare_1973_Hints on Programming Language Design.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1973_Hints on Programming Language Design.pdf:application/pdf}
}

@article{shannon_communication_1949,
	title = {Communication theory of secrecy systems},
	volume = {28},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/j.1538-7305.1949.tb00928.x/full},
	number = {4},
	urldate = {2017-08-09},
	journal = {Bell Labs Technical Journal},
	author = {Shannon, Claude E.},
	year = {1949},
	pages = {656--715},
	file = {Shannon_1949_Communication theory of secrecy systems.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shannon_1949_Communication theory of secrecy systems.pdf:application/pdf}
}

@inproceedings{elphinstone_towards_2007,
	title = {Towards a {Practical}, {Verified} {Kernel}.},
	url = {https://www.usenix.org/legacy/events/hotos07/tech/full_papers/elphinstone/elphinstone_html/},
	urldate = {2017-08-09},
	booktitle = {{HotOS}},
	author = {Elphinstone, Kevin and Klein, Gerwin and Derrin, Philip and Roscoe, Timothy and Heiser, Gernot},
	year = {2007},
	file = {Elphinstone et al_2007_Towards a Practical, Verified Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elphinstone et al_2007_Towards a Practical, Verified Kernel.pdf:application/pdf}
}

@article{sewell_x86-tso:_2010,
	title = {X86-{TSO}: {A} {Rigorous} and {Usable} {Programmer}'s {Model} for x86 {Multiprocessors}},
	volume = {53},
	issn = {0001-0782},
	shorttitle = {X86-{TSO}},
	url = {http://doi.acm.org/10.1145/1785414.1785443},
	doi = {10.1145/1785414.1785443},
	abstract = {Exploiting the multiprocessors that have recently become ubiquitous requires high-performance and reliable concurrent systems code, for concurrent data structures, operating system kernels, synchronization libraries, compilers, and so on. However, concurrent programming, which is always challenging, is made much more so by two problems. First, real multiprocessors typically do not provide the sequentially consistent memory that is assumed by most work on semantics and verification. Instead, they have relaxed memory models, varying in subtle ways between processor families, in which different hardware threads may have only loosely consistent views of a shared memory. Second, the public vendor architectures, supposedly specifying what programmers can rely on, are often in ambiguous informal prose (a particularly poor medium for loose specifications), leading to widespread confusion. In this paper we focus on x86 processors. We review several recent Intel and AMD specifications, showing that all contain serious ambiguities, some are arguably too weak to program above, and some are simply unsound with respect to actual hardware. We present a new x86-TSO programmer's model that, to the best of our knowledge, suffers from none of these problems. It is mathematically precise (rigorously defined in HOL4) but can be presented as an intuitive abstract machine which should be widely accessible to working programmers. We illustrate how this can be used to reason about the correctness of a Linux spinlock implementation and describe a general theory of data-race freedom for x86-TSO. This should put x86 multiprocessor system building on a more solid foundation; it should also provide a basis for future work on verification of such systems.},
	number = {7},
	urldate = {2017-08-09},
	journal = {Commun. ACM},
	author = {Sewell, Peter and Sarkar, Susmit and Owens, Scott and Nardelli, Francesco Zappa and Myreen, Magnus O.},
	month = jul,
	year = {2010},
	pages = {89--97},
	file = {Sewell et al_2010_X86-TSO - A Rigorous and Usable Programmer's Model for x86 Multiprocessors.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sewell et al_2010_X86-TSO - A Rigorous and Usable Programmer's Model for x86 Multiprocessors.pdf:application/pdf}
}

@article{gay_linear_2010,
	title = {Linear type theory for asynchronous session types},
	volume = {20},
	issn = {1469-7653, 0956-7968},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/linear-type-theory-for-asynchronous-session-types/605DA26DDDE9B1CCD35D33D0D62DF20C},
	doi = {10.1017/S0956796809990268},
	abstract = {AbstractSession types support a type-theoretic formulation of structured patterns of communication, so that the communication behaviour of agents in a distributed system can be verified by static typechecking. Applications include network protocols, business processes and operating system services. In this paper we define a multithreaded functional language with session types, which unifies, simplifies and extends previous work. There are four main contributions. First is an operational semantics with buffered channels, instead of the synchronous communication of previous work. Second, we prove that the session type of a channel gives an upper bound on the necessary size of the buffer. Third, session types are manipulated by means of the standard structures of a linear type theory, rather than by means of new forms of typing judgement. Fourth, a notion of subtyping, including the standard subtyping relation for session types (imported into the functional setting), and a novel form of subtyping between standard and linear function types, which allows the typechecker to handle linear types conveniently. Our new approach significantly simplifies session types in the functional setting, clarifies their essential features and provides a secure foundation for language developments such as polymorphism and object-orientation.},
	number = {1},
	journal = {Journal of Functional Programming},
	author = {Gay, Simon J. and Vasconcelos, Vasco T.},
	month = jan,
	year = {2010},
	pages = {19--50},
	file = {Gay_Vasconcelos_2010_Linear type theory for asynchronous session types.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay_Vasconcelos_2010_Linear type theory for asynchronous session types.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/JSJ2DN5Q/605DA26DDDE9B1CCD35D33D0D62DF20C.html:text/html}
}

@inproceedings{backes_automatic_2009,
	title = {Automatic {Discovery} and {Quantification} of {Information} {Leaks}},
	doi = {10.1109/SP.2009.18},
	abstract = {Information-flow analysis is a powerful technique for reasoning about the sensitive information exposed by a program during its execution. We present the first automatic method for information-flow analysis that discovers what information is leaked and computes its comprehensive quantitative interpretation. The leaked information is characterized by an equivalence relation on secret artifacts, and is represented by a logical assertion over the corresponding program variables. Our measurement procedure computes the number of discovered equivalence classes and their sizes. This provides a basis for computing a set of quantitative properties, which includes all established information-theoretic measures in quantitative information-flow. Our method exploits an inherent connection between formal models of qualitative information-flow and program verification techniques. We provide an implementation of our method that builds upon existing tools for program verification and information-theoretic analysis. Our experimental evaluation indicates the practical applicability of the presented method.},
	booktitle = {2009 30th {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Backes, M. and Köpf, B. and Rybalchenko, A.},
	month = may,
	year = {2009},
	keywords = {Channel capacity, Communication channels, comprehensive quantitative interpretation, Data flow computing, Entropy, Information analysis, Information Flow, information leaks, Information security, Information theory, Information Theory, information-flow analysis, information-theoretic analysis, Privacy, Program Analysis, program verification techniques, reasoning about programs, security of data, Size measurement, Throughput},
	pages = {141--153},
	file = {Backes et al_2009_Automatic Discovery and Quantification of Information Leaks.pdf:/home/michael/Dropbox/zotero-pdfs/B/Backes et al_2009_Automatic Discovery and Quantification of Information Leaks.pdf:application/pdf;IEEE Xplore Abstract Record:/home/michael/Zotero/storage/K3MIBBYH/5207642.html:text/html}
}

@inproceedings{liang_monad_1995,
	address = {New York, NY, USA},
	series = {{POPL} '95},
	title = {Monad {Transformers} and {Modular} {Interpreters}},
	isbn = {978-0-89791-692-9},
	url = {http://doi.acm.org/10.1145/199448.199528},
	doi = {10.1145/199448.199528},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Liang, Sheng and Hudak, Paul and Jones, Mark},
	year = {1995},
	pages = {333--343},
	file = {Liang et al_1995_Monad Transformers and Modular Interpreters.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liang et al_1995_Monad Transformers and Modular Interpreters.pdf:application/pdf}
}

@article{borchert_hardening_2016,
	title = {Hardening an {L}4 {Microkernel} {Against} {Soft} {Errors} by {Aspect}-{Oriented} {Programming} and {Whole}-{Program} {Analysis}},
	volume = {49},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/2883591.2883600},
	doi = {10.1145/2883591.2883600},
	abstract = {Transient hardware faults in computer systems have become widespread as shrinking structures and low supply voltages reduce the amount of energy needed to trigger a fault. This paper describes the latest improvements of a software-based fault-tolerance mechanism called Generic Object Protection (GOP). It is based on Aspect-Orientied Programming in AspectC++ and has been used in a case study to harden the L4/Fiasco.OC microkernel. As a result, the improved GOP avoids 60\% of kernel failures at an acceptable overhead of 19\% code size and less than 1\% runtime. The GOP improvements use static whole-program analysis and have been implemented in a prototypical manner. As an outlook, the paper presents envisioned language extensions providing whole-program control-flow and data-flow analyses in future AspectC++ versions.},
	number = {2},
	urldate = {2017-08-09},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Borchert, Christoph and Spinczyk, Olaf},
	month = jan,
	year = {2016},
	pages = {37--43},
	file = {Borchert_Spinczyk_2016_Hardening an L4 Microkernel Against Soft Errors by Aspect-Oriented Programming.pdf:/home/michael/Dropbox/zotero-pdfs/B/Borchert_Spinczyk_2016_Hardening an L4 Microkernel Against Soft Errors by Aspect-Oriented Programming.pdf:application/pdf}
}

@article{madhavapeddy_unikernels:_2013,
	title = {Unikernels: {Rise} of the {Virtual} {Library} {Operating} {System}},
	volume = {11},
	issn = {1542-7730},
	shorttitle = {Unikernels},
	url = {http://doi.acm.org/10.1145/2557963.2566628},
	doi = {10.1145/2557963.2566628},
	abstract = {What if all the software layers in a virtual appliance were compiled within the same safe, high-level language framework?},
	number = {11},
	urldate = {2017-08-09},
	journal = {Queue},
	author = {Madhavapeddy, Anil and Scott, David J.},
	month = dec,
	year = {2013},
	pages = {30:30--30:44},
	file = {Madhavapeddy_Scott_2013_Unikernels - Rise of the Virtual Library Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madhavapeddy_Scott_2013_Unikernels - Rise of the Virtual Library Operating System.pdf:application/pdf}
}

@inproceedings{bacon_guava:_2000,
	address = {New York, NY, USA},
	series = {{OOPSLA} '00},
	title = {Guava: {A} {Dialect} of {Java} {Without} {Data} {Races}},
	isbn = {978-1-58113-200-7},
	shorttitle = {Guava},
	url = {http://doi.acm.org/10.1145/353171.353197},
	doi = {10.1145/353171.353197},
	abstract = {We introduce Guava, a dialect of Java whose rules statically guarantee that parallel threads access shared data only through synchronized methods. Our dialect distinguishes three categories of classes: (1) monitors, which may be referenced from multiple threads, but whose methods are accessed serially; (2) values, which cannot be referenced and therefore are never shared; and (3) objects, which can have multiple references but only from within one thread, and therefore do not need to be synchronized. Guava circumvents the problems associated with today's Java memory model, which must define behavior when concurrent threads access shared memory without synchronization.We present an overview of the syntax and the semantic rules of Guava. We discuss how implementations of Guava can exploit these rules to re-enable compiler optimizations inhibited by standard Java. We discuss how compilers for certain multiprocessor architectures can automatically generate certain programming idioms, such as double-check reads, as optimizations of serialized monitors.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Bacon, David F. and Strom, Robert E. and Tarafdar, Ashis},
	year = {2000},
	keywords = {data races, concurrency, Java, monitors, multiprocessors, programming languages, thread safety},
	pages = {382--400},
	file = {Bacon et al_2000_Guava - A Dialect of Java Without Data Races.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bacon et al_2000_Guava - A Dialect of Java Without Data Races.pdf:application/pdf}
}

@inproceedings{flanagan_type-based_2000,
	address = {New York, NY, USA},
	series = {{PLDI} '00},
	title = {Type-based {Race} {Detection} for {Java}},
	isbn = {978-1-58113-199-4},
	url = {http://doi.acm.org/10.1145/349299.349328},
	doi = {10.1145/349299.349328},
	abstract = {This paper presents a static race detection analysis for multithreaded Java programs. Our analysis is based on a formal type system that is capable of capturing many common synchronization patterns. These patterns include classes with internal synchronization, classes thatrequire client-side synchronization, and thread-local classes. Experience checking over 40,000 lines of Java code with the type system demonstrates that it is an effective approach for eliminating races conditions. On large examples, fewer than 20 additional type annotations per 1000 lines of code were required by the type checker, and we found a number of races in the standard Java libraries and other test programs.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2000 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Flanagan, Cormac and Freund, Stephen N.},
	year = {2000},
	pages = {219--232},
	file = {Flanagan_Freund_2000_Type-based Race Detection for Java.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flanagan_Freund_2000_Type-based Race Detection for Java.pdf:application/pdf}
}

@inproceedings{kedia_simple_2017,
	title = {Simple, fast, and safe manual memory management},
	url = {http://dl.acm.org/citation.cfm?id=3062376},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Kedia, Piyus and Costa, Manuel and Parkinson, Matthew and Vaswani, Kapil and Vytiniotis, Dimitrios and Blankstein, Aaron},
	year = {2017},
	pages = {233--247},
	file = {Kedia et al_2017_Simple, fast, and safe manual memory management.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kedia et al_2017_Simple, fast, and safe manual memory management.pdf:application/pdf}
}

@article{caballero_type_2016,
	title = {Type {Inference} on {Executables}},
	volume = {48},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2896499},
	doi = {10.1145/2896499},
	abstract = {In many applications, source code and debugging symbols of a target program are not available, and the only thing that we can access is the program executable. A fundamental challenge with executables is that, during compilation, critical information such as variables and types is lost. Given that typed variables provide fundamental semantics of a program, for the last 16 years, a large amount of research has been carried out on binary code type inference, a challenging task that aims to infer typed variables from executables (also referred to as binary code). In this article, we systematize the area of binary code type inference according to its most important dimensions: the applications that motivate its importance, the approaches used, the types that those approaches infer, the implementation of those approaches, and how the inference results are evaluated. We also discuss limitations, underdeveloped problems and open challenges, and propose further applications.},
	number = {4},
	urldate = {2017-08-09},
	journal = {ACM Comput. Surv.},
	author = {Caballero, Juan and Lin, Zhiqiang},
	month = may,
	year = {2016},
	keywords = {binary code analysis, program executables, Type inference},
	pages = {65:1--65:35},
	file = {Caballero_Lin_2016_Type Inference on Executables.pdf:/home/michael/Dropbox/zotero-pdfs/C/Caballero_Lin_2016_Type Inference on Executables.pdf:application/pdf}
}

@inproceedings{wang_type-preserving_2001,
	address = {New York, NY, USA},
	series = {{POPL} '01},
	title = {Type-preserving {Garbage} {Collectors}},
	isbn = {978-1-58113-336-3},
	url = {http://doi.acm.org/10.1145/360204.360218},
	doi = {10.1145/360204.360218},
	abstract = {By combining existing type systems with standard type-based compilation techniques, we describe how to write strongly typed programs that include a function that acts as a t racing garbage collector for the program. Since the garbage collector is an explicit function, we do not need to provide a t rusted garbage collector as a runtime service to manage memory.Since our language is strongly typed, the standard type soundness guarantee "Well typed programs do not go wrong" is extended to include the collector. Our type safety guarantee is non-trivial since not only does it guarantee the type safety of the garbage collector, but it guarantees that the collector preservers the type safety of the program being garbage collected. We describe the technique in detail and report performance measurements for a few microbench-marks as well as sketch the proofs of type soundness for our system.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 28th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Wang, Daniel C. and Appel, Andrew W.},
	year = {2001},
	pages = {166--178},
	file = {Wang_Appel_2001_Type-preserving Garbage Collectors.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang_Appel_2001_Type-preserving Garbage Collectors.pdf:application/pdf}
}

@inproceedings{walker_regions_2001,
	address = {New York, NY, USA},
	series = {{ICFP} '01},
	title = {On {Regions} and {Linear} {Types} ({Extended} {Abstract})},
	isbn = {978-1-58113-415-5},
	url = {http://doi.acm.org/10.1145/507635.507658},
	doi = {10.1145/507635.507658},
	abstract = {We explore how two different mechanisms for reasoning about state,
linear typing and the type, region and effect discipline,
complement one another in the design of a strongly typed functional
programming language. The basis for our language is a simple lambda
calculus containing first-class memory regions, which are
explicitly passed as arguments to functions, returned as results
and stored in user-defined data structures. In order to ensure
appropriate memory safety properties, we draw upon the literature
on linear type systems to help control access to and deallocation
of regions. In fact, we use two different interpretations of linear
types, one in which multiple-use values are freely copied and
discarded and one in which multiple-use values are explicitly
reference-counted, and show that both interpretations give rise to
interesting invariants for manipulating regions. We also explore
new programming paradigms that arise by mixing first-class regions
and conventional linear data structures.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Sixth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Walker, David and Watkins, Kevin},
	year = {2001},
	pages = {181--192},
	file = {Walker_Watkins_2001_On Regions and Linear Types (Extended Abstract).pdf:/home/michael/Dropbox/zotero-pdfs/W/Walker_Watkins_2001_On Regions and Linear Types (Extended Abstract).pdf:application/pdf}
}

@inproceedings{crary_typed_1999,
	address = {New York, NY, USA},
	series = {{POPL} '99},
	title = {Typed {Memory} {Management} in a {Calculus} of {Capabilities}},
	isbn = {978-1-58113-095-9},
	url = {http://doi.acm.org/10.1145/292540.292564},
	doi = {10.1145/292540.292564},
	abstract = {An increasing number of systems rely on programming language technology to ensure safety and security of low-level code. Unfortunately, these systems typically rely on a complex, trusted garbage collector. Region-based type systems provide an alternative to garbage collection by making memory management explicit but verifiably safe. However, it has not been clear how to use regions in low-level, type-safe code.We present a compiler intermediate language, called the Capability Calculus, that supports region-based memory management, enjoys a provably safe type system, and is straightforward to compile to a typed assembly language. Source languages may be compiled to our language using known region inference algorithms. Furthermore, region lifetimes need not be lexically scoped in our language, yet the language may be checked for safety without complex analyses. Finally, our soundness proof is relatively simple, employing only standard techniques.The central novelty is the use of static capabilities to specify the permissibility of various operations, such as memory access and deallocation. In order to ensure capabilities are relinquished properly, the type system tracks aliasing information using a form of bounded quantification.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Crary, Karl and Walker, David and Morrisett, Greg},
	year = {1999},
	pages = {262--275},
	file = {Crary et al_1999_Typed Memory Management in a Calculus of Capabilities.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary et al_1999_Typed Memory Management in a Calculus of Capabilities.pdf:application/pdf}
}

@inproceedings{monnier_principled_2001,
	address = {New York, NY, USA},
	series = {{PLDI} '01},
	title = {Principled {Scavenging}},
	isbn = {978-1-58113-414-8},
	url = {http://doi.acm.org/10.1145/378795.378817},
	doi = {10.1145/378795.378817},
	abstract = {Proof-carrying code and typed assembly languages aim to minimize the trusted computing base by directly certifying the actual machine code. Unfortunately, these systems cannot get rid of the dependency on a trusted garbage collector. Indeed, constructing a provably type-safe garbage collector is one of the major open problems in the area of certifying compilation.
Building on an idea by Wang and Appel, we present a series of new techniques for writing type-safe stop-and-copy garbage collectors. We show how to use intensional type analysis to capture the contract between the mutator and the collector, and how the same method can be applied to support forwarding pointers and generations. Unlike Wang and Appel (which requires whole-program analysis), our new framework directly supports higher-order funtions and is compatible with separate compilation; our collectors are written in provably type-safe languages with rigorous semantics and fully formalized soundness proofs.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2001 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Monnier, Stefan and Saha, Bratin and Shao, Zhong},
	year = {2001},
	pages = {81--91},
	file = {Monnier et al_2001_Principled Scavenging.pdf:/home/michael/Dropbox/zotero-pdfs/M/Monnier et al_2001_Principled Scavenging.pdf:application/pdf}
}

@article{mitchell_abstract_1988,
	title = {Abstract {Types} {Have} {Existential} {Type}},
	volume = {10},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/44501.45065},
	doi = {10.1145/44501.45065},
	abstract = {Abstract data type declarations appear in typed programming languages like Ada, Alphard, CLU and ML. This form of declaration binds a list of identifiers to a type with associated operations, a composite “value” we call a data algebra. We use a second-order typed lambda calculus SOL to show how data algebras may be given types, passed as parameters, and returned as results of function calls. In the process, we discuss the semantics of abstract data type declarations and review a connection between typed programming languages and constructive logic.},
	number = {3},
	urldate = {2017-08-09},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Mitchell, John C. and Plotkin, Gordon D.},
	month = jul,
	year = {1988},
	keywords = {classic-PL},
	pages = {470--502},
	file = {Mitchell_Plotkin_1988_Abstract Types Have Existential Type.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mitchell_Plotkin_1988_Abstract Types Have Existential Type.pdf:application/pdf}
}

@inproceedings{minamide_typed_1996,
	address = {New York, NY, USA},
	series = {{POPL} '96},
	title = {Typed {Closure} {Conversion}},
	isbn = {978-0-89791-769-8},
	url = {http://doi.acm.org/10.1145/237721.237791},
	doi = {10.1145/237721.237791},
	abstract = {Closure conversion is a program transformation used by compilers to separate code from data. Previous accounts of closure conversion use only untyped target languages. Recent studies show that translating to typed target languages is a useful methodology for building compilers, because a compiler can use the types to implement efficient data representations, calling conventions, and tag-free garbage collection. Furthermore, type-based translations facilitate security and debugging through automatic type checking, as well as correctness arguments through the method of logical relations.We present closure conversion as a type-directed, and type-preserving translation for both the simply-typed and the polymorphic ¿-calculus. Our translations are based on a simple "closures as objects" principle: higher-order functions are viewed as objects consisting of a single method (the code) and a single instance variable (the environment). In the simply-typed case, the Pierce-Turner model of object typing where objects are packages of existential type suffices. In the polymorphic case, more careful tracking of type sharing is required. We exploit a variant of the Harper-Lillibridge "translucent type" formalism to characterize the types of polymorphic closures.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 23rd {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Minamide, Yasuhiko and Morrisett, Greg and Harper, Robert},
	year = {1996},
	pages = {271--283},
	file = {Minamide et al_1996_Typed Closure Conversion.pdf:/home/michael/Dropbox/zotero-pdfs/M/Minamide et al_1996_Typed Closure Conversion.pdf:application/pdf}
}

@inproceedings{henglein_direct_2001,
	address = {New York, NY, USA},
	series = {{PPDP} '01},
	title = {A {Direct} {Approach} to {Control}-flow {Sensitive} {Region}-based {Memory} {Management}},
	isbn = {978-1-58113-388-2},
	url = {http://doi.acm.org/10.1145/773184.773203},
	doi = {10.1145/773184.773203},
	abstract = {Region-based memory management can be used to control dynamic memory allocations and deallocations safely and efficiently. Existing (direct-style) region systems that statically guarantee region safety---no dereferencing of dangling pointers---are based on refinements of Tofte and Talpin's seminal work on region inference for managing heap memory in stacks of regions.We present a unified Floyd-Hoare Logic inspired region type system for reasoning about and inferring region-based memory management, using a sublanguage of imperative region commands. Our system expresses and performs control-sensitive region management without requiring a stack discipline for allocating and deallocating regions. Furthermore, it captures storage mode analysis and late allocation/early deallocation analysis in a single, expressive, unified logical framework. Explicit region aliasing in combination with reference-counted regions provides flexible, context-sensitive early memory deallocation and simultaneously dispenses with the need for an integrated region alias analysis.In this paper we present the design of our region type system, illustrate its practical expressiveness, compare it to existing region analyses, demonstrate how this eliminates the need for previously required source code rewritings for good memory performance, and describe automatic inference of region commands that give consistently better (or at least equally good) memory performance as existing inference techniques.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 3rd {ACM} {SIGPLAN} {International} {Conference} on {Principles} and {Practice} of {Declarative} {Programming}},
	publisher = {ACM},
	author = {Henglein, Fritz and Makholm, Henning and Niss, Henning},
	year = {2001},
	pages = {175--186},
	file = {Henglein et al_2001_A Direct Approach to Control-flow Sensitive Region-based Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/H/Henglein et al_2001_A Direct Approach to Control-flow Sensitive Region-based Memory Management.pdf:application/pdf}
}

@inproceedings{gay_memory_1998,
	address = {New York, NY, USA},
	series = {{PLDI} '98},
	title = {Memory {Management} with {Explicit} {Regions}},
	isbn = {978-0-89791-987-6},
	url = {http://doi.acm.org/10.1145/277650.277748},
	doi = {10.1145/277650.277748},
	abstract = {Much research has been devoted to studies of and algorithms for memory management based on garbage collection or explicit allocation and deallocation. An alternative approach, region-based memory management, has been known for decades, but has not been well-studied. In a region-based system each allocation specifies a region, and memory is reclaimed by destroying a region, freeing all the storage allocated therein. We show that on a suite of allocation-intensive C programs, regions are competitive with malloc/free and sometimes substantially faster. We also show that regions support safe memory management with low overhead. Experience with our benchmarks suggests that modifying many existing programs to use regions is not difficult.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1998 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Gay, David and Aiken, Alex},
	year = {1998},
	pages = {313--323},
	file = {Gay_Aiken_1998_Memory Management with Explicit Regions.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay_Aiken_1998_Memory Management with Explicit Regions.pdf:application/pdf}
}

@inproceedings{evans_static_1996,
	address = {New York, NY, USA},
	series = {{PLDI} '96},
	title = {Static {Detection} of {Dynamic} {Memory} {Errors}},
	isbn = {978-0-89791-795-7},
	url = {http://doi.acm.org/10.1145/231379.231389},
	doi = {10.1145/231379.231389},
	abstract = {Many important classes of bugs result from invalid assumptions about the results of functions and the values of parameters and global variables. Using traditional methods, these bugs cannot be detected efficiently at compile-time, since detailed cross-procedural analyses would be required to determine the relevant assumptions. In this work, we introduce annotations to make certain assumptions explicit at interface points. An efficient static checking tool that exploits these annotations can detect a broad class of errors including misuses of null pointers, uses of dead storage, memory leaks, and dangerous aliasing. This technique has been used successfully to fix memory management problems in a large program.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1996 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Evans, David},
	year = {1996},
	pages = {44--53},
	file = {Evans_1996_Static Detection of Dynamic Memory Errors.pdf:/home/michael/Dropbox/zotero-pdfs/E/Evans_1996_Static Detection of Dynamic Memory Errors.pdf:application/pdf}
}

@inproceedings{marino_generic_2009,
	address = {New York, NY, USA},
	series = {{TLDI} '09},
	title = {A {Generic} {Type}-and-effect {System}},
	isbn = {978-1-60558-420-1},
	url = {http://doi.acm.org/10.1145/1481861.1481868},
	doi = {10.1145/1481861.1481868},
	abstract = {Type-and-effect systems are a natural approach for statically reasoning about a program's execution. They have been used to track a variety of computational effects, for example memory manipulation, exceptions, and locking. However, each type-and-effect system is typically implemented as its own monolithic type system that hard-codes a particular syntax of effects along with particular rules to track and control those effects. We present a generic type-and-effect system, which is parameterized by the syntax of effects to track and by two functions that together specify the effect discipline to be statically enforced. We describe how a standard form of type soundness is ensured by requiring these two functions to obey a few natural monotonicity requirements. We demonstrate that several effect systems from the literature can be viewed as instantiations of our generic type system. Finally, we describe the implementation of our type-and-effect system and mechanically checked type soundness proof in the Twelf proof assistant.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 4th {International} {Workshop} on {Types} in {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Marino, Daniel and Millstein, Todd},
	year = {2009},
	keywords = {systems, type-and-effect},
	pages = {39--50},
	file = {Marino_Millstein_2009_A Generic Type-and-effect System.pdf:/home/michael/Dropbox/zotero-pdfs/M/Marino_Millstein_2009_A Generic Type-and-effect System.pdf:application/pdf}
}

@article{tofte_region_1998,
	title = {A {Region} {Inference} {Algorithm}},
	volume = {20},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/291891.291894},
	doi = {10.1145/291891.291894},
	abstract = {Region Inference is a program analysis which infers lifetimes of values. It is targeted at a runtime model in which the store consists of a stack of regions and memory management predominantly consists of pushing and popping regions, rather than performing garbage collection. Region Inference has previously been specified by a set of inference rules which formalize when regions may be allocated and deallocated. This article presents an algorithm which implements the specification. We prove that the algorithm is sound with respect to the region inference rules and that it always terminates even though the region inference rules permit polymorphic recursion in regions. The algorithm is the result of several years of experiments with region inference algorithms in the ML Kit, a compiler  from Standard ML to assembly language.  We report on practical experience with the algorithm and give hints on how to implement it.},
	number = {4},
	urldate = {2017-08-09},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Tofte, Mads and Birkedal, Lars},
	month = jul,
	year = {1998},
	keywords = {regions, standard ML},
	pages = {724--767},
	file = {Tofte_Birkedal_1998_A Region Inference Algorithm.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte_Birkedal_1998_A Region Inference Algorithm.pdf:application/pdf}
}

@inproceedings{matsakis_rust_2014,
	address = {New York, NY, USA},
	series = {{HILT} '14},
	title = {The {Rust} {Language}},
	isbn = {978-1-4503-3217-0},
	url = {http://doi.acm.org/10.1145/2663171.2663188},
	doi = {10.1145/2663171.2663188},
	abstract = {Rust is a new programming language for developing reliable and efficient systems. It is designed to support concurrency and parallelism in building applications and libraries that take full advantage of modern hardware. Rust's static type system is safe1 and expressive and provides strong guarantees about isolation, concurrency, and memory safety. Rust also offers a clear performance model, making it easier to predict and reason about program efficiency. One important way it accomplishes this is by allowing fine-grained control over memory representations, with direct support for stack allocation and contiguous record storage. The language balances such controls with the absolute requirement for safety: Rust's type system and runtime guarantee the absence of data races, buffer overflows, stack overflows, and accesses to uninitialized or deallocated memory.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2014 {ACM} {SIGAda} {Annual} {Conference} on {High} {Integrity} {Language} {Technology}},
	publisher = {ACM},
	author = {Matsakis, Nicholas D. and Klock, II, Felix S.},
	year = {2014},
	keywords = {memory management, rust, affine type systems, systems programming},
	pages = {103--104},
	file = {Matsakis_Klock_2014_The Rust Language.pdf:/home/michael/Dropbox/zotero-pdfs/M/Matsakis_Klock_2014_The Rust Language.pdf:application/pdf}
}

@inproceedings{belay_dune:_2012,
	title = {Dune: {Safe} {User}-level {Access} to {Privileged} {CPU} {Features}.},
	volume = {12},
	shorttitle = {Dune},
	url = {https://www.usenix.org/system/files/conference/osdi12/osdi12-final-117.pdf},
	urldate = {2017-08-09},
	booktitle = {Osdi},
	author = {Belay, Adam and Bittau, Andrea and Mashtizadeh, Ali José and Terei, David and Mazières, David and Kozyrakis, Christos},
	year = {2012},
	pages = {335--348},
	file = {Belay et al_2012_Dune - Safe User-level Access to Privileged CPU Features.pdf:/home/michael/Dropbox/zotero-pdfs/B/Belay et al_2012_Dune - Safe User-level Access to Privileged CPU Features.pdf:application/pdf}
}

@inproceedings{vytiniotis_halo:_2013,
	address = {New York, NY, USA},
	series = {{POPL} '13},
	title = {{HALO}: {Haskell} to {Logic} {Through} {Denotational} {Semantics}},
	isbn = {978-1-4503-1832-7},
	shorttitle = {{HALO}},
	url = {http://doi.acm.org/10.1145/2429069.2429121},
	doi = {10.1145/2429069.2429121},
	abstract = {Even well-typed programs can go wrong in modern functional languages, by encountering a pattern-match failure, or simply returning the wrong answer. An increasingly-popular response is to allow programmers to write contracts that express semantic properties, such as crash-freedom or some useful post-condition. We study the static verification of such contracts. Our main contribution is a novel translation to first-order logic of both Haskell programs, and contracts written in Haskell, all justified by denotational semantics. This translation enables us to prove that functions satisfy their contracts using an off-the-shelf first-order logic theorem prover.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 40th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Claessen, Koen and Rosén, Dan},
	year = {2013},
	keywords = {first-order logic, static contract checking},
	pages = {431--442},
	file = {Vytiniotis et al_2013_HALO - Haskell to Logic Through Denotational Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/V/Vytiniotis et al_2013_HALO - Haskell to Logic Through Denotational Semantics.pdf:application/pdf}
}

@book{appel_compiling_1992,
	address = {Cambridge ; New York},
	title = {Compiling with continuations},
	isbn = {978-0-521-41695-5},
	publisher = {Cambridge University Press},
	author = {Appel, Andrew W.},
	year = {1992},
	keywords = {Compilers (Computer programs), Standard ML of New Jersey},
	file = {Appel_1992_Compiling with continuations.pdf:/home/michael/Dropbox/zotero-pdfs/A/Appel_1992_Compiling with continuations.pdf:application/pdf}
}

@inproceedings{klein_experience_2009,
	address = {New York, NY, USA},
	series = {{ICFP} '09},
	title = {Experience {Report}: {SeL}4: {Formally} {Verifying} a {High}-performance {Microkernel}},
	isbn = {978-1-60558-332-7},
	shorttitle = {Experience {Report}},
	url = {http://doi.acm.org/10.1145/1596550.1596566},
	doi = {10.1145/1596550.1596566},
	abstract = {We report on our experience using Haskell as an executable specification language in the formal verification of the seL4 microkernel. The verification connects an abstract operational specification in the theorem prover Isabelle/HOL to a C implementation of the microkernel. We describe how this project differs from other efforts, and examine the effect of using Haskell in a large-scale formal verification. The kernel comprises 8,700 lines of C code; the verification more than 150,000 lines of proof script.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 14th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Klein, Gerwin and Derrin, Philip and Elphinstone, Kevin},
	year = {2009},
	keywords = {haskell, Isabelle/HOL, microkernel, seL4},
	pages = {91--96},
	file = {Klein et al_2009_Experience Report - SeL4 - Formally Verifying a High-performance Microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_2009_Experience Report - SeL4 - Formally Verifying a High-performance Microkernel.pdf:application/pdf}
}

@inproceedings{lucia_intermittent_2017,
	title = {Intermittent {Computing}: {Challenges} and {Opportunities}},
	volume = {71},
	shorttitle = {Intermittent {Computing}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2017/7131/},
	urldate = {2017-08-09},
	booktitle = {{LIPIcs}-{Leibniz} {International} {Proceedings} in {Informatics}},
	publisher = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik},
	author = {Lucia, Brandon and Balaji, Vignesh and Colin, Alexei and Maeng, Kiwan and Ruppel, Emily},
	year = {2017},
	file = {Lucia et al_2017_Intermittent Computing - Challenges and Opportunities.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lucia et al_2017_Intermittent Computing - Challenges and Opportunities.pdf:application/pdf}
}

@inproceedings{chlipala_bedrock_2013,
	address = {New York, NY, USA},
	series = {{ICFP} '13},
	title = {The {Bedrock} {Structured} {Programming} {System}: {Combining} {Generative} {Metaprogramming} and {Hoare} {Logic} in an {Extensible} {Program} {Verifier}},
	isbn = {978-1-4503-2326-0},
	shorttitle = {The {Bedrock} {Structured} {Programming} {System}},
	url = {http://doi.acm.org/10.1145/2500365.2500592},
	doi = {10.1145/2500365.2500592},
	abstract = {We report on the design and implementation of an extensible programming language and its intrinsic support for formal verification. Our language is targeted at low-level programming of infrastructure like operating systems and runtime systems. It is based on a cross-platform core combining characteristics of assembly languages and compiler intermediate languages. From this foundation, we take literally the saying that C is a "macro assembly language": we introduce an expressive notion of certified low-level macros, sufficient to build up the usual features of C and beyond as macros with no special support in the core. Furthermore, our macros have integrated support for strongest postcondition calculation and verification condition generation, so that we can provide a high-productivity formal verification environment within Coq for programs composed from any combination of macros. Our macro interface is expressive enough to support features that low-level programs usually only access through external tools with no formal guarantees, such as declarative parsing or SQL-inspired querying. The abstraction level of these macros only imposes a compile-time cost, via the execution of functional Coq programs that compute programs in our intermediate language; but the run-time cost is not substantially greater than for more conventional C code. We describe our experiences constructing a full C-like language stack using macros, with some experiments on the verifiability and performance of individual programs running on that stack.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Chlipala, Adam},
	year = {2013},
	keywords = {functional programming, generative metaprogramming, interactive proof assistants, low-level programming languages},
	pages = {391--402},
	file = {Chlipala_2013_The Bedrock Structured Programming System - Combining Generative Metaprogramming.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chlipala_2013_The Bedrock Structured Programming System - Combining Generative Metaprogramming.pdf:application/pdf}
}

@inproceedings{sewell_sel4_2011,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{seL}4 {Enforces} {Integrity}},
	isbn = {978-3-642-22862-9 978-3-642-22863-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-22863-6_24},
	doi = {10.1007/978-3-642-22863-6_24},
	abstract = {We prove that the seL4 microkernel enforces two high-level access control properties: integrity and authority confinement. Integrity provides an upper bound on write operations. Authority confinement provides an upper bound on how authority may change. Apart from being a desirable security property in its own right, integrity can be used as a general framing property for the verification of user-level system composition. The proof is machine checked in Isabelle/HOL and the results hold via refinement for the C implementation of the kernel.},
	language = {en},
	booktitle = {Interactive {Theorem} {Proving}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Sewell, Thomas and Winwood, Simon and Gammie, Peter and Murray, Toby and Andronick, June and Klein, Gerwin},
	month = aug,
	year = {2011},
	pages = {325--340},
	file = {Sewell et al_2011_seL4 Enforces Integrity.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sewell et al_2011_seL4 Enforces Integrity.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/C6MJSPN6/978-3-642-22863-6_24.html:text/html}
}

@inproceedings{levin_policy/mechanism_1975,
	address = {New York, NY, USA},
	series = {{SOSP} '75},
	title = {Policy/{Mechanism} {Separation} in {Hydra}},
	url = {http://doi.acm.org/10.1145/800213.806531},
	doi = {10.1145/800213.806531},
	abstract = {The extent to which resource allocation policies are entrusted to user-level software determines in large part the degree of flexibility present in an operating system. In Hydra the determination to separate mechanism and policy is established as a basic design principle and is implemented by the construction of a kernel composed (almost) entirely of mechanisms. This paper presents three such mechanisms (scheduling, paging, protection) and examines how external policies which manipulate them may be constructed. It is shown that the policy decisions which remain embedded in the kernel exist for the sole purpose of arbitrating conflicting requests for physical resources, and then only to the extent of guaranteeing fairness.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Fifth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Levin, R. and Cohen, E. and Corwin, W. and Pollack, F. and Wulf, W.},
	year = {1975},
	keywords = {Mechanism, Operating system, Paging, Policy, Protection, Resource allocation, Scheduling},
	pages = {132--140},
	file = {Levin et al_1975_Policy-Mechanism Separation in Hydra.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levin et al_1975_Policy-Mechanism Separation in Hydra.pdf:application/pdf}
}

@inproceedings{sewell_translation_2013,
	address = {New York, NY, USA},
	series = {{PLDI} '13},
	title = {Translation {Validation} for a {Verified} {OS} {Kernel}},
	isbn = {978-1-4503-2014-6},
	url = {http://doi.acm.org/10.1145/2491956.2462183},
	doi = {10.1145/2491956.2462183},
	abstract = {We extend the existing formal verification of the seL4 operating system microkernel from 9500 lines of C source code to the binary level. We handle all functions that were part of the previous verification. Like the original verification, we currently omit the assembly routines and volatile accesses used to control system hardware. More generally, we present an approach for proving refinement between the formal semantics of a program on the C source level and its formal semantics on the binary level, thus checking the validity of compilation, including some optimisations, and linking, and extending static properties proved of the source code to the executable. We make use of recent improvements in SMT solvers to almost fully automate this process. We handle binaries generated by unmodified gcc 4.5.1 at optimisation level 1, and can handle most of seL4 even at optimisation level 2.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 34th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Sewell, Thomas Arthur Leck and Myreen, Magnus O. and Klein, Gerwin},
	year = {2013},
	keywords = {microkernel, seL4, binary verification},
	pages = {471--482},
	file = {Sewell et al_2013_Translation Validation for a Verified OS Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sewell et al_2013_Translation Validation for a Verified OS Kernel.pdf:application/pdf}
}

@inproceedings{appel_verified_2011,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Verified {Software} {Toolchain}},
	isbn = {978-3-642-19717-8 978-3-642-19718-5},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-19718-5_1},
	doi = {10.1007/978-3-642-19718-5_1},
	abstract = {The software toolchain includes static analyzers to check assertions about programs; optimizing compilers to translate programs to machine language; operating systems and libraries to supply context for programs. Our Verified Software Toolchain verifies with machine-checked proofs that the assertions claimed at the top of the toolchain really hold in the machine-language program, running in the operating-system context, on a weakly-consistent-shared-memory machine.Our verification approach is modular, in that proofs about operating systems or concurrency libraries are oblivious of the programming language or machine language, proofs about compilers are oblivious of the program logic used to verify static analyzers, and so on. The approach is scalable, in that each component is verified in the semantic idiom most natural for that component.Finally, the verification is foundational: the trusted base for proofs of observable properties of the machine-language program includes only the operational semantics of the machine language, not the source language, the compiler, the program logic, or any other part of the toolchain—even when these proofs are carried out by source-level static analyzers.In this paper I explain some semantic techniques for building a verified toolchain.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Appel, Andrew W.},
	month = mar,
	year = {2011},
	pages = {1--17},
	file = {Appel_2011_Verified Software Toolchain.pdf:/home/michael/Dropbox/zotero-pdfs/A/Appel_2011_Verified Software Toolchain.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/BDDZ2YCE/978-3-642-19718-5_1.html:text/html}
}

@inproceedings{murray_noninterference_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Noninterference for {Operating} {System} {Kernels}},
	isbn = {978-3-642-35307-9 978-3-642-35308-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-35308-6_12},
	doi = {10.1007/978-3-642-35308-6_12},
	abstract = {While intransitive noninterference is a natural property for any secure OS kernel to enforce, proving that the implementation of any particular general-purpose kernel enforces this property is yet to be achieved. In this paper we take a significant step towards this vision by presenting a machine-checked formulation of intransitive noninterference for OS kernels, and its associated sound and complete unwinding conditions, as well as a scalable proof calculus over nondeterministic state monads for discharging these unwinding conditions across a kernel’s implementation. Our ongoing experience applying this noninterference framework and proof calculus to the seL4 microkernel validates their utility and real-world applicability.},
	language = {en},
	booktitle = {Certified {Programs} and {Proofs}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Murray, Toby and Matichuk, Daniel and Brassil, Matthew and Gammie, Peter and Klein, Gerwin},
	month = dec,
	year = {2012},
	pages = {126--142},
	file = {Murray et al_2012_Noninterference for Operating System Kernels.pdf:/home/michael/Dropbox/zotero-pdfs/M/Murray et al_2012_Noninterference for Operating System Kernels.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/TGSEZSFH/978-3-642-35308-6_12.html:text/html}
}

@inproceedings{tuch_types_2007,
	address = {New York, NY, USA},
	series = {{POPL} '07},
	title = {Types, {Bytes}, and {Separation} {Logic}},
	isbn = {978-1-59593-575-5},
	url = {http://doi.acm.org/10.1145/1190216.1190234},
	doi = {10.1145/1190216.1190234},
	abstract = {We present a formal model of memory that both captures the low-level features of C's pointers and memory, and that forms the basis for an expressive implementation of separation logic. At the low level, we do not commit common oversimplifications, but correctly deal with C's model of programming language values and the heap. At the level of separation logic, we are still able to reason abstractly and efficiently. We implement this framework in the theorem prover Isabelle/HOL and demonstrate it on two case studies. We show that the divide between detailed and abstract does not impose undue verification overhead, and that simple programs remain easy to verify. We also show that the framework is applicable to real, security- and safety-critical code by formally verifying the memory allocator of the L4 microkernel.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 34th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Tuch, Harvey and Klein, Gerwin and Norrish, Michael},
	year = {2007},
	keywords = {C, interactive theorem proving, separation logic},
	pages = {97--108},
	file = {Tuch et al_2007_Types, Bytes, and Separation Logic.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tuch et al_2007_Types, Bytes, and Separation Logic.pdf:application/pdf}
}

@inproceedings{kennedy_compiling_2007,
	address = {New York, NY, USA},
	series = {{ICFP} '07},
	title = {Compiling with {Continuations}, {Continued}},
	isbn = {978-1-59593-815-2},
	url = {http://doi.acm.org/10.1145/1291151.1291179},
	doi = {10.1145/1291151.1291179},
	abstract = {We present a series of CPS-based intermediate languages suitable for functional language compilation, arguing that they have practical benefits over direct-style languages based on A-normal form (ANF) or monads. Inlining of functions demonstrates the benefits most clearly: in ANF-based languages, inlining involves a re-normalization step that rearranges let expressions and possibly introduces a new 'join point' function, and in monadic languages, commuting conversions must be applied; in contrast, inlining in our CPS language is a simple substitution of variables for variables. We present a contification transformation implemented by simple rewrites on the intermediate language. Exceptions are modelled using so-called 'double-barrelled' CPS. Subtyping on exception constructors then gives a very straightforward effect analysis for exceptions. We also show how a graph-based representation of CPS terms can be implemented extremely efficiently, with linear-time term simplification.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 12th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Kennedy, Andrew},
	year = {2007},
	keywords = {continuation passing style, continuations, functional programming languages, monads, optimizing compilation},
	pages = {177--190},
	file = {Kennedy_2007_Compiling with Continuations, Continued.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kennedy_2007_Compiling with Continuations, Continued.pdf:application/pdf}
}

@techreport{noauthor_sel4_2017,
	title = {{seL}4 {Reference} {Manual} {Version} 6.0.0},
	urldate = {2017-08-09},
	institution = {Data61 Trustworthy Systems},
	year = {2017},
	file = {2017_seL4 Reference Manual Version 6.0.0.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/2017_seL4 Reference Manual Version 6.0.0.pdf:application/pdf}
}

@incollection{bove_dependent_2009,
	title = {Dependent types at work},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-03153-3_2},
	urldate = {2017-08-09},
	booktitle = {Language engineering and rigorous software development},
	publisher = {Springer},
	author = {Bove, Ana and Dybjer, Peter},
	year = {2009},
	pages = {57--99},
	file = {Bove_Dybjer_2009_Dependent types at work.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bove_Dybjer_2009_Dependent types at work.pdf:application/pdf}
}

@book{nipkow_concrete_2014,
	address = {Cham},
	title = {Concrete {Semantics} with {Isabelle}/{HOL}},
	isbn = {978-3-319-10541-3 978-3-319-10542-0},
	url = {http://link.springer.com/10.1007/978-3-319-10542-0},
	language = {en},
	urldate = {2017-08-09},
	publisher = {Springer International Publishing},
	author = {Nipkow, Tobias and Klein, Gerwin},
	year = {2014},
	doi = {10.1007/978-3-319-10542-0},
	file = {Nipkow_Klein_2014_Concrete Semantics with Isabelle-HOL.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nipkow_Klein_2014_Concrete Semantics with Isabelle-HOL.pdf:application/pdf}
}

@article{whitaker_scale_2002,
	title = {Scale and {Performance} in the {Denali} {Isolation} {Kernel}},
	volume = {36},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/844128.844147},
	doi = {10.1145/844128.844147},
	abstract = {This paper describes the Denali isolation kernel, an operating system architecture that safely multiplexes a large number of untrusted Internet services on shared hardware. Denali's goal is to allow new Internet services to be "pushed" into third party infrastructure, relieving Internet service authors from the burden of acquiring and maintaining physical infrastructure. Our isolation kernel exposes a virtual machine abstraction, but unlike conventional virtual machine monitors, Denali does not attempt to emulate the underlying physical architecture precisely, and instead modifies the virtual architecture to gain scale, performance, and simplicity of implementation. In this paper, we first discuss design principles of isolation kernels, and then we describe the design and implementation of Denali. Following this, we present a detailed evaluation of Denali, demonstrating that the overhead of virtualization is small, that our architectural choices are warranted, and that we can successfully scale to more than 10,000 virtual machines on commodity hardware.},
	number = {SI},
	urldate = {2017-08-09},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Whitaker, Andrew and Shaw, Marianne and Gribble, Steven D.},
	month = dec,
	year = {2002},
	pages = {195--209},
	file = {Whitaker et al_2002_Scale and Performance in the Denali Isolation Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/W/Whitaker et al_2002_Scale and Performance in the Denali Isolation Kernel.pdf:application/pdf}
}

@article{cardelli_basic_1987,
	title = {Basic polymorphic typechecking},
	volume = {8},
	url = {http://www.sciencedirect.com/science/article/pii/0167642387900190},
	number = {2},
	urldate = {2017-08-09},
	journal = {Science of computer programming},
	author = {Cardelli, Luca},
	year = {1987},
	pages = {147--172},
	file = {Cardelli_1987_Basic polymorphic typechecking.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli_1987_Basic polymorphic typechecking.pdf:application/pdf}
}

@inproceedings{kell_operating_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {The {Operating} {System}: {Should} {There} {Be} {One}?},
	isbn = {978-1-4503-2460-1},
	shorttitle = {The {Operating} {System}},
	url = {http://doi.acm.org/10.1145/2525528.2525534},
	doi = {10.1145/2525528.2525534},
	abstract = {Operating systems and programming languages are often informally evaluated on their conduciveness towards composition. We revisit Dan Ingalls' Smalltalk-inspired position that "an operating system is a collection of things that don't fit inside a language; there shouldn't be one", discussing what it means, why it appears not to have materialised, and how we might work towards the same effect in the postmodern reality of today's systems. We argue that the trajectory of the "file" abstraction through Unix and Plan 9 culminates in a Smalltalk-style object, with other filesystem calls as a primitive metasystem. Meanwhile, the key features of Smalltalk have many analogues in the fragmented world of Unix programming (including techniques at the library, file and socket level). Based on the themes of unifying OS- and language-level mechanisms, and increasing the expressiveness of the meta-system, we identify some evolutionary approaches to a postmodern realisation of Ingalls' vision, arguing that an operating system is still necessary after all.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Kell, Stephen},
	year = {2013},
	keywords = {binding, composition, integration, metasystem, plan 9, smalltalk, Unix},
	pages = {8:1--8:7},
	file = {Kell_2013_The Operating System - Should There Be One.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kell_2013_The Operating System - Should There Be One.pdf:application/pdf}
}

@inproceedings{slowinska_dde:_2010,
	address = {New York, NY, USA},
	series = {{APSys} '10},
	title = {{DDE}: {Dynamic} {Data} {Structure} {Excavation}},
	isbn = {978-1-4503-0195-4},
	shorttitle = {{DDE}},
	url = {http://doi.acm.org/10.1145/1851276.1851280},
	doi = {10.1145/1851276.1851280},
	abstract = {Dynamic Datastructure Excavation (DDE) is a new approach to extract datastructures from C binaries without any need for debugging symbols. Unlike most existing tools, DDE uses dynamic analysis (on a QEMU-based emulator) and detects data structures by tracking how a program uses memory. Its results are much more accurate than those of previous methods.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {First} {ACM} {Asia}-pacific {Workshop} on {Workshop} on {Systems}},
	publisher = {ACM},
	author = {Slowinska, Asia and Stancescu, Traian and Bos, Herbert},
	year = {2010},
	keywords = {binary, detecting data structures, dynamic analysis},
	pages = {13--18},
	file = {Slowinska et al_2010_DDE - Dynamic Data Structure Excavation.pdf:/home/michael/Dropbox/zotero-pdfs/S/Slowinska et al_2010_DDE - Dynamic Data Structure Excavation.pdf:application/pdf}
}

@article{ingalls_design_1981,
	title = {Design {Principles} {Behind} {Smalltalk}},
	journal = {Byte Magazine},
	author = {Ingalls, Dan},
	year = {1981},
	pages = {300--312},
	file = {Ingalls_1981_Design Principles Behind Smalltalk.pdf:/home/michael/Dropbox/zotero-pdfs/I/Ingalls_1981_Design Principles Behind Smalltalk.pdf:application/pdf}
}

@book{black_squeak_2009,
	address = {Bern},
	edition = {Revised ed. with corrections},
	title = {Squeak by example},
	isbn = {978-3-9523341-0-2},
	language = {eng},
	publisher = {Universtiy of Bern},
	editor = {Black, Andrew P.},
	year = {2009},
	note = {OCLC: 839025310},
	file = {Black_2009_Squeak by example.pdf:/home/michael/Dropbox/zotero-pdfs/B/Black_2009_Squeak by example.pdf:application/pdf}
}

@article{launchbury_state_1995,
	title = {State in {Haskell}},
	volume = {8},
	issn = {0892-4635, 1573-0557},
	url = {https://link.springer.com/article/10.1007/BF01018827},
	doi = {10.1007/BF01018827},
	abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language. The security of the encapsulation is assured by the type system, using parametricity. The same framework is also used to handle input/output operations (state changes on the external world) and calls to C.},
	language = {en},
	number = {4},
	journal = {LISP and Symbolic Computation},
	author = {Launchbury, John and Jones, Simon L. Peyton},
	month = dec,
	year = {1995},
	pages = {293--341},
	file = {Launchbury_Jones_1995_State in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/L/Launchbury_Jones_1995_State in Haskell.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/7NZA7QPZ/BF01018827.html:text/html}
}

@inproceedings{karachalias_gadts_2015,
	title = {{GADTs} meet their match: pattern-matching warnings that account for {GADTs}, guards, and laziness},
	volume = {50},
	shorttitle = {{GADTs} meet their match},
	url = {http://dl.acm.org/citation.cfm?id=2784748},
	urldate = {2017-08-09},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Karachalias, Georgios and Schrijvers, Tom and Vytiniotis, Dimitrios and Jones, Simon Peyton},
	year = {2015},
	pages = {424--436},
	file = {Karachalias et al_2015_GADTs meet their match - pattern-matching warnings that account for GADTs,.pdf:/home/michael/Dropbox/zotero-pdfs/K/Karachalias et al_2015_GADTs meet their match - pattern-matching warnings that account for GADTs,.pdf:application/pdf}
}

@inproceedings{ingalls_back_1997,
	address = {New York, NY, USA},
	series = {{OOPSLA} '97},
	title = {Back to the {Future}: {The} {Story} of {Squeak}, a {Practical} {Smalltalk} {Written} in {Itself}},
	isbn = {978-0-89791-908-1},
	shorttitle = {Back to the {Future}},
	url = {http://doi.acm.org/10.1145/263698.263754},
	doi = {10.1145/263698.263754},
	abstract = {Squeak is an open, highly-portable Smalltalk implementation whose virtual machine is written entirely in Smalltalk, making it easy to. debug, analyze, and change. To achieve practical performance, a translator produces an equivalent C program whose performance is comparable to commercial Smalltalks.Other noteworthy aspects of Squeak include: a compact object format that typically requires only a single word of overhead per object; a simple yet efficient incremental garbage collector for 32-bit direct pointers; efficient bulk-mutation of objects; extensions of BitBlt to handle color of any depth and anti-aliased image rotation and scaling; and real-time sound and music synthesis written entirely in Smalltalk.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 12th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Ingalls, Dan and Kaehler, Ted and Maloney, John and Wallace, Scott and Kay, Alan},
	year = {1997},
	pages = {318--326},
	file = {Ingalls et al_1997_Back to the Future - The Story of Squeak, a Practical Smalltalk Written in Itself.pdf:/home/michael/Dropbox/zotero-pdfs/I/Ingalls et al_1997_Back to the Future - The Story of Squeak, a Practical Smalltalk Written in Itself.pdf:application/pdf}
}

@inproceedings{brady_idris_2011,
	address = {New York, NY, USA},
	series = {{PLPV} '11},
	title = {{IDRIS} — {Systems} {Programming} {Meets} {Full} {Dependent} {Types}},
	isbn = {978-1-4503-0487-0},
	shorttitle = {{IDRIS} —},
	url = {http://doi.acm.org/10.1145/1929529.1929536},
	doi = {10.1145/1929529.1929536},
	abstract = {Dependent types have emerged in recent years as a promising approach to ensuring program correctness. However, existing dependently typed languages such as Agda and Coq work at a very high level of abstraction, making it difficult to map verified programs to suitably efficient executable code. This is particularly problematic for programs which work with bit level data, e.g. network packet processing, binary file formats or operating system services. Such programs, being fundamental to the operation of computers in general, may stand to benefit significantly from program verification techniques. This paper describes the use of a dependently typed programming language, Idris, for specifying and verifying properties of low-level systems programs, taking network packet processing as an extended example. We give an overview of the distinctive features of Idris which allow it to interact with external systems code, with precise types. Furthermore, we show how to integrate tactic scripts and plugin decision procedures to reduce the burden of proof on application developers. The ideas we present are readily adaptable to languages with related type systems.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 5th {ACM} {Workshop} on {Programming} {Languages} {Meets} {Program} {Verification}},
	publisher = {ACM},
	author = {Brady, Edwin C.},
	year = {2011},
	keywords = {dependent types, data description},
	pages = {43--54},
	file = {Brady_2011_IDRIS — Systems Programming Meets Full Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brady_2011_IDRIS — Systems Programming Meets Full Dependent Types.pdf:application/pdf}
}

@inproceedings{koomsin_running_2015,
	address = {New York, NY, USA},
	series = {{PLOS} '15},
	title = {Running {Application} {Specific} {Kernel} {Code} by a {Just}-in-time {Compiler}},
	isbn = {978-1-4503-3942-1},
	url = {http://doi.acm.org/10.1145/2818302.2818305},
	doi = {10.1145/2818302.2818305},
	abstract = {Kernel scripting is a technique to run an extension code in a script language in an operating system kernel. Conventional kernel scripting has two limitations. First, it affects an entire system and only privileged users are allowed to install a new script. This prohibits developers from running their own application-specific code in the kernel. Second, its performance is not sufficient for some time-sensitive applications. In this paper, we address these problems. Our system call scripting allows developers to run their own application-specific code in the kernel without the root privilege. Our system call scripting runs with less overhead because we use a Just-In-Time (JIT) compiler. To evaluate our idea, we ported the LuaJIT compiler into the FreeBSD 10.1 x86 kernel. We modified Memcached to use system call scripting that processes multiple UDP GET requests at a time. With one worker thread and under a high-load condition, we achieved a 33\% reduction in the average response time and a 44\% improvement in the throughput when the response value size was small.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 8th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Koomsin, Ake and Shinjo, Yasushi},
	year = {2015},
	keywords = {JIT compilers, kernel scripting, Lua programming language, scriptable operating systems, system call scripting},
	pages = {15--20},
	file = {Koomsin_Shinjo_2015_Running Application Specific Kernel Code by a Just-in-time Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/K/Koomsin_Shinjo_2015_Running Application Specific Kernel Code by a Just-in-time Compiler.pdf:application/pdf}
}

@inproceedings{arya_semi-automated_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Semi-automated {Debugging} via {Binary} {Search} {Through} a {Process} {Lifetime}},
	isbn = {978-1-4503-2460-1},
	url = {http://doi.acm.org/10.1145/2525528.2525533},
	doi = {10.1145/2525528.2525533},
	abstract = {A common programmer experience is to execute a long-running computation only to see a bug crash the program after hours or days. While it is often easy to capture a "buggy" expression value at the point of the crash, it is less easy to discover the point in the program where the expression became buggy. For such "difficult" bugs, this work presents an automated tool based on binary search through a process lifetime. The tool operates both in single-threaded and multi-threaded program. The underlying algorithm depends on on checkpoints, deterministic replay, and decomposition of debugging histories. The tool is scalable in the sense that the running time is a small constant factor beyond the standalone running time. Further, it requires only a logarithmic number of probes of the expression value --- an advantage when the time to execute the expression is large. The algorithm is demonstrated for such real-world programs as MySQL.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Arya, Kapil and Denniston, Tyler and Visan, Ana-Maria and Cooperman, Gene},
	year = {2013},
	pages = {9:1--9:7},
	file = {Arya et al_2013_Semi-automated Debugging via Binary Search Through a Process Lifetime.pdf:/home/michael/Dropbox/zotero-pdfs/A/Arya et al_2013_Semi-automated Debugging via Binary Search Through a Process Lifetime.pdf:application/pdf}
}

@inproceedings{burtsev_weir:_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Weir: {A} {Streaming} {Language} for {Performance} {Analysis}},
	isbn = {978-1-4503-2460-1},
	shorttitle = {Weir},
	url = {http://doi.acm.org/10.1145/2525528.2525537},
	doi = {10.1145/2525528.2525537},
	abstract = {For modern software systems, performance analysis can be a challenging task. The software stack can be a complex, multi-layer, multi-component, concurrent, and parallel environment with multiple contexts of execution and multiple sources of performance data. Although much performance data is available, because modern systems incorporate many mature data-collection mechanisms, analysis algorithms suffer from the lack of a unifying programming environment for processing the collected performance data, potentially from multiple sources, in a convenient and script-like manner. This paper presents Weir, a streaming language for systems performance analysis. Weir is based on the insight that performance-analysis algorithms can be naturally expressed as stream-processing pipelines. In Weir, an analysis algorithm is implemented as a graph composed of stages, where each stage operates on a stream of events that represent collected performance measurements. Weir is an imperative streaming language with a syntax designed for the convenient construction of stream pipelines that utilize composable and reusable analysis stages. To demonstrate practical application, this paper presents the authors' experience in using Weir to analyze performance in systems based on the Xen virtualization platform.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Burtsev, Anton and Mishrikoti, Nikhil and Eide, Eric and Ricci, Robert},
	year = {2013},
	pages = {6:1--6:6},
	file = {Burtsev et al_2013_Weir - A Streaming Language for Performance Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/B/Burtsev et al_2013_Weir - A Streaming Language for Performance Analysis.pdf:application/pdf}
}

@inproceedings{shinde_modeling_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Modeling {NICs} with {Unicorn}},
	isbn = {978-1-4503-2460-1},
	url = {http://doi.acm.org/10.1145/2525528.2525532},
	doi = {10.1145/2525528.2525532},
	abstract = {NICs are increasingly complex and diverse, offering a wide range of hardware functionality to aid network protocol processing. Harnessing the power of NIC hardware requires the ability to control and reason about a variety of different feature sets in the network stack. Towards this goal, we propose Unicorn, a language for describing modern NICs. Unicorn offers a simple set of abstractions for modeling both NIC functionality and the state of a protocol stack. To evaluate its expressivity and potential, we present a non-trivial model for the Intel i82599 10GbE NIC, and an algorithm that uses graph embedding to optimize the use of NIC hardware in the network stack.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Shinde, Pravin and Kaufmann, Antoine and Kourtis, Kornilios and Roscoe, Timothy},
	year = {2013},
	pages = {3:1--3:6},
	file = {Shinde et al_2013_Modeling NICs with Unicorn.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shinde et al_2013_Modeling NICs with Unicorn.pdf:application/pdf}
}

@inproceedings{keller_file_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {File {Systems} {Deserve} {Verification} {Too}!},
	isbn = {978-1-4503-2460-1},
	url = {http://doi.acm.org/10.1145/2525528.2525530},
	doi = {10.1145/2525528.2525530},
	abstract = {File systems are too important, and current ones are too buggy, to remain unverified. Yet the most successful verification methods for functional correctness remain too expensive for current file system implementations --- we need verified correctness but at reasonable cost. This paper presents our vision and ongoing work to achieve this goal for a new high-performance flash file system, called BilbyFs. BilbyFs is carefully designed to be highly modular, so it can be verified against a high-level functional specification one component at a time. This modular implementation is captured in a set of domain specific languages from which we produce the design-level specification, as well as its optimised C implementation. Importantly, we also automatically generate the proof linking these two artefacts. The combination of these features dramatically reduces verification effort. Verified file systems are now within reach for the first time.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Keller, Gabriele and Murray, Toby and Amani, Sidney and O'Connor, Liam and Chen, Zilin and Ryzhyk, Leonid and Klein, Gerwin and Heiser, Gernot},
	year = {2013},
	pages = {1:1--1:7},
	file = {Keller et al_2013_File Systems Deserve Verification Too!.pdf:/home/michael/Dropbox/zotero-pdfs/K/Keller et al_2013_File Systems Deserve Verification Too!.pdf:application/pdf}
}

@inproceedings{dzik_mbrace:_2013,
	title = {{MBrace}: cloud computing with monads},
	isbn = {978-1-4503-2460-1},
	shorttitle = {{MBrace}},
	url = {http://dl.acm.org/citation.cfm?doid=2525528.2525531},
	doi = {10.1145/2525528.2525531},
	language = {en},
	urldate = {2017-08-09},
	publisher = {ACM Press},
	author = {Dzik, Jan and Palladinos, Nick and Rontogiannis, Konstantinos and Tsarpalis, Eirik and Vathis, Nikolaos},
	year = {2013},
	pages = {1--6},
	file = {Dzik et al_2013_MBrace - cloud computing with monads.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dzik et al_2013_MBrace - cloud computing with monads.pdf:application/pdf}
}

@inproceedings{sun_annotation_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Annotation for {Automation}: {Rapid} {Generation} of {File} {System} {Tools}},
	isbn = {978-1-4503-2460-1},
	shorttitle = {Annotation for {Automation}},
	url = {http://doi.acm.org/10.1145/2525528.2525529},
	doi = {10.1145/2525528.2525529},
	abstract = {Today file system tools and file-system aware storage applications are tightly coupled with file system implementations. Developing these applications is challenging because it requires detailed knowledge of the file system format, and the code for interpreting file system metadata has to be written manually. This code is complex and file-system specific, and so the application requires significant re-engineering to support different file systems. We propose a file system annotation language for specifying a file system's on-disk metadata format. File system developers are asked to annotate the data structure definitions of a file system's metadata. The annotated code is parsed and used by tool-specific code templates to create interpretation routines (e.g., a metadata parser) for the desired file system tool. The benefit is that different tools can reuse the interpretation routines, and they are much less dependent on file system formats and implementations. We show the feasibility of this approach by implementing a compiler that generates a runtime metadata interpreter for an annotated toy file system. The generated code has low overhead (roughly 3\%) compared to a hand-written version of the same application.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Sun, Kuei (Jack) and Fryer, Daniel and Brown, Angela Demke and Goel, Ashvin},
	year = {2013},
	pages = {4:1--4:6},
	file = {Sun et al_2013_Annotation for Automation - Rapid Generation of File System Tools.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sun et al_2013_Annotation for Automation - Rapid Generation of File System Tools.pdf:application/pdf}
}

@inproceedings{tschudin_understanding_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Understanding the {Genetic} {Makeup} of {Linux} {Device} {Drivers}},
	isbn = {978-1-4503-2460-1},
	url = {http://doi.acm.org/10.1145/2525528.2525536},
	doi = {10.1145/2525528.2525536},
	abstract = {Attempts have been made to understand driver development in terms of code clones. In this paper, we propose an alternate view, based on the metaphor of a gene. Guided by this metaphor, we study the structure of Linux 3.10 ethernet platform driver probe functions.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Tschudin, Peter Senna and Réveillère, Laurent and Jiang, Lingxiao and Lo, David and Lawall, Julia and Muller, Gilles},
	year = {2013},
	pages = {10:1--10:6},
	file = {Tschudin et al_2013_Understanding the Genetic Makeup of Linux Device Drivers.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tschudin et al_2013_Understanding the Genetic Makeup of Linux Device Drivers.pdf:application/pdf}
}

@inproceedings{yuan_making_2015,
	address = {New York, NY, USA},
	series = {{PLOS} '15},
	title = {Making {Lock}-free {Data} {Structures} {Verifiable} with {Artificial} {Transactions}},
	isbn = {978-1-4503-3942-1},
	url = {http://doi.acm.org/10.1145/2818302.2818309},
	doi = {10.1145/2818302.2818309},
	abstract = {Among all classes of parallel programming abstractions, lock-free data structures are considered one of the most scalable and efficient thanks to their fine-grained style of synchronization. However, they are also challenging for developers and tools to verify because of the huge number of possible interleavings that result from fine-grained synchronizations. This paper addresses this fundamental problem between performance and verifiability of lock-free data structure implementations. We present Txit, a system that greatly reduces the set of possible interleavings by inserting transactions into the implementation of a lock-free data structure. We leverage hardware transactional memory support from Intel Haswell processors to enforce these artificial transactions. Evaluation on six popular lock-free data structure libraries shows that Txit makes it easy to verify lock-free data structures while incurring acceptable runtime overhead. Further analysis shows that two inefficiencies in Haswell are the largest contributors to this overhead.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 8th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Yuan, Xinhao and Williams-King, David and Yang, Junfeng and Sethumadhavan, Simha},
	year = {2015},
	keywords = {artificial transactions, lock-free data structures, software model checking, state space reduction, transactional memory},
	pages = {39--45},
	file = {Yuan et al_2015_Making Lock-free Data Structures Verifiable with Artificial Transactions.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yuan et al_2015_Making Lock-free Data Structures Verifiable with Artificial Transactions.pdf:application/pdf}
}

@inproceedings{vijayaraghavan_modular_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Modular {Deductive} {Verification} of {Multiprocessor} {Hardware} {Designs}},
	isbn = {978-3-319-21667-6 978-3-319-21668-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-21668-3_7},
	doi = {10.1007/978-3-319-21668-3_7},
	abstract = {We present a new framework for modular verification of hardware designs in the style of the Bluespec language. That is, we formalize the idea of components in a hardware design, with well-defined input and output channels; and we show how to specify and verify components individually, with machine-checked proofs in the Coq proof assistant. As a demonstration, we verify a fairly realistic implementation of a multicore shared-memory system with two types of components: memory system and processor. Both components include nontrivial optimizations, with the memory system employing an arbitrary hierarchy of cache nodes that communicate with each other concurrently, and with the processor doing speculative execution of many concurrent read operations. Nonetheless, we prove that the combined system implements sequential consistency. To our knowledge, our memory-system proof is the first machine verification of a cache-coherence protocol parameterized over an arbitrary cache hierarchy, and our full-system proof is the first machine verification of sequential consistency for a multicore hardware design that includes caches and speculative processors.},
	language = {en},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Cham},
	author = {Vijayaraghavan, Muralidaran and Chlipala, Adam and Arvind and Dave, Nirav},
	month = jul,
	year = {2015},
	pages = {109--127},
	file = {Snapshot:/home/michael/Zotero/storage/YMWS7DS3/978-3-319-21668-3_7.html:text/html;Vijayaraghavan et al_2015_Modular Deductive Verification of Multiprocessor Hardware Designs.pdf:/home/michael/Dropbox/zotero-pdfs/V/Vijayaraghavan et al_2015_Modular Deductive Verification of Multiprocessor Hardware Designs.pdf:application/pdf}
}

@inproceedings{braibant_formal_2013,
	title = {Formal verification of hardware synthesis},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-39799-8_14},
	urldate = {2017-08-09},
	booktitle = {International {Conference} on {Computer} {Aided} {Verification}},
	publisher = {Springer},
	author = {Braibant, Thomas and Chlipala, Adam},
	year = {2013},
	keywords = {TO-READ},
	pages = {213--228},
	file = {Braibant_Chlipala_2013_Formal verification of hardware synthesis.pdf:/home/michael/Dropbox/zotero-pdfs/B/Braibant_Chlipala_2013_Formal verification of hardware synthesis.pdf:application/pdf}
}

@inproceedings{patterson_funtal:_2017,
	address = {New York, NY, USA},
	series = {{PLDI} 2017},
	title = {{FunTAL}: {Reasonably} {Mixing} a {Functional} {Language} with {Assembly}},
	isbn = {978-1-4503-4988-8},
	shorttitle = {{FunTAL}},
	url = {http://doi.acm.org/10.1145/3062341.3062347},
	doi = {10.1145/3062341.3062347},
	abstract = {We present FunTAL, the first multi-language system to formalize safe interoperability between a high-level functional language and low-level assembly code while supporting compositional reasoning about the mix. A central challenge in developing such a multi-language is bridging the gap between assembly, which is staged into jumps to continuations, and high-level code, where subterms return a result. We present a compositional stack-based typed assembly language that supports components, comprised of one or more basic blocks, that may be embedded in high-level contexts. We also present a logical relation for FunTAL that supports reasoning about equivalence of high-level components and their assembly replacements, mixed-language programs with callbacks between languages, and assembly components comprised of different numbers of basic blocks.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Patterson, Daniel and Perconti, Jamie and Dimoulas, Christos and Ahmed, Amal},
	year = {2017},
	keywords = {typed assembly language, contextual equivalence, inline assembly, logical relations, multi-language semantics},
	pages = {495--509},
	file = {Patterson et al_2017_FunTAL - Reasonably Mixing a Functional Language with Assembly.pdf:/home/michael/Dropbox/zotero-pdfs/P/Patterson et al_2017_FunTAL - Reasonably Mixing a Functional Language with Assembly.pdf:application/pdf}
}

@inproceedings{chlipala_end_2017,
	title = {The {End} of {History}? {Using} a {Proof} {Assistant} to {Replace} {Language} {Design} with {Library} {Design}},
	volume = {71},
	shorttitle = {The {End} of {History}?},
	url = {http://drops.dagstuhl.de/opus/volltexte/2017/7123/},
	urldate = {2017-08-09},
	booktitle = {{LIPIcs}-{Leibniz} {International} {Proceedings} in {Informatics}},
	publisher = {Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik},
	author = {Chlipala, Adam and Delaware, Benjamin and Duchovni, Samuel and Gross, Jason and Pit-Claudel, Clément and Suriyakarn, Sorawit and Wang, Peng and Ye, Katherine},
	year = {2017},
	keywords = {TO-READ},
	file = {Chlipala et al_2017_The End of History - Using a Proof Assistant to Replace Language Design with.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chlipala et al_2017_The End of History - Using a Proof Assistant to Replace Language Design with.pdf:application/pdf}
}

@inproceedings{ertl_optimizing_2003,
	address = {New York, NY, USA},
	series = {{PLDI} '03},
	title = {Optimizing {Indirect} {Branch} {Prediction} {Accuracy} in {Virtual} {Machine} {Interpreters}},
	isbn = {978-1-58113-662-3},
	url = {http://doi.acm.org/10.1145/781131.781162},
	doi = {10.1145/781131.781162},
	abstract = {Interpreters designed for efficiency execute a huge number of indirect branches and can spend more than half of the execution time in indirect branch mispredictions. Branch target buffers are the best widely available form of indirect branch prediction; however, their prediction accuracy for existing interpreters is only 2\%--50\%. In this paper we investigate two methods for improving the prediction accuracy of BTBs for interpreters: replicating virtual machine (VM) instructions and combining sequences of VM instructions into superinstructions. We investigate static (interpreter build-time) and dynamic (interpreter run-time) variants of these techniques and compare them and several combinations of these techniques. These techniques can eliminate nearly all of the dispatch branch mispredictions, and have other benefits, resulting in speedups by a factor of up to 3.17 over efficient threaded-code interpreters, and speedups by a factor of up to 1.3 over techniques relying on superinstructions alone.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2003 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Ertl, M. Anton and Gregg, David},
	year = {2003},
	keywords = {branch prediction, branch target buffer, code replication, interpreter, superinstruction},
	pages = {278--288},
	file = {Ertl_Gregg_2003_Optimizing Indirect Branch Prediction Accuracy in Virtual Machine Interpreters.pdf:/home/michael/Dropbox/zotero-pdfs/E/Ertl_Gregg_2003_Optimizing Indirect Branch Prediction Accuracy in Virtual Machine Interpreters.pdf:application/pdf}
}

@inproceedings{burke_jalapeno_1999,
	address = {New York, NY, USA},
	series = {{JAVA} '99},
	title = {The {Jalapeno} {Dynamic} {Optimizing} {Compiler} for {Java}},
	isbn = {978-1-58113-161-1},
	url = {http://doi.acm.org/10.1145/304065.304113},
	doi = {10.1145/304065.304113},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} 1999 {Conference} on {Java} {Grande}},
	publisher = {ACM},
	author = {Burke, Michael G. and Choi, Jong-Deok and Fink, Stephen and Grove, David and Hind, Michael and Sarkar, Vivek and Serrano, Mauricio J. and Sreedhar, V. C. and Srinivasan, Harini and Whaley, John},
	year = {1999},
	pages = {129--141},
	file = {Burke et al_1999_The Jalapeno Dynamic Optimizing Compiler for Java.pdf:/home/michael/Dropbox/zotero-pdfs/B/Burke et al_1999_The Jalapeno Dynamic Optimizing Compiler for Java.pdf:application/pdf}
}

@inproceedings{arnold_framework_2001,
	address = {New York, NY, USA},
	series = {{PLDI} '01},
	title = {A {Framework} for {Reducing} the {Cost} of {Instrumented} {Code}},
	isbn = {978-1-58113-414-8},
	url = {http://doi.acm.org/10.1145/378795.378832},
	doi = {10.1145/378795.378832},
	abstract = {Instrumenting code to collect profiling information can cause substantial execution overhead. This overhead makes instrumentation difficult to perform at runtime, often preventing many known offline feedback-directed optimizations from being used in online systems. This paper presents a general framework for performing instrumentation sampling to reduce the overhead of previously expensive instrumentation. The framework is simple and effective, using code-duplication and counter-based sampling to allow switching between instrumented and non-instrumented code.
Our framework does not rely on any hardware or operating system support, yet provides a high frequency sample rate that is tunable, allowing the tradeoff between overhead and accuracy to be adjusted easily at runtime. Experimental results are presented to validate that our technique can collect accurate profiles (93-98\% overlap with a perfect profile) with low overhead (averaging 6\% total overhead with a naive implementation). A Jalape{\textasciitilde} no-specific optimization is also presented that reduces overhead further, resulting in an average total overhead of 3\%.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2001 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Arnold, Matthew and Ryder, Barbara G.},
	year = {2001},
	pages = {168--179},
	file = {Arnold_Ryder_2001_A Framework for Reducing the Cost of Instrumented Code.pdf:/home/michael/Dropbox/zotero-pdfs/A/Arnold_Ryder_2001_A Framework for Reducing the Cost of Instrumented Code.pdf:application/pdf}
}

@inproceedings{arnold_adaptive_2000,
	address = {New York, NY, USA},
	series = {{OOPSLA} '00},
	title = {Adaptive {Optimization} in the {JalapeÑO} {JVM}},
	isbn = {978-1-58113-200-7},
	url = {http://doi.acm.org/10.1145/353171.353175},
	doi = {10.1145/353171.353175},
	abstract = {Future high-performance virtual machines will improve performance through sophisticated online feedback-directed optimizations. this paper presents the architecture of the Jalape\&ntilde;o Adaptive Optimization System, a system to support leading-edge virtual machine technology and enable ongoing research on online feedback-directed optimizations. We describe the extensible system architecture, based on a federation of threads with asynchronous communication. We present an implementation of the general architecture that supports adaptive multi-level optimization based purely on statistical sampling. We empirically demonstrate that this profiling technique has low overhead and can improve startup and steady-state performance, even without the presence of online feedback-directed optimizations. The paper also describes and evaluates an online feedback-directed inlining optimization based on statistical edge sampling. The system is written completely in Java, applying the described techniques not only to application code and standard libraries, but also to the virtual machine itself.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Arnold, Matthew and Fink, Stephen and Grove, David and Hind, Michael and Sweeney, Peter F.},
	year = {2000},
	pages = {47--65},
	file = {Arnold et al_2000_Adaptive Optimization in the JalapeNO JVM.pdf:/home/michael/Dropbox/zotero-pdfs/A/Arnold et al_2000_Adaptive Optimization in the JalapeNO JVM.pdf:application/pdf}
}

@inproceedings{ancona_rpython:_2007,
	address = {New York, NY, USA},
	series = {{DLS} '07},
	title = {{RPython}: {A} {Step} {Towards} {Reconciling} {Dynamically} and {Statically} {Typed} {OO} {Languages}},
	isbn = {978-1-59593-868-8},
	shorttitle = {{RPython}},
	url = {http://doi.acm.org/10.1145/1297081.1297091},
	doi = {10.1145/1297081.1297091},
	abstract = {Although the C-based interpreter of Python is reasonably fast, implementations on the CLI or the JVM platforms offers some advantages in terms of robustness and interoperability. Unfortunately, because the CLI and JVM are primarily designed to execute statically typed, object-oriented languages, most dynamic language implementations cannot use the native bytecodes for common operations like method calls and exception handling; as a result, they are not able to take full advantage of the power offered by the CLI and JVM. We describe a different approach that attempts to preserve the flexibility of Python, while still allowing for efficient execution. This is achieved by limiting the use of the more dynamic features of Python to an initial, bootstrapping phase. This phase is used to construct a final RPython (Restricted Python) program that is actually executed. RPython is a proper subset of Python, is statically typed, and does not allow dynamic modification of class or method definitions; however, it can still take advantage of Python features such as mixins and first-class methods and classes. This paper presents an overview of RPython, including its design and its translation to both CLI and JVM bytecode. We show how the bootstrapping phase can be used to implement advanced features, like extensible classes and generative programming. We also discuss what work remains before RPython is truly ready for general use, and compare the performance of RPython with that of other approaches.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2007 {Symposium} on {Dynamic} {Languages}},
	publisher = {ACM},
	author = {Ancona, Davide and Ancona, Massimo and Cuni, Antonio and Matsakis, Nicholas D.},
	year = {2007},
	keywords = {.NET, JVM, Python},
	pages = {53--64},
	file = {Ancona et al_2007_RPython - A Step Towards Reconciling Dynamically and Statically Typed OO.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ancona et al_2007_RPython - A Step Towards Reconciling Dynamically and Statically Typed OO.pdf:application/pdf}
}

@techreport{petricek_context-aware_2017,
	title = {Context-aware programming languages},
	url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-906.html},
	urldate = {2017-08-09},
	institution = {University of Cambridge, Computer Laboratory},
	author = {Petricek, Tomas},
	year = {2017},
	file = {Petricek_2017_Context-aware programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petricek_2017_Context-aware programming languages.pdf:application/pdf}
}

@inproceedings{alglave_ogre_2017,
	title = {Ogre and {Pythia}: an invariance proof method for weak consistency models.},
	shorttitle = {Ogre and {Pythia}},
	url = {http://www.cs.nyu.edu/~pcousot/publications.www/Alglave-Cousot-POPL2017.pdf},
	urldate = {2017-08-09},
	booktitle = {{POPL}},
	author = {Alglave, Jade and Cousot, Patrick},
	year = {2017},
	pages = {3--18},
	file = {Alglave_Cousot_2017_Ogre and Pythia - an invariance proof method for weak consistency models.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alglave_Cousot_2017_Ogre and Pythia - an invariance proof method for weak consistency models.pdf:application/pdf}
}

@inproceedings{petricek_coeffects:_2014,
	address = {New York, NY, USA},
	series = {{ICFP} '14},
	title = {Coeffects: {A} {Calculus} of {Context}-dependent {Computation}},
	isbn = {978-1-4503-2873-9},
	shorttitle = {Coeffects},
	url = {http://doi.acm.org/10.1145/2628136.2628160},
	doi = {10.1145/2628136.2628160},
	abstract = {The notion of context in functional languages no longer refers just to variables in scope. Context can capture additional properties of variables (usage patterns in linear logics; caching requirements in dataflow languages) as well as additional resources or properties of the execution environment (rebindable resources; platform version in a cross-platform application). The recently introduced notion of coeffects captures the latter, whole-context properties, but it failed to capture fine-grained per-variable properties. We remedy this by developing a generalized coeffect system with annotations indexed by a coeffect shape. By instantiating a concrete shape, our system captures previously studied flat (whole-context) coeffects, but also structural (per-variable) coeffects, making coeffect analyses more useful. We show that the structural system enjoys desirable syntactic properties and we give a categorical semantics using extended notions of indexed comonad. The examples presented in this paper are based on analysis of established language features (liveness, linear logics, dataflow, dynamic scoping) and we argue that such context-aware properties will also be useful for future development of languages for increasingly heterogeneous and distributed platforms.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Petricek, Tomas and Orchard, Dominic and Mycroft, Alan},
	year = {2014},
	keywords = {coeffects, context, indexed comonads, types},
	pages = {123--135},
	file = {Petricek et al_2014_Coeffects - A Calculus of Context-dependent Computation.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petricek et al_2014_Coeffects - A Calculus of Context-dependent Computation.pdf:application/pdf}
}

@inproceedings{petricek_coeffects:_2013,
	title = {Coeffects: {Unified} static analysis of context-dependence},
	shorttitle = {Coeffects},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-39212-2_35},
	urldate = {2017-08-09},
	booktitle = {International {Colloquium} on {Automata}, {Languages}, and {Programming}},
	publisher = {Springer},
	author = {Petricek, Tomas and Orchard, Dominic and Mycroft, Alan},
	year = {2013},
	pages = {385--397},
	file = {Petricek et al_2013_Coeffects - Unified static analysis of context-dependence.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petricek et al_2013_Coeffects - Unified static analysis of context-dependence.pdf:application/pdf}
}

@inproceedings{elphinstone_l3_2013,
	address = {New York, NY, USA},
	series = {{SOSP} '13},
	title = {From {L}3 to {seL}4 {What} {Have} {We} {Learnt} in 20 {Years} of {L}4 {Microkernels}?},
	isbn = {978-1-4503-2388-8},
	url = {http://doi.acm.org/10.1145/2517349.2522720},
	doi = {10.1145/2517349.2522720},
	abstract = {The L4 microkernel has undergone 20 years of use and evolution. It has an active user and developer community, and there are commercial versions which are deployed on a large scale and in safety-critical systems. In this paper we examine the lessons learnt in those 20 years about microkernel design and implementation. We revisit the L4 design papers, and examine the evolution of design and implementation from the original L4 to the latest generation of L4 kernels, especially seL4, which has pushed the L4 model furthest and was the first OS kernel to undergo a complete formal verification of its implementation as well as a sound analysis of worst-case execution times. We demonstrate that while much has changed, the fundamental principles of minimality and high IPC performance remain the main drivers of design and implementation decisions.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twenty}-{Fourth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Elphinstone, Kevin and Heiser, Gernot},
	year = {2013},
	pages = {133--150},
	file = {Elphinstone_Heiser_2013_From L3 to seL4 What Have We Learnt in 20 Years of L4 Microkernels.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elphinstone_Heiser_2013_From L3 to seL4 What Have We Learnt in 20 Years of L4 Microkernels.pdf:application/pdf}
}

@inproceedings{blackham_improving_2012,
	address = {New York, NY, USA},
	series = {{EuroSys} '12},
	title = {Improving {Interrupt} {Response} {Time} in a {Verifiable} {Protected} {Microkernel}},
	isbn = {978-1-4503-1223-3},
	url = {http://doi.acm.org/10.1145/2168836.2168869},
	doi = {10.1145/2168836.2168869},
	abstract = {Many real-time operating systems (RTOSes) offer very small interrupt latencies, in the order of tens or hundreds of cycles. They achieve this by making the RTOS kernel fully preemptible, permitting interrupts at almost any point in execution except for some small critical sections. One drawback of this approach is that it is difficult to reason about or formally model the kernel's behavior for verification, especially when written in a low-level language such as C. An alternate model for an RTOS kernel is to permit interrupts at specific preemption points only. This controls the possible interleavings and enables the use of techniques such as formal verification or model checking. Although this model cannot (yet) obtain the small interrupt latencies achievable with a fully-preemptible kernel, it can still achieve worst-case latencies in the range of 10,000s to 100,000s of cycles. As modern embedded CPUs enter the 1 GHz range, such latencies become acceptable for more applications, particularly when they come with the additional benefit of simplicity and formal models. This is particularly attractive for protected multitasking microkernels, where the (inherently non-preemptible) kernel entry and exit costs dominate the latencies of many system calls. This paper explores how to reduce the worst-case interrupt latency in a (mostly) non-preemptible protected kernel, and still maintain the ability to apply formal methods for analysis. We use the formally-verified seL4 microkernel as a case study and demonstrate that it is possible to achieve reasonable response-time guarantees. By combining short predictable interrupt latencies with formal verification, a design such as seL4's creates a compelling platform for building mixed-criticality real-time systems.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 7th {ACM} {European} {Conference} on {Computer} {Systems}},
	publisher = {ACM},
	author = {Blackham, Bernard and Shi, Yao and Heiser, Gernot},
	year = {2012},
	keywords = {microkernels, formal verification, hard real-time systems, trusted systems, worst-case execution time},
	pages = {323--336},
	file = {Blackham et al_2012_Improving Interrupt Response Time in a Verifiable Protected Microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/B/Blackham et al_2012_Improving Interrupt Response Time in a Verifiable Protected Microkernel.pdf:application/pdf}
}

@article{uhlig_design_1994,
	title = {Design {Tradeoffs} for {Software}-managed {TLBs}},
	volume = {12},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/185514.185515},
	doi = {10.1145/185514.185515},
	abstract = {An increasing number of architectures provide virtual memory support through software-managed TLBs. However, software management can impose considerable penalties that are highly dependent on the operating system's structure and its use of virtual memory. This work explores software-managed TLB design tradeoffs and their interaction with a range of monolithic and microkernel operating systems. Through hardware monitoring and simulation, we explore TLB performance for benchmarks running on a MIPS R2000-based workstation running Ultrix, OSF/1, and three versions of Mach 3.0.},
	number = {3},
	urldate = {2017-08-09},
	journal = {ACM Trans. Comput. Syst.},
	author = {Uhlig, Richard and Nagle, David and Stanley, Tim and Mudge, Trevor and Sechrest, Stuart and Brown, Richard},
	month = aug,
	year = {1994},
	keywords = {hardware monitoring, translation lookaside buffer (TLB), trap-driven simulation},
	pages = {175--205},
	file = {Uhlig et al_1994_Design Tradeoffs for Software-managed TLBs.pdf:/home/michael/Dropbox/zotero-pdfs/U/Uhlig et al_1994_Design Tradeoffs for Software-managed TLBs.pdf:application/pdf}
}

@techreport{andronick_abstract_2014,
	title = {Abstract {Formal} {Specification} of the {seL}4/{ARMv}6 {API}},
	url = {http://www.ooatool.com/docs/SMMethod96.pdf},
	urldate = {2017-08-09},
	institution = {NICTA},
	author = {Andronick, June and Bourke, Timothy and Derrin, Philip and Elphinstone, Kevin and Greenaway, David and Klein, Gerwin and Kolanski, Rafal and Matichuk, Daniel and Sewell, Thomas and Winwood, Simon},
	year = {2014},
	file = {Andronick et al_2014_Abstract Formal Specification of the seL4-ARMv6 API.pdf:/home/michael/Dropbox/zotero-pdfs/A/Andronick et al_2014_Abstract Formal Specification of the seL4-ARMv6 API.pdf:application/pdf}
}

@inproceedings{liedtke_improving_1993,
	address = {New York, NY, USA},
	series = {{SOSP} '93},
	title = {Improving {IPC} by {Kernel} {Design}},
	isbn = {978-0-89791-632-5},
	url = {http://doi.acm.org/10.1145/168619.168633},
	doi = {10.1145/168619.168633},
	abstract = {Inter-process communication (ipc) has to be fast and effective, otherwise programmers will not use remote procedure calls (RPC), multithreading and multitasking adequately. Thus ipc performance is vital for modern operating systems, especially \&mu;-kernel based ones. Surprisingly, most \&mu;-kernels exhibit poor ipc performance, typically requiring 100 \&mu;s for a short message transfer on a modern processor, running with 50 MHz clock rate.In contrast, we achieve 5 \&mu;s; a twentyfold improvement.This paper describes the methods and principles used, starting from the architectural design and going down to the coding level. There is no single trick to obtaining this high performance; rather, a synergetic approach in design and implementation on all levels is needed. The methods and their synergy are illustrated by applying them to a concrete example, the L3 \&mu;-kernel (an industrial-quality operating system in daily use at several hundred sites). The main ideas are to guide the complete kernel design by the ipc requirements, and to make heavy use of the concept of virtual address space inside the \&mu;-kernel itself.As the L3 experiment shows, significant performance gains are possible: compared with Mach, they range from a factor of 22 (8-byte messages) to 3 (4-Kbyte messages). Although hardware specific details influence both the design and implementation, these techniques are applicable to the whole class of conventional general purpose von Neumann processors supporting virtual addresses. Furthermore, the effort required is reasonably small, for example the dedicated parts of the \&mu;-kernel can be concentrated in a single medium sized module.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Fourteenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Liedtke, Jochen},
	year = {1993},
	pages = {175--188},
	file = {Liedtke_1993_Improving IPC by Kernel Design.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liedtke_1993_Improving IPC by Kernel Design.pdf:application/pdf}
}

@inproceedings{blackham_preempt_2012,
	address = {New York, NY, USA},
	series = {{APSYS} '12},
	title = {To {Preempt} or {Not} to {Preempt}, {That} is the {Question}},
	isbn = {978-1-4503-1669-9},
	url = {http://doi.acm.org/10.1145/2349896.2349904},
	doi = {10.1145/2349896.2349904},
	abstract = {Real-time operating systems (RTOSes) are traditionally designed to be fully preemptible. This improves the average interrupt response time of the system but increases kernel complexity. An alternative design is to make the kernel mostly non-preemptible and only handle pending interrupts at specific pre-emption points within the kernel. While this potentially worsens interrupt response times, we claim that for a protected-mode RTOS, as required for multi-criticality systems, non-preemptible kernels can achieve worst-case latencies comparable to those of fully-preemptible kernels. In order to understand the latency limits achievable in both approaches, we analyse and compare the worst-case interrupt latencies of a fully-preemptible commercial RTOS (QNX Neutrino) and a non-preemptible real-time kernel (seL4). Our results indicate that a non-preemptible kernel can achieve interrupt latencies which are within a factor of two from those exhibited by a fully-preemptible kernel.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Asia}-{Pacific} {Workshop} on {Systems}},
	publisher = {ACM},
	author = {Blackham, Bernard and Tang, Vernon and Heiser, Gernot},
	year = {2012},
	pages = {8:1--8:7},
	file = {Blackham et al_2012_To Preempt or Not to Preempt, That is the Question.pdf:/home/michael/Dropbox/zotero-pdfs/B/Blackham et al_2012_To Preempt or Not to Preempt, That is the Question.pdf:application/pdf}
}

@inproceedings{liedtke_micro-kernel_1995,
	address = {New York, NY, USA},
	series = {{SOSP} '95},
	title = {On {Micro}-kernel {Construction}},
	isbn = {978-0-89791-715-5},
	url = {http://doi.acm.org/10.1145/224056.224075},
	doi = {10.1145/224056.224075},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Liedtke, J.},
	year = {1995},
	pages = {237--250},
	file = {Liedtke_1995_On Micro-kernel Construction.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liedtke_1995_On Micro-kernel Construction.pdf:application/pdf}
}

@inproceedings{balakrishnan_codesurfer/x86platform_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CodeSurfer}/x86—{A} {Platform} for {Analyzing} x86 {Executables}},
	isbn = {978-3-540-25411-9 978-3-540-31985-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-31985-6_19},
	doi = {10.1007/978-3-540-31985-6_19},
	abstract = {CodeSurfer/x86 is a prototype system for analyzing x86 executables. It uses a static-analysis algorithm called value-set analysis (VSA) to recover intermediate representations that are similar to those that a compiler creates for a program written in a high-level language. A major challenge in building an analysis tool for executables is in providing useful information about operations involving memory. This is difficult when symbol-table and debugging information is absent or untrusted. CodeSurfer/x86 overcomes these challenges to provide an analyst with a powerful and flexible platform for investigating the properties and behaviors of potentially malicious code (such as COTS components, plugins, mobile code, worms, Trojans, and virus-infected code) using (i) CodeSurfer/x86’s GUI, (ii) CodeSurfer/x86’s scripting language, which provides access to all of the intermediate representations that CodeSurfer/x86 builds for the executable, and (iii) GrammaTech’s Path Inspector, which is a tool that uses a sophisticated pattern-matching engine to answer questions about the flow of execution in a program.},
	language = {en},
	booktitle = {Compiler {Construction}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Balakrishnan, Gogul and Gruian, Radu and Reps, Thomas and Teitelbaum, Tim},
	month = apr,
	year = {2005},
	pages = {250--254},
	file = {Balakrishnan et al_2005_CodeSurfer-x86—A Platform for Analyzing x86 Executables.pdf:/home/michael/Dropbox/zotero-pdfs/B/Balakrishnan et al_2005_CodeSurfer-x86—A Platform for Analyzing x86 Executables.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/5IJJMQUQ/978-3-540-31985-6_19.html:text/html}
}

@article{klein_comprehensive_2014,
	title = {Comprehensive {Formal} {Verification} of an {OS} {Microkernel}},
	volume = {32},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/2560537},
	doi = {10.1145/2560537},
	abstract = {We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel. We discuss the kernel design we used to make its verification tractable. We then describe the functional correctness proof of the kernel's C implementation and we cover further steps that transform this result into a comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary code of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a proof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and an automatic initialiser for user-level systems that connects kernel-level access-control enforcement with reasoning about system behaviour. We summarise these results and show how they integrate to form a coherent overall analysis, backed by machine-checked, end-to-end theorems. The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully formally verified to this degree. It is also the only example of formal proof of this scale that is kept current as the requirements, design and implementation of the system evolve over almost a decade. We report on our experience in maintaining this evolving formally verified code base.},
	number = {1},
	urldate = {2017-08-09},
	journal = {ACM Trans. Comput. Syst.},
	author = {Klein, Gerwin and Andronick, June and Elphinstone, Kevin and Murray, Toby and Sewell, Thomas and Kolanski, Rafal and Heiser, Gernot},
	month = feb,
	year = {2014},
	keywords = {Isabelle/HOL, microkernel, seL4, L4, operating systems},
	pages = {2:1--2:70},
	file = {Klein et al_2014_Comprehensive Formal Verification of an OS Microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_2014_Comprehensive Formal Verification of an OS Microkernel.pdf:application/pdf}
}

@inproceedings{elphinstone_formalising_2006,
	title = {Formalising a high-performance microkernel},
	url = {http://isabelle.in.tum.de/~kleing/papers/vstte06.pdf},
	urldate = {2017-08-09},
	booktitle = {Workshop on {Verified} {Software}: {Theories}, {Tools}, and {Experiments} ({VSTTE} 06), {Microsoft} {Research} {Technical} {Report} {MSR}-{TR}-2006-117},
	author = {Elphinstone, Kevin and Klein, Gerwin and Kolanski, Rafal},
	year = {2006},
	pages = {1--7},
	file = {Elphinstone et al_2006_Formalising a high-performance microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elphinstone et al_2006_Formalising a high-performance microkernel.pdf:application/pdf}
}

@inproceedings{porter_rethinking_2011,
	title = {Rethinking the library {OS} from the top down},
	volume = {46},
	url = {http://dl.acm.org/citation.cfm?id=1950399},
	urldate = {2017-08-09},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Porter, Donald E. and Boyd-Wickizer, Silas and Howell, Jon and Olinsky, Reuben and Hunt, Galen C.},
	year = {2011},
	pages = {291--304},
	file = {Porter et al_2011_Rethinking the library OS from the top down.pdf:/home/michael/Dropbox/zotero-pdfs/P/Porter et al_2011_Rethinking the library OS from the top down.pdf:application/pdf}
}

@inproceedings{hawblitzel_garbage-collecting_2007,
	address = {New York, NY, USA},
	series = {{TLDI} '07},
	title = {A {Garbage}-collecting {Typed} {Assembly} {Language}},
	isbn = {978-1-59593-393-5},
	url = {http://doi.acm.org/10.1145/1190315.1190323},
	doi = {10.1145/1190315.1190323},
	abstract = {Typed assembly languages usually support heap allocation safely, but often rely on an external garbage collector to deallocate objects from the heap and prevent unsafe dangling pointers. Even if the external garbage collector is provably correct, verifying the safety of the interaction between TAL programs and garbage collection is nontrivial. This paper introduces a typed assembly language whose type system is expressive enough to type-check a Cheney-queue copying garbage collector, so that ordinary programs and garbage collection can co-exist and interact inside a single typed language. The only built-in types for memory are linear types describing individual memory words, so that TAL programmers can define their own object layouts, method table layouts, heap layouts, and memory management techniques.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2007 {ACM} {SIGPLAN} {International} {Workshop} on {Types} in {Languages} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Hawblitzel, Chris and Huang, Heng and Wittie, Lea and Chen, Juan},
	year = {2007},
	keywords = {typed assembly language, garbage collection},
	pages = {41--52},
	file = {Hawblitzel et al_2007_A Garbage-collecting Typed Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hawblitzel et al_2007_A Garbage-collecting Typed Assembly Language.pdf:application/pdf}
}

@techreport{cheney_linearly_2003,
	title = {A linearly typed assembly language},
	url = {https://ecommons.cornell.edu/handle/1813/5613},
	urldate = {2017-08-09},
	institution = {Cornell University},
	author = {Cheney, James and Morrisett, Greg},
	year = {2003},
	keywords = {linear types, assembly},
	file = {Cheney_Morrisett_2003_A linearly typed assembly language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cheney_Morrisett_2003_A linearly typed assembly language.pdf:application/pdf}
}

@inproceedings{necula_proof-carrying_1997,
	address = {New York, NY, USA},
	series = {{POPL} '97},
	title = {Proof-carrying {Code}},
	isbn = {978-0-89791-853-4},
	url = {http://doi.acm.org/10.1145/263699.263712},
	doi = {10.1145/263699.263712},
	abstract = {This paper describes proof-carrying code (PCC), a mechanism by which a host system can determine with certainty that it is safe to execute a program supplied (possibly in binary form) by an untrusted source. For this to be possible, the untrusted code producer must supply with the code a safety proof that attests to the code's adherence to a previously defined safety policy. The host can then easily and quickly validate the proof without using cryptography and without consulting any external agents.In order to gain preliminary experience with PCC, we have performed several case studies. We show in this paper how proof-carrying code might be used to develop safe assembly-language extensions of ML programs. In the context of this case study, we present and prove the adequacy of concrete representations for the safety policy, the safety proofs, and the proof validation. Finally, we briefly discuss how we use proof-carrying code to develop network packet filters that are faster than similar filters developed using other techniques and are formally guaranteed to be safe with respect to a given operating system safety policy.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 24th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Necula, George C.},
	year = {1997},
	pages = {106--119},
	file = {Necula_1997_Proof-carrying Code.pdf:/home/michael/Dropbox/zotero-pdfs/N/Necula_1997_Proof-carrying Code.pdf:application/pdf}
}

@article{lee_tie:_2011,
	title = {{TIE}: {Principled} reverse engineering of types in binary programs},
	shorttitle = {{TIE}},
	url = {http://repository.cmu.edu/ece/235/},
	urldate = {2017-08-09},
	author = {Lee, JongHyup and Avgerinos, Thanassis and Brumley, David},
	year = {2011},
	file = {Lee et al_2011_TIE - Principled reverse engineering of types in binary programs.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee et al_2011_TIE - Principled reverse engineering of types in binary programs.pdf:application/pdf}
}

@inproceedings{yu_typed_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Typed} {Assembly} {Language} for {Confidentiality}},
	isbn = {978-3-540-33095-0 978-3-540-33096-7},
	url = {https://link.springer.com/chapter/10.1007/11693024_12},
	doi = {10.1007/11693024_12},
	abstract = {Language-based information-flow analysis is promising in protecting data confidentiality. Although much work has been carried out in this area, relatively little has been done for assembly code. Source-level techniques do not easily generalize Techniques at a source level do not generalize straightforwardly to assembly code, because assembly code does not readily present certain abstraction about the program structure that is crucial to information-flow analysis. Nonetheless, low-level information-flow analysis is desirable, because it yields a small trusted computing base. Furthermore, many (untrusted) applications are distributed in native code; their verification should not be overlooked.We present a simple yet effective solution for this problem. Our observation is that the missing abstraction in assembly code can be restored using annotations. Following the philosophy of certifying compilation, these annotations are generated by a compiler, used for static validation, and erased before execution. In particular, we propose a type system for low-level information-flow analysis. Our system is compatible with Typed Assembly Language, and models key features including a call stack, memory tuples and first-class code pointers. A noninterference theorem articulates that well-typed programs respect confidentiality. We also present a security-type preserving translation that targets our system, together with its soundness theorem. This illustrates the application of certifying compilation for noninterference.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Yu, Dachuan and Islam, Nayeem},
	month = mar,
	year = {2006},
	pages = {162--179},
	file = {Snapshot:/home/michael/Zotero/storage/QCTNB9QS/10.html:text/html;Yu_Islam_2006_A Typed Assembly Language for Confidentiality.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yu_Islam_2006_A Typed Assembly Language for Confidentiality.pdf:application/pdf}
}

@inproceedings{breuer_typed_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Typed {Assembler} for a {RISC} {Crypto}-{Processor}},
	isbn = {978-3-642-28165-5 978-3-642-28166-2},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-28166-2_3},
	doi = {10.1007/978-3-642-28166-2_3},
	abstract = {Our general purpose crypto-processor runs RISC machine code in an encrypted environment, reading encrypted inputs and generating encrypted outputs while maintaining data encrypted in memory. Its intended use is secure remote processing. However, program addresses are processed unencrypted, resulting in a mix of encrypted and unencrypted data in memory and registers at any time. An aspect of compiling for it is typing the assembler code to make sure that those instructions that expect encrypted data always get encrypted data at execution time, and those that expect unencrypted data get unencrypted data. A type inference system is specified here and transformed into an executable typing algorithm, such that a type-checked asembler program is guaranteed type-safe.},
	language = {en},
	booktitle = {Engineering {Secure} {Software} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Breuer, Peter T. and Bowen, Jonathan P.},
	month = feb,
	year = {2012},
	pages = {22--29},
	file = {Breuer_Bowen_2012_Typed Assembler for a RISC Crypto-Processor.pdf:/home/michael/Dropbox/zotero-pdfs/B/Breuer_Bowen_2012_Typed Assembler for a RISC Crypto-Processor.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/WC9SWIKI/10.html:text/html}
}

@inproceedings{kim_typed_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Typed {Architectures}: {Architectural} {Support} for {Lightweight} {Scripting}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {Typed {Architectures}},
	url = {http://doi.acm.org/10.1145/3037697.3037726},
	doi = {10.1145/3037697.3037726},
	abstract = {Dynamic scripting languages are becoming more and more widely adopted not only for fast prototyping but also for developing production-grade applications. They provide high-productivity programming environments featuring high levels of abstraction with powerful built-in functions, automatic memory management, object-oriented programming paradigm and dynamic typing. However, their flexible, dynamic type systems easily become the source of inefficiency in terms of instruction count, memory footprint, and energy consumption. This overhead makes it challenging to deploy these high-productivity programming technologies on emerging single-board computers for IoT applications. Addressing this challenge, this paper introduces Typed Architectures, a high-efficiency, low-cost execution substrate for dynamic scripting languages, where each data variable retains high-level type information at an ISA level. Typed Architectures calculate and check the dynamic type of each variable implicitly in hardware, rather than explicitly in software, hence significantly reducing instruction count for dynamic type checking. Besides, Typed Architectures introduce polymorphic instructions (e.g., xadd), which are bound to the correct native instruction at runtime within the pipeline (e.g., add or fadd) to efficiently implement polymorphic operators. Finally, Typed Architectures provide hardware support for flexible yet efficient type tag extraction and insertion, capturing common data layout patterns of tag-value pairs. Our evaluation using a fully synthesizable RISC-V RTL design on FPGA shows that Typed Architectures achieve geomean speedups of 11.2\% and 9.9\% with maximum speedups of 32.6\% and 43.5\% for two production-grade scripting engines for JavaScript and Lua, respectively. Moreover, Typed Architectures improve the energy-delay product (EDP) by 19.3\% for JavaScript and 16.5\% for Lua with an area overhead of 1.6\% at a 40nm technology node.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Kim, Channoh and Kim, Jaehyeok and Kim, Sungmin and Kim, Dooyoung and Kim, Namho and Na, Gitae and Oh, Young H. and Cho, Hyeon Gyu and Lee, Jae W.},
	year = {2017},
	keywords = {instruction set architecture, internet of things (iot), interpreters, javascript, lua, microarchitecture, performance, pipeline, scripting languages, type checking},
	pages = {77--90},
	file = {Kim et al_2017_Typed Architectures - Architectural Support for Lightweight Scripting.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kim et al_2017_Typed Architectures - Architectural Support for Lightweight Scripting.pdf:application/pdf}
}

@inproceedings{fahndrich_language_2006,
	address = {New York, NY, USA},
	series = {{EuroSys} '06},
	title = {Language {Support} for {Fast} and {Reliable} {Message}-based {Communication} in {Singularity} {OS}},
	isbn = {978-1-59593-322-5},
	url = {http://doi.acm.org/10.1145/1217935.1217953},
	doi = {10.1145/1217935.1217953},
	abstract = {Message-based communication offers the potential benefits of providing stronger specification and cleaner separation between components. Compared with shared-memory interactions, message passing has the potential disadvantages of more expensive data exchange (no direct sharing) and more complicated programming.In this paper we report on the language, verification, and run-time system features that make messages practical as the sole means of communication between processes in the Singularity operating system. We show that using advanced programming language and verification techniques, it is possible to provide and enforce strong system-wide invariants that enable efficient communication and low-overhead software-based process isolation. Furthermore, specifications on communication channels help in detecting programmer mistakes early---namely at compile-time---thereby reducing the difficulty of the message-based programming model.The paper describes our communication invariants, the language and verification features that support them, as well as implementation details of the infrastructure. A number of benchmarks show the competitiveness of this approach.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 1st {ACM} {SIGOPS}/{EuroSys} {European} {Conference} on {Computer} {Systems} 2006},
	publisher = {ACM},
	author = {Fähndrich, Manuel and Aiken, Mark and Hawblitzel, Chris and Hodson, Orion and Hunt, Galen and Larus, James R. and Levi, Steven},
	year = {2006},
	keywords = {asynchronous communication, channels, data ownership, protocols, static checking, MAE, CONCURRENCY},
	pages = {177--190},
	file = {Fahndrich et al_2006_Language Support for Fast and Reliable Message-based Communication in.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fahndrich et al_2006_Language Support for Fast and Reliable Message-based Communication in.pdf:application/pdf}
}

@inproceedings{yang_safe_2010,
	address = {New York, NY, USA},
	series = {{PLDI} '10},
	title = {Safe to the {Last} {Instruction}: {Automated} {Verification} of a {Type}-safe {Operating} {System}},
	isbn = {978-1-4503-0019-3},
	shorttitle = {Safe to the {Last} {Instruction}},
	url = {http://doi.acm.org/10.1145/1806596.1806610},
	doi = {10.1145/1806596.1806610},
	abstract = {Typed assembly language (TAL) and Hoare logic can verify the absence of many kinds of errors in low-level code. We use TAL and Hoare logic to achieve highly automated, static verification of the safety of a new operating system called Verve. Our techniques and tools mechanically verify the safety of every assembly language instruction in the operating system, run-time system, drivers, and applications (in fact, every part of the system software except the boot loader). Verve consists of a "Nucleus" that provides primitive access to hardware and memory, a kernel that builds services on top of the Nucleus, and applications that run on top of the kernel. The Nucleus, written in verified assembly language, implements allocation, garbage collection, multiple stacks, interrupt handling, and device access. The kernel, written in C\# and compiled to TAL, builds higher-level services, such as preemptive threads, on top of the Nucleus. A TAL checker verifies the safety of the kernel and applications. A Hoare-style verifier with an automated theorem prover verifies both the safety and correctness of the Nucleus. Verve is, to the best of our knowledge, the first operating system mechanically verified to guarantee both type and memory safety. More generally, Verve's approach demonstrates a practical way to mix high-level typed code with low-level untyped code in a verifiably safe manner.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 31st {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Yang, Jean and Hawblitzel, Chris},
	year = {2010},
	keywords = {type safety, operating system, run-time system, verification},
	pages = {99--110},
	file = {Yang_Hawblitzel_2010_Safe to the Last Instruction.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yang_Hawblitzel_2010_Safe to the Last Instruction.pdf:application/pdf}
}

@inproceedings{derrin_running_2006,
	address = {New York, NY, USA},
	series = {Haskell '06},
	title = {Running the {Manual}: {An} {Approach} to {High}-assurance {Microkernel} {Development}},
	isbn = {978-1-59593-489-5},
	shorttitle = {Running the {Manual}},
	url = {http://doi.acm.org/10.1145/1159842.1159850},
	doi = {10.1145/1159842.1159850},
	abstract = {We propose a development methodology for designing and prototyping high assurance microkernels, and describe our application of it. The methodology is based on rapid prototyping and iterative refinement of the microkernel in a functional programming language. The prototype provides a precise semi-formal model, which is also combined with a machine simulator to form a reference implementation capable of executing real user-level software, to obtain accurate feedback on the suitability of the kernel API during development phases. We extract from the prototype a machine-checkable formal specification in higher-order logic, which may be used to verify properties of the design, and also results in corrections to the design without the need for full verification. We found the approach leads to productive, highly iterative development where formal modelling, semi-formal design and prototyping, and end use all contribute to a more mature final design in a shorter period of time.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2006 {ACM} {SIGPLAN} {Workshop} on {Haskell}},
	publisher = {ACM},
	author = {Derrin, Philip and Elphinstone, Kevin and Klein, Gerwin and Cock, David and Chakravarty, Manuel M. T.},
	year = {2006},
	keywords = {Isabelle/HOL, monads, operating systems, verification, executable specification, formalisation, Haskell, rapid prototyping},
	pages = {60--71},
	file = {Derrin et al_2006_Running the Manual - An Approach to High-assurance Microkernel Development.pdf:/home/michael/Dropbox/zotero-pdfs/D/Derrin et al_2006_Running the Manual - An Approach to High-assurance Microkernel Development.pdf:application/pdf}
}

@inproceedings{weelden_towards_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards a {Strongly} {Typed} {Functional} {Operating} {System}},
	isbn = {978-3-540-40190-2 978-3-540-44854-9},
	url = {https://link.springer.com/chapter/10.1007/3-540-44854-3_14},
	doi = {10.1007/3-540-44854-3_14},
	abstract = {In this paper, we present Famke. It is a prototype implementation of a strongly typed operating system written in Clean. Famke enables the creation and management of independent distributed Clean processes on a network of workstations. It uses Clean’s dynamic type system and its dynamic linker to communicate values of any type, e.g. data, closures, and functions (i.e. compiled code), between running applications in a type safe way. Mobile processes can be implemented using Famke’s ability to communicate functions. We have built an interactive shell on top of Famke that enables user interaction. The shell uses a functional-style command language that allows construction of new processes, and it type checks the command line before executing it. Famke’s type safe run-time extensibility makes it a strongly typed operating system that can be tailored to a given situation.},
	language = {en},
	booktitle = {Implementation of {Functional} {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Weelden, Arjen van and Plasmeijer, Rinus},
	month = sep,
	year = {2002},
	keywords = {TO-READ},
	pages = {215--231},
	file = {Snapshot:/home/michael/Zotero/storage/NER5KF9M/3-540-44854-3_14.html:text/html;Weelden_Plasmeijer_2002_Towards a Strongly Typed Functional Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/W/Weelden_Plasmeijer_2002_Towards a Strongly Typed Functional Operating System.pdf:application/pdf}
}

@inproceedings{winwood_mind_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mind the {Gap}: {A} {Verification} {Framework} for {Low}-{Level} {C}},
	isbn = {978-3-642-03358-2 978-3-642-03359-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-03359-9_34},
	doi = {10.1007/978-3-642-03359-9_34},
	abstract = {This paper presents the formal Isabelle/HOL framework we use to prove refinement between an executable, monadic specification and the C implementation of the seL4 microkernel. We describe the refinement framework itself, the automated tactics it supports, and the connection to our previous C verification framework. We also report on our experience in applying the framework to seL4. The characteristics of this microkernel verification are the size of the target (8,700 lines of C code), the treatment of low-level programming constructs, the focus on high performance, and the large subset of the C programming language addressed, which includes pointer arithmetic and type-unsafe code.},
	language = {en},
	booktitle = {Theorem {Proving} in {Higher} {Order} {Logics}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Winwood, Simon and Klein, Gerwin and Sewell, Thomas and Andronick, June and Cock, David and Norrish, Michael},
	month = aug,
	year = {2009},
	pages = {500--515},
	file = {Snapshot:/home/michael/Zotero/storage/Y4YSGC63/10.html:text/html;Winwood et al_2009_Mind the Gap.pdf:/home/michael/Dropbox/zotero-pdfs/W/Winwood et al_2009_Mind the Gap.pdf:application/pdf}
}

@inproceedings{venkitaraman_static_2004,
	address = {New York, NY, USA},
	series = {{CASES} '04},
	title = {Static {Program} {Analysis} of {Embedded} {Executable} {Assembly} {Code}},
	isbn = {978-1-58113-890-0},
	url = {http://doi.acm.org/10.1145/1023833.1023857},
	doi = {10.1145/1023833.1023857},
	abstract = {We consider the problem of automatically checking if coding standards have been followed in the development of embedded applications. The problem arises from practical considerations because DSP chip manufacturers (in our case Texas Instruments) want various third party software developers to adhere to a certain coding standard to facilitate system integration during application development. Checking for compliance with coding standards, in general, is undecidable. Moreover, only machine code of the system components is available since for proprietary reasons vendors of various components do not want to share their source code. In this paper, we describe an approach based on static analysis of embedded assembly code to check for compliance with such coding standards. This static analysis rests on an abstract interpretation framework. We illustrate our approach by showing how we statically analyze the presence of hard-coded pointer variables in embedded assembly code. Hard coded pointer variables are those that are assigned a fixed memory address by the programmer instead of being assigned a value via proper operations in the source language (e.g., malloc/calloc/realloc and \& operator in C). Our analyzer takes object code as input, disassembles it, builds the flow-graph, and statically analyzes the flow-graph for the presence of dereferenced pointers that are hard coded. The analyzer is currently being extended to check for compliance with other rules adopted by TI as part of its coding standards.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 2004 {International} {Conference} on {Compilers}, {Architecture}, and {Synthesis} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Venkitaraman, Ramakrishnan and Gupta, Gopal},
	year = {2004},
	keywords = {abstract interpretation, assembly code, embedded software components, executable code, static analysis},
	pages = {157--166},
	file = {Venkitaraman_Gupta_2004_Static Program Analysis of Embedded Executable Assembly Code.pdf:/home/michael/Dropbox/zotero-pdfs/V/Venkitaraman_Gupta_2004_Static Program Analysis of Embedded Executable Assembly Code.pdf:application/pdf}
}

@inproceedings{cova_static_2006,
	title = {Static {Detection} of {Vulnerabilities} in x86 {Executables}},
	doi = {10.1109/ACSAC.2006.50},
	abstract = {Several approaches have been proposed to perform vulnerability analysis of applications written in high-level languages. However, little has been done to automatically identify security-relevant flaws in binary code. In this paper, we present a novel approach to the identification of vulnerabilities in x86 executables in ELF binary format. Our approach is based on static analysis and symbolic execution techniques. We implemented our approach in a proof-of-concept tool and used it to detect taint-style vulnerabilities in binary code. The results of our evaluation show that our approach is both practical and effective},
	booktitle = {2006 22nd {Annual} {Computer} {Security} {Applications} {Conference} ({ACSAC}'06)},
	author = {Cova, M. and Felmetsger, V. and Banks, G. and Vigna, G.},
	month = dec,
	year = {2006},
	keywords = {security of data, Application software, binary code, Binary codes, binary static analysis, Computer science, executable and linking format, Geophysical measurement techniques, Ground penetrating radar, High level languages, machine oriented languages, Performance analysis, program diagnostics, Risk analysis, Runtime, Security, security-relevant flaws identification, software tools, symbolic execution, taint analysis, taint analysis., vulnerability analysis, Vulnerability analysis, x86 executables},
	pages = {269--278},
	file = {Cova et al_2006_Static Detection of Vulnerabilities in x86 Executables.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cova et al_2006_Static Detection of Vulnerabilities in x86 Executables.pdf:application/pdf;IEEE Xplore Abstract Record:/home/michael/Zotero/storage/QWBAIFD7/4041173.html:text/html}
}

@inproceedings{heule_stratified_2016,
	address = {New York, NY, USA},
	series = {{PLDI} '16},
	title = {Stratified {Synthesis}: {Automatically} {Learning} the x86-64 {Instruction} {Set}},
	isbn = {978-1-4503-4261-2},
	shorttitle = {Stratified {Synthesis}},
	url = {http://doi.acm.org/10.1145/2908080.2908121},
	doi = {10.1145/2908080.2908121},
	abstract = {The x86-64 ISA sits at the bottom of the software stack of most desktop and server software. Because of its importance, many software analysis and verification tools depend, either explicitly or implicitly, on correct modeling of the semantics of x86-64 instructions. However, formal semantics for the x86-64 ISA are difficult to obtain and often written manually through great effort. We describe an automatically synthesized formal semantics of the input/output behavior for a large fraction of the x86-64 Haswell ISA’s many thousands of instruction variants. The key to our results is stratified synthesis, where we use a set of instructions whose semantics are known to synthesize the semantics of additional instructions whose semantics are unknown. As the set of formally described instructions increases, the synthesis vocabulary expands, making it possible to synthesize the semantics of increasingly complex instructions. Using this technique we automatically synthesized formal semantics for 1,795 instruction variants of the x86-64 Haswell ISA. We evaluate the learned semantics against manually written semantics (where available) and find that they are formally equivalent with the exception of 50 instructions, where the manually written semantics contain an error. We further find the learned formulas to be largely as precise as manually written ones and of similar size.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Heule, Stefan and Schkufza, Eric and Sharma, Rahul and Aiken, Alex},
	year = {2016},
	keywords = {ISA specification, program synthesis, x86-64},
	pages = {237--250},
	file = {Heule et al_2016_Stratified Synthesis - Automatically Learning the x86-64 Instruction Set.pdf:/home/michael/Dropbox/zotero-pdfs/H/Heule et al_2016_Stratified Synthesis - Automatically Learning the x86-64 Instruction Set.pdf:application/pdf}
}

@inproceedings{song_bitblaze:_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{BitBlaze}: {A} {New} {Approach} to {Computer} {Security} via {Binary} {Analysis}},
	isbn = {978-3-540-89861-0 978-3-540-89862-7},
	shorttitle = {{BitBlaze}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-89862-7_1},
	doi = {10.1007/978-3-540-89862-7_1},
	abstract = {In this paper, we give an overview of the BitBlaze project, a new approach to computer security via binary analysis. In particular, BitBlaze focuses on building a unified binary analysis platform and using it to provide novel solutions to a broad spectrum of different security problems. The binary analysis platform is designed to enable accurate analysis, provide an extensible architecture, and combines static and dynamic analysis as well as program verification techniques to satisfy the common needs of security applications. By extracting security-related properties from binary programs directly, BitBlaze enables a principled, root-cause based approach to computer security, offering novel and effective solutions, as demonstrated with over a dozen different security applications.},
	language = {en},
	booktitle = {Information {Systems} {Security}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Song, Dawn and Brumley, David and Yin, Heng and Caballero, Juan and Jager, Ivan and Kang, Min Gyung and Liang, Zhenkai and Newsome, James and Poosankam, Pongsin and Saxena, Prateek},
	month = dec,
	year = {2008},
	pages = {1--25},
	file = {Snapshot:/home/michael/Zotero/storage/GUH3T2FU/10.html:text/html;Song et al_2008_BitBlaze - A New Approach to Computer Security via Binary Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/S/Song et al_2008_BitBlaze - A New Approach to Computer Security via Binary Analysis.pdf:application/pdf}
}

@inproceedings{sampson_enerj:_2011,
	address = {New York, NY, USA},
	series = {{PLDI} '11},
	title = {{EnerJ}: {Approximate} {Data} {Types} for {Safe} and {General} {Low}-power {Computation}},
	isbn = {978-1-4503-0663-8},
	shorttitle = {{EnerJ}},
	url = {http://doi.acm.org/10.1145/1993498.1993518},
	doi = {10.1145/1993498.1993518},
	abstract = {Energy is increasingly a first-order concern in computer systems. Exploiting energy-accuracy trade-offs is an attractive choice in applications that can tolerate inaccuracies. Recent work has explored exposing this trade-off in programming models. A key challenge, though, is how to isolate parts of the program that must be precise from those that can be approximated so that a program functions correctly even as quality of service degrades. We propose using type qualifiers to declare data that may be subject to approximate computation. Using these types, the system automatically maps approximate variables to low-power storage, uses low-power operations, and even applies more energy-efficient algorithms provided by the programmer. In addition, the system can statically guarantee isolation of the precise program component from the approximate component. This allows a programmer to control explicitly how information flows from approximate data to precise data. Importantly, employing static analysis eliminates the need for dynamic checks, further improving energy savings. As a proof of concept, we develop EnerJ, an extension to Java that adds approximate data types. We also propose a hardware architecture that offers explicit approximate storage and computation. We port several applications to EnerJ and show that our extensions are expressive and effective; a small number of annotations lead to significant potential energy savings (10\%-50\%) at very little accuracy cost.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 32Nd {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Sampson, Adrian and Dietl, Werner and Fortuna, Emily and Gnanapragasam, Danushen and Ceze, Luis and Grossman, Dan},
	year = {2011},
	keywords = {accuracy-aware computing, critical data, energy, power-aware computing, soft errors},
	pages = {164--174},
	file = {Sampson et al_2011_EnerJ - Approximate Data Types for Safe and General Low-power Computation.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sampson et al_2011_EnerJ - Approximate Data Types for Safe and General Low-power Computation.pdf:application/pdf}
}

@inproceedings{ringenburg_monitoring_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {Monitoring and {Debugging} the {Quality} of {Results} in {Approximate} {Programs}},
	isbn = {978-1-4503-2835-7},
	url = {http://doi.acm.org/10.1145/2694344.2694365},
	doi = {10.1145/2694344.2694365},
	abstract = {Energy efficiency is a key concern in the design of modern computer systems. One promising approach to energy-efficient computation, approximate computing, trades off output accuracy for significant gains in energy efficiency. However, debugging the actual cause of output quality problems in approximate programs is challenging. This paper presents dynamic techniques to debug and monitor the quality of approximate computations. We propose both offline debugging tools that instrument code to determine the key sources of output degradation and online approaches that monitor the quality of deployed applications. We present two offline debugging techniques and three online monitoring mechanisms. The first offline tool identifies correlations between output quality and the execution of individual approximate operations. The second tracks approximate operations that flow into a particular value. Our online monitoring mechanisms are complementary approaches designed for detecting quality problems in deployed applications, while still maintaining the energy savings from approximation. We present implementations of our techniques and describe their usage with seven applications. Our online monitors control output quality while still maintaining significant energy efficiency gains, and our offline tools provide new insights into the effects of approximation on output quality.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Ringenburg, Michael and Sampson, Adrian and Ackerman, Isaac and Ceze, Luis and Grossman, Dan},
	year = {2015},
	keywords = {approximate computing, debugging, monitoring},
	pages = {399--411},
	file = {Ringenburg et al_2015_Monitoring and Debugging the Quality of Results in Approximate Programs.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ringenburg et al_2015_Monitoring and Debugging the Quality of Results in Approximate Programs.pdf:application/pdf}
}

@article{manohar_comparing_2015,
	title = {Comparing {Stochastic} and {Deterministic} {Computing}},
	volume = {14},
	issn = {1556-6056},
	doi = {10.1109/LCA.2015.2412553},
	abstract = {Technology scaling has raised the specter of myriads of cheap, but unreliable and/or stochastic devices that must be creatively combined to create a reliable computing system. This has renewed the interest in computing that exploits stochasticity-embracing, not combating the device physics. If a stochastic representation is used to implement a programmable general-purpose architecture akin to CPUs, GPUs, or FPGAs, the preponderance of evidence indicates that most of the system energy will be expended in communication and storage as opposed to computation. This paper presents an analytical treatment of the benefits and drawbacks of adopting a stochastic approach by examining the cost of representing a value. We show both scaling laws and costs for low precision representations. We also analyze the cost of multiplication implemented using stochastic versus deterministic approaches, since multiplication is the prototypical inexpensive stochastic operation. We show that the deterministic approach compares favorably to the stochastic approach when holding precision and reliability constant.},
	number = {2},
	journal = {IEEE Computer Architecture Letters},
	author = {Manohar, R.},
	month = jul,
	year = {2015},
	keywords = {Complexity theory, Computer architecture, deterministic computing, Encoding, field programmable gate arrays, FPGAs, general-purpose architecture, GPUs, graphics processing units, Logic gates, Receivers, reliable computing system, stochastic computing, stochastic processes, Stochastic processes, stochastic representation},
	pages = {119--122},
	file = {IEEE Xplore Abstract Record:/home/michael/Zotero/storage/GFDDJU7G/7059235.html:text/html;Manohar_2015_Comparing Stochastic and Deterministic Computing.pdf:/home/michael/Dropbox/zotero-pdfs/M/Manohar_2015_Comparing Stochastic and Deterministic Computing.pdf:application/pdf}
}

@inproceedings{wadler_linear_1990,
	title = {Linear types can change the world},
	volume = {2},
	url = {https://pdfs.semanticscholar.org/4106/dd3be01f1283f80a8260420138d6ee874753.pdf},
	urldate = {2017-08-09},
	booktitle = {{IFIP} {TC}},
	author = {Wadler, Philip},
	year = {1990},
	pages = {347--359},
	file = {Wadler_1990_Linear types can change the world.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_1990_Linear types can change the world.pdf:application/pdf}
}

@article{hawblitzel_linear_2005,
	title = {Linear types for aliased resources},
	url = {https://www.microsoft.com/en-us/research/publication/linear-types-for-aliased-resources/},
	abstract = {Type systems that track aliasing can verify state-dependent program properties. For example, such systems can verify that a program does not access a resource after deallocating the resource. The simplest way to track aliasing is to use linear types, which on the surface appear to ban the aliasing of linear resources entirely. Since banning aliasing …},
	journal = {Microsoft Research},
	author = {Hawblitzel, Chris},
	month = oct,
	year = {2005},
	file = {Hawblitzel_2005_Linear types for aliased resources.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hawblitzel_2005_Linear types for aliased resources.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/KMSRTUES/linear-types-for-aliased-resources.html:text/html}
}

@article{shapiro_towards_2004,
	title = {Towards a verified, general-purpose operating system kernel},
	url = {http://wwwbroy.informatik.tu-muenchen.de/~kleing/papers/os-verify-04.pdf#page=7},
	urldate = {2017-08-09},
	journal = {Klein [10]},
	author = {Shapiro, Jonathan and Doerrie, Michael Scott and Northup, Eric and Sridhar, Swaroop and Miller, Mark},
	year = {2004},
	pages = {1--19},
	file = {Shapiro et al_2004_Towards a verified, general-purpose operating system kernel.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shapiro et al_2004_Towards a verified, general-purpose operating system kernel.pdf:application/pdf}
}

@inproceedings{cousot_abstract_1977,
	address = {New York, NY, USA},
	series = {{POPL} '77},
	title = {Abstract {Interpretation}: {A} {Unified} {Lattice} {Model} for {Static} {Analysis} of {Programs} by {Construction} or {Approximation} of {Fixpoints}},
	shorttitle = {Abstract {Interpretation}},
	url = {http://doi.acm.org/10.1145/512950.512973},
	doi = {10.1145/512950.512973},
	abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe \{(+), (-), (±)\} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 4th {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Cousot, Patrick and Cousot, Radhia},
	year = {1977},
	pages = {238--252},
	file = {Cousot_Cousot_1977_Abstract Interpretation - A Unified Lattice Model for Static Analysis of.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cousot_Cousot_1977_Abstract Interpretation - A Unified Lattice Model for Static Analysis of.pdf:application/pdf}
}

@inproceedings{kildall_unified_1973,
	address = {New York, NY, USA},
	series = {{POPL} '73},
	title = {A {Unified} {Approach} to {Global} {Program} {Optimization}},
	url = {http://doi.acm.org/10.1145/512927.512945},
	doi = {10.1145/512927.512945},
	abstract = {A technique is presented for global analysis of program structure in order to perform compile time optimization of object code generated for expressions. The global expression optimization presented includes constant propagation, common subexpression elimination, elimination of redundant register load operations, and live expression analysis. A general purpose program flow analysis algorithm is developed which depends upon the existence of an "optimizing function." The algorithm is defined formally using a directed graph model of program flow structure, and is shown to be correct. Several optimizing functions are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily be defined for other forms of global code optimization.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 1st {Annual} {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kildall, Gary A.},
	year = {1973},
	pages = {194--206},
	file = {Kildall_1973_A Unified Approach to Global Program Optimization.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kildall_1973_A Unified Approach to Global Program Optimization.pdf:application/pdf}
}

@inproceedings{cousot_systematic_1979,
	address = {New York, NY, USA},
	series = {{POPL} '79},
	title = {Systematic {Design} of {Program} {Analysis} {Frameworks}},
	url = {http://doi.acm.org/10.1145/567752.567778},
	doi = {10.1145/567752.567778},
	abstract = {Semantic analysis of programs is essential in optimizing
compilers and program verification systems. It encompasses data
flow analysis, data type determination, generation of approximate
invariant assertions, etc.

Several recent papers (among others Cousot \& Cousot[77a],
Graham \& Wegman[76], Kam \& Ullman[76], Kildall[73],
Rosen[78], Tarjan[76], Wegbreit[75]) have introduced abstract
approaches to program analysis which are tantamount to the use of a
program analysis framework (A,t,ã) where A is a
lattice of (approximate) assertions, t is an (approximate)
predicate transformer and ã is an often implicit function
specifying the meaning of the elements of A. This paper is devoted
to the systematic and correct design of program analysis frameworks
with respect to a formal semantics.

Preliminary definitions are given in Section 2 concerning the
merge over all paths and (least) fixpoint program-wide analysis
methods. In Section 3 we briefly define the (forward and backward)
deductive semantics of programs which is later used as a formal
basis in order to prove the correctness of the approximate program
analysis frameworks. Section 4 very shortly recall the main
elements of the lattice theoretic approach to approximate semantic
analysis of programs.

The design of a space of approximate assertions A is studied in
Section 5. We first justify the very reasonable assumption that A
must be chosen such that the exact invariant assertions of any
program must have an upper approximation in A and that the
approximate analysis of any program must be performed using a
deterministic process. These assumptions are shown to imply that A
is a Moore family, that the approximation operator (wich defines
the least upper approximation of any assertion) is an upper closure
operator and that A is necessarily a complete lattice. We next show
that the connection between a space of approximate assertions and a
computer representation is naturally made using a pair of isotone
adjoined functions. This type of connection between two complete
lattices is related to Galois connections thus making available
classical mathematical results. Additional results are proved, they
hold when no two approximate assertions have the same meaning.

In Section 6 we study and examplify various methods which can be
used in order to define a space of approximate assertions or
equivalently an approximation function. They include the
characterization of the least Moore family containing an arbitrary
set of assertions, the construction of the least closure operator
greater than or equal to an arbitrary approximation function, the
definition of closure operators by composition, the definition of a
space of approximate assertions by means of a complete join
congruence relation or by means of a family of principal
ideals.

Section 7 is dedicated to the design of the approximate
predicate transformer induced by a space of approximate assertions.
First we look for a reasonable definition of the correctness of
approximate predicate transformers and show that a local
correctness condition can be given which has to be verified for
every type of elementary statement. This local correctness
condition ensures that the (merge over all paths or fixpoint)
global analysis of any program is correct. Since isotony is not
required for approximate predicate transformers to be correct it is
shown that non-isotone program analysis frameworks are manageable
although it is later argued that the isotony hypothesis is natural.
We next show that among all possible approximate predicate
transformers which can be used with a given space of approximate
assertions there exists a best one which provides the maximum
information relative to a program-wide analysis method. The best
approximate predicate transformer induced by a space of approximate
assertions turns out to be isotone. Some interesting consequences
of the existence of a best predicate transformer are examined. One
is that we have in hand a formal specification of the programs
which have to be written in order to implement a program analysis
framework once a representation of the space of approximate
assertions has been chosen. Examples are given, including ones
where the semantics of programs is formalized using Hoare[78]'s
sets of traces.

In Section 8 we show that a hierarchy of approximate analyses
can be defined according to the fineness of the approximations
specified by a program analysis framework. Some elements of the
hierarchy are shortly exhibited and related to the relevant
literature.

In Section 9 we consider global program analysis methods. The
distinction between "distributive" and "non-distributive" program
analysis frameworks is studied. It is shown that when the best
approximate predicate transformer is considered the coincidence or
not of the merge over all paths and least fixpoint global analyses
of programs is a consequence of the choice of the space of
approximate assertions. It is shown that the space of approximate
assertions can always be refined so that the merge over all paths
analysis of a program can be defined by means of a least fixpoint
of isotone equations.

Section 10 is devoted to the combination of program analysis
frameworks. We study and examplify how to perform the "sum",
"product" and "power" of program analysis frameworks. It is shown
that combined analyses lead to more accurate information than the
conjunction of the corresponding separate analyses but this can
only be achieved by a new design of the approximate predicate
transformer induced by the combined program analysis
frameworks.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 6th {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Cousot, Patrick and Cousot, Radhia},
	year = {1979},
	pages = {269--282},
	file = {Cousot_Cousot_1979_Systematic Design of Program Analysis Frameworks.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cousot_Cousot_1979_Systematic Design of Program Analysis Frameworks.pdf:application/pdf}
}

@inproceedings{shivers_control_1988,
	address = {New York, NY, USA},
	series = {{PLDI} '88},
	title = {Control {Flow} {Analysis} in {Scheme}},
	isbn = {978-0-89791-269-3},
	url = {http://doi.acm.org/10.1145/53990.54007},
	doi = {10.1145/53990.54007},
	abstract = {Traditional flow analysis techniques, such as the ones typically employed by optimizing Fortran compilers, do not work for Scheme-like languages. This paper presents a flow analysis technique — control flow analysis — which is applicable to Scheme-like languages. As a demonstration application, the information gathered by control flow analysis is used to perform a traditional flow analysis problem, induction variable elimination. Extensions and limitations are discussed.
The techniques presented in this paper are backed up by working code. They are applicable not only to Scheme, but also to related languages, such as Common Lisp and ML.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1988 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Shivers, O.},
	year = {1988},
	pages = {164--174},
	file = {Shivers_1988_Control Flow Analysis in Scheme.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shivers_1988_Control Flow Analysis in Scheme.pdf:application/pdf}
}

@inproceedings{steensgaard_points-analysis_1996,
	address = {New York, NY, USA},
	series = {{POPL} '96},
	title = {Points-to {Analysis} in {Almost} {Linear} {Time}},
	isbn = {978-0-89791-769-8},
	url = {http://doi.acm.org/10.1145/237721.237727},
	doi = {10.1145/237721.237727},
	abstract = {We present an interprocedural flow-insensitive points-to analysis based on type inference methods with an almost linear time cost complexity To our knowledge, this is the asymptotically fastest non-trivial interprocedural points-to analysis algorithm yet described The algorithm is based on a non-standard type system. The type inferred for any variable represents a set of locations and includes a type which in turn represents a set of locations possibly pointed to by the variable. The type inferred for a function variable represents a set of functions It may point to and includes a type signature for these functions The results are equivalent to those of a flow-insensitive alias analysis (and control flow analysis) that assumes alias relations are reflexive and transitive.This work makes three contributions. The first is a type system for describing a universally valid storage shape graph for a program in linear space. The second is a constraint system which often leads to better results than the "obvious" constraint system for the given type system The third is an almost linear time algorithm for points-to analysis by solving a constraint system.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the 23rd {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Steensgaard, Bjarne},
	year = {1996},
	pages = {32--41},
	file = {Steensgaard_1996_Points-to Analysis in Almost Linear Time.pdf:/home/michael/Dropbox/zotero-pdfs/S/Steensgaard_1996_Points-to Analysis in Almost Linear Time.pdf:application/pdf}
}

@article{cytron_efficiently_1991,
	title = {Efficiently {Computing} {Static} {Single} {Assignment} {Form} and the {Control} {Dependence} {Graph}},
	volume = {13},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/115372.115320},
	doi = {10.1145/115372.115320},
	number = {4},
	urldate = {2017-08-09},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Cytron, Ron and Ferrante, Jeanne and Rosen, Barry K. and Wegman, Mark N. and Zadeck, F. Kenneth},
	month = oct,
	year = {1991},
	keywords = {control dependence, control flow graph, def-use chain, dominator, optimizing compilers},
	pages = {451--490},
	file = {Cytron et al_1991_Efficiently Computing Static Single Assignment Form and the Control Dependence.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cytron et al_1991_Efficiently Computing Static Single Assignment Form and the Control Dependence.pdf:application/pdf}
}

@inproceedings{chisnall_beyond_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {Beyond the {PDP}-11: {Architectural} {Support} for a {Memory}-{Safe} {C} {Abstract} {Machine}},
	isbn = {978-1-4503-2835-7},
	shorttitle = {Beyond the {PDP}-11},
	url = {http://doi.acm.org/10.1145/2694344.2694367},
	doi = {10.1145/2694344.2694367},
	abstract = {We propose a new memory-safe interpretation of the C abstract machine that provides stronger protection to benefit security and debugging. Despite ambiguities in the specification intended to provide implementation flexibility, contemporary implementations of C have converged on a memory model similar to the PDP-11, the original target for C. This model lacks support for memory safety despite well-documented impacts on security and reliability. Attempts to change this model are often hampered by assumptions embedded in a large body of existing C code, dating back to the memory model exposed by the original C compiler for the PDP-11. Our experience with attempting to implement a memory-safe variant of C on the CHERI experimental microprocessor led us to identify a number of problematic idioms. We describe these as well as their interaction with existing memory safety schemes and the assumptions that they make beyond the requirements of the C specification. Finally, we refine the CHERI ISA and abstract model for C, by combining elements of the CHERI capability model and fat pointers, and present a softcore CPU that implements a C abstract machine that can run legacy C code with strong memory protection guarantees.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Chisnall, David and Rothwell, Colin and Watson, Robert N.M. and Woodruff, Jonathan and Vadera, Munraj and Moore, Simon W. and Roe, Michael and Davis, Brooks and Neumann, Peter G.},
	year = {2015},
	keywords = {security, memory safety, bounds checking, C language, capabilities, compilers, memory protection, processor design, TO-READ},
	pages = {117--130},
	file = {Chisnall et al_2015_Beyond the PDP-11.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chisnall et al_2015_Beyond the PDP-11.pdf:application/pdf}
}

@inproceedings{sidiroglou-douskos_targeted_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {Targeted {Automatic} {Integer} {Overflow} {Discovery} {Using} {Goal}-{Directed} {Conditional} {Branch} {Enforcement}},
	isbn = {978-1-4503-2835-7},
	url = {http://doi.acm.org/10.1145/2694344.2694389},
	doi = {10.1145/2694344.2694389},
	abstract = {We present a new technique and system, DIODE, for auto- matically generating inputs that trigger overflows at memory allocation sites. DIODE is designed to identify relevant sanity checks that inputs must satisfy to trigger overflows at target memory allocation sites, then generate inputs that satisfy these sanity checks to successfully trigger the overflow. DIODE works with off-the-shelf, production x86 binaries. Our results show that, for our benchmark set of applications, and for every target memory allocation site exercised by our seed inputs (which the applications process correctly with no overflows), either 1) DIODE is able to generate an input that triggers an overflow at that site or 2) there is no input that would trigger an overflow for the observed target expression at that site.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Sidiroglou-Douskos, Stelios and Lahtinen, Eric and Rittenhouse, Nathan and Piselli, Paolo and Long, Fan and Kim, Deokhwan and Rinard, Martin},
	year = {2015},
	keywords = {bug detection, integer overflow, targeted symbolic execution},
	pages = {473--486},
	file = {Sidiroglou-Douskos et al_2015_Targeted Automatic Integer Overflow Discovery Using Goal-Directed Conditional.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sidiroglou-Douskos et al_2015_Targeted Automatic Integer Overflow Discovery Using Goal-Directed Conditional.pdf:application/pdf}
}

@inproceedings{sridharan_memory_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {Memory {Errors} in {Modern} {Systems}: {The} {Good}, {The} {Bad}, and {The} {Ugly}},
	isbn = {978-1-4503-2835-7},
	shorttitle = {Memory {Errors} in {Modern} {Systems}},
	url = {http://doi.acm.org/10.1145/2694344.2694348},
	doi = {10.1145/2694344.2694348},
	abstract = {Several recent publications have shown that hardware faults in the memory subsystem are commonplace. These faults are predicted to become more frequent in future systems that contain orders of magnitude more DRAM and SRAM than found in current memory subsystems. These memory subsystems will need to provide resilience techniques to tolerate these faults when deployed in high-performance computing systems and data centers containing tens of thousands of nodes. Therefore, it is critical to understand the efficacy of current hardware resilience techniques to determine whether they will be suitable for future systems. In this paper, we present a study of DRAM and SRAM faults and errors from the field. We use data from two leadership-class high-performance computer systems to analyze the reliability impact of hardware resilience schemes that are deployed in current systems. Our study has several key findings about the efficacy of many currently deployed reliability techniques such as DRAM ECC, DDR address/command parity, and SRAM ECC and parity. We also perform a methodological study, and find that counting errors instead of faults, a common practice among researchers and data center operators, can lead to incorrect conclusions about system reliability. Finally, we use our data to project the needs of future large-scale systems. We find that SRAM faults are unlikely to pose a significantly larger reliability threat in the future, while DRAM faults will be a major concern and stronger DRAM resilience schemes will be needed to maintain acceptable failure rates similar to those found on today's systems.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Sridharan, Vilas and DeBardeleben, Nathan and Blanchard, Sean and Ferreira, Kurt B. and Stearley, Jon and Shalf, John and Gurumurthi, Sudhanva},
	year = {2015},
	keywords = {field studies, large-scale systems, reliability},
	pages = {297--310},
	file = {Sridharan et al_2015_Memory Errors in Modern Systems - The Good, The Bad, and The Ugly.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sridharan et al_2015_Memory Errors in Modern Systems - The Good, The Bad, and The Ugly.pdf:application/pdf}
}

@inproceedings{zhang_hardware_2015,
	address = {New York, NY, USA},
	series = {{ASPLOS} '15},
	title = {A {Hardware} {Design} {Language} for {Timing}-{Sensitive} {Information}-{Flow} {Security}},
	isbn = {978-1-4503-2835-7},
	url = {http://doi.acm.org/10.1145/2694344.2694372},
	doi = {10.1145/2694344.2694372},
	abstract = {Information security can be compromised by leakage via low-level hardware features. One recently prominent example is cache probing attacks, which rely on timing channels created by caches. We introduce a hardware design language, SecVerilog, which makes it possible to statically analyze information flow at the hardware level. With SecVerilog, systems can be built with verifiable control of timing channels and other information channels. SecVerilog is Verilog, extended with expressive type annotations that enable precise reasoning about information flow. It also comes with rigorous formal assurance: we prove that SecVerilog enforces timing-sensitive noninterference and thus ensures secure information flow. By building a secure MIPS processor and its caches, we demonstrate that SecVerilog makes it possible to build complex hardware designs with verified security, yet with low overhead in time, space, and HW designer effort.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Zhang, Danfeng and Wang, Yao and Suh, G. Edward and Myers, Andrew C.},
	year = {2015},
	keywords = {dependent types, hardware description language, information flow control, timing channels},
	pages = {503--516},
	file = {Zhang et al_2015_A Hardware Design Language for Timing-Sensitive Information-Flow Security.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhang et al_2015_A Hardware Design Language for Timing-Sensitive Information-Flow Security.pdf:application/pdf}
}

@inproceedings{bornholt_specifying_2016,
	address = {New York, NY, USA},
	series = {{ASPLOS} '16},
	title = {Specifying and {Checking} {File} {System} {Crash}-{Consistency} {Models}},
	isbn = {978-1-4503-4091-5},
	url = {http://doi.acm.org/10.1145/2872362.2872406},
	doi = {10.1145/2872362.2872406},
	abstract = {Applications depend on persistent storage to recover state after system crashes. But the POSIX file system interfaces do not define the possible outcomes of a crash. As a result, it is difficult for application writers to correctly understand the ordering of and dependencies between file system operations, which can lead to corrupt application state and, in the worst case, catastrophic data loss. This paper presents crash-consistency models, analogous to memory consistency models, which describe the behavior of a file system across crashes. Crash-consistency models include both litmus tests, which demonstrate allowed and forbidden behaviors, and axiomatic and operational specifications. We present a formal framework for developing crash-consistency models, and a toolkit, called Ferrite, for validating those models against real file system implementations. We develop a crash-consistency model for ext4, and use Ferrite to demonstrate unintuitive crash behaviors of the ext4 implementation. To demonstrate the utility of crash-consistency models to application writers, we use our models to prototype proof-of-concept verification and synthesis tools, as well as new library interfaces for crash-safe applications.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Bornholt, James and Kaufmann, Antoine and Li, Jialin and Krishnamurthy, Arvind and Torlak, Emina and Wang, Xi},
	year = {2016},
	keywords = {verification, crash consistency, file systems},
	pages = {83--98},
	file = {Bornholt et al_2016_Specifying and Checking File System Crash-Consistency Models.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bornholt et al_2016_Specifying and Checking File System Crash-Consistency Models.pdf:application/pdf}
}

@inproceedings{fernandez_towards_2013,
	address = {New York, NY, USA},
	series = {{PLOS} '13},
	title = {Towards a {Verified} {Component} {Platform}},
	isbn = {978-1-4503-2460-1},
	url = {http://doi.acm.org/10.1145/2525528.2525535},
	doi = {10.1145/2525528.2525535},
	abstract = {This paper describes ongoing work on a new technique for reducing the cost of assurance of large software systems by building on a verified component platform. From a component architecture description, we automatically derive a formal model of the system and a semantics for the runtime behaviour of generated inter-component communication code. We can prove wellformedness properties of the architecture automatically and provide a framework in which users can reason about their component code and its behaviour. By leveraging the isolation properties and communication guarantees of a formally verified platform, correctness arguments for critical components will be able to be derived independently and composed together to reason about system-level correctness.},
	urldate = {2017-08-09},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Fernandez, Matthew and Kuz, Ihor and Klein, Gerwin and Andronick, June},
	year = {2013},
	pages = {2:1--2:7},
	file = {Fernandez et al_2013_Towards a Verified Component Platform.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fernandez et al_2013_Towards a Verified Component Platform.pdf:application/pdf}
}

@book{curry_combinatory_1958,
	title = {Combinatory {Logic}},
	publisher = {North-Holland Publishing Company},
	author = {Curry, Haskell and Feys, Robert},
	year = {1958},
	keywords = {combinatory logic}
}

@incollection{howard_formulas-as-types_1980,
	address = {New York},
	title = {The formulas-as-types notion of construction},
	url = {http://lecomte.al.free.fr/ressources/PARIS8_LSL/Howard80.pdf},
	urldate = {2017-08-10},
	booktitle = {To {H}. {B}. {Curry}: {Essays} on {Combinatory} {Logic}, {Lambda} {Calculus}, and {Formalism}},
	publisher = {Academic Press},
	author = {Howard, William},
	year = {1980},
	keywords = {classic-PL},
	pages = {479--490},
	file = {Howard_1980_The formulas-as-types notion of construction.pdf:/home/michael/Dropbox/zotero-pdfs/H/Howard_1980_The formulas-as-types notion of construction.pdf:application/pdf}
}

@book{pfenning_computation_2001,
	title = {Computation and {Deduction}},
	abstract = {Syntax  The language of types centrally a\#ects the kinds of expression constructs that should be available in the language. The types we include in our formulation of MiniML are natural numbers, products, and function types. Many phenomena in the theory of Mini-ML can be explored with these types; some others are the subject of Exercises 2.7, 2.8, and 2.10. For our purposes it is convenient to ignore certain questions of concrete syntax and parsing and present the abstract syntax of the language in Backus Naur Form (BNF). The vertical bar "{\textbar}" separates alternatives on the right-hand side of the definition symbol "::=". Definitions in this style 9  10 CHAPTER 2. THE MINI-ML LANGUAGE can be understood as inductive definitions of syntactic categories such as types or expressions.},
	author = {Pfenning, Frank},
	year = {2001},
	file = {Citeseer - Snapshot:/home/michael/Zotero/storage/F5CX6D7V/summary.html:text/html;Pfenning_2001_Computation and Deduction.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_2001_Computation and Deduction.pdf:application/pdf}
}

@book{goubault-larrecq_proof_2001,
	title = {Proof {Theory} and {Automated} {Deduction}},
	isbn = {978-1-4020-0368-4},
	abstract = {The last twenty years have witnessed an accelerated development of pure and ap plied logic, particularly in response to the urgent needs of computer science. Many traditional logicians have developed interest in applications and in parallel a new generation of researchers in logic has arisen from the computer science community. A new attitude to applied logic has evolved, where researchers tailor a logic for their own use in the same way they define a computer language, and where auto mated deduction for the logic and its fragments is as important as the logic itself. In such a climate there is a need to emphasise algorithmic logic methodologies alongside any individual logics. Thus the tableaux method or the resolution method are as central to todays discipline of logic as classical logic or intuitionistic logic are. From this point of view, J. Goubault and I. Mackie's book on Proof Theory and Automated Deduction is most welcome. It covers major algorithmic methodolo gies as well as a variety of logical systems. It gives a wide overview for the ap plied consumer of logic while at the same time remains relatively elementary for the beginning student. A decade ago I put forward my view that a logical system should be presented as a point in a grid. One coordinate is its philosphy, motivation, its accepted theorems and its required non-theorems. The other coordinate is the algorithmic methodol ogy and execution chosen for its effective presentation. Together these two aspects constitute a 'logic'.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Goubault-Larrecq, Jean and Mackie, I.},
	month = nov,
	year = {2001},
	note = {Google-Books-ID: izUG9d2iNosC},
	keywords = {Computers / Intelligence (AI) \& Semantics, Computers / Programming / Algorithms, Mathematics / Discrete Mathematics, Mathematics / General, Mathematics / History \& Philosophy, Mathematics / Logic, Philosophy / Logic}
}

@book{simmons_derivation_2000,
	title = {Derivation and {Computation}: {Taking} the {Curry}-{Howard} {Correspondence} {Seriously}},
	isbn = {978-0-521-77173-3},
	shorttitle = {Derivation and {Computation}},
	abstract = {Mathematics is about proofs, that is the derivation of correct statements; and calculations, that is the production of results according to well-defined sets of rules. The two notions are intimately related. Proofs can involve calculations, and the algorithm underlying a calculation should be proved correct. The aim of the author is to explore this relationship. The book itself forms an introduction to simple type theory. Starting from the familiar propositional calculus the author develops the central idea of an applied lambda-calculus. This is illustrated by an account of Gdel's T, a system which codifies number-theoretic function hierarchies. Each of the book's 52 sections ends with a set of exercises, some 200 in total. These are designed to help the reader get to grips with the subject, and develop a further understanding. An appendix contains complete solutions of these exercises.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Simmons, H.},
	month = may,
	year = {2000},
	note = {Google-Books-ID: J6qWPYIhFCoC},
	keywords = {Mathematics / Discrete Mathematics, Mathematics / History \& Philosophy, Mathematics / Logic, Mathematics / Calculus}
}

@article{girard_linear_1987,
	title = {Linear logic},
	volume = {50},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397587900454},
	doi = {10.1016/0304-3975(87)90045-4},
	abstract = {The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.},
	number = {1},
	urldate = {2017-08-10},
	journal = {Theoretical Computer Science},
	author = {Girard, Jean-Yves},
	month = jan,
	year = {1987},
	keywords = {classic-PL},
	pages = {1--101},
	file = {Girard_1987_Linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/G/Girard_1987_Linear logic.pdf:application/pdf;ScienceDirect Snapshot:/home/michael/Zotero/storage/FJIZWAXQ/0304397587900454.html:text/html}
}

@inproceedings{wadler_is_1991,
	address = {New York, NY, USA},
	series = {{PEPM} '91},
	title = {Is {There} a {Use} for {Linear} {Logic}?},
	isbn = {978-0-89791-433-8},
	url = {http://doi.acm.org/10.1145/115865.115894},
	doi = {10.1145/115865.115894},
	urldate = {2017-08-10},
	booktitle = {Proceedings of the 1991 {ACM} {SIGPLAN} {Symposium} on {Partial} {Evaluation} and {Semantics}-based {Program} {Manipulation}},
	publisher = {ACM},
	author = {Wadler, Philip},
	year = {1991},
	pages = {255--273},
	file = {Wadler_1991_Is There a Use for Linear Logic.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_1991_Is There a Use for Linear Logic.pdf:application/pdf}
}

@inproceedings{hodas_lolli:_1992,
	title = {Lolli: {An} {Extension} of {Lambda}-{Prolog} with {Linear} {Logic} {Context} {Management}},
	shorttitle = {Lolli},
	abstract = {This paperappears in the proceedings of the 1992 Workshop on the Prolog Programming Language. The entire proceedings is available electronically at http://www.cis.upenn.edu/{\textasciitilde}dale/lProlog/workshop92.html.  then the proof of the goal off {\textbackslash}Gammaffi toggle(G) might proceed as follows: {\textbackslash}Gamma; off {\textbackslash}Gamma! off},
	booktitle = {In {Prolog} {Worshop}},
	author = {Hodas, Joshua S.},
	year = {1992},
	file = {Citeseer - Snapshot:/home/michael/Zotero/storage/NWML5ZGT/summary.html:text/html;Hodas_1992_Lolli - An Extension of Lambda-Prolog with Linear Logic Context Management.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hodas_1992_Lolli - An Extension of Lambda-Prolog with Linear Logic Context Management.pdf:application/pdf}
}

@article{mackie_lilac:_1994,
	title = {Lilac: a functional programming language based on linear logic},
	volume = {4},
	issn = {1469-7653, 0956-7968},
	shorttitle = {Lilac},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/lilac-a-functional-programming-language-based-on-linear-logic/67CAB4EBFCC3B9861BEFA108793C699A},
	doi = {10.1017/S0956796800001131},
	abstract = {AbstractWe take Abramsky's term assignment for Intuitionistic Linear Logic (the linear term calculus) as the basis of a functional programming language. This is a language where the programmer must embed explicitly the resource and control information of an algorithm. We give a type reconstruction algorithm for our language in the style of Milner's W algorithm, together with a description of the implementation and examples of use.},
	number = {4},
	journal = {Journal of Functional Programming},
	author = {Mackie, Ian},
	month = oct,
	year = {1994},
	pages = {395--433},
	file = {Snapshot:/home/michael/Zotero/storage/B8BJTXIY/67CAB4EBFCC3B9861BEFA108793C699A.html:text/html}
}

@article{kobayashi_linearity_1999,
	title = {Linearity and the {Pi}-calculus},
	volume = {21},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/330249.330251},
	doi = {10.1145/330249.330251},
	abstract = {The economy and flexibility of the pi-calculus make it an attractive object of theoretical study and a clean basis for concurrent language design and implementation. However, such generality has a cost: encoding higher-level features like functional computation in pi-calculus throws away potentially useful information. We show how a linear type system can be used to recover important static information about a process's behavior. In particular, we can guarantee that two processes communicating over a linear channel cannot interfere with other communicating processes. After developing standard results such as soundness of typing, we focus on equivalences, adapting the standard notion of barbed bisimulation to the linear setting and showing how reductions on linear channels induce a  useful “partial confluence” of process behaviors. For an extended example of the theory, we prove the validity of a tail-call optimization for higher-order functions represented as processes.},
	number = {5},
	urldate = {2017-08-10},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Kobayashi, Naoki and Pierce, Benjamin C. and Turner, David N.},
	month = sep,
	year = {1999},
	keywords = {linear types, concurrency, confluence, pi-calculus, process calculi},
	pages = {914--947},
	file = {Kobayashi et al_1999_Linearity and the Pi-calculus.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kobayashi et al_1999_Linearity and the Pi-calculus.pdf:application/pdf}
}

@article{davies_modal_2001,
	title = {A {Modal} {Analysis} of {Staged} {Computation}},
	volume = {48},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/382780.382785},
	doi = {10.1145/382780.382785},
	abstract = {We show that a type system based on the intuitionistic modal logic S4  provides an expressive framework for specifying and analyzing computation stages in the context of typed \&lgr;-calculi and functional languages. We directly demonstrate the sense in which our   l→□e -calculus captures staging, and also give a conservative embeddng of Nielson and Nielson's two-level functional language in our functional language Mini-ML  □ , thus proving  that binding-time correctness is equivalent to modal correctness on this fragment. In addition,   Mini-ML□    can also express immediate evaluation and sharing of code across multiple stages, thus supporting run-time code generation as well as partial evaluation.},
	number = {3},
	urldate = {2017-08-10},
	journal = {J. ACM},
	author = {Davies, Rowan and Pfenning, Frank},
	month = may,
	year = {2001},
	keywords = {binding times, run-time code generation, staged computation},
	pages = {555--604},
	file = {Davies_Pfenning_2001_A Modal Analysis of Staged Computation.pdf:/home/michael/Dropbox/zotero-pdfs/D/Davies_Pfenning_2001_A Modal Analysis of Staged Computation.pdf:application/pdf}
}

@article{wickline_modal_1998,
	title = {Modal types as staging specifications for run-time code generation},
	volume = {30(3es)},
	url = {https://www.cs.cmu.edu/~fp/papers/sope98.pdf},
	urldate = {2017-08-10},
	journal = {ACM Comput. Surv.},
	author = {Wickline, Philip and Pfenning, Frank and Davies, Rowan},
	month = sep,
	year = {1998},
	file = {Wickline et al_1998_Modal types as staging specifications for run-time code generation.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wickline et al_1998_Modal types as staging specifications for run-time code generation.pdf:application/pdf}
}

@article{gallier_constructive_1993,
	title = {Constructive logics {Part} {I}: {A} tutorial on proof systems and typed λ-calculi},
	volume = {110},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/030439759390011H},
	doi = {http://dx.doi.org/10.1016/0304-3975(93)90011-H},
	number = {2},
	journal = {Theoretical Computer Science},
	author = {Gallier, Jean},
	year = {1993},
	pages = {249 -- 339},
	file = {Gallier_1993_Constructive logics Part I - A tutorial on proof systems and typed λ-calculi.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gallier_1993_Constructive logics Part I - A tutorial on proof systems and typed λ-calculi.pdf:application/pdf}
}

@inproceedings{nielson_type_1999,
	address = {London, UK, UK},
	title = {Type and {Effect} {Systems}},
	isbn = {978-3-540-66624-0},
	url = {http://dl.acm.org/citation.cfm?id=646005.673740},
	abstract = {The design and implementation of a correct system can benefit from employing static techniques for ensuring that the dynamic behaviour satisfies the specification. Many programming languages incorporate types for ensuring that certain operations are only applied to data of the appropriate form. A natural extension of type checking techniques is to enrich the types with annotations and effects that further describe intensional aspects of the dynamic behaviour.},
	urldate = {2017-08-10},
	booktitle = {Correct {System} {Design}, {Recent} {Insight} and {Advances}, (to {Hans} {Langmaack} on the {Occasion} of {His} {Retirement} from {His} {Professorship} at the {University} of {Kiel})},
	publisher = {Springer-Verlag},
	author = {Nielson, Flemming and Nielson, Hanne Riis},
	year = {1999},
	pages = {114--136},
	file = {Nielson_Nielson_1999_Type and Effect Systems.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nielson_Nielson_1999_Type and Effect Systems.pdf:application/pdf}
}

@article{gentzen_investigations_1964,
	title = {Investigations into {Logical} {Deduction}},
	volume = {1},
	issn = {0003-0481},
	url = {http://www.jstor.org/stable/20009142},
	doi = {10.2307/20009142},
	number = {4},
	urldate = {2017-08-10},
	journal = {American Philosophical Quarterly},
	author = {Gentzen, Gerhard},
	year = {1964},
	keywords = {classic-PL},
	pages = {288--306},
	file = {Gentzen_1964_Investigations into Logical Deduction.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gentzen_1964_Investigations into Logical Deduction.pdf:application/pdf}
}

@article{hoare_axiomatic_1969,
	title = {An {Axiomatic} {Basis} for {Computer} {Programming}},
	volume = {12},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/363235.363259},
	doi = {10.1145/363235.363259},
	abstract = {In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. This involves the elucidation of sets of axioms and rules of inference which can be used in proofs of the properties of computer programs. Examples are given of such axioms and rules, and a formal proof of a simple theorem is displayed. Finally, it is argued that important advantage, both theoretical and practical, may follow from a pursuance of these topics.},
	number = {10},
	urldate = {2017-08-10},
	journal = {Commun. ACM},
	author = {Hoare, C. A. R.},
	month = oct,
	year = {1969},
	keywords = {programming language design, classic-PL, axiomatic method, formal language definition, machine-independent programming, program documentation, theory of programming' proofs of programs},
	pages = {576--580},
	file = {Hoare_1969_An Axiomatic Basis for Computer Programming.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1969_An Axiomatic Basis for Computer Programming.pdf:application/pdf}
}

@article{dijkstra_guarded_1975,
	title = {Guarded {Commands}, {Nondeterminacy} and {Formal} {Derivation} of {Programs}},
	volume = {18},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/360933.360975},
	doi = {10.1145/360933.360975},
	abstract = {So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.},
	number = {8},
	urldate = {2017-08-10},
	journal = {Commun. ACM},
	author = {Dijkstra, Edsger W.},
	month = aug,
	year = {1975},
	keywords = {programming languages, classic-PL, case-construction, correctness proof, derivation of programs, nondeterminancy, program semantics, programming language semantics, programming methodology, repetition, sequencing primitives, termination},
	pages = {453--457},
	file = {Dijkstra_1975_Guarded Commands, Nondeterminacy and Formal Derivation of Programs.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dijkstra_1975_Guarded Commands, Nondeterminacy and Formal Derivation of Programs.pdf:application/pdf}
}

@article{hoare_proof_1971,
	title = {Proof of a {Program}: {FIND}},
	volume = {14},
	issn = {0001-0782},
	shorttitle = {Proof of a {Program}},
	url = {http://doi.acm.org/10.1145/362452.362489},
	doi = {10.1145/362452.362489},
	abstract = {A proof is given of the correctness of the algorithm “Find.” First, an informal description is given of the purpose of the program and the method used. A systematic technique is described for constructing the program proof during the process of coding it, in such a way as to prevent the intrusion of logical errors. The proof of termination is treated as a separate exercise. Finally, some conclusions relating to general programming methodology are drawn.},
	number = {1},
	urldate = {2017-08-10},
	journal = {Commun. ACM},
	author = {Hoare, C. A. R.},
	month = jan,
	year = {1971},
	keywords = {classic-PL, program documentation, programming methodology, program correctness, proofs of programs, theory of programming},
	pages = {39--45},
	file = {Hoare_1971_Proof of a Program - FIND.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1971_Proof of a Program - FIND.pdf:application/pdf}
}

@article{church_properties_1936,
	title = {Some {Properties} of {Conversion}},
	volume = {39},
	issn = {00029947},
	url = {http://www.jstor.org/stable/1989762?origin=crossref},
	doi = {10.2307/1989762},
	number = {3},
	urldate = {2017-08-10},
	journal = {Transactions of the American Mathematical Society},
	author = {Church, Alonzo and Rosser, J. B.},
	month = may,
	year = {1936},
	keywords = {classic-PL},
	pages = {472},
	file = {Church_Rosser_1936_Some Properties of Conversion.pdf:/home/michael/Dropbox/zotero-pdfs/C/Church_Rosser_1936_Some Properties of Conversion.pdf:application/pdf}
}

@article{landin_mechanical_1964,
	title = {The mechanical evaluation of expressions},
	volume = {6},
	url = {https://academic.oup.com/comjnl/article-abstract/6/4/308/375725},
	number = {4},
	urldate = {2017-08-10},
	journal = {The Computer Journal},
	author = {Landin, Peter J.},
	year = {1964},
	keywords = {classic-PL},
	pages = {308--320},
	file = {Landin_1964_The mechanical evaluation of expressions.pdf:/home/michael/Dropbox/zotero-pdfs/L/Landin_1964_The mechanical evaluation of expressions.pdf:application/pdf}
}

@article{hoare_communicating_1978,
	title = {Communicating {Sequential} {Processes}},
	volume = {21},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359576.359585},
	doi = {10.1145/359576.359585},
	abstract = {This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions of a variety of a familiar programming exercises.},
	number = {8},
	urldate = {2017-08-10},
	journal = {Commun. ACM},
	author = {Hoare, C. A. R.},
	month = aug,
	year = {1978},
	keywords = {concurrency, monitors, programming languages, programming, classic-PL, classes, conditional critical regions, coroutines, data representations, guarded commands, input, iterative arrays, multiple entries, multiple exits, nondeterminacy, output, parallel programming, procedures, program structures, programming primitives, recursion},
	pages = {666--677},
	file = {Hoare_1978_Communicating Sequential Processes.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1978_Communicating Sequential Processes.pdf:application/pdf}
}

@article{martin-lof_meanings_1996,
	title = {On the meanings of the logical constants and the justifications of the logical laws},
	volume = {1},
	url = {http://www.ae-info.org/attach/User/Martin-L%C3%B6f_Per/OtherInformation/article.pdf},
	number = {1},
	urldate = {2017-08-10},
	journal = {Nordic journal of philosophical logic},
	author = {Martin-LÖf, Per},
	year = {1996},
	keywords = {classic-PL},
	pages = {11--60},
	file = {Martin-Lof_1996_On the meanings of the logical constants and the justifications of the logical.pdf:/home/michael/Dropbox/zotero-pdfs/M/Martin-Lof_1996_On the meanings of the logical constants and the justifications of the logical.pdf:application/pdf}
}

@misc{martin-lof_intuitionistic_1980,
	title = {Intuitionistic {Type} {Theory}},
	url = {https://www.cs.cmu.edu/~crary/819-f09/Martin-Lof80.pdf},
	urldate = {2017-08-10},
	author = {Martin-Löf, Per},
	year = {1980},
	keywords = {classic-PL},
	file = {Martin-Lof_1980_Intuitionistic Type Theory.pdf:/home/michael/Dropbox/zotero-pdfs/M/Martin-Lof_1980_Intuitionistic Type Theory.pdf:application/pdf}
}

@book{scott_towards_1971,
	title = {Towards a mathematical semantics for computer languages},
	url = {https://www.cs.cmu.edu/~crary/819-f09/Scott71.pdf},
	urldate = {2017-08-10},
	author = {Scott, Dana and Strachey, Christopher},
	year = {1971},
	keywords = {classic-PL},
	file = {Scott_Strachey_1971_Towards a mathematical semantics for computer languages.pdf:/home/michael/Dropbox/zotero-pdfs/S/Scott_Strachey_1971_Towards a mathematical semantics for computer languages.pdf:application/pdf}
}

@inproceedings{moggi_computational_1989,
	address = {Piscataway, NJ, USA},
	title = {Computational {Lambda}-calculus and {Monads}},
	isbn = {978-0-8186-1954-0},
	url = {http://dl.acm.org/citation.cfm?id=77350.77353},
	urldate = {2017-08-10},
	booktitle = {Proceedings of the {Fourth} {Annual} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {IEEE Press},
	author = {Moggi, E.},
	year = {1989},
	keywords = {classic-PL},
	pages = {14--23},
	file = {Moggi_1989_Computational Lambda-calculus and Monads.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moggi_1989_Computational Lambda-calculus and Monads.pdf:application/pdf}
}

@incollection{reynolds_essence_1997,
	address = {Cambridge, MA, USA},
	title = {The essence of {ALGOL}},
	volume = {1},
	isbn = {978-0-8176-3880-1},
	url = {http://dl.acm.org/citation.cfm?id=251167.251168},
	urldate = {2017-08-10},
	booktitle = {{ALGOL}-like {Languages}},
	publisher = {Birkhauser Boston Inc.},
	author = {Reynolds, John C.},
	editor = {O'Hearn, Peter W. and Tennent, Robert D.},
	year = {1997},
	keywords = {classic-PL},
	pages = {67--88},
	file = {Reynolds_1997_The essence of ALGOL.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reynolds_1997_The essence of ALGOL.pdf:application/pdf}
}

@inproceedings{reynolds_towards_1974,
	address = {London, UK, UK},
	title = {Towards a {Theory} of {Type} {Structure}},
	isbn = {978-3-540-06859-4},
	url = {http://dl.acm.org/citation.cfm?id=647323.721503},
	urldate = {2017-08-10},
	booktitle = {Programming {Symposium}, {Proceedings} {Colloque} {Sur} {La} {Programmation}},
	publisher = {Springer-Verlag},
	author = {Reynolds, John C.},
	year = {1974},
	keywords = {classic-PL},
	pages = {408--423},
	file = {Reynolds_1974_Towards a Theory of Type Structure.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reynolds_1974_Towards a Theory of Type Structure.pdf:application/pdf}
}

@techreport{murthy_evaluation_1991,
	title = {An {Evaluation} {Semantics} for {Classical} {Proofs}},
	url = {https://www.cs.cmu.edu/~crary/819-f09/Murthy91.pdf},
	number = {TR 91-1213},
	urldate = {2017-08-10},
	author = {Murthy, Chetan},
	month = jun,
	year = {1991},
	keywords = {classic-PL},
	file = {Murthy_1991_An Evaluation Semantics for Classical Proofs.pdf:/home/michael/Dropbox/zotero-pdfs/M/Murthy_1991_An Evaluation Semantics for Classical Proofs.pdf:application/pdf}
}

@article{reynolds_types_1983,
	series = {Information {Processing}},
	title = {Types, {Abstraction} and {Parametric} {Polymorphism}},
	url = {https://www.cs.cmu.edu/~crary/819-f09/Reynolds83.pdf},
	urldate = {2017-08-10},
	author = {Reynolds, John},
	year = {1983},
	keywords = {classic-PL},
	file = {Reynolds_1983_Types, Abstraction and Parametric Polymorphism.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reynolds_1983_Types, Abstraction and Parametric Polymorphism.pdf:application/pdf}
}

@inproceedings{macqueen_using_1986,
	address = {New York, NY, USA},
	series = {{POPL} '86},
	title = {Using {Dependent} {Types} to {Express} {Modular} {Structure}},
	url = {http://doi.acm.org/10.1145/512644.512670},
	doi = {10.1145/512644.512670},
	abstract = {Writing any large program poses difficult problems of organization. In many modern programming languages these problems are addressed by special linguistic constructs, variously known as modules, packages, or clusters, which provide for partitioning programs into manageable components and for securely combining these components to form complete programs. Some general purpose components are able to take on a life of their own, being separately compiled and stored in libraries of generic, reusable program units. Usually modularity constructs also support some form of information hiding, such as "abstract data types." "Programming in the large" is concerned with using such constructs to impose structure on large programs, in contrast to "programming in the small", which deals with the detailed implementation of algorithms in terms of data structures and control constructs. Our goal here is to examine some of the proposed linguistic notions with respect to how they meet the pragmatic requirements of programming in the large.},
	urldate = {2017-08-10},
	booktitle = {Proceedings of the 13th {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {MacQueen, David B.},
	year = {1986},
	keywords = {classic-PL},
	pages = {277--286},
	file = {MacQueen_1986_Using Dependent Types to Express Modular Structure.pdf:/home/michael/Dropbox/zotero-pdfs/M/MacQueen_1986_Using Dependent Types to Express Modular Structure.pdf:application/pdf}
}

@inproceedings{harper_higher-order_1990,
	address = {New York, NY, USA},
	series = {{POPL} '90},
	title = {Higher-order {Modules} and the {Phase} {Distinction}},
	isbn = {978-0-89791-343-0},
	url = {http://doi.acm.org/10.1145/96709.96744},
	doi = {10.1145/96709.96744},
	abstract = {In earlier work, we used a typed function calculus, XML, with dependent types to analyze several aspects of the Standard ML type system. In this paper, we introduce a refinement of XML with a clear compile-time/run-time phase distinction, and a direct compile-time type checking algorithm. The calculus uses a finer separation of types into universes than XML and enforces the phase distinction using a nonstandard equational theory for module and signature expressions. While unusual from a type-theoretic point of view, the nonstandard equational theory arises naturally from the well-known Grothendieck construction on an indexed category.},
	urldate = {2017-08-10},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Harper, Robert and Mitchell, John C. and Moggi, Eugenio},
	year = {1990},
	keywords = {classic-PL},
	pages = {341--354},
	file = {Harper et al_1990_Higher-order Modules and the Phase Distinction.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harper et al_1990_Higher-order Modules and the Phase Distinction.pdf:application/pdf}
}

@article{strachey_fundamental_2000,
	title = {Fundamental {Concepts} in {Programming} {Languages}},
	volume = {13},
	issn = {1388-3690, 1573-0557},
	url = {https://link.springer.com/article/10.1023/A:1010000313106},
	doi = {10.1023/A:1010000313106},
	abstract = {This paper forms the substance of a course of lectures given at the International Summer School in Computer Programming at Copenhagen in August, 1967. The lectures were originally given from notes and the paper was written after the course was finished. In spite of this, and only partly because of the shortage of time, the paper still retains many of the shortcomings of a lecture course. The chief of these are an uncertainty of aim—it is never quite clear what sort of audience there will be for such lectures—and an associated switching from formal to informal modes of presentation which may well be less acceptable in print than it is natural in the lecture room. For these (and other) faults, I apologise to the reader.There are numerous references throughout the course to CPL [1–3]. This is a programming language which has been under development since 1962 at Cambridge and London and Oxford. It has served as a vehicle for research into both programming languages and the design of compilers. Partial implementations exist at Cambridge and London. The language is still evolving so that there is no definitive manual available yet. We hope to reach another resting point in its evolution quite soon and to produce a compiler and reference manuals for this version. The compiler will probably be written in such a way that it is relatively easyto transfer it to another machine, and in the first instance we hope to establish it on three or four machines more or less at the same time.The lack of a precise formulation for CPL should not cause much difficulty in this course, as we are primarily concerned with the ideas and concepts involved rather than with their precise representation in a programming language.},
	language = {en},
	number = {1-2},
	journal = {Higher-Order and Symbolic Computation},
	author = {Strachey, Christopher},
	month = apr,
	year = {2000},
	keywords = {classic-PL},
	pages = {11--49},
	file = {Snapshot:/home/michael/Zotero/storage/M7B7LN2G/A1010000313106.html:text/html;Strachey_2000_Fundamental Concepts in Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/S/Strachey_2000_Fundamental Concepts in Programming Languages.pdf:application/pdf}
}

@inproceedings{damas_principal_1982,
	address = {New York, NY, USA},
	series = {{POPL} '82},
	title = {Principal {Type}-schemes for {Functional} {Programs}},
	isbn = {978-0-89791-065-1},
	url = {http://doi.acm.org/10.1145/582153.582176},
	doi = {10.1145/582153.582176},
	urldate = {2017-08-10},
	booktitle = {Proceedings of the 9th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Damas, Luis and Milner, Robin},
	year = {1982},
	keywords = {classic-PL},
	pages = {207--212},
	file = {Damas_Milner_1982_Principal Type-schemes for Functional Programs.pdf:/home/michael/Dropbox/zotero-pdfs/D/Damas_Milner_1982_Principal Type-schemes for Functional Programs.pdf:application/pdf}
}

@article{scott_type-theoretical_1993,
	title = {A {Type}-theoretical {Alternative} to {ISWIM}, {CUCH}, {OWHY}},
	volume = {121},
	issn = {0304-3975},
	url = {http://dx.doi.org/10.1016/0304-3975(93)90095-B},
	doi = {10.1016/0304-3975(93)90095-B},
	number = {1-2},
	urldate = {2017-08-10},
	journal = {Theor. Comput. Sci.},
	author = {Scott, Dana S.},
	month = dec,
	year = {1993},
	keywords = {classic-PL},
	pages = {411--440},
	file = {Scott_1993_A Type-theoretical Alternative to ISWIM, CUCH, OWHY.pdf:/home/michael/Dropbox/zotero-pdfs/S/Scott_1993_A Type-theoretical Alternative to ISWIM, CUCH, OWHY.pdf:application/pdf}
}

@article{milner_theory_1978,
	title = {A theory of type polymorphism in programming},
	volume = {17},
	abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple pro-gramming language, and a compile time type-checking algorithm w which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong ” and a Syntactic Soundness Theorem states that if fl accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on w is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system, 1.},
	journal = {Journal of Computer and System Sciences},
	author = {Milner, Robin},
	year = {1978},
	pages = {348--375},
	file = {Citeseer - Snapshot:/home/michael/Zotero/storage/SHIL9AHB/summary.html:text/html;Milner_1978_A theory of type polymorphism in programming.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_1978_A theory of type polymorphism in programming.pdf:application/pdf}
}

@article{abramsky_computational_1993,
	title = {Computational interpretations of linear logic},
	volume = {111},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/030439759390181R},
	doi = {10.1016/0304-3975(93)90181-R},
	abstract = {We study Girard's linear logic from the point of view of giving a concrete computational interpretation of the logic, based on the Curry—Howard isomorphism. In the case of Intuitionistic linear logic, this leads to a refinement of the lambda calculus, giving finer control over order of evaluation and storage allocation, while maintaining the logical content of programs as proofs, and computation as cut-elimination. In the classical case, it leads to a concurrent process paradigm with an operational semantics in the style of Berry and Boudol's chemical abstract machine. This opens up a promising new approach to the parallel implementation of functional programming languages; and offers the prospect of typed concurrent programming in which correctness is guaranteed by the typing.},
	number = {1},
	urldate = {2017-08-12},
	journal = {Theoretical Computer Science},
	author = {Abramsky, Samson},
	month = apr,
	year = {1993},
	pages = {3--57},
	file = {Abramsky_1993_Computational interpretations of linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/A/Abramsky_1993_Computational interpretations of linear logic.pdf:application/pdf}
}

@inproceedings{lincoln_operational_1992,
	title = {Operational {Aspects} of {Linear} {Lambda} {Calculus}},
	abstract = {Linear logic is a resource-aware logic that is based on an analysis of the classical proof rules of contraction (copying) and weakening (throwing away). Several previous researchers have studied functional programming languages derived from linear logic according to the "formulas-as-types" correspondence. In languages with linear logic types, one may hope that traditional implementation problems in functional languages such as update in place could be simplified by careful use of the type system. In this paper, we prove that the standard sequent calculus proof system of linear logic is equivalent to a natural deduction style proof system. Using the natural deduction system, we investigate the pragmatic problems of type inference and type safety for a linear lambda calculus. Although terms do not have a single most-general type (for either the standard sequent presentation or our natural deduction formulation), there is a set of most-general types that may be computed using unification....},
	booktitle = {In 7'th {Symposium} on {Logic} in {Computer} {Science}, {IEEE}},
	publisher = {IEEE Computer Society Press},
	author = {Lincoln, Patrick and Mitchell, John},
	year = {1992},
	pages = {235--246},
	file = {Citeseer - Snapshot:/home/michael/Zotero/storage/BTXIMEH7/summary.html:text/html;Lincoln_Mitchell_1992_Operational Aspects of Linear Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lincoln_Mitchell_1992_Operational Aspects of Linear Lambda Calculus.pdf:application/pdf}
}

@inproceedings{reddy_typed_1992,
	title = {A typed foundation for directional logic programming},
	url = {https://link.springer.com/chapter/10.1007/3-540-56454-3_15},
	urldate = {2017-08-12},
	booktitle = {International {Workshop} on {Extensions} of {Logic} {Programming}},
	publisher = {Springer},
	author = {Reddy, Uday S.},
	year = {1992},
	pages = {282--318},
	file = {Reddy_1992_A typed foundation for directional logic programming.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reddy_1992_A typed foundation for directional logic programming.pdf:application/pdf}
}

@article{girard_unity_1993,
	title = {On the unity of logic},
	volume = {59},
	url = {http://www.sciencedirect.com/science/article/pii/016800729390093S},
	number = {3},
	urldate = {2017-08-12},
	journal = {Annals of pure and applied logic},
	author = {Girard, Jean-Yves},
	year = {1993},
	pages = {201--217},
	file = {Girard_1993_On the unity of logic.pdf:/home/michael/Dropbox/zotero-pdfs/G/Girard_1993_On the unity of logic.pdf:application/pdf}
}

@book{seely_linear_1987,
	title = {Linear logic,*-autonomous categories and cofree coalgebras},
	url = {https://www.ncatlab.org/nlab/files/SeelyLinearLogic.pdf},
	urldate = {2017-08-12},
	publisher = {Ste. Anne de Bellevue, Quebec: CEGEP John Abbott College},
	author = {Seely, Robert AG},
	year = {1987},
	file = {Seely_1987_Linear logic,-autonomous categories and cofree coalgebras.pdf:/home/michael/Dropbox/zotero-pdfs/S/Seely_1987_Linear logic,-autonomous categories and cofree coalgebras.pdf:application/pdf}
}

@book{troelstra_lectures_1992,
	address = {Stanford, CA},
	series = {{CSLI} lecture notes},
	title = {Lectures on linear logic},
	isbn = {978-0-937073-78-0 978-0-937073-77-3},
	number = {no. 29},
	publisher = {Center for the Study of Language and Information},
	author = {Troelstra, A. S.},
	year = {1992},
	keywords = {Logic, Symbolic and mathematical},
	file = {Troelstra_1992_Lectures on linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/T/Troelstra_1992_Lectures on linear logic.pdf:application/pdf}
}

@article{lafont_linear_1988,
	title = {The linear abstract machine},
	volume = {59},
	url = {http://www.sciencedirect.com/science/article/pii/0304397588901004},
	number = {1-2},
	urldate = {2017-08-12},
	journal = {Theoretical computer science},
	author = {Lafont, Yves},
	year = {1988},
	pages = {157--180},
	file = {Lafont_1988_The linear abstract machine.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lafont_1988_The linear abstract machine.pdf:application/pdf}
}

@inproceedings{hofmann_type_2000,
	address = {London, UK, UK},
	series = {{ESOP} '00},
	title = {A {Type} {System} for {Bounded} {Space} and {Functional} {In}-{Place} {Update}–{Extended} {Abstract}},
	isbn = {978-3-540-67262-3},
	url = {http://dl.acm.org/citation.cfm?id=645394.651913},
	abstract = {We show how linear typing can be used to obtain functional programs which modify heap-allocated data structures in place. We present this both as a "design pattern" for writing C-code in a functional style and as a compilation process from linearly typed first-order functional programs into malloc()-free C code. The main technical result is the correctness of this compilation. The crucial innovation over previous linear typing schemes consists of the introduction of a resource type ⋄ which controls the number of constructor symbols such as cons in recursive definitions and ensures linear space while restricting expressive power surprisingly little. While the space efficiency brought about by the new typing scheme and the compilation into C can also be realised by with state-of-the-art optimising compilers for functional languages such as OCAML [15], the present method provides guaranteed bounds on heap space which will be of use for applications such as languages for embedded systems or 'proof carrying code' [18].},
	urldate = {2017-08-12},
	booktitle = {Proceedings of the 9th {European} {Symposium} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Hofmann, Martin},
	year = {2000},
	pages = {165--179},
	file = {Hofmann_2000_A Type System for Bounded Space and Functional In-Place Update–Extended Abstract.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hofmann_2000_A Type System for Bounded Space and Functional In-Place Update–Extended Abstract.pdf:application/pdf}
}

@inproceedings{wakeling_linearity_1991,
	title = {Linearity and laziness},
	url = {http://www.springerlink.com/index/P8MM282L368591L1.pdf},
	urldate = {2017-08-12},
	booktitle = {Functional {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer},
	author = {Wakeling, David and Runciman, Colin},
	year = {1991},
	pages = {215--240},
	file = {Wakeling_Runciman_1991_Linearity and laziness.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wakeling_Runciman_1991_Linearity and laziness.pdf:application/pdf}
}

@article{bal_programming_1989,
	title = {Programming languages for distributed computing systems},
	volume = {21},
	url = {http://dl.acm.org/citation.cfm?id=72552},
	number = {3},
	urldate = {2017-08-14},
	journal = {ACM Computing Surveys (CSUR)},
	author = {Bal, Henri E. and Steiner, Jennifer G. and Tanenbaum, Andrew S.},
	year = {1989},
	pages = {261--322},
	file = {Bal et al_1989_Programming languages for distributed computing systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bal et al_1989_Programming languages for distributed computing systems.pdf:application/pdf}
}

@inproceedings{matthews_operational_2007,
	address = {New York, NY, USA},
	series = {{POPL} '07},
	title = {Operational {Semantics} for {Multi}-language {Programs}},
	isbn = {978-1-59593-575-5},
	url = {http://doi.acm.org/10.1145/1190216.1190220},
	doi = {10.1145/1190216.1190220},
	abstract = {Inter-language interoperability is big business, as the success of Microsoft's .NET and COM and Sun's JVM show. Programming language designers are designing programming languages that reflect that fact --- SML\#, Mondrian, and Scala, to name just a few examples, all treat interoperability with other languages as a central design feature. Still, current multi-language research tends not to focus on the semantics of interoperation features, but only on how to implement them efficiently. In this paper, we take first steps toward higher-level models of interoperating systems. Our technique abstracts away the low-level details of interoperability like garbage collection and representation coherence, and lets us focus on semantic properties like type-safety and observable equivalence.Beyond giving simple expressive models that are natural compositions of single-language models, our studies have uncovered several interesting facts about interoperability. For example, higher-order contracts naturally emerge as the glue to ensure that interoperating languages respect each other's type systems. While we present our results in an abstract setting, they shed light on real multi-language systems and tools such as the JNI, SWIG, and Haskell's stable pointers.},
	urldate = {2017-08-16},
	booktitle = {Proceedings of the 34th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Matthews, Jacob and Findler, Robert Bruce},
	year = {2007},
	keywords = {interoperability, multi-language systems, operational semantics},
	pages = {3--10},
	file = {Matthews_Findler_2007_Operational Semantics for Multi-language Programs.pdf:/home/michael/Dropbox/zotero-pdfs/M/Matthews_Findler_2007_Operational Semantics for Multi-language Programs.pdf:application/pdf}
}

@inproceedings{morrisett_stack-based_1998,
	title = {Stack-based typed assembly language},
	url = {http://link.springer.com/chapter/10.1007/BFb0055511},
	urldate = {2017-08-16},
	booktitle = {International {Workshop} on {Types} in {Compilation}},
	publisher = {Springer},
	author = {Morrisett, Greg and Crary, Karl and Glew, Neal and Walker, David},
	year = {1998},
	pages = {28--52},
	file = {Morrisett et al_1998_Stack-based typed assembly language.pdf:/home/michael/Dropbox/zotero-pdfs/M/Morrisett et al_1998_Stack-based typed assembly language.pdf:application/pdf}
}

@inproceedings{ramsey_hoopl:_2010,
	title = {Hoopl: a modular, reusable library for dataflow analysis and transformation},
	volume = {45},
	shorttitle = {Hoopl},
	url = {http://dl.acm.org/citation.cfm?id=1863539},
	urldate = {2017-08-26},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Ramsey, Norman and Dias, Joao and Peyton Jones, Simon},
	year = {2010},
	pages = {121--134},
	file = {Ramsey et al_2010_Hoopl - a modular, reusable library for dataflow analysis and transformation.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ramsey et al_2010_Hoopl - a modular, reusable library for dataflow analysis and transformation.pdf:application/pdf}
}

@inproceedings{peyton_jones_how_2004,
	title = {How to make a fast curry: push/enter vs eval/apply},
	url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/eval-apply.pdf},
	abstract = {Higher-order languages that encourage currying are typically implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.

Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.

Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	urldate = {2017-08-26},
	booktitle = {Internal {Conference} on {Functional} {Programming}},
	author = {Peyton Jones, Simon},
	year = {2004},
	keywords = {Haskell},
	file = {Peyton Jones_2004_How to make a fast curry - push-enter vs eval-apply.pdf:/home/michael/Dropbox/zotero-pdfs/P/Peyton Jones_2004_How to make a fast curry - push-enter vs eval-apply.pdf:application/pdf}
}

@book{peyton_jones_implementation_1987,
	title = {The {Implementation} of {Functional} {Progamming} {Languages}},
	url = {https://www.microsoft.com/en-us/research/wp-content/uploads/1992/01/student.pdf},
	urldate = {2017-08-26},
	publisher = {Prentice Hall New York},
	author = {Peyton Jones, Simon},
	year = {1987},
	keywords = {Haskell},
	file = {Peyton Jones_1987_The Implementation of Functional Progamming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/P/Peyton Jones_1987_The Implementation of Functional Progamming Languages.pdf:application/pdf}
}

@article{peyton_jones_implementing_1992,
	title = {Implementing {Lazy} {Functional} {Languages} on {Stock} {Hardware}: {The} {Spineless} {Tagless} {G}-machine},
	volume = {2},
	url = {https://www.microsoft.com/en-us/research/wp-content/uploads/1992/04/spineless-tagless-gmachine.pdf},
	abstract = {The Spineless Tagless G-machine is an abstract machine designed to support non- strict higher-order functional languages. This presentation of the machine falls into three parts. Firstly, we give a general discussion of the design issues involved in implementing non-strict functional languages.
Next, we present the STG language, an austere but recognisably-functional language, which as well as a denotational meaning has a well-defined operational semantics. The STG language is the {\textbackslash}abstract machine code” for the Spineless Tagless G-machine.
Lastly, we discuss the mapping of the STG language onto stock hardware. The success of an abstract machine model depends largely on how efficient this mapping can be made, though this topic is often relegated to a short section. Instead, we give a detailed discussion of the design issues and the choices we have made. Our principal target is the C language, treating the C compiler as a portable assembler.},
	urldate = {2017-08-26},
	journal = {Journal of Functional Programming},
	author = {Peyton Jones, Simon},
	month = jul,
	year = {1992},
	keywords = {Haskell},
	pages = {127--202},
	file = {Peyton Jones_Implementing Lazy Functional Languages on Stock Hardware - The Spineless Tagless.pdf:/home/michael/Dropbox/zotero-pdfs/P/Peyton Jones_Implementing Lazy Functional Languages on Stock Hardware - The Spineless Tagless.pdf:application/pdf}
}

@book{peyton_jones_implementing_1992-1,
	title = {Implementing functional languages: a tutorial},
	abstract = {This book gives a practical approach to understanding implementations of non-strict functional languages using lazy graph reduction. The book is intended to be a source of practical labwork material, to help make functional-language implementations `come alive’, by helping the reader to develop, modify and experiment with some non-trivial compilers.},
	publisher = {Prentice Hall New York},
	author = {Peyton Jones, Simon},
	year = {1992},
	keywords = {Haskell},
	file = {Peyton Jones_1992_Implementing functional languages - a tutorial.pdf:/home/michael/Dropbox/zotero-pdfs/P/Peyton Jones_1992_Implementing functional languages - a tutorial.pdf:application/pdf}
}

@article{pu_synthesis_1988,
	title = {The synthesis kernel},
	volume = {1},
	url = {https://www.usenix.org/legacy/publications/compsystems/1988/win_pu.pdf},
	number = {1},
	urldate = {2017-08-28},
	journal = {Computing Systems},
	author = {Pu, Calton and Massalin, Henry and Ioannidis, John},
	year = {1988},
	pages = {11--32},
	file = {Pu et al_1988_The synthesis kernel.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pu et al_1988_The synthesis kernel.pdf:application/pdf}
}

@inproceedings{chisnall_cheri_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {{CHERI} {JNI}: {Sinking} the {Java} {Security} {Model} into the {C}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{CHERI} {JNI}},
	url = {http://doi.acm.org/10.1145/3037697.3037725},
	doi = {10.1145/3037697.3037725},
	abstract = {Java provides security and robustness by building a high-level security model atop the foundation of memory protection. Unfortunately, any native code linked into a Java program -- including the million lines used to implement the standard library -- is able to bypass both the memory protection and the higher-level policies. We present a hardware-assisted implementation of the Java native code interface, which extends the guarantees required for Java's security model to native code. Our design supports safe direct access to buffers owned by the JVM, including hardware-enforced read-only access where appropriate. We also present Java language syntax to declaratively describe isolated compartments for native code. We show that it is possible to preserve the memory safety and isolation requirements of the Java security model in C code, allowing native code to run in the same process as Java code with the same impact on security as running equivalent Java code. Our approach has a negligible impact on performance, compared with the existing unsafe native code interface. We demonstrate a prototype implementation running on the CHERI microprocessor synthesized in FPGA.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Chisnall, David and Davis, Brooks and Gudka, Khilan and Brazdil, David and Joannou, Alexandre and Woodruff, Jonathan and Markettos, A. Theodore and Maste, J. Edward and Norton, Robert and Son, Stacey and Roe, Michael and Moore, Simon W. and Neumann, Peter G. and Laurie, Ben and Watson, Robert N.M.},
	year = {2017},
	keywords = {compilers, memory protection, architecture, capability systems, cheri, compartmentalization, hardware security, java, jni, language security, sandboxing},
	pages = {569--583},
	file = {Chisnall et al_2017_CHERI JNI - Sinking the Java Security Model into the C.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chisnall et al_2017_CHERI JNI - Sinking the Java Security Model into the C.pdf:application/pdf}
}

@inproceedings{ferraiuolo_verification_2017,
	title = {Verification of a {Practical} {Hardware} {Security} {Architecture} {Through} {Static} {Information} {Flow} {Analysis}},
	isbn = {978-1-4503-4465-4},
	url = {http://dl.acm.org/citation.cfm?doid=3037697.3037739},
	doi = {10.1145/3037697.3037739},
	language = {en},
	urldate = {2017-09-05},
	publisher = {ACM Press},
	author = {Ferraiuolo, Andrew and Xu, Rui and Zhang, Danfeng and Myers, Andrew C. and Suh, G. Edward},
	year = {2017},
	pages = {555--568},
	file = {Ferraiuolo et al_2017_Verification of a Practical Hardware Security Architecture Through Static.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ferraiuolo et al_2017_Verification of a Practical Hardware Security Architecture Through Static.pdf:application/pdf}
}

@article{powers_browsix:_2016,
	title = {Browsix: {Bridging} the {Gap} {Between} {Unix} and the {Browser}},
	shorttitle = {Browsix},
	url = {http://arxiv.org/abs/1611.07862},
	abstract = {Applications written to run on conventional operating systems typically depend on OS abstractions like processes, pipes, signals, sockets, and a shared file system. Porting these applications to the web currently requires extensive rewriting or hosting significant portions of code server-side because browsers present a nontraditional runtime environment that lacks OS functionality. This paper presents Browsix, a framework that bridges the considerable gap between conventional operating systems and the browser, enabling unmodified programs expecting a Unix-like environment to run directly in the browser. Browsix comprises two core parts: (1) a JavaScript-only system that makes core Unix features (including pipes, concurrent processes, signals, sockets, and a shared file system) available to web applications; and (2) extended JavaScript runtimes for C, C++, Go, and Node.js that support running programs written in these languages as processes in the browser. Browsix supports running a POSIX shell, making it straightforward to connect applications together via pipes. We illustrate Browsix's capabilities via case studies that demonstrate how it eases porting legacy applications to the browser and enables new functionality. We demonstrate a Browsix-enabled LaTeX editor that operates by executing unmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can render documents in seconds, making it fast enough to be practical. We further demonstrate how Browsix lets us port a client-server application to run entirely in the browser for disconnected operation. Creating these applications required less than 50 lines of glue code and no code modifications, demonstrating how easily Browsix can be used to build sophisticated web applications from existing parts without modification.},
	urldate = {2017-09-05},
	journal = {arXiv:1611.07862 [cs]},
	author = {Powers, Bobby and Vilk, John and Berger, Emery D.},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.07862},
	keywords = {Computer Science - Operating Systems, Computer Science - Programming Languages},
	file = {Powers et al_2016_Browsix - Bridging the Gap Between Unix and the Browser.pdf:/home/michael/Dropbox/zotero-pdfs/P/Powers et al_2016_Browsix - Bridging the Gap Between Unix and the Browser.pdf:application/pdf}
}

@inproceedings{calciu_black-box_2017,
	title = {Black-box {Concurrent} {Data} {Structures} for {NUMA} {Architectures}},
	isbn = {978-1-4503-4465-4},
	url = {http://dl.acm.org/citation.cfm?doid=3037697.3037721},
	doi = {10.1145/3037697.3037721},
	language = {en},
	urldate = {2017-09-05},
	publisher = {ACM Press},
	author = {Calciu, Irina and Sen, Siddhartha and Balakrishnan, Mahesh and Aguilera, Marcos K.},
	year = {2017},
	pages = {207--221},
	file = {Calciu et al_2017_Black-box Concurrent Data Structures for NUMA Architectures.pdf:/home/michael/Dropbox/zotero-pdfs/C/Calciu et al_2017_Black-box Concurrent Data Structures for NUMA Architectures.pdf:application/pdf}
}

@inproceedings{wen_redspy:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {{REDSPY}: {Exploring} {Value} {Locality} in {Software}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{REDSPY}},
	url = {http://doi.acm.org/10.1145/3037697.3037729},
	doi = {10.1145/3037697.3037729},
	abstract = {Complex code bases with several layers of abstractions have abundant inefficiencies that affect the execution time. Value redundancy is a kind of inefficiency where the same values are repeatedly computed, stored, or retrieved over the course of execution. Not all redundancies can be easily detected or eliminated with compiler optimization passes due to the inherent limitations of the static analysis. Microscopic observation of whole executions at instruction- and operand-level granularity breaks down abstractions and helps recognize redundancies that masquerade in complex programs. We have developed REDSPY---a fine-grained profiler to pinpoint and quantify redundant operations in program executions. Value redundancy may happen over time at same locations or in adjacent locations, and thus it has temporal and spatial locality. REDSPY identifies both temporal and spatial value locality. Furthermore, REDSPY is capable of identifying values that are approximately the same, enabling optimization opportunities in HPC codes that often use floating point computations. REDSPY provides intuitive optimization guidance by apportioning redundancies to their provenance---source lines and execution calling contexts. REDSPY pinpointed dramatically high volume of redundancies in programs that were optimization targets for decades, such as SPEC CPU2006 suite, Rodinia benchmark, and NWChem---a production computational chemistry code. Guided by REDSPY, we were able to eliminate redundancies that resulted in significant speedups.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Wen, Shasha and Chabbi, Milind and Liu, Xu},
	year = {2017},
	keywords = {approximate computing, cctlib, performance tools, pin, redundancy detection and elimination, value profiling},
	pages = {47--61},
	file = {Wen et al_2017_REDSPY - Exploring Value Locality in Software.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wen et al_2017_REDSPY - Exploring Value Locality in Software.pdf:application/pdf}
}

@inproceedings{kanev_mallacc:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Mallacc: {Accelerating} {Memory} {Allocation}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {Mallacc},
	url = {http://doi.acm.org/10.1145/3037697.3037736},
	doi = {10.1145/3037697.3037736},
	abstract = {Recent work shows that dynamic memory allocation consumes nearly 7\% of all cycles in Google datacenters. With the trend towards increased specialization of hardware, we propose Mallacc, an in-core hardware accelerator designed for broad use across a number of high-performance, modern memory allocators. The design of Mallacc is quite different from traditional throughput-oriented hardware accelerators. Because memory allocation requests tend to be very frequent, fast, and interspersed inside other application code, accelerators must be optimized for latency rather than throughput and area overheads must be kept to a bare minimum. Mallacc accelerates the three primary operations of a typical memory allocation request: size class computation, retrieval of a free memory block, and sampling of memory usage. Our results show that malloc latency can be reduced by up to 50\% with a hardware cost of less than 1500 um2 of silicon area, less than 0.006\% of a typical high-performance processor core.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Kanev, Svilen and Xi, Sam Likun and Wei, Gu-Yeon and Brooks, David},
	year = {2017},
	keywords = {accelerators, datacenter tax, memory allocation},
	pages = {33--45},
	file = {Kanev et al_2017_Mallacc - Accelerating Memory Allocation.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kanev et al_2017_Mallacc - Accelerating Memory Allocation.pdf:application/pdf}
}

@inproceedings{goguen_security_1982,
	title = {Security {Policies} and {Security} {Models}},
	doi = {10.1109/SP.1982.10014},
	abstract = {We assune that the reader is familiar with the ubiquity of information in the modern world and is sympathetic with the need for restricting rights to read, add, modify, or delete information in specific contexts. This need is particularly acute for systems having computers as significant components.},
	booktitle = {1982 {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Goguen, J. A. and Meseguer, J.},
	month = apr,
	year = {1982},
	keywords = {Automata, Computational modeling, Computers, Data models, Finite element methods, Mathematical model, Message systems},
	pages = {11--11},
	file = {Goguen_Meseguer_1982_Security Policies and Security Models.pdf:/home/michael/Dropbox/zotero-pdfs/G/Goguen_Meseguer_1982_Security Policies and Security Models.pdf:application/pdf}
}

@inproceedings{smith_secure_1998,
	address = {New York, NY, USA},
	series = {{POPL} '98},
	title = {Secure {Information} {Flow} in a {Multi}-threaded {Imperative} {Language}},
	isbn = {978-0-89791-979-1},
	url = {http://doi.acm.org/10.1145/268946.268975},
	doi = {10.1145/268946.268975},
	abstract = {Previously, we developed a type system to ensure secure information flow in a sequential, imperative programming language [VSI96]. Program variables are classified as either high or low security; intuitively, we wish to prevent information from flowing from high variables to low variables. Here, we extend the analysis to deal with a multithreaded language. We show that the previous type system is insufficient to ensure a desirable security property called noninterference. Noninterference basically means that the final values of low variables are independent of the initial values of high variables. By modifying the sequential type system, we are able to guarantee noninterference for concurrent programs. Crucial to this result, however, is the use of purely nondeterministic thread scheduling. Since implementing such scheduling is problematic, we also show how a more restrictive type system can guarantee noninterference, given a more deterministic (and easily implementable) scheduling policy, such as round-robin time slicing. Finally, we consider the consequences of adding a clock to the language.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Smith, Geoffrey and Volpano, Dennis},
	year = {1998},
	pages = {355--364},
	file = {Smith_Volpano_1998_Secure Information Flow in a Multi-threaded Imperative Language.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_Volpano_1998_Secure Information Flow in a Multi-threaded Imperative Language.pdf:application/pdf}
}

@inproceedings{palsberg_trust_1995,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Trust in the λ-calculus},
	isbn = {978-3-540-60360-3 978-3-540-45050-4},
	url = {https://link.springer.com/chapter/10.1007/3-540-60360-3_47},
	doi = {10.1007/3-540-60360-3_47},
	abstract = {This paper introduces trust analysis for higher-order languages. Trust analysis encourages the programmer to make explicit the trustworthiness of data, and in return it can guarantee that no mistakes with respect to trust will be made at run-time. We present a confluent λ-calculus with explicit trust operations, and we equip it with a trusttype system which has the subject reduction property. Trust information in presented as two annotations of each function type constructor, and type inference is computable in O(n3) time.},
	language = {en},
	urldate = {2017-09-05},
	booktitle = {Static {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Palsberg, Jens and Ørbæk, Peter},
	month = sep,
	year = {1995},
	pages = {314--329},
	file = {Palsberg_Orb⇓ek_1995_Trust in the λ-calculus.pdf:/home/michael/Dropbox/zotero-pdfs/P/Palsberg_Orb⇓ek_1995_Trust in the λ-calculus.pdf:application/pdf}
}

@article{mizuno_security_1992,
	title = {A security flow control algorithm and its denotational semantics correctness proof},
	volume = {4},
	issn = {0934-5043, 1433-299X},
	url = {https://link.springer.com/article/10.1007/BF03180570},
	doi = {10.1007/BF03180570},
	abstract = {We derive a security flow control algorithm for message-based, modular systems and prove the algorithm correct. The development is noteworthy because it is completely rigorous: the flow control algorithm is derived as an abstract interpretation of the denotational semantics of the programming language for the modular system, and the correctness proof is a proof by logical relations of the congruence between the denotational semantics and its abstract interpretation. Effectiveness is also addressed: we give conditions under which an abstract interpretation can be computed as a traditional iterative data flow analysis, and we prove that our security flow control algorithm satisfies the conditions. We also show that symbolic expressions (that is, data flow values that contain unknowns) can be used in a convergent, iterative analysis. An important consequence of the latter result is that the security flow control algorithm can analyse individual modules in a system for well formedness and later can link the analyses to obtain an analysis of the entire system.},
	language = {en},
	number = {1},
	urldate = {2017-09-05},
	journal = {Formal Aspects of Computing},
	author = {Mizuno, Masaaki and Schmidt, David},
	month = nov,
	year = {1992},
	pages = {727--754},
	file = {Mizuno_Schmidt_1992_A security flow control algorithm and its denotational semantics correctness.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mizuno_Schmidt_1992_A security flow control algorithm and its denotational semantics correctness.pdf:application/pdf}
}

@inproceedings{kobayashi_type-based_2002,
	title = {Type-{Based} {Information} {Flow} {Analysis} for {Low}-{Level} {Languages}},
	abstract = {A static program analysis called information flow analysis  has been studied for high-level programming languages, to check that  programs do not leak information about secret data such as passwords.},
	booktitle = {In {Proceedings} of the 3rd {Asian} {Workshop} on {Programming} {Languages} and {Systems} ({APLAS}’02},
	author = {Kobayashi, Naoki and Shirane, Keita},
	year = {2002},
	pages = {2--21},
	file = {Kobayashi_Shirane_2002_Type-Based Information Flow Analysis for Low-Level Languages.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kobayashi_Shirane_2002_Type-Based Information Flow Analysis for Low-Level Languages.pdf:application/pdf}
}

@article{denning_certification_1977,
	title = {Certification of {Programs} for {Secure} {Information} {Flow}},
	volume = {20},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359636.359712},
	doi = {10.1145/359636.359712},
	abstract = {ertification mechanism for verifying the secure flow of information through a program. Because it exploits the properties of a lattice structure among security classes, the procedure is sufficiently simple that it can easily be included in the analysis phase of most existing compilers. Appropriate semantics are presented and proved correct. An important application is the confinement problem: The mechanism can prove that a program cannot cause supposedly nonconfidential results to depend on confidential input data.},
	number = {7},
	urldate = {2017-09-05},
	journal = {Commun. ACM},
	author = {Denning, Dorothy E. and Denning, Peter J.},
	month = jul,
	year = {1977},
	keywords = {security, confinement, protection, information flow, lattice, program certification, security classes},
	pages = {504--513},
	file = {Denning_Denning_1977_Certification of Programs for Secure Information Flow.pdf:/home/michael/Dropbox/zotero-pdfs/D/Denning_Denning_1977_Certification of Programs for Secure Information Flow.pdf:application/pdf}
}

@article{denning_lattice_1976,
	title = {A {Lattice} {Model} of {Secure} {Information} {Flow}},
	volume = {19},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/360051.360056},
	doi = {10.1145/360051.360056},
	abstract = {This paper investigates mechanisms that guarantee secure information flow in a computer system. These mechanisms are examined within a mathematical framework suitable for formulating the requirements of secure information flow among security classes. The central component of the model is a lattice structure derived from the security classes and justified by the semantics of information flow. The lattice properties permit concise formulations of the security requirements of different existing systems and facilitate the construction of mechanisms that enforce security. The model provides a unifying view of all systems that restrict information flow, enables a classification of them according to security objectives, and suggests some new approaches. It also leads to the construction of automatic program certification mechanisms for verifying the secure flow of information through a program.},
	number = {5},
	urldate = {2017-09-05},
	journal = {Commun. ACM},
	author = {Denning, Dorothy E.},
	month = may,
	year = {1976},
	keywords = {security, protection, information flow, lattice, program certification, security class},
	pages = {236--243},
	file = {Denning_1976_A Lattice Model of Secure Information Flow.pdf:/home/michael/Dropbox/zotero-pdfs/D/Denning_1976_A Lattice Model of Secure Information Flow.pdf:application/pdf}
}

@misc{sheeran_hardware_nodate,
	title = {Hardware {Design} and {Functional} {Programming}:a {Perfect} {Match}},
	url = {http://www.jucs.org/jucs_11_7/hardware_design_and_functional;internal&action=js.execute.action&Parameter=%23%28UIClass%3APaperCollectionObjectUI%29%28Method%3AgetMetadataAsBibTex%29},
	urldate = {2017-09-05},
	author = {Sheeran, Mary},
	file = {Sheeran_Hardware Design and Functional Programming -a Perfect Match.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sheeran_Hardware Design and Functional Programming -a Perfect Match.pdf:application/pdf}
}

@inproceedings{bjesse_lava:_1998,
	address = {New York, NY, USA},
	series = {{ICFP} '98},
	title = {Lava: {Hardware} {Design} in {Haskell}},
	isbn = {978-1-58113-024-9},
	shorttitle = {Lava},
	url = {http://doi.acm.org/10.1145/289423.289440},
	doi = {10.1145/289423.289440},
	abstract = {Lava is a tool to assist circuit designers in specifying, designing, verifying and implementing hardware. It is a collection of Haskell modules. The system design exploits functional programming language features, such as monads and type classes, to provide multiple interpretations of circuit descriptions. These interpretations implement standard circuit analyses such as simulation, formal verification and the generation of code for the production of real circuits.Lava also uses polymorphism and higher order functions to provide more abstract and general descriptions than are possible in traditional hardware description languages. Two Fast Fourier Transform circuit examples illustrate this.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Third} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Bjesse, Per and Claessen, Koen and Sheeran, Mary and Singh, Satnam},
	year = {1998},
	pages = {174--184},
	file = {Bjesse et al_1998_Lava - Hardware Design in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bjesse et al_1998_Lava - Hardware Design in Haskell.pdf:application/pdf}
}

@incollection{milner_polyadic_1993,
	title = {The polyadic π-calculus: a tutorial},
	shorttitle = {The polyadic π-calculus},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-58041-3_6},
	urldate = {2017-09-05},
	booktitle = {Logic and algebra of specification},
	publisher = {Springer},
	author = {Milner, Robin},
	year = {1993},
	pages = {203--246},
	file = {Milner_1993_The polyadic π-calculus - a tutorial.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_1993_The polyadic π-calculus - a tutorial.pdf:application/pdf}
}

@inproceedings{carette_symbolic_2005,
	title = {Symbolic interpretation of legacy assembly language},
	doi = {10.1109/WCRE.2005.31},
	abstract = {We apply static analysis and symbolic interpretation techniques to reverse engineer the semantics of legacy assembler code. We examine the case of IBM-1800 programs in detail. From the documented operational semantics of the IBM-1800, we simultaneously obtain an emulator and a symbolic analysis program. Augmented with some control flow information, we can use the symbolic analysis to provide both complete and generic semantics for some interesting code sequences.},
	booktitle = {12th {Working} {Conference} on {Reverse} {Engineering} ({WCRE}'05)},
	author = {Carette, J. and Chowdhury, P. K.},
	month = nov,
	year = {2005},
	keywords = {Information analysis, static analysis, High level languages, program diagnostics, reverse engineering, programming language semantics, TO-READ, Assembly, assembly language, code sequences, Computer languages, control flow information, Control system analysis, Control systems, documented operational semantics, emulator program, Equations, IBM-1800 programs, legacy assembler code, Power generation, Registers, Reverse engineering, software maintenance, symbolic analysis program, symbolic interpretation},
	pages = {10 pp.--},
	file = {Carette_Chowdhury_2005_Symbolic interpretation of legacy assembly language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Carette_Chowdhury_2005_Symbolic interpretation of legacy assembly language.pdf:application/pdf}
}

@inproceedings{launchbury_lazy_1994,
	address = {New York, NY, USA},
	series = {{PLDI} '94},
	title = {Lazy {Functional} {State} {Threads}},
	isbn = {978-0-89791-662-2},
	url = {http://doi.acm.org/10.1145/178243.178246},
	doi = {10.1145/178243.178246},
	abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language.The security of the encapsulation is assured by the type system, using parametricity. Intriguingly, this parametricity requires the provision of a (single) constant with a rank-2 polymorphic type.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1994 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Launchbury, John and Peyton Jones, Simon L.},
	year = {1994},
	pages = {24--35},
	file = {Launchbury_Peyton Jones_1994_Lazy Functional State Threads.pdf:/home/michael/Dropbox/zotero-pdfs/L/Launchbury_Peyton Jones_1994_Lazy Functional State Threads.pdf:application/pdf}
}

@inproceedings{jones_functional_1995,
	title = {Functional programming with overloading and higher-order polymorphism},
	url = {https://link.springer.com/chapter/10.1007/3-540-59451-5_4},
	urldate = {2017-09-05},
	booktitle = {International {School} on {Advanced} {Functional} {Programming}},
	publisher = {Springer},
	author = {Jones, Mark P.},
	year = {1995},
	pages = {97--136},
	file = {Jones_1995_Functional programming with overloading and higher-order polymorphism.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_1995_Functional programming with overloading and higher-order polymorphism.pdf:application/pdf}
}

@inproceedings{hudak_history_2007,
	address = {New York, NY, USA},
	series = {{HOPL} {III}},
	title = {A {History} of {Haskell}: {Being} {Lazy} with {Class}},
	isbn = {978-1-59593-766-7},
	shorttitle = {A {History} of {Haskell}},
	url = {http://doi.acm.org/10.1145/1238844.1238856},
	doi = {10.1145/1238844.1238856},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Third} {ACM} {SIGPLAN} {Conference} on {History} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Hudak, Paul and Hughes, John and Peyton Jones, Simon and Wadler, Philip},
	year = {2007},
	pages = {12--1--12--55},
	file = {Hudak et al_2007_A History of Haskell - Being Lazy with Class.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hudak et al_2007_A History of Haskell - Being Lazy with Class.pdf:application/pdf}
}

@inproceedings{marlow_making_2004,
	address = {New York, NY, USA},
	series = {{ICFP} '04},
	title = {Making a {Fast} {Curry}: {Push}/{Enter} vs. {Eval}/{Apply} for {Higher}-order {Languages}},
	isbn = {978-1-58113-905-1},
	shorttitle = {Making a {Fast} {Curry}},
	url = {http://doi.acm.org/10.1145/1016850.1016856},
	doi = {10.1145/1016850.1016856},
	abstract = {Higher-order languages that encourage currying are implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Ninth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Marlow, Simon and Jones, Simon Peyton},
	year = {2004},
	pages = {4--15},
	file = {Marlow_Jones_2004_Making a Fast Curry - Push-Enter vs. Eval-Apply for Higher-order Languages.pdf:/home/michael/Dropbox/zotero-pdfs/M/Marlow_Jones_2004_Making a Fast Curry - Push-Enter vs. Eval-Apply for Higher-order Languages.pdf:application/pdf}
}

@inproceedings{launchbury_natural_1993,
	address = {New York, NY, USA},
	series = {{POPL} '93},
	title = {A {Natural} {Semantics} for {Lazy} {Evaluation}},
	isbn = {978-0-89791-560-1},
	url = {http://doi.acm.org/10.1145/158511.158618},
	doi = {10.1145/158511.158618},
	abstract = {We define an operational semantics for lazy evaluation which provides an accurate model for sharing. The only computational structure we introduce is a set of bindings which corresponds closely to a heap. The semantics is set at a considerably higher level of abstraction than operational semantics for particular abstract machines, so is more suitable for a variety of proofs. Furthermore, because a heap is explicitly modelled, the semantics provides a suitable framework for studies about space behaviour of terms under lazy evaluation.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Launchbury, John},
	year = {1993},
	keywords = {TO-READ},
	pages = {144--154},
	file = {Launchbury_1993_A Natural Semantics for Lazy Evaluation.pdf:/home/michael/Dropbox/zotero-pdfs/L/Launchbury_1993_A Natural Semantics for Lazy Evaluation.pdf:application/pdf}
}

@inproceedings{gordon_operational_1993,
	address = {New York, NY, USA},
	series = {{FPCA} '93},
	title = {An {Operational} {Semantics} for {I}/{O} in a {Lazy} {Functional} {Language}},
	isbn = {978-0-89791-595-3},
	url = {http://doi.acm.org/10.1145/165180.165199},
	doi = {10.1145/165180.165199},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {ACM},
	author = {Gordon, Andrew D.},
	year = {1993},
	pages = {136--145},
	file = {Gordon_1993_An Operational Semantics for I-O in a Lazy Functional Language.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon_1993_An Operational Semantics for I-O in a Lazy Functional Language.pdf:application/pdf}
}

@article{josephs_semantics_1989,
	title = {The semantics of lazy functional languages},
	volume = {68},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397589901229},
	doi = {10.1016/0304-3975(89)90122-9},
	abstract = {A denotational semantics for the λ-calculus is described. The semantics is continuation-based, and so reflects the order in which expressions are evaluated. It provides a means by which lazy functional languages can be better understood.},
	number = {1},
	urldate = {2017-09-05},
	journal = {Theoretical Computer Science},
	author = {Josephs, Mark B.},
	month = oct,
	year = {1989},
	pages = {105--111},
	file = {Josephs_1989_The semantics of lazy functional languages.pdf:/home/michael/Dropbox/zotero-pdfs/J/Josephs_1989_The semantics of lazy functional languages.pdf:application/pdf}
}

@article{veen_dataflow_1986,
	title = {Dataflow {Machine} {Architecture}},
	volume = {18},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/27633.28055},
	doi = {10.1145/27633.28055},
	abstract = {Dataflow machines are programmable computers of which the hardware is optimized for fine-grain data-driven parallel computation. The principles and complications of data-driven execution are explained, as well as the advantages and costs of fine-grain parallelism. A general model for a dataflow machine is presented and the major design options are discussed.
Most dataflow machines described in the literature are surveyed on the basis of this model and its associated technology. For general-purpose computing the most promising dataflow machines are those that employ packet-switching communication and support general recursion. Such a recursion mechanism requires an extremely fast mechanism to map a sparsely occupied virtual space to a physical space of realistic size. No solution has yet proved fully satisfactory.
A working prototype of one processing element is described in detail. On the basis of experience with this prototype, some of the objections raised against the dataflow approach are discussed. It appears that the overhead due to fine-grain parallelism can be made acceptable by sophisticated compiling and employing special hardware for the storage of data structures. Many computing-intensive programs show sufficient parallelism. In fact, a major problem is to restrain parallelism when machine resources tend to get overloaded. Another issue that requires further investigation is the distribution of computation and data structures over the processing elements.},
	number = {4},
	urldate = {2017-09-05},
	journal = {ACM Comput. Surv.},
	author = {Veen, Arthur H.},
	month = dec,
	year = {1986},
	pages = {365--396},
	file = {Veen_1986_Dataflow Machine Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/V/Veen_1986_Dataflow Machine Architecture.pdf:application/pdf;Veen_1986_Dataflow machine architecture.pdf:/home/michael/Dropbox/zotero-pdfs/V/Veen_1986_Dataflow machine architecture.pdf:application/pdf}
}

@inproceedings{rosu_runtime_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Runtime {Verification} of {C} {Memory} {Safety}},
	isbn = {978-3-642-04693-3 978-3-642-04694-0},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-04694-0_10},
	doi = {10.1007/978-3-642-04694-0_10},
	abstract = {C is the most widely used imperative system’s implementation language. While C provides types and high-level abstractions, its design goal has been to provide highest performance which often requires low-level access to memory. As a consequence C supports arbitrary pointer arithmetic, casting, and explicit allocation and deallocation. These operations are difficult to use, resulting in programs that often have software bugs like buffer overflows and dangling pointers that cause security vulnerabilities. We say a C program is memory safe, if at runtime it never goes wrong with such a memory access error. Based on standards for writing “good” C code, this paper proposes strong memory safety as the least restrictive formal definition of memory safety amenable for runtime verification. We show that although verification of memory safety is in general undecidable, even when restricted to closed, terminating programs, runtime verification of strong memory safety is a decision procedure for this class of programs. We verify strong memory safety of a program by executing the program using a symbolic, deterministic definition of the dynamic semantics. A prototype implementation of these ideas shows the feasibility of this approach.},
	language = {en},
	urldate = {2017-09-05},
	booktitle = {Runtime {Verification}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Roşu, Grigore and Schulte, Wolfram and Şerbănuţă, Traian Florin},
	month = jun,
	year = {2009},
	pages = {132--151},
	file = {Rosu et al_2009_Runtime Verification of C Memory Safety.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosu et al_2009_Runtime Verification of C Memory Safety.pdf:application/pdf}
}

@article{leroy_formally_2009,
	title = {A {Formally} {Verified} {Compiler} {Back}-end},
	volume = {43},
	issn = {0168-7433},
	url = {http://dx.doi.org/10.1007/s10817-009-9155-4},
	doi = {10.1007/s10817-009-9155-4},
	abstract = {This article describes the development and formal verification (proof of semantic preservation) of a compiler back-end from Cminor (a simple imperative intermediate language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its soundness. Such a verified compiler is useful in the context of formal methods applied to the certification of critical software: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
	number = {4},
	urldate = {2017-09-05},
	journal = {J. Autom. Reason.},
	author = {Leroy, Xavier},
	month = dec,
	year = {2009},
	keywords = {Compiler transformations and optimizations, Compiler verification, Formal methods, Program proof, Semantic preservation, The Coq theorem prover},
	pages = {363--446}
}

@misc{chen_low-level_nodate,
	title = {A {Low}-{Level} {Typed} {Assembly} {Language} with a {Machine}-{Checkable} {Soundness} {Proof} ({Thesis})},
	url = {https://www.cs.princeton.edu/research/techreps/TR-704-04},
	urldate = {2017-09-05},
	author = {Chen, Juan},
	keywords = {typed assembly},
	file = {Chen_A Low-Level Typed Assembly Language with a Machine-Checkable Soundness Proof.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chen_A Low-Level Typed Assembly Language with a Machine-Checkable Soundness Proof.pdf:application/pdf}
}

@inproceedings{morrisett_semantics_1997,
	title = {Semantics of {Memory} {Management} for {Polymorphic} {Languages}},
	abstract = {We present a static and dynamic semantics for an abstract machine that evaluates expressions of a polymorphic programming language. Unlike traditional semantics, our abstract machine exposes many important issues of memory management, such as value sharing and control representation. We prove the soundness of the static semantics with respect to the dynamic semantics using traditional techniques. We then show how these same techniques may be used to establish the soundness of various memory management strategies, including type-based, tag-free garbage collection; tailcall elimination; and environment strengthening. 1 Introduction  Type theory and operational semantics are remarkably effective tools for programming language design and implementation [28, 13]. An important and influential example is provided by The Definition of Standard ML (SML) [28]. The static semantics of SML is specified as a collection of elaboration rules that defines the context-sensitive constraints on the forma...},
	booktitle = {Higher {Order} {Operational} {Techniques} in {Semantics}, {Publications} of the {Newton} {Institute}},
	publisher = {Cambridge University Press},
	author = {Morrisett, Greg and Harper, Robert},
	year = {1997},
	pages = {175--226},
	file = {Morrisett_Harper_1997_Semantics of Memory Management for Polymorphic Languages.pdf:/home/michael/Dropbox/zotero-pdfs/M/Morrisett_Harper_1997_Semantics of Memory Management for Polymorphic Languages.pdf:application/pdf}
}

@techreport{felleisen_control_1986,
	title = {Control {Operators}, the {SECD}-{Machine}, and the {Lambda}-{Calculus}},
	url = {https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR197},
	urldate = {2017-09-05},
	author = {Felleisen, Matthias and Friedman, Daniel},
	year = {1986},
	file = {Felleisen_Friedman_1986_Control Operators, the SECD-Machine, and the Lambda-Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felleisen_Friedman_1986_Control Operators, the SECD-Machine, and the Lambda-Calculus.pdf:application/pdf}
}

@inproceedings{harrison_parallel_1987,
	title = {The parallel graph reduction machine, {Alice}},
	url = {http://link.springer.com/chapter/10.1007/3-540-18420-1_55},
	urldate = {2017-09-05},
	booktitle = {Graph {Reduction}},
	publisher = {Springer},
	author = {Harrison, Peter G. and Reeve, Michael J.},
	year = {1987},
	pages = {181--202},
	file = {Harrison_Reeve_1987_The parallel graph reduction machine, Alice.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harrison_Reeve_1987_The parallel graph reduction machine, Alice.pdf:application/pdf;Harrison_Reeve_1987_The parallel graph reduction machine, Alice.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harrison_Reeve_1987_The parallel graph reduction machine, Alice2.pdf:application/pdf}
}

@article{treleaven_data-driven_1982,
	title = {Data-{Driven} and {Demand}-{Driven} {Computer} {Architecture}},
	volume = {14},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/356869.356873},
	doi = {10.1145/356869.356873},
	number = {1},
	urldate = {2017-09-05},
	journal = {ACM Comput. Surv.},
	author = {Treleaven, Philip C. and Brownbridge, David R. and Hopkins, Richard P.},
	month = mar,
	year = {1982},
	pages = {93--143},
	file = {Treleaven et al_1982_Data-Driven and Demand-Driven Computer Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/T/Treleaven et al_1982_Data-Driven and Demand-Driven Computer Architecture.pdf:application/pdf}
}

@inproceedings{darlington_alice_1981,
	address = {New York, NY, USA},
	series = {{FPCA} '81},
	title = {{ALICE} a {Multi}-processor {Reduction} {Machine} for the {Parallel} {Evaluation} {CF} {Applicative} {Languages}},
	isbn = {978-0-89791-060-6},
	url = {http://doi.acm.org/10.1145/800223.806764},
	doi = {10.1145/800223.806764},
	abstract = {The functional or applicative languages have long been regarded as suitable vehicles for overcoming many of the problems involved in the production and maintenance of correct and reliable software. However, their inherent inefficiences when run on conventional von Neumann style machines have prevented their widespread acceptance. With the declining cost of hardware and the increasing feasibility of multi-processor architectures this position is changing, for, in contrast to conventional programs where it is difficult to detect those parts that may be executed, concurrently, applicative programs are ideally suited to parallel evaluation. In this paper we present a scheme for the parallel evaluation of a wide variety of applicative languages and provide an overview of the architecture of a machine on which it may be implemented. First we describe the scheme, which may be characterized as performing graph reduction, at the abstract level and discuss mechanisms that allow several modes of parallel evaluation to be achieved efficiently. We also show how a variety of languages are supported. We then suggest an implementation of the scheme that has the property of being highly modular; larger and faster machines being built by joining together smaller ones. Performance estimates illustrate that a small machine (of the size that we envisage would form the basic building block of large systems) would provide an efficient desk-top personal applicative computer, while the larger versions promise very high levels of performance Indeed. The machine is designed to be ultimately constructed from a small number of types of VLSI component. Finally we compare our approach with the other proposes schemes for the parallel evaluation of applicative languages and discuss planned future developments.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 1981 {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {ACM},
	author = {Darlington, John and Reeve, Mike},
	year = {1981},
	pages = {65--76},
	file = {Darlington_Reeve_1981_ALICE a Multi-processor Reduction Machine for the Parallel Evaluation CF.pdf:/home/michael/Dropbox/zotero-pdfs/D/Darlington_Reeve_1981_ALICE a Multi-processor Reduction Machine for the Parallel Evaluation CF.pdf:application/pdf;Darlington_Reeve_1981_ALICE a multi-processor reduction machine for the parallel evaluation CF.pdf:/home/michael/Dropbox/zotero-pdfs/D/Darlington_Reeve_1981_ALICE a multi-processor reduction machine for the parallel evaluation CF.pdf:application/pdf}
}

@article{turner_new_1979,
	title = {A new implementation technique for applicative languages},
	volume = {9},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380090105/abstract},
	doi = {10.1002/spe.4380090105},
	abstract = {It is shown how by using results from combinatory logic an applicative language, such as LISP, can be translated into a form from which all bound variables have been removed. A machine is described which can efficiently execute the resulting code. This implementation is compared with a conventional interpreter and found to have a number of advantages. Of these the most important is that programs which exploit higher order functions to achieve great compactness of expression are executed much more efficiently.},
	language = {en},
	number = {1},
	urldate = {2017-09-05},
	journal = {Software: Practice and Experience},
	author = {Turner, D. A.},
	month = jan,
	year = {1979},
	keywords = {Applicative languages, Bracket abstraction, Combinators, Lazy evaluation, Normal graph reduction, Substitution machine},
	pages = {31--49},
	file = {Turner_1979_A new implementation technique for applicative languages.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turner_1979_A new implementation technique for applicative languages.pdf:application/pdf}
}

@phdthesis{knight_implementation_1979,
	type = {Thesis},
	title = {Implementation of a list processing machine},
	copyright = {http://dspace.mit.edu/handle/1721.1/7582},
	url = {http://dspace.mit.edu/handle/1721.1/16033},
	abstract = {Thesis (M.S.)--Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 1979.},
	language = {eng},
	urldate = {2017-09-05},
	school = {Massachusetts Institute of Technology},
	author = {Knight, Thomas F.},
	year = {1979},
	file = {Knight_1979_Implementation of a list processing machine.pdf:/home/michael/Dropbox/zotero-pdfs/K/Knight_1979_Implementation of a list processing machine.pdf:application/pdf}
}

@inproceedings{berkling_reduction_1975,
	address = {New York, NY, USA},
	series = {{ISCA} '75},
	title = {Reduction {Languages} for {Reduction} {Machines}},
	url = {http://doi.acm.org/10.1145/642089.642112},
	doi = {10.1145/642089.642112},
	abstract = {This paper describes a particular realization of a Lambda-Red language as a machine language. Parts of it resemble the Lambda Calculus or a transposed form of it. A constructor syntax is employed such that a linearized preorder representation of the syntax tree is the information structure on which the machine operates. Instances of reduction rules are recognized by combinations of constructors and atoms. Reduction rules with 1, 2 and 3 constructors and/or atoms have been described.A recursive control structure forms the essential part of the implementation. There is a one to one correspondence between constructor syntax and control structure rather than a simulation of recursive structure by von Neumann type instruction sequencing. Thus the system is easily expandable by new constructors and atoms. Execution, that is the application of reduction rules, is subsumed under editing. Emphasis has been on the following pragmatic concepts: locality of action, directness, and security. There are no error messages, errors appear as irreducible expressions. There is no "RUN" instruction, instead the number of reductions to be performed is specified. Whatever happens - it is restricted to subexpressions. The user has the security that all his actions are limited and predictable.The machine language resembles a higher level programming language, but it is "variable-free": expressions are named, not boxes which contain expressions. There seems to be a concept of late binding. However, this is not made a matter of principle, but a matter of degree. Between a general statement of a problem and the result are many intermediate representations - all in the same language - corresponding to various degrees of binding parameters. The user has complete freedom in the choice of variable names. There is a specially developped protection system which avoids confusion of variables.The efficiency of the system is limited by the rate characters can be processed which is essentially determined by the control store cycletime. Measurements will be performed as soon as a simulation of the system is available. Three other important subjects, namely arithmetic, the definition of constants, and source sink input-output will be reported later.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 2Nd {Annual} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Berkling, K. J.},
	year = {1975},
	pages = {133--140},
	file = {Berkling_1975_Reduction Languages for Reduction Machines.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berkling_1975_Reduction Languages for Reduction Machines.pdf:application/pdf}
}

@inproceedings{dennis_preliminary_1975,
	address = {New York, NY, USA},
	series = {{ISCA} '75},
	title = {A {Preliminary} {Architecture} for a {Basic} {Data}-flow {Processor}},
	url = {http://doi.acm.org/10.1145/642089.642111},
	doi = {10.1145/642089.642111},
	abstract = {A processor is described which can achieve highly parallel execution of programs represented in data-flow form. The language implemented incorporates conditional and iteration mechanisms, and the processor is a step toward a practical data-flow processor for a Fortran-level data-flow language. The processor has a unique architecture which avoids the problems of processor switching and memory/processor interconnecion that usually limit the degree of realizable concurrent processing. The architecture offers an unusual solution to the problem of structuring and managing a two-level memory system.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 2Nd {Annual} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Dennis, Jack B. and Misunas, David P.},
	year = {1975},
	pages = {126--132},
	file = {Dennis_Misunas_1975_A Preliminary Architecture for a Basic Data-flow Processor.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dennis_Misunas_1975_A Preliminary Architecture for a Basic Data-flow Processor.pdf:application/pdf}
}

@misc{karlsson_nebula_1981,
	title = {Nebula - {A} functional operating system},
	author = {Karlsson, K},
	year = {1981}
}

@article{s_jones_functional_1989,
	title = {Functional {Programming} and {Operating} {Systems}},
	volume = {32},
	url = {http://link.springer.com/article/10.1007/s10858-011-9569-2},
	number = {2},
	urldate = {2017-09-05},
	journal = {The Computer Journal},
	author = {{S Jones} and Sinclair, F},
	year = {1989},
	keywords = {functional programming, operating system},
	pages = {162--174},
	file = {S Jones_Sinclair_1989_Functional Programming and Operating Systems.pdf:/home/michael/Dropbox/zotero-pdfs/S/S Jones_Sinclair_1989_Functional Programming and Operating Systems.pdf:application/pdf}
}

@article{hohmuth_vfiasco_2005,
	title = {The {VFiasco} approach for a verified operating system},
	url = {https://pdfs.semanticscholar.org/c547/1da30579d8686b7fc50a60fe5043442e69d7.pdf},
	urldate = {2017-09-05},
	journal = {2nd PLOS},
	author = {Hohmuth, Michael and Tews, Hendrik},
	year = {2005},
	file = {Hohmuth_Tews_2005_The VFiasco approach for a verified operating system.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hohmuth_Tews_2005_The VFiasco approach for a verified operating system.pdf:application/pdf}
}

@article{heiser_l4_2016,
	title = {L4 {Microkernels}: {The} {Lessons} from 20 {Years} of {Research} and {Deployment}},
	volume = {34},
	issn = {07342071},
	shorttitle = {L4 {Microkernels}},
	url = {http://dl.acm.org/citation.cfm?doid=2912578.2893177},
	doi = {10.1145/2893177},
	language = {en},
	number = {1},
	urldate = {2017-09-05},
	journal = {ACM Transactions on Computer Systems},
	author = {Heiser, Gernot and Elphinstone, Kevin},
	month = apr,
	year = {2016},
	pages = {1--29},
	file = {Heiser_Elphinstone_2016_L4 Microkernels - The Lessons from 20 Years of Research and Deployment.pdf:/home/michael/Dropbox/zotero-pdfs/H/Heiser_Elphinstone_2016_L4 Microkernels - The Lessons from 20 Years of Research and Deployment.pdf:application/pdf}
}

@misc{gu_certikos:_nodate,
	title = {{CertiKOS}: {An} {Extensible} {Architecture} for {Building} {Certified} {Concurrent} {OS} {Kernels} {\textbar} {USENIX}},
	url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/gu},
	abstract = {Complete formal verification of a non-trivial concurrent
OS kernel is widely considered a grand challenge. We
present a novel compositional approach for building cer-
tified concurrent OS kernels. Concurrency allows inter-
leaved execution of kernel/user modules across different
layers of abstraction. Each such layer can have a different
set of observable events. We insist on formally specifying
these layers and their observable events, and then verify-
ing each kernel module at its proper abstraction level. To
support certified linking with other CPUs or threads, we
prove a strong contextual refinement property for every
kernel function, which states that the implementation of
each such function will behave like its specification under
any kernel/user context with any valid interleaving. We
have successfully developed a practical concurrent OS
kernel and verified its (contextual) functional correctness
in Coq. Our certified kernel is written in 6500 lines of
C and x86 assembly and runs on stock x86 multicore
machines. To our knowledge, this is the first proof of
functional correctness of a complete, general-purpose
concurrent OS kernel with fine-grained locking.},
	urldate = {2017-09-05},
	author = {Gu, Ronghui and Shao, Zhong and Chen, Hao and Wu, Xiongnan and Jieung, Kim and Sjöberg,, Vilhelm and Costanzo, David},
	file = {Gu et al_CertiKOS - An Extensible Architecture for Building Certified Concurrent OS.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gu et al_CertiKOS - An Extensible Architecture for Building Certified Concurrent OS.pdf:application/pdf}
}

@article{tuch_formal_2009,
	title = {Formal {Verification} of {C} {Systems} {Code}},
	volume = {42},
	issn = {0168-7433, 1573-0670},
	url = {https://link.springer.com/article/10.1007/s10817-009-9120-2},
	doi = {10.1007/s10817-009-9120-2},
	abstract = {Systems code is almost universally written in the C programming language or a variant. C has a very low level of type and memory abstraction and formal reasoning about C systems code requires a memory model that is able to capture the semantics of C pointers and types. At the same time, proof-based verification demands abstraction, in particular from the aliasing and frame problems. In this paper we present a study in the mechanisation of two proof abstractions for pointer program verification in the Isabelle/HOL theorem prover, based on a low-level memory model for C. The language’s type system presents challenges for the multiple independent typed heaps (Burstall-Bornat) and separation logic proof techniques. In addition to issues arising from explicit value size/alignment, padding, type-unsafe casts and pointer address arithmetic, structured types such as C’s arrays and structs are problematic due to the non-monotonic nature of pointer and lvalue validity in the presence of the unary \&-operator. For example, type-safe updates through pointers to fields of a struct break the independence of updates across typed heaps or ∧*-conjuncts. We provide models and rules that are able to cope with these language features and types, eschewing common over-simplifications and utilising expressive shallow embeddings in higher-order logic. Two case studies are provided that demonstrate the applicability of the mechanised models to real-world systems code; a working of the standard in-place list reversal example and an overview of the verification of the L4 microkernel’s memory allocator.},
	language = {en},
	number = {2-4},
	urldate = {2017-09-05},
	journal = {Journal of Automated Reasoning},
	author = {Tuch, Harvey},
	month = apr,
	year = {2009},
	pages = {125--187},
	file = {Tuch_2009_Formal Verification of C Systems Code.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tuch_2009_Formal Verification of C Systems Code.pdf:application/pdf}
}

@inproceedings{klein_sel4:_2009,
	address = {New York, NY, USA},
	series = {{SOSP} '09},
	title = {{seL}4: {Formal} {Verification} of an {OS} {Kernel}},
	isbn = {978-1-60558-752-3},
	shorttitle = {{seL}4},
	url = {http://doi.acm.org/10.1145/1629575.1629596},
	doi = {10.1145/1629575.1629596},
	abstract = {Complete formal verification is the only known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 22Nd {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Klein, Gerwin and Elphinstone, Kevin and Heiser, Gernot and Andronick, June and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon},
	year = {2009},
	keywords = {microkernel, isabelle/hol, l4, sel4},
	pages = {207--220},
	file = {Klein et al_2009_seL4 - Formal Verification of an OS Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_2009_seL4 - Formal Verification of an OS Kernel.pdf:application/pdf}
}

@article{klein_operating_2009,
	title = {Operating system verification—{An} overview},
	volume = {34},
	issn = {0256-2499, 0973-7677},
	url = {https://link.springer.com/article/10.1007/s12046-009-0002-4},
	doi = {10.1007/s12046-009-0002-4},
	abstract = {This paper gives a high-level introduction to the topic of formal, interactive, machine-checked software verification in general, and the verification of operating systems code in particular. We survey the state of the art, the advantages and limitations of machine-checked code proofs, and describe two specific ongoing larger-scale verification projects in more detail.},
	language = {en},
	number = {1},
	urldate = {2017-09-05},
	journal = {Sadhana},
	author = {Klein, Gerwin},
	month = feb,
	year = {2009},
	pages = {27--69},
	file = {Klein_2009_Operating system verification—An overview.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein_2009_Operating system verification—An overview.pdf:application/pdf}
}

@inproceedings{cock_secure_2008,
	address = {Berlin, Heidelberg},
	series = {{TPHOLs} '08},
	title = {Secure {Microkernels}, {State} {Monads} and {Scalable} {Refinement}},
	isbn = {978-3-540-71065-3},
	url = {http://dx.doi.org/10.1007/978-3-540-71067-7_16},
	doi = {10.1007/978-3-540-71067-7_16},
	abstract = {We present a scalable, practical Hoare Logic and refinement calculus for the nondeterministic state monad with exceptions and failure in Isabelle/HOL. The emphasis of this formalisation is on large-scale verification of imperative-style functional programs, rather than expressing monad calculi in full generality. We achieve scalability in two dimensions. The method scales to multiple team members working productively and largely independently on a single proof and also to large programs with large and complex properties.We report on our experience in applying the techniques in an extensive (100,000 lines of proof) case study--the formal verification of an executable model of the seL4 operating system microkernel.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Theorem} {Proving} in {Higher} {Order} {Logics}},
	publisher = {Springer-Verlag},
	author = {Cock, David and Klein, Gerwin and Sewell, Thomas},
	year = {2008},
	pages = {167--182},
	file = {Cock et al_2008_Secure Microkernels, State Monads and Scalable Refinement.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cock et al_2008_Secure Microkernels, State Monads and Scalable Refinement.pdf:application/pdf}
}

@techreport{ferdinand_static_2006,
	address = {Warrendale, PA},
	type = {{SAE} {Technical} {Paper}},
	title = {Static {Memory} and {Execution} {Time} {Analysis} of {Embedded} {Code}},
	url = {http://papers.sae.org/2006-01-1499/},
	abstract = {Failure of a safety-critical application on an embedded processor can lead to severe damage or even loss of life. Here we are concerned with two kinds of failure: stack overflow, which usually leads to run-time errors that are difficult to diagnose, and failure to meet deadlines, which is catastrophical for systems with hard real-time characteristics. Classical validation methods like code review and testing with repeated measurements require a lot of effort, are expensive, and do not really help in proving the absence of such errors. AbsInt's tools StackAnalyzer and aiT (timing analyzer) provide a solution to this problem. They use abstract interpretation as a formal method that allows to obtain statements valid for all program runs with all inputs.},
	language = {English},
	number = {2006-01-1499},
	urldate = {2017-09-05},
	institution = {SAE International},
	author = {Ferdinand, Christian and Heckmann, Reinhold},
	month = apr,
	year = {2006},
	doi = {10.4271/2006-01-1499}
}

@article{sandell_static_nodate,
	title = {Static {Timing} {Analysis} of {Real}-{Time} {Operating} {System} {Code}},
	author = {Sandell, Daniel and Ermedahl, Andreas and Gustafsson, Jan and Lisper, Bjorn},
	keywords = {Echtzeitverarbeitung, Grenzfall, Hochschulschrift, Pipeline-Rechner},
	file = {Sandell et al_Static Timing Analysis of Real-Time Operating System Code.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sandell et al_Static Timing Analysis of Real-Time Operating System Code.pdf:application/pdf}
}

@inproceedings{heitmeyer_formal_2006,
	address = {New York, NY, USA},
	series = {{CCS} '06},
	title = {Formal {Specification} and {Verification} of {Data} {Separation} in a {Separation} {Kernel} for an {Embedded} {System}},
	isbn = {978-1-59593-518-2},
	url = {http://doi.acm.org/10.1145/1180405.1180448},
	doi = {10.1145/1180405.1180448},
	abstract = {Although many algorithms, hardware designs, and security protocols have been formally verified, formal verification of the security of software is still rare. This is due in large part to the large size of software, which results in huge costs for verification. This paper describes a novel and practical approach to formally establishing the security of code. The approach begins with a well-defined set of security properties and, based on the properties, constructs a compact security model containing only information needed to rea-son about the properties. Our approach was formulated to provide evidence for a Common Criteria evaluation of an embedded soft-ware system which uses a separation kernel to enforce data separation. The paper describes 1) our approach to verifying the kernel code and 2) the artifacts used in the evaluation: a Top Level Specification (TLS) of the kernel behavior, a formal definition of dataseparation, a mechanized proof that the TLS enforces data separation, code annotated with pre- and postconditions and partitioned into three categories, and a formal demonstration that each category of code enforces data separation. Also presented is the formal argument that the code satisfies the TLS.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Heitmeyer, Constance L. and Archer, Myla and Leonard, Elizabeth I. and McLean, John},
	year = {2006},
	keywords = {code verification, formal model, formal specification, separation kernel, theorem proving},
	pages = {346--355},
	file = {Heitmeyer et al_2006_Formal Specification and Verification of Data Separation in a Separation Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/H/Heitmeyer et al_2006_Formal Specification and Verification of Data Separation in a Separation Kernel.pdf:application/pdf}
}

@inproceedings{hallgren_principled_2005,
	title = {A principled approach to operating system construction in {Haskell}},
	volume = {40},
	url = {http://dl.acm.org/citation.cfm?id=1086380},
	urldate = {2017-09-05},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Hallgren, Thomas and Jones, Mark P. and Leslie, Rebekah and Tolmach, Andrew},
	year = {2005},
	pages = {116--128},
	file = {Hallgren et al_2005_A principled approach to operating system construction in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hallgren et al_2005_A principled approach to operating system construction in Haskell.pdf:application/pdf;HALLGREN-JONES_a-principled-approach-to-operating-system-construction-in-haskell_2005_icfp.pdf:/home/michael/Zotero/storage/3ZGEAKEJ/HALLGREN-JONES_a-principled-approach-to-operating-system-construction-in-haskell_2005_icfp.pdf:application/pdf}
}

@inproceedings{butterfield_proving_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Proving {Correctness} of {Programs} with {IO} —{A} {Paradigm} {Comparison}},
	isbn = {978-3-540-43537-2 978-3-540-46028-2},
	url = {https://link.springer.com/chapter/10.1007/3-540-46028-4_5},
	doi = {10.1007/3-540-46028-4_5},
	abstract = {This paper discusses reasoning about IO operations in Haskell, Clean and C and compares the effect on ease of reasoning of the different approaches taken to IO in these languages. An IO system model is built using VDM and is used to prove a basic property of a program written in each of the three languages. We tentatively draw the conclusions that functional languages are easier to reason about and that Monads can make the reasoning process slightly more difficult, but note that much future work is needed.},
	language = {en},
	urldate = {2017-09-05},
	booktitle = {Implementation of {Functional} {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Butterfield, Andrew and Strong, Glenn},
	month = sep,
	year = {2001},
	pages = {72--87},
	file = {Butterfield_Strong_2001_Proving Correctness of Programs with IO —A Paradigm Comparison.pdf:/home/michael/Dropbox/zotero-pdfs/B/Butterfield_Strong_2001_Proving Correctness of Programs with IO —A Paradigm Comparison.pdf:application/pdf}
}

@inproceedings{adya_cooperative_2002,
	title = {Cooperative {Task} {Management} {Without} {Manual} {Stack} {Management}.},
	url = {http://static.usenix.org/publications/library/proceedings/usenix02/full_papers/adyahowell/adyahowell_html/},
	urldate = {2017-09-05},
	booktitle = {{USENIX} {Annual} {Technical} {Conference}, {General} {Track}},
	author = {Adya, Atul and Howell, Jon and Theimer, Marvin and Bolosky, William J. and Douceur, John R.},
	year = {2002},
	pages = {289--302},
	file = {Adya et al_2002_Cooperative Task Management Without Manual Stack Management.pdf:/home/michael/Dropbox/zotero-pdfs/A/Adya et al_2002_Cooperative Task Management Without Manual Stack Management.pdf:application/pdf}
}

@phdthesis{fu_design_1999,
	title = {Design and {Implementation} of an {Operating} {System} in {Standard} {ML}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.4273&rep=rep1&type=pdf},
	urldate = {2017-09-05},
	school = {Citeseer},
	author = {Fu, Guangrui},
	year = {1999}
}

@book{shapiro_eros:_1999,
	title = {{EROS}: a fast capability system},
	volume = {33},
	shorttitle = {{EROS}},
	url = {http://dl.acm.org/citation.cfm?id=319163},
	number = {5},
	urldate = {2017-09-05},
	publisher = {ACM},
	author = {Shapiro, Jonathan S. and Smith, Jonathan M. and Farber, David J.},
	year = {1999},
	file = {Shapiro et al_1999_EROS - a fast capability system.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shapiro et al_1999_EROS - a fast capability system.pdf:application/pdf}
}

@inproceedings{ford_microkernels_1996,
	address = {New York, NY, USA},
	series = {{OSDI} '96},
	title = {Microkernels {Meet} {Recursive} {Virtual} {Machines}},
	isbn = {978-1-880446-82-9},
	url = {http://doi.acm.org/10.1145/238721.238769},
	doi = {10.1145/238721.238769},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Second} {USENIX} {Symposium} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Ford, Bryan and Hibler, Mike and Lepreau, Jay and Tullmann, Patrick and Back, Godmar and Clawson, Stephen},
	year = {1996},
	pages = {137--151},
	file = {Ford et al_1996_Microkernels Meet Recursive Virtual Machines.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ford et al_1996_Microkernels Meet Recursive Virtual Machines.pdf:application/pdf}
}

@techreport{rees_security_1996,
	address = {Cambridge, MA, USA},
	title = {A {Security} {Kernel} {Based} on the {Lambda}-{Calculus}},
	abstract = {Cooperation between independent agents depends upon establishing adegree of security. Each of the cooperating agents needs assurance that the cooperation will not endanger resources of value to that agent. In a computer system, a computational mechanism can assure safe cooperation among the system''s users by mediating resource access according to desired security policy. Such a mechanism, which is called a \{{\textbackslash}em\{\}security kernel{\textbackslash}/\}, lies at the heart of many operating systems and programming environments.The report describes Scheme 48, a programming environment whose design is guided by established principles of operating system security. Scheme 48''s security kernel is small, consisting of the call-by- value \${\textbackslash}lambda\$-calculus with a few simple extensions to support abstract data types, object mutation, and access to hardware resources. Each agent (user or subsystem) has a separate evaluation environment that holds objects representing privileges granted to that agent. Because environments ultimately determine availability of object references, protection and sharing can be controlled largely by the way in which environments are constructed. I will describe experience with Scheme 48 that shows how it serves as a robust and flexible experimental platform. Two successful applications of Scheme 48 are the programming environment for the Cornell mobile robots, where Scheme 48 runs with no (other) operating system support; and a secure multi-user environment that runs on workstations.},
	institution = {Massachusetts Institute of Technology},
	author = {Rees, Jonathan A.},
	year = {1996},
	file = {Rees_1996_A Security Kernel Based on the Lambda-Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rees_1996_A Security Kernel Based on the Lambda-Calculus.pdf:application/pdf}
}

@inproceedings{brus_clean:_1987,
	address = {London, UK, UK},
	title = {Clean: {A} {Language} for {Functional} {Graph} {Rewriting}},
	isbn = {978-0-387-18317-6},
	shorttitle = {{CLEAN}},
	url = {http://dl.acm.org/citation.cfm?id=36583.36603},
	urldate = {2017-09-05},
	booktitle = {Proc. {Of} a {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer-Verlag},
	author = {Brus, T. H. and van Eekelen, C. J. D. and van Leer, M. O. and Plasmeijer, M. J.},
	year = {1987},
	pages = {364--384},
	file = {Brus et al_1987_Clean - A Language for Functional Graph Rewriting.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brus et al_1987_Clean - A Language for Functional Graph Rewriting.pdf:application/pdf}
}

@inproceedings{flanagan_essence_1993,
	address = {New York, NY, USA},
	series = {{PLDI} '93},
	title = {The {Essence} of {Compiling} with {Continuations}},
	isbn = {978-0-89791-598-4},
	url = {http://doi.acm.org/10.1145/155090.155113},
	doi = {10.1145/155090.155113},
	abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style (CPS) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the “continuation”). Since the nai¨ve CPS transformation considerably increases the size of programs, CPS compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the CPS transformation, this step is conceptually a second phase. Finally, code generators for typical CPS compilers treat continuations specially in order to optimize the interpretation of continuation parameters.
A thorough analysis of the abstract machine for CPS terms show that the actions of the code generator invert the nai¨ve CPS translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed CPS compilers do not need to employ the CPS transformation but can achieve the same results with a simple source-level transformation.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1993 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
	year = {1993},
	pages = {237--247},
	file = {Flanagan et al_1993_The Essence of Compiling with Continuations.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flanagan et al_1993_The Essence of Compiling with Continuations.pdf:application/pdf}
}

@inproceedings{cartwright_semantics_1989,
	address = {New York, NY, USA},
	series = {{PLDI} '89},
	title = {The {Semantics} of {Program} {Dependence}},
	isbn = {978-0-89791-306-5},
	url = {http://doi.acm.org/10.1145/73141.74820},
	doi = {10.1145/73141.74820},
	abstract = {Optimizing and parallelizing compilers for procedural languages rely on various forms of program dependence graphs (pdgs) to express the essential control and data dependencies among atomic program operations. In this paper, we provide a semantic justification for this practice by deriving two different forms of program dependence graph — the output pdg and the def-order pdg—and their semantic definitions from non-strict generalizations of the denotational semantics of the programming language. In the process, we demonstrate that both the output pdg and the def-order pdg (with minor technical modifications) are conventional data-flow programs. In addition, we show that the semantics of the def-order pdg dominates the semantics of the output pdg and that both of these semantics dominate—rather than preserve—the semantics of sequential execution.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1989 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Cartwright, Robert and Felleisen, Mattias},
	year = {1989},
	pages = {13--27},
	file = {Cartwright_Felleisen_1989_The Semantics of Program Dependence.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cartwright_Felleisen_1989_The Semantics of Program Dependence.pdf:application/pdf}
}

@article{stoye_message-based_1986,
	title = {Message-based functional operating systems},
	volume = {6},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/0167642386900286},
	doi = {10.1016/0167-6423(86)90028-6},
	abstract = {A scheme is described for writing nondeterministic programs in a functional language. The scheme is based on message passing between a number of expressions being evaluated in parallel. I suggest that is represents a significant improvement over previous methods employing a nondeterministic merge primitive, and overcomes numerous drawbacks in that approach.},
	urldate = {2017-09-05},
	journal = {Science of Computer Programming},
	author = {Stoye, William},
	month = jan,
	year = {1986},
	pages = {291--311},
	file = {Stoye_1986_Message-based functional operating systems.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stoye_1986_Message-based functional operating systems.pdf:application/pdf}
}

@misc{jones_range_1984,
	title = {A {Range} of {Operating} {Systems} {Written} in a {Purely} {Functional} {Style}},
	url = {https://www.cs.ox.ac.uk/files/3313/PRG42.pdf},
	urldate = {2017-09-05},
	author = {Jones, Simon},
	year = {1984},
	file = {Jones_1984_A Range of Operating Systems Written in a Purely Functional Style.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_1984_A Range of Operating Systems Written in a Purely Functional Style.pdf:application/pdf}
}

@inproceedings{rushby_proof_1982,
	address = {London, UK, UK},
	title = {Proof of {Separability}: {A} {Verification} {Technique} for a {Class} of a {Security} {Kernels}},
	isbn = {978-3-540-11494-9},
	shorttitle = {Proof of {Separability}},
	url = {http://dl.acm.org/citation.cfm?id=647325.721663},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 5th {Colloquium} on {International} {Symposium} on {Programming}},
	publisher = {Springer-Verlag},
	author = {Rushby, John M.},
	year = {1982},
	pages = {352--367},
	file = {[31]_RUSHBY_proof-of-separability-a-verification-technique-for-a-class-of-security-kernels_1981_isp.pdf:/home/michael/Zotero/storage/WSGZHX2R/[31]_RUSHBY_proof-of-separability-a-verification-technique-for-a-class-of-security-kernels_1981_isp.pdf:application/pdf}
}

@inproceedings{feiertag_proving_1977,
	address = {New York, NY, USA},
	series = {{SOSP} '77},
	title = {Proving {Multilevel} {Security} of a {System} {Design}},
	url = {http://doi.acm.org/10.1145/800214.806547},
	doi = {10.1145/800214.806547},
	abstract = {Two nearly equivalent models of multilevel security are presented. The use of multiple models permits the utilization of each model for purposes where that model is particularly advantageous. In this case, the more general model is simple and easily comprehensible, being more abstract, and is useful for exposition of the meaning of multilevel security. The less general model relates well to design specifications and permits straightforward proof of the security of a system design. The correspondence between the two models is easily demonstrated. The two models when applied appropriately are more useful for defining and proving the multilevel security of systems than existing models. The utility of the two models and their relationship to existing models is discussed and the proof of the security of one particular system design is illustrated. The technique for accomplishing the security proof is straightforward and can be extensively automated.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Sixth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Feiertag, R. J. and Levitt, K. N. and Robinson, L.},
	year = {1977},
	pages = {57--65},
	file = {Feiertag et al_1977_Proving Multilevel Security of a System Design.pdf:/home/michael/Dropbox/zotero-pdfs/F/Feiertag et al_1977_Proving Multilevel Security of a System Design.pdf:application/pdf}
}

@techreport{kahn_coroutines_1976,
	type = {Research {Report}},
	title = {Coroutines and {Networks} of {Parallel} {Processes}},
	url = {https://hal.inria.fr/inria-00306565},
	abstract = {Les concepts de coroutine et de processus interviennent dans une grande variété d'applications, où il est en général nécessaire de produire ou de transformer des données de façon progressive. Nous présentons un langage, fondé sur une vue sémantique précises de l'interaction entre processus, qui facilite la programmation de réseaux de processus qui évoluent dynamiquement. Ces réseaux ont un comportement externe unique, qu'ils soient exécutés de manière séquentielle ou parallèle. Les avantages d'une sémantique dénotationelle simple sont illustrés par des preuves de programmes. Ce langage de programmation permet aussi de clarifier les relations entre plusieurs concepts : coroutines, appel par nécessité, structures de données dynamiques et calcul parallèle.},
	urldate = {2017-09-05},
	author = {Kahn, Gilles and Macqueen, David},
	year = {1976},
	pages = {20},
	file = {Kahn_Macqueen_1976_Coroutines and Networks of Parallel Processes.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kahn_Macqueen_1976_Coroutines and Networks of Parallel Processes.pdf:application/pdf;Kahn_Macqueen_1976_Coroutines and Networks of Parallel Processes.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kahn_Macqueen_1976_Coroutines and Networks of Parallel Processes.pdf:application/pdf}
}

@techreport{neumann_provably_1975,
	title = {A {Provably} {Secure} {Operating} {System}.},
	url = {http://www.dtic.mil/docs/citations/ADA088601},
	urldate = {2017-09-05},
	institution = {STANFORD RESEARCH INST MENLO PARK CALIF},
	author = {Neumann, Peter G. and Robinson, L. and Levitt, Karl N. and Boyer, R. S. and Saxena, A. R.},
	year = {1975},
	file = {Neumann et al_1975_A Provably Secure Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/N/Neumann et al_1975_A Provably Secure Operating System.pdf:application/pdf}
}

@techreport{bell_secure_1973,
	title = {Secure {Computer} {Systems}: {Mathematical} {Foundations}},
	shorttitle = {Secure {Computer} {Systems}},
	url = {http://www.dtic.mil/docs/citations/AD0770768},
	abstract = {Set theory, Mathematical models, Computer information security, Computer privacy, Computer security, Systems theoryThe paper reports the first results of an investigation into solutions to problems of security in computer systems; it establishes the basis for rigorous investigation by providing a general descriptive model of a computer system. Borrowing basic concepts and constructs from general systems theory, the authors formed a basic result concerning security in computer systems, using precise notions of 'security' and 'compromise'. The authors also demonstrate how a change in requirements can be reflected in the resulting mathematical model. A lengthy introductory section is included in order to bridge the gap between general systems theory and practical problem solving.},
	number = {MTR-2547-VOL-1},
	urldate = {2017-09-05},
	institution = {MITRE CORP BEDFORD MA, MITRE CORP BEDFORD MA},
	author = {Bell, D. E. and LaPadula, Leonard J.},
	month = nov,
	year = {1973},
	file = {Bell_LaPadula_1973_Secure Computer Systems - Mathematical Foundations.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bell_LaPadula_1973_Secure Computer Systems - Mathematical Foundations.pdf:application/pdf}
}

@inproceedings{deutsch_lisp_1973,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'73},
	title = {A {LISP} {Machine} with {Very} {Compact} {Programs}},
	url = {http://dl.acm.org/citation.cfm?id=1624775.1624860},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 3rd {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Deutsch, L. Peter},
	year = {1973},
	pages = {697--703}
}

@article{stata_type_1999,
	title = {A {Type} {System} for {Java} {Bytecode} {Subroutines}},
	volume = {21},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/314602.314606},
	doi = {10.1145/314602.314606},
	abstract = {Java is typically compiled into an intermediate language, JVML, that 
is interpreted by the Java Virtual Machine. Because mobile JVML code is not always trusted, a bytecode verifier enforces static constraints that prevent various dynamic errors. Given the importance of the bytecode verifier for security, its current descriptions are inadequate. This article proposes using typing rules to describe the bytecode verifier because they are more precise than prose, clearer than code, and easier to reason about than either. JVML has a subroutine construct which is used for the compilation of Java's try-finally statement. Subroutines are a major source of complexity for the bytecode verifier because they are not obviously last-in/first-out and because they require a kind of polymorphism.  Focusing on subroutines, we isolate an interesting, small subset of JVML. We give typing rules for this subset and prove their correctness. Our type system constitutes a sound basis for bytecode verification and a rational reconstruction of a delicate part of Sun's bytecode verifier.},
	number = {1},
	urldate = {2017-09-01},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Stata, Raymie and Abadi, Martin},
	month = jan,
	year = {1999},
	keywords = {Java, bytecode verification},
	pages = {90--137},
	file = {Stata_Abadi_1999_A Type System for Java Bytecode Subroutines.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stata_Abadi_1999_A Type System for Java Bytecode Subroutines.pdf:application/pdf}
}

@misc{moggi_abstract_nodate,
	title = {An {Abstract} {View} of {Programming} {Languages}},
	url = {http://www.lfcs.inf.ed.ac.uk/reports/90/ECS-LFCS-90-113/},
	urldate = {2017-09-05},
	author = {Moggi, Eugenio},
	file = {Moggi_An Abstract View of Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moggi_An Abstract View of Programming Languages.pdf:application/pdf}
}

@inproceedings{akturk_amnesiac:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {{AMNESIAC}: {Amnesic} {Automatic} {Computer}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{AMNESIAC}},
	url = {http://doi.acm.org/10.1145/3037697.3037741},
	doi = {10.1145/3037697.3037741},
	abstract = {Due to imbalances in technology scaling, the energy consumption of data storage and communication by far exceeds the energy consumption of actual data production, i.e., computation. As a consequence, recomputing data can become more energy efficient than storing and retrieving precomputed data. At the same time, recomputation can relax the pressure on the memory hierarchy and the communication bandwidth. This study hence assesses the energy efficiency prospects of trading computation for communication. We introduce an illustrative proof-of-concept design, identify practical limitations, and provide design guidelines.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Akturk, Ismail and Karpuzcu, Ulya R.},
	year = {2017},
	keywords = {energy efficiency, recomputation},
	pages = {811--824},
	file = {Akturk_Karpuzcu_2017_AMNESIAC - Amnesic Automatic Computer.pdf:/home/michael/Dropbox/zotero-pdfs/A/Akturk_Karpuzcu_2017_AMNESIAC - Amnesic Automatic Computer.pdf:application/pdf}
}

@inproceedings{huang_pallas:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Pallas: {Semantic}-{Aware} {Checking} for {Finding} {Deep} {Bugs} in {Fast} {Path}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {Pallas},
	url = {http://doi.acm.org/10.1145/3037697.3037743},
	doi = {10.1145/3037697.3037743},
	abstract = {Software optimization is constantly a serious concern for developing high-performance systems. To accelerate the workflow execution of a specific functionality, software developers usually define and implement a fast path to speed up the critical and commonly executed functions in the workflow. However, producing a bug-free fast path is nontrivial. Our study on the Linux kernel discloses that a committed fast path can have up to 19 follow-up patches for bug fixing, and most of them are deep semantic bugs, which are difficult to be pinpointed by existing bug-finding tools. In this paper, we present such a new category of software bugs based on our fast-path bug study across various system software including virtual memory manager, file systems, network, and device drivers. We investigate their root causes and identify five error-prone aspects in a fast path: path state, trigger condition, path output, fault handling, and assistant data structure. We find that many of the deep bugs can be prevented by applying static analysis incorporating simple semantic information. We extract a set of rules based on our findings and build a toolkit PALLAS to check fast-path bugs. The evaluation results show that PALLAS can effectively reveal fast-path bugs in a variety of systems including Linux kernel, mobile operating system, software-defined networking system, and web browser.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Huang, Jian and Allen-Bond, Michael and Zhang, Xuechen},
	year = {2017},
	keywords = {static analysis, fast path, semantic bugs, software optimization},
	pages = {709--722},
	file = {Huang et al_2017_Pallas - Semantic-Aware Checking for Finding Deep Bugs in Fast Path.pdf:/home/michael/Dropbox/zotero-pdfs/H/Huang et al_2017_Pallas - Semantic-Aware Checking for Finding Deep Bugs in Fast Path.pdf:application/pdf}
}

@inproceedings{mashtizadeh_towards_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Towards {Practical} {Default}-{On} {Multi}-{Core} {Record}/{Replay}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037751},
	doi = {10.1145/3037697.3037751},
	abstract = {We present Castor, a record/replay system for multi-core applications that provides consistently low and predictable overheads. With Castor, developers can leave record and replay on by default, making it practical to record and reproduce production bugs, or employ fault tolerance to recover from hardware failures. Castor is inspired by several observations: First, an efficient mechanism for logging non-deterministic events is critical for recording demanding workloads with low overhead. Through careful use of hardware we were able to increase log throughput by 10x or more, e.g., we could record a server handling 10x more requests per second for the same record overhead. Second, most applications can be recorded without modifying source code by using the compiler to instrument language level sources of non-determinism, in conjunction with more familiar techniques like shared library interposition. Third, while Castor cannot deterministically replay all data races, this limitation is generally unimportant in practice, contrary to what prior work has assumed. Castor currently supports applications written in C, C++, and Go on FreeBSD. We have evaluated Castor on parallel and server workloads, including a commercial implementation of memcached in Go, which runs Castor in production.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Mashtizadeh, Ali José and Garfinkel, Tal and Terei, David and Mazieres, David and Rosenblum, Mendel},
	year = {2017},
	keywords = {fault-tolerance, multi-core replay, replay debugging},
	pages = {693--708},
	file = {Mashtizadeh et al_2017_Towards Practical Default-On Multi-Core Record-Replay.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mashtizadeh et al_2017_Towards Practical Default-On Multi-Core Record-Replay.pdf:application/pdf}
}

@inproceedings{lustig_automated_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Automated {Synthesis} of {Comprehensive} {Memory} {Model} {Litmus} {Test} {Suites}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037723},
	doi = {10.1145/3037697.3037723},
	abstract = {The memory consistency model is a fundamental part of any shared memory architecture or programming model. Modern weak memory models are notoriously difficult to define and to implement correctly. Most real-world programming languages, compilers, and (micro)architectures therefore rely heavily on black-box testing methodologies. The success of such techniques requires that the suite of litmus tests used to perform the testing be comprehensive--it should ideally stress all obscure corner cases of the model and of its implementation. Most litmus test suites today are generated from some combination of manual effort and randomization; however, the complex and subtle nature of contemporary memory models means that manual effort is both error-prone and subject to incomplete coverage. This paper presents a methodology for synthesizing comprehensive litmus test suites directly from a memory model specification. By construction, these suites contain all tests satisfying a minimality criterion: that no synchronization mechanism in the test can be weakened without causing new behaviors to become observable. We formalize this notion using the Alloy modeling language, and we apply it to a number of existing and newly-proposed memory models. Our results show not only that this synthesis technique can automatically reproduce all manually-generated tests from existing suites, but also that it discovers new tests that are not as well studied.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Lustig, Daniel and Wright, Andrew and Papakonstantinou, Alexandros and Giroux, Olivier},
	year = {2017},
	keywords = {litmus tests, memory consistency models, synchronization, synthesis},
	pages = {661--675},
	file = {Lustig et al_2017_Automated Synthesis of Comprehensive Memory Model Litmus Test Suites.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lustig et al_2017_Automated Synthesis of Comprehensive Memory Model Litmus Test Suites.pdf:application/pdf}
}

@inproceedings{ge_griffin:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {{GRIFFIN}: {Guarding} {Control} {Flows} {Using} {Intel} {Processor} {Trace}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{GRIFFIN}},
	url = {http://doi.acm.org/10.1145/3037697.3037716},
	doi = {10.1145/3037697.3037716},
	abstract = {Researchers are actively exploring techniques to enforce control-flow integrity (CFI), which restricts program execution to a predefined set of targets for each indirect control transfer to prevent code-reuse attacks. While hardware-assisted CFI enforcement may have the potential for advantages in performance and flexibility over software instrumentation, current hardware-assisted defenses are either incomplete (i.e., do not enforce all control transfers) or less efficient in comparison. We find that the recent introduction of hardware features to log complete control-flow traces, such as Intel Processor Trace (PT), provides an opportunity to explore how efficient and flexible a hardware-assisted CFI enforcement system may become. While Intel PT was designed to aid in offline debugging and failure diagnosis, we explore its effectiveness for online CFI enforcement over unmodified binaries by designing a parallelized method for enforcing various types of CFI policies. We have implemented a prototype called GRIFFIN in the Linux 4.2 kernel that enables complete CFI enforcement over a variety of software, including the Firefox browser and its jitted code. Our experiments show that GRIFFIN can enforce fine-grained CFI policies with shadow stack as recommended by researchers at a performance that is comparable to software-only instrumentation techniques. In addition, we find that alternative logging approaches yield significant performance improvements for trace processing, identifying opportunities for further hardware assistance.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Ge, Xinyang and Cui, Weidong and Jaeger, Trent},
	year = {2017},
	keywords = {control-flow integrity, intel processor trace},
	pages = {585--598},
	file = {Ge et al_2017_GRIFFIN - Guarding Control Flows Using Intel Processor Trace.pdf:/home/michael/Dropbox/zotero-pdfs/G/Ge et al_2017_GRIFFIN - Guarding Control Flows Using Intel Processor Trace.pdf:application/pdf}
}

@inproceedings{zhang_identifying_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Identifying {Security} {Critical} {Properties} for the {Dynamic} {Verification} of a {Processor}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037734},
	doi = {10.1145/3037697.3037734},
	abstract = {We present a methodology for identifying security critical properties for use in the dynamic verification of a processor. Such verification has been shown to be an effective way to prevent exploits of vulnerabilities in the processor, given a meaningful set of security properties. We use known processor errata to establish an initial set of security-critical invariants of the processor. We then use machine learning to infer an additional set of invariants that are not tied to any particular, known vulnerability, yet are critical to security. We build a tool chain implementing the approach and evaluate it for the open-source OR1200 RISC processor. We find that our tool can identify 19 (86.4\%) of the 22 manually crafted security-critical properties from prior work and generates 3 new security properties not covered in prior work.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Zhang, Rui and Stanley, Natalie and Griggs, Christopher and Chi, Andrew and Sturton, Cynthia},
	year = {2017},
	keywords = {hardware security, processor errata, security properties, supervised learning},
	pages = {541--554},
	file = {Zhang et al_2017_Identifying Security Critical Properties for the Dynamic Verification of a.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhang et al_2017_Identifying Security Critical Properties for the Dynamic Verification of a.pdf:application/pdf}
}

@inproceedings{wang_graspan:_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Graspan: {A} {Single}-machine {Disk}-based {Graph} {System} for {Interprocedural} {Static} {Analyses} of {Large}-scale {Systems} {Code}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {Graspan},
	url = {http://doi.acm.org/10.1145/3037697.3037744},
	doi = {10.1145/3037697.3037744},
	abstract = {There is more than a decade-long history of using static analysis to find bugs in systems such as Linux. Most of the existing static analyses developed for these systems are simple checkers that find bugs based on pattern matching. Despite the presence of many sophisticated interprocedural analyses, few of them have been employed to improve checkers for systems code due to their complex implementations and poor scalability. In this paper, we revisit the scalability problem of interprocedural static analysis from a "Big Data" perspective. That is, we turn sophisticated code analysis into Big Data analytics and leverage novel data processing techniques to solve this traditional programming language problem. We develop Graspan, a disk-based parallel graph system that uses an edge-pair centric computation model to compute dynamic transitive closures on very large program graphs. We implement context-sensitive pointer/alias and dataflow analyses on Graspan. An evaluation of these analyses on large codebases such as Linux shows that their Graspan implementations scale to millions of lines of code and are much simpler than their original implementations. Moreover, we show that these analyses can be used to augment the existing checkers; these augmented checkers uncovered 132 new NULL pointer bugs and 1308 unnecessary NULL tests in Linux 4.4.0-rc5, PostgreSQL 8.3.9, and Apache httpd 2.2.18.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Wang, Kai and Hussain, Aftab and Zuo, Zhiqiang and Xu, Guoqing and Amiri Sani, Ardalan},
	year = {2017},
	keywords = {static analysis, disk-based systems, graph processing},
	pages = {389--404},
	file = {Wang et al_2017_Graspan - A Single-machine Disk-based Graph System for Interprocedural Static.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang et al_2017_Graspan - A Single-machine Disk-based Graph System for Interprocedural Static.pdf:application/pdf}
}

@inproceedings{jevdjic_approximate_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Approximate {Storage} of {Compressed} and {Encrypted} {Videos}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037718},
	doi = {10.1145/3037697.3037718},
	abstract = {The popularization of video capture devices has created strong storage demand for encoded videos. Approximate storage can ease this demand by enabling denser storage at the expense of occasional errors. Unfortunately, even minor storage errors, such as bit flips, can result in major visual damage in encoded videos. Similarly, video encryption, widely employed for privacy and digital rights management, may create long dependencies between bits that show little or no tolerance to storage errors. In this paper we propose VideoApp, a novel and efficient methodology to compute bit-level reliability requirements for encoded videos by tracking visual and metadata dependencies within encoded bitstreams. We further show how VideoApp can be used to trade video quality for storage density in an optimal way. We integrate our methodology into a popular H.264 encoder to partition an encoded video stream into multiple streams that can receive different levels of error correction according to their reliability needs. When applied to a dense and highly error-prone multi-level cell storage substrate, our variable error correction mechanism reduces the error correction overhead by half under the most error-intolerant encoder settings, achieving quality/density points that neither compression nor approximation can achieve alone. Finally, we define the basic invariants needed to support encrypted approximate video storage. We present an analysis of block cipher modes of operation, showing that some are fully compatible with approximation, enabling approximate and secure video storage systems.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Jevdjic, Djordje and Strauss, Karin and Ceze, Luis and Malvar, Henrique S.},
	year = {2017},
	keywords = {approximate storage, encryption, multi-level cells, video encoding},
	pages = {361--373},
	file = {Jevdjic et al_2017_Approximate Storage of Compressed and Encrypted Videos.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jevdjic et al_2017_Approximate Storage of Compressed and Encrypted Videos.pdf:application/pdf}
}

@inproceedings{churchill_sound_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Sound {Loop} {Superoptimization} for {Google} {Native} {Client}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037754},
	doi = {10.1145/3037697.3037754},
	abstract = {Software fault isolation (SFI) is an important technique for the construction of secure operating systems, web browsers, and other extensible software. We demonstrate that superoptimization can dramatically improve the performance of Google Native Client, a SFI system that ships inside the Google Chrome Browser. Key to our results are new techniques for superoptimization of loops: we propose a new architecture for superoptimization tools that incorporates both a fully sound verification technique to ensure correctness and a bounded verification technique to guide the search to optimized code. In our evaluation we optimize 13 libc string functions, formally verify the correctness of the optimizations and report a median and average speedup of 25\% over the libraries shipped by Google.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Churchill, Berkeley and Sharma, Rahul and Bastien, JF and Aiken, Alex},
	year = {2017},
	keywords = {verification, x86-64, assembly, bounded verification, data-driven verification, equivalence checking, native client, superoptimization},
	pages = {313--326},
	file = {Churchill et al_2017_Sound Loop Superoptimization for Google Native Client.pdf:/home/michael/Dropbox/zotero-pdfs/C/Churchill et al_2017_Sound Loop Superoptimization for Google Native Client.pdf:application/pdf}
}

@inproceedings{olson_crossing_2017,
	title = {Crossing {Guard}: {Mediating} {Host}-{Accelerator} {Coherence} {Interactions}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {Crossing {Guard}},
	url = {http://dl.acm.org/citation.cfm?doid=3037697.3037715},
	doi = {10.1145/3037697.3037715},
	language = {en},
	urldate = {2017-09-05},
	publisher = {ACM Press},
	author = {Olson, Lena E. and Hill, Mark D. and Wood, David A.},
	year = {2017},
	pages = {163--176},
	file = {Olson et al_2017_Crossing Guard - Mediating Host-Accelerator Coherence Interactions.pdf:/home/michael/Dropbox/zotero-pdfs/O/Olson et al_2017_Crossing Guard - Mediating Host-Accelerator Coherence Interactions.pdf:application/pdf}
}

@inproceedings{zhang_prorace:_2017,
	title = {{ProRace}: {Practical} {Data} {Race} {Detection} for {Production} {Use}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{ProRace}},
	url = {http://dl.acm.org/citation.cfm?doid=3037697.3037708},
	doi = {10.1145/3037697.3037708},
	language = {en},
	urldate = {2017-09-05},
	publisher = {ACM Press},
	author = {Zhang, Tong and Jung, Changhee and Lee, Dongyoon},
	year = {2017},
	pages = {149--162},
	file = {Zhang et al_2017_ProRace - Practical Data Race Detection for Production Use.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhang et al_2017_ProRace - Practical Data Race Detection for Production Use.pdf:application/pdf}
}

@inproceedings{nalli_analysis_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {An {Analysis} of {Persistent} {Memory} {Use} with {WHISPER}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037730},
	doi = {10.1145/3037697.3037730},
	abstract = {Emerging non-volatile memory (NVM) technologies promise durability with read and write latencies comparable to volatile memory (DRAM). We define Persistent Memory (PM) as NVM accessed with byte addressability at low latency via normal memory instructions. Persistent-memory applications ensure the consistency of persistent data by inserting ordering points between writes to PM allowing the construction of higher-level transaction mechanisms. An epoch is a set of writes to PM between ordering points. To put systems research in PM on a firmer footing, we developed and analyzed a PM benchmark suite called WHISPER (Wisconsin-HP Labs Suite for Persistence) that comprises ten PM applications we gathered to cover all current interfaces to PM. A quantitative analysis reveals several insights: (a) only 4\% of writes in PM-aware applications are to PM and the rest are to volatile memory, (b) software transactions are often implemented with 5 to 50 ordering points (c) 75\% of epochs update exactly one 64B cache line, (d) 80\% of epochs from the same thread depend on previous epochs from the same thread, while few epochs depend on epochs from other threads. Based on our analysis, we propose the Hands-off Persistence System (HOPS) to track updates to PM in hardware. Current hardware design requires applications to force data to PM as each epoch ends. HOPS provides high-level ISA primitives for applications to express durability and ordering constraints separately and enforces them automatically, while achieving 24.3\% better performance over current approaches to persistence.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Nalli, Sanketh and Haria, Swapnil and Hill, Mark D. and Swift, Michael M. and Volos, Haris and Keeton, Kimberly},
	year = {2017},
	keywords = {benchmark, caches, non-volatile memory (nvm), persistent memory (pm), storage-class memory},
	pages = {135--148},
	file = {Nalli et al_2017_An Analysis of Persistent Memory Use with WHISPER.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nalli et al_2017_An Analysis of Persistent Memory Use with WHISPER.pdf:application/pdf}
}

@inproceedings{bhattacharjee_translation-triggered_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Translation-{Triggered} {Prefetching}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037705},
	doi = {10.1145/3037697.3037705},
	abstract = {We propose translation-enabled memory prefetching optimizations or TEMPO, a low-overhead hardware mechanism to boost memory performance by exploiting the operating system's (OS) virtual memory subsystem. We are the first to make the following observations: (1) a substantial fraction (20-40\%) of DRAM references in modern big- data workloads are devoted to accessing page tables; and (2) when memory references require page table lookups in DRAM, the vast majority of them (98\%+) also look up DRAM for the subsequent data access. TEMPO exploits these observations to enable DRAM row-buffer and on-chip cache prefetching of the data that page tables point to. TEMPO requires trivial changes to the memory controller (under 3\% additional area), no OS or application changes, and improves performance by 10-30\% and energy by 1-14\%.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Bhattacharjee, Abhishek},
	year = {2017},
	keywords = {cache prefetching, dram., virtual memory},
	pages = {63--76},
	file = {Bhattacharjee_2017_Translation-Triggered Prefetching.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bhattacharjee_2017_Translation-Triggered Prefetching.pdf:application/pdf}
}

@inproceedings{cherupalli_determining_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {Determining {Application}-specific {Peak} {Power} and {Energy} {Requirements} for {Ultra}-low {Power} {Processors}},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037711},
	doi = {10.1145/3037697.3037711},
	abstract = {Many emerging applications such as IoT, wearables, implantables, and sensor networks are power- and energy-constrained. These applications rely on ultra-low-power processors that have rapidly become the most abundant type of processor manufactured today. In the ultra-low-power embedded systems used by these applications, peak power and energy requirements are the primary factors that determine critical system characteristics, such as size, weight, cost, and lifetime. While the power and energy requirements of these systems tend to be application-specific, conventional techniques for rating peak power and energy cannot accurately bound the power and energy requirements of an application running on a processor, leading to over-provisioning that increases system size and weight. In this paper, we present an automated technique that performs hardware-software co-analysis of the application and ultra-low-power processor in an embedded system to determine application-specific peak power and energy requirements. Our technique provides more accurate, tighter bounds than conventional techniques for determining peak power and energy requirements, reporting 15\% lower peak power and 17\% lower peak energy, on average, than a conventional approach based on profiling and guardbanding. Compared to an aggressive stressmark-based approach, our technique reports power and energy bounds that are 26\% and 26\% lower, respectively, on average. Also, unlike conventional approaches, our technique reports guaranteed bounds on peak power and energy independent of an application's input set. Tighter bounds on peak power and energy can be exploited to reduce system size, weight, and cost.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Cherupalli, Hari and Duwe, Henry and Ye, Weidong and Kumar, Rakesh and Sartori, John},
	year = {2017},
	keywords = {internet of things (iot), embedded computing, energy management, power},
	pages = {3--16},
	file = {Cherupalli et al_2017_Determining Application-specific Peak Power and Energy Requirements for.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cherupalli et al_2017_Determining Application-specific Peak Power and Energy Requirements for.pdf:application/pdf}
}

@inproceedings{lion_dont_2016,
	title = {Don't {Get} {Caught} in the {Cold}, {Warm}-up {Your} {JVM}: {Understand} and {Eliminate} {JVM} {Warm}-up {Overhead} in {Data}-{Parallel} {Systems}.},
	shorttitle = {Don't {Get} {Caught} in the {Cold}, {Warm}-up {Your} {JVM}},
	url = {https://www.usenix.org/system/files/conference/osdi16/osdi16-lion.pdf},
	urldate = {2017-09-05},
	booktitle = {{OSDI}},
	author = {Lion, David and Chiu, Adrian and Sun, Hailong and Zhuang, Xin and Grcevski, Nikola and Yuan, Ding},
	year = {2016},
	pages = {383--400},
	file = {Lion et al_2016_Don't Get Caught in the Cold, Warm-up Your JVM - Understand and Eliminate JVM.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lion et al_2016_Don't Get Caught in the Cold, Warm-up Your JVM - Understand and Eliminate JVM.pdf:application/pdf}
}

@inproceedings{nguyen_yak:_2016,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'16},
	title = {Yak: {A} {High}-performance {Big}-data-friendly {Garbage} {Collector}},
	isbn = {978-1-931971-33-1},
	shorttitle = {Yak},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026905},
	abstract = {Most "Big Data" systems are written in managed languages, such as Java, C\#, or Scala. These systems suffer from severe memory problems due to the massive volume of objects created to process input data. Allocating and deallocating a sea of data objects puts a severe strain on existing garbage collectors (GC), leading to high memory management overheads and reduced performance. This paper describes the design and implementation of Yak, a "Big Data" friendly garbage collector that provides high throughput and low latency for all JVM-based languages. Yak divides the managed heap into a control space (CS) and a data space (DS), based on the observation that a typical data-intensive system has a clear distinction between a control path and a data path. Objects created in the control path are allocated in the CS and subject to regular tracing GC. The lifetimes of objects in the data path often align with epochs creating them. They are thus allocated in the DS and subject to region-based memory management. Our evaluation with three large systems shows very positive results.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 12th {USENIX} {Conference} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Nguyen, Khanh and Fang, Lu and Xu, Guoqing and Demsky, Brian and Lu, Shan and Alamian, Sanazsadat and Mutlu, Onur},
	year = {2016},
	pages = {349--365}
}

@inproceedings{porter_rex:_2016,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'16},
	title = {{REX}: {A} {Development} {Platform} and {Online} {Learning} {Approach} for {Runtime} {Emergent} {Software} {Systems}},
	isbn = {978-1-931971-33-1},
	shorttitle = {{REX}},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026904},
	abstract = {Conventional approaches to self-adaptive software architectures require human experts to specify models, policies and processes by which software can adapt to its environment. We present REX, a complete platform and online learning approach for runtime emergent software systems, in which all decisions about the assembly and adaptation of software are machine-derived. REX is built with three major, integrated layers: (i) a novel component-based programming language called Dana, enabling discovered assembly of systems and very low cost adaptation of those systems for dynamic re-assembly; (ii) a perception, assembly and learning framework (PAL) built on Dana, which abstracts emergent software into configurations and perception streams; and (iii) an online learning implementation based on a linear bandit model, which helps solve the search space explosion problem inherent in runtime emergent software. Using an emergent web server as a case study, we show how software can be autonomously self-assembled from discovered parts, and continually optimized over time (by using alternative parts) as it is subjected to different deployment conditions. Our system begins with no knowledge that it is specifically assembling a web server, nor with knowledge of the deployment conditions that may occur at runtime.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 12th {USENIX} {Conference} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Porter, Barry and Grieves, Matthew and Filho, Roberto Rodrigues and Leslie, David},
	year = {2016},
	pages = {333--348}
}

@article{hutton_tutorial_1999,
	title = {A tutorial on the universality and expressiveness of fold},
	volume = {9},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/a-tutorial-on-the-universality-and-expressiveness-of-fold/CDBAA53C7120E23CBBBE206FD47FDBAA},
	number = {4},
	urldate = {2017-09-05},
	journal = {Journal of Functional Programming},
	author = {Hutton, Graham},
	year = {1999},
	pages = {355--372},
	file = {Hutton_1999_A tutorial on the universality and expressiveness of fold.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hutton_1999_A tutorial on the universality and expressiveness of fold.pdf:application/pdf}
}

@article{jones_flow_2007,
	series = {Festschrift for {John} {C}. {Reynolds}’s 70th birthday},
	title = {Flow analysis of lazy higher-order functional programs},
	volume = {375},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397506009194},
	doi = {10.1016/j.tcs.2006.12.030},
	abstract = {In recent years much interest has been shown in a class of functional languages including HASKELL, lazy ML, SASL/KRC/MIRANDA, ALFL, ORWELL, and PONDER. It has been seen that their expressive power is great, programs are compact, and program manipulation and transformation is much easier than with imperative languages or more traditional applicative ones. Common characteristics: they are purely applicative, manipulate trees as data objects, use pattern matching both to determine control flow and to decompose compound data structures, and use a “lazy” evaluation strategy. In this paper we describe a technique for data flow analysis of programs in this class by safely approximating the behavior of a certain class of term rewriting systems. In particular we obtain “safe” descriptions of program inputs, outputs and intermediate results by regular sets of trees. Potential applications include optimization, strictness analysis and partial evaluation. The technique improves earlier work because of its applicability to programs with higher-order functions, and with either eager or lazy evaluation. The technique addresses the call-by-name aspect of laziness, but not memoization.},
	number = {1},
	urldate = {2017-09-05},
	journal = {Theoretical Computer Science},
	author = {Jones, Neil D. and Andersen, Nils},
	month = may,
	year = {2007},
	keywords = {Lazy evaluation, Collecting semantics, Higher-order program, Program flow analysis, Reynolds analysis of applicative LISP programs Term rewriting system, Tree grammar},
	pages = {120--136},
	file = {Jones_Andersen_2007_Flow analysis of lazy higher-order functional programs.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Andersen_2007_Flow analysis of lazy higher-order functional programs.pdf:application/pdf}
}

@inproceedings{abramsky_lazy_1990,
	title = {The {Lazy} λ- {Calculus}},
	url = {https://ora.ox.ac.uk/objects/uuid:d4b2e87c-0048-4398-8220-d0298ec13210/datastreams/ATTACHMENT01},
	urldate = {2017-09-05},
	booktitle = {Research topics in functional programming},
	publisher = {Addison Wesley},
	author = {Abramsky, Samson},
	year = {1990},
	file = {Abramsky_1990_The Lazy λ- Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/A/Abramsky_1990_The Lazy λ- Calculus.pdf:application/pdf}
}

@inproceedings{horvath_proving_2003,
	title = {Proving {Invariants} of {Functional} {Programs}.},
	url = {http://cs.uef.fi/uku/research/publications/reports/A-2003-1/page115.pdf},
	urldate = {2017-09-05},
	booktitle = {{SPLST}},
	author = {Horváth, Zoltán and Kozsik, Tamás and Tejfel, Máté},
	year = {2003},
	pages = {115--126},
	file = {Horvath et al_2003_Proving Invariants of Functional Programs.pdf:/home/michael/Dropbox/zotero-pdfs/H/Horvath et al_2003_Proving Invariants of Functional Programs.pdf:application/pdf}
}

@techreport{jones_static_1991,
	title = {A {Static} {Semantics} for {Haskell}},
	abstract = {This paper gives a static semantics for a large subset of Haskell, including giving a  translation into a language without overloading.  It is our intention to cover the complete language in due course.  One innovative aspect is the use of ideas from the second-order lambda calculus to  record type information in the program.  Contents  1 Introduction 4 2 A sketch of how overloading is resolved 6 3 Notation 7 4 Abstract syntax 13 5 Programs 19 6 Type declarations 21 7 Class declarations 24 8 Instance declarations 26 9 Value declarations 28 10 Expressions 37 1  11 Pattern matching 40 12 Dictionary manipulation 45 13 Implementation notes 47 14 References 47 List of Figures  1 Syntax of semantic types : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 10 2 Environments : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 11 3 Abstract syntax for Haskell: declarations and bindings : : : : : : : : : : : : : 14 4 Abstract syntax of Haskell: patterns and expression...},
	author = {Jones, Simon L. Peyton and Wadler, Philip},
	year = {1991},
	file = {Jones_Wadler_1991_A Static Semantics for Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Wadler_1991_A Static Semantics for Haskell.pdf:application/pdf}
}

@inproceedings{kiselyov_substructural_2007,
	address = {Berlin, Heidelberg},
	series = {{TLCA}'07},
	title = {A {Substructural} {Type} {System} for {Delimited} {Continuations}},
	isbn = {978-3-540-73227-3},
	url = {http://dl.acm.org/citation.cfm?id=1770203.1770220},
	abstract = {We propose type systems that abstractly interpret small-step rather than big-step operational semantics. We treat an expression or evaluation context as a structure in a linear logic with hypothetical reasoning. Evaluation order is not only regulated by familiar focusing rules in the operational semantics, but also expressed by structural rules in the type system, so the types track control flow more closely. Binding and evaluation contexts are related, but the latter are linear. We use these ideas to build a type system for delimited continuations. It lets control operators change the answer type or act beyond the nearest dynamically-enclosing delimiter, yet needs no extra fields in judgments and arrow types to record answer types. The typing derivation of a directstyle program desugars it into continuation-passing style.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Typed} {Lambda} {Calculi} and {Applications}},
	publisher = {Springer-Verlag},
	author = {Kiselyov, Oleg and Shan, Chung-chieh},
	year = {2007},
	pages = {223--239},
	file = {Kiselyov_Shan_2007_A Substructural Type System for Delimited Continuations.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kiselyov_Shan_2007_A Substructural Type System for Delimited Continuations.pdf:application/pdf}
}

@inproceedings{ferraiuolo_secure_2017,
	address = {New York, NY, USA},
	series = {{DAC} '17},
	title = {Secure {Information} {Flow} {Verification} with {Mutable} {Dependent} {Types}},
	isbn = {978-1-4503-4927-7},
	url = {http://doi.acm.org/10.1145/3061639.3062316},
	doi = {10.1145/3061639.3062316},
	abstract = {This paper presents a novel secure hardware description language (HDL) that uses an information flow type system to ensure that hardware is secure at design time. The novelty of this HDL lies in its ability to securely share hardware modules and storage elements across multiple security levels. Unlike previous secure HDLs, the new HDL enables secure sharing at a fine granularity and without implicitly adding hardware for security enforcement; this is important because the implicitly added hardware can break functionality and harm efficiency. The new HDL enables practical hardware designs that are secure, correct, and efficient. We demonstrate the practicality of the new HDL by using it to design and type-check a synthesizable pipelined processor implementation that support protection rings and instructions that change modes.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 54th {Annual} {Design} {Automation} {Conference} 2017},
	publisher = {ACM},
	author = {Ferraiuolo, Andrew and Hua, Weizhe and Myers, Andrew C. and Suh, G. Edward},
	year = {2017},
	pages = {6:1--6:6},
	file = {Ferraiuolo et al_2017_Secure Information Flow Verification with Mutable Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ferraiuolo et al_2017_Secure Information Flow Verification with Mutable Dependent Types.pdf:application/pdf}
}

@article{shao_type_2005,
	title = {A {Type} {System} for {Certified} {Binaries}},
	volume = {27},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1053468.1053469},
	doi = {10.1145/1053468.1053469},
	abstract = {A certified binary is a value together with a proof that the value satisfies a given specification. Existing compilers that generate certified code have focused on simple memory and control-flow safety rather than more advanced properties. In this article, we present a general framework for explicitly representing complex propositions and proofs in typed intermediate and assembly languages. The new framework allows us to reason about certified programs that involve effects while still maintaining decidable typechecking. We show how to integrate an entire proof system (the calculus of inductive constructions) into a compiler intermediate language and how the intermediate language can undergo complex transformations (CPS and closure conversion) while preserving proofs represented in the type system. Our work provides a foundation for the process of automatically generating certified binaries in a type-theoretic framework.},
	number = {1},
	urldate = {2017-09-05},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Shao, Zhong and Trifonov, Valery and Saha, Bratin and Papaspyrou, Nikolaos},
	month = jan,
	year = {2005},
	keywords = {typed intermediate languages, Certified code, proof-preserving compilation},
	pages = {1--45},
	file = {Shao et al_2005_A Type System for Certified Binaries.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shao et al_2005_A Type System for Certified Binaries.pdf:application/pdf}
}

@techreport{sorensen_lectures_2006,
	title = {Lectures on the {Curry}-{Howard} {Isomorphism}},
	url = {https://karczmarczuk.users.greyc.fr/matrs/Fuprog/Doc/curry-howard.pdf},
	urldate = {2017-09-05},
	author = {Sørensen, Morten Heine B. and Urzyczyn, Pawe},
	year = {2006},
	pages = {77--101},
	file = {Sorensen_Urzyczyn_2006_Lectures on the Curry-Howard Isomorphism.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sorensen_Urzyczyn_2006_Lectures on the Curry-Howard Isomorphism.pdf:application/pdf}
}

@inproceedings{williams-king_shuffler:_2016,
	title = {Shuffler: {Fast} and {Deployable} {Continuous} {Code} {Re}-{Randomization}.},
	shorttitle = {Shuffler},
	url = {https://www.usenix.org/system/files/conference/osdi16/osdi16-williams-king.pdf},
	urldate = {2017-09-05},
	booktitle = {{OSDI}},
	author = {Williams-King, David and Gobieski, Graham and Williams-King, Kent and Blake, James P. and Yuan, Xinhao and Colp, Patrick and Zheng, Michelle and Kemerlis, Vasileios P. and Yang, Junfeng and Aiello, William},
	year = {2016},
	pages = {367--382},
	file = {Williams-King et al_2016_Shuffler - Fast and Deployable Continuous Code Re-Randomization.pdf:/home/michael/Dropbox/zotero-pdfs/W/Williams-King et al_2016_Shuffler - Fast and Deployable Continuous Code Re-Randomization.pdf:application/pdf}
}

@book{wilhelm_determining_nodate,
	title = {Determining {Bounds} on {Execution} {Times}},
	abstract = {Run-time guarantees play an important role in the area of embedded systems and especially hard real-time systems. These systems are typically subject to stringent timing constraints, which often result from the interaction with the surrounding physical environment. It is essential that the computations are completed within their associated time bounds; otherwise severe damages may result, or the system may be unusable. Therefore, a schedulability analysis has to be performed which guarantees that all timing constraints will be met. Schedulability analyses require upper bounds for the execution times of all tasks in the system to be known. These bounds must be safe, i.e., they may never underestimate the real execution time. Furthermore, they should be tight, i.e., the overestimation should be as small as possible. In modern microprocessor architectures, caches, pipelines, and all kinds of speculation are key features for improving (average-case) performance. Unfortunately, they make the analysis of the timing behaviour of instructions very difficult, since the execution time of an instruction depends on the execution history. A lack of precision in the predicted timing behaviour may lead to a waste of hardware resources, which},
	author = {Wilhelm, Reinhard},
	file = {Wilhelm_Determining Bounds on Execution Times.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wilhelm_Determining Bounds on Execution Times.pdf:application/pdf}
}

@inproceedings{wadler_monads_1995,
	title = {Monads for functional programming},
	url = {http://link.springer.com/chapter/10.1007/3-540-59451-5_2},
	urldate = {2017-09-05},
	booktitle = {International {School} on {Advanced} {Functional} {Programming}},
	publisher = {Springer},
	author = {Wadler, Philip},
	year = {1995},
	pages = {24--52},
	file = {Wadler_1995_Monads for functional programming.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_1995_Monads for functional programming.pdf:application/pdf}
}

@inproceedings{sabry_reasoning_1992,
	address = {New York, NY, USA},
	series = {{LFP} '92},
	title = {Reasoning {About} {Programs} in {Continuation}-passing {Style}.},
	isbn = {978-0-89791-481-9},
	url = {http://doi.acm.org/10.1145/141471.141563},
	doi = {10.1145/141471.141563},
	abstract = {Plotkin's \&lgr;-value calculus is sound but incomplete for reasoning about \&bgr;eegr;-transformations on programs in continuation-passing style (CPS).  To find a complete extension, we define a new, compactifying CPS transformation and an “inverse”mapping, un-CPS, both of which are interesting in their own right.   Using the new CPS transformation, we can determine the precise language of CPS terms closed under \&bgr;7eegr;-transformations.  Using the un-CPS transformation, we can derive a set of axioms such that every equation between source programs is provable if and only if \&bgr;\&eegr; can prove the corresponding equation between CPS programs.  The extended calculus is equivalent to an untyped variant of Moggi's computational \&lgr;-calculus.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 1992 {ACM} {Conference} on {LISP} and {Functional} {Programming}},
	publisher = {ACM},
	author = {Sabry, Amr and Felleisen, Matthias},
	year = {1992},
	pages = {288--298},
	file = {Sabry_Felleisen_1992_Reasoning About Programs in Continuation-passing Style.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sabry_Felleisen_1992_Reasoning About Programs in Continuation-passing Style.pdf:application/pdf}
}

@article{plotkin_powerdomain_1976,
	title = {A powerdomain construction},
	volume = {5},
	url = {http://epubs.siam.org/doi/abs/10.1137/0205035},
	number = {3},
	urldate = {2017-09-05},
	journal = {SIAM Journal on Computing},
	author = {Plotkin, Gordon D.},
	year = {1976},
	pages = {452--487},
	file = {Plotkin_1976_A powerdomain construction.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_1976_A powerdomain construction.pdf:application/pdf}
}

@inproceedings{morrisett_abstract_1995,
	address = {New York, NY, USA},
	series = {{FPCA} '95},
	title = {Abstract {Models} of {Memory} {Management}},
	isbn = {978-0-89791-719-3},
	url = {http://doi.acm.org/10.1145/224164.224182},
	doi = {10.1145/224164.224182},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {Seventh} {International} {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {ACM},
	author = {Morrisett, Greg and Felleisen, Matthias and Harper, Robert},
	year = {1995},
	pages = {66--77},
	file = {Morrisett et al_1995_Abstract Models of Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/M/Morrisett et al_1995_Abstract Models of Memory Management.pdf:application/pdf}
}

@inproceedings{kocher_differential_1999,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Differential {Power} {Analysis}},
	isbn = {978-3-540-66347-8 978-3-540-48405-9},
	url = {https://link.springer.com/chapter/10.1007/3-540-48405-1_25},
	doi = {10.1007/3-540-48405-1_25},
	abstract = {Cryptosystem designers frequently assume that secrets will be manipulated in closed, reliable computing environments. Unfortunately, actual computers and microchips leak information about the operations they process. This paper examines specific methods for analyzing power consumption measurements to find secret keys from tamper resistant devices. We also discuss approaches for building cryptosystems that can operate securely in existing hardware that leaks information.},
	language = {en},
	urldate = {2017-09-05},
	booktitle = {Advances in {Cryptology} — {CRYPTO}’ 99},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Kocher, Paul and Jaffe, Joshua and Jun, Benjamin},
	month = aug,
	year = {1999},
	pages = {388--397},
	file = {Kocher et al_1999_Differential Power Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kocher et al_1999_Differential Power Analysis.pdf:application/pdf}
}

@article{hawblitzel_ironfleet:_2015,
	title = {{IronFleet}: {Proving} {Practical} {Distributed} {Systems} {Correct}},
	shorttitle = {{IronFleet}},
	url = {https://www.microsoft.com/en-us/research/publication/ironfleet-proving-practical-distributed-systems-correct/},
	abstract = {Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs a priori, but verification has historically been difficult to apply at full-program scale, much less distributed-system scale. We describe a methodology for building practical and provably correct distributed systems based on a unique blend of TLA-style state-machine refinement and Hoare-logic …},
	urldate = {2017-09-05},
	journal = {Microsoft Research},
	author = {Hawblitzel, Chris and Howell, Jon and Kapritsos, Manos and Lorch, Jay and Parno, Bryan and Roberts, Michael Lowell and Setty, Srinath and Zill, Brian},
	month = oct,
	year = {2015},
	file = {Hawblitzel et al_2015_IronFleet - Proving Practical Distributed Systems Correct.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hawblitzel et al_2015_IronFleet - Proving Practical Distributed Systems Correct.pdf:application/pdf}
}

@inproceedings{felleisen_theory_1988,
	address = {New York, NY, USA},
	series = {{POPL} '88},
	title = {The {Theory} and {Practice} of {First}-class {Prompts}},
	isbn = {978-0-89791-252-5},
	url = {http://doi.acm.org/10.1145/73560.73576},
	doi = {10.1145/73560.73576},
	abstract = {An analysis of the \&lgr;ugr;-C-calculus and its problematic relationship to operational equivalence leads to a new control facility: the prompt-application. With the introduction of prompt-applications, the control calculus becomes a traditional calculus all of whose equations imply operational equivalence. In addition, prompt-applications enhance the expressiveness and efficiency of the language. We illustrate the latter claim with examples from such distinct areas as systems programming and tree processing.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Felleisen, Mattias},
	year = {1988},
	pages = {180--190},
	file = {Felleisen_1988_The Theory and Practice of First-class Prompts.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felleisen_1988_The Theory and Practice of First-class Prompts.pdf:application/pdf}
}

@article{burstall_programming_1972,
	title = {Programming in {Pop}-2},
	volume = {2},
	issn = {1097-024X},
	shorttitle = {Programming in {Pop}-2, {R}. {M}. {Burstall}, {J}. {S}. {Collins} and {R}. {J}. {Popplestone}, {Edinburgh} {University} {Press}, 1971. {No}. of pages},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380020114/abstract},
	doi = {10.1002/spe.4380020114},
	language = {en},
	number = {1},
	urldate = {2017-09-05},
	journal = {Software: Practice and Experience},
	author = {Burstall, R and Collins, J and Popplestone, R},
	month = jan,
	year = {1972},
	pages = {99--99}
}

@article{bainomugisha_survey_2013,
	title = {A {Survey} on {Reactive} {Programming}},
	volume = {45},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2501654.2501666},
	doi = {10.1145/2501654.2501666},
	abstract = {Reactive programming has recently gained popularity as a paradigm that is well-suited for developing event-driven and interactive applications. It facilitates the development of such applications by providing abstractions to express time-varying values and automatically managing dependencies between such values. A number of approaches have been recently proposed embedded in various languages such as Haskell, Scheme, JavaScript, Java, .NET, etc. This survey describes and provides a taxonomy of existing reactive programming approaches along six axes: representation of time-varying values, evaluation model, lifting operations, multidirectionality, glitch avoidance, and support for distribution. From this taxonomy, we observe that there are still open challenges in the field of reactive programming. For instance, multidirectionality is supported only by a small number of languages, which do not automatically track dependencies between time-varying values. Similarly, glitch avoidance, which is subtle in reactive programs, cannot be ensured in distributed reactive programs using the current techniques.},
	number = {4},
	urldate = {2017-09-05},
	journal = {ACM Comput. Surv.},
	author = {Bainomugisha, Engineer and Carreton, Andoni Lombide and Cutsem, Tom van and Mostinckx, Stijn and Meuter, Wolfgang de},
	month = aug,
	year = {2013},
	keywords = {dataflow programming, event-driven applications, functional reactive programming, interactive applications, Reactive programming, reactive systems, FROM-BEN},
	pages = {52:1--52:34},
	file = {Bainomugisha et al_2013_A Survey on Reactive Programming.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bainomugisha et al_2013_A Survey on Reactive Programming.pdf:application/pdf}
}

@inproceedings{agat_transforming_2000,
	title = {Transforming out timing leaks},
	url = {http://dl.acm.org/citation.cfm?id=325702},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 27th {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages},
	publisher = {ACM},
	author = {Agat, Johan},
	year = {2000},
	pages = {40--53},
	file = {Agat_2000_Transforming out timing leaks.pdf:/home/michael/Dropbox/zotero-pdfs/A/Agat_2000_Transforming out timing leaks.pdf:application/pdf}
}

@incollection{kluge_abstract_2008,
	title = {Abstract λ-{Calculus} {Machines}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-88059-2_4},
	urldate = {2017-09-05},
	booktitle = {Central {European} {Functional} {Programming} {School}},
	publisher = {Springer},
	author = {Kluge, Werner E.},
	year = {2008},
	pages = {112--157},
	file = {Kluge_2008_Abstract λ-Calculus Machines.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kluge_2008_Abstract λ-Calculus Machines.pdf:application/pdf}
}

@inproceedings{henderson_lazy_1976,
	address = {New York, NY, USA},
	series = {{POPL} '76},
	title = {A {Lazy} {Evaluator}},
	url = {http://doi.acm.org/10.1145/800168.811543},
	doi = {10.1145/800168.811543},
	abstract = {A different way to execute pure LISP programs is presented. It delays the evaluation of parameters and list structures without ever having to perform more evaluation steps than the usual method. Although the central idea can be found in earlier work this paper is of interest since it treats a rather well-known language and works out an algorithm which avoids full substitution. A partial correctness proof using Scott-Strachey semantics is sketched in a later section.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 3rd {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} on {Programming} {Languages}},
	publisher = {ACM},
	author = {Henderson, Peter and Morris, Jr., James H.},
	year = {1976},
	pages = {95--103},
	file = {Henderson_Morris_1976_A Lazy Evaluator.pdf:/home/michael/Dropbox/zotero-pdfs/H/Henderson_Morris_1976_A Lazy Evaluator.pdf:application/pdf}
}

@article{friedman_cons_nodate,
	title = {{CONS} should not {Evaluate} its {Arguments}},
	url = {https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR44},
	urldate = {2017-09-05},
	author = {Friedman, D and Wise, D},
	file = {Friedman_Wise_CONS should not Evaluate its Arguments.pdf:/home/michael/Dropbox/zotero-pdfs/F/Friedman_Wise_CONS should not Evaluate its Arguments.pdf:application/pdf}
}

@article{milner_co-induction_1991,
	title = {Co-induction in relational semantics},
	volume = {87},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/030439759190033X},
	doi = {10.1016/0304-3975(91)90033-X},
	abstract = {An application of the mathematical theory of maximum fixed points of monotonic set operators to relational semantics is presented. It is shown how an important proof method which we call co-induction, a variant of Park's (1969) principle of fixpoint induction, can be used to prove the consistency of the static and the dynamic relational semantics of a small functional programming language with recursive functions.},
	number = {1},
	urldate = {2017-09-05},
	journal = {Theoretical Computer Science},
	author = {Milner, Robin and Tofte, Mads},
	month = sep,
	year = {1991},
	pages = {209--220},
	file = {Milner_Tofte_1991_Co-induction in relational semantics.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_Tofte_1991_Co-induction in relational semantics.pdf:application/pdf}
}

@inproceedings{turner_semantic_1981,
	address = {New York, NY, USA},
	series = {{FPCA} '81},
	title = {The {Semantic} {Elegance} of {Applicative} {Languages}},
	isbn = {978-0-89791-060-6},
	url = {http://doi.acm.org/10.1145/800223.806766},
	doi = {10.1145/800223.806766},
	abstract = {In what does the alleged superiority of applicative languages consist? In the last analysis the answer must be in terms of the reduction in the time required to produce a correct program to solve a given problem. On reflection I decided that the best way to demonstrate this would be to take some reasonably non-trivial problem and show how, by proceeding within a certain kind of applicative language framework it was possible to develop a working solution with a fraction of the effort that would have been necessary in a conventional imperative language. The particular problem I have chosen also brings out a number of general points of interest which I shall discuss briefly afterwards. Before proceeding it will be necessary for me to quickly outline the language framework within which we shall be working. Very briefly it can be summarised as (non-strict, higher order) recursion equations + set abstraction. Obviously what matters are the underlying semantic concepts, not the particular syntax that is used to express them, but for the sake of definiteness I shall use the notation of KRC (\&equil; “Kent RecUrsive Calculator”), an applicative programming system implemented at the University of Kent [Turner 81]. KRC is fairly closely based on the earlier language SASL, [Turner 763, but I have added a facility for set abstraction.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 1981 {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {ACM},
	author = {Turner, D. A.},
	year = {1981},
	pages = {85--92},
	file = {Turner_1981_The Semantic Elegance of Applicative Languages.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turner_1981_The Semantic Elegance of Applicative Languages.pdf:application/pdf}
}

@article{plotkin_origins_2004,
	series = {Structural {Operational} {Semantics}},
	title = {The origins of structural operational semantics},
	volume = {60},
	issn = {1567-8326},
	url = {http://www.sciencedirect.com/science/article/pii/S1567832604000268},
	doi = {10.1016/j.jlap.2004.03.009},
	abstract = {We review the origins of structural operational semantics. The main publication `A Structural Approach to Operational Semantics,' also known as the `Aarhus Notes,' appeared in 1981 [G.D. Plotkin, A structural approach to operational semantics, DAIMI FN-19, Computer Science Department, Aarhus University, 1981]. The development of the ideas dates back to the early 1970s, involving many people and building on previous work on programming languages and logic. The former included abstract syntax, the SECD machine, and the abstract interpreting machines of the Vienna school; the latter included the λ-calculus and formal systems. The initial development of structural operational semantics was for simple functional languages, more or less variations of the λ-calculus; after that the ideas were gradually extended to include languages with parallel features, such as Milner's CCS. This experience set the ground for a more systematic exposition, the subject of an invited course of lectures at Aarhus University; some of these appeared in print as the 1981 Notes. We discuss the content of these lectures and some related considerations such as `small state' versus `grand state,' structural versus compositional semantics, the influence of the Scott–Strachey approach to denotational semantics, the treatment of recursion and jumps, and static semantics. We next discuss relations with other work and some immediate further development. We conclude with an account of an old, previously unpublished, idea: an alternative, perhaps more readable, graphical presentation of systems of rules for operational semantics.},
	urldate = {2017-09-05},
	journal = {The Journal of Logic and Algebraic Programming},
	author = {Plotkin, Gordon D},
	month = jul,
	year = {2004},
	keywords = {-calculus, (Labelled) transition systems, (Structural) operational semantics, Abstract machines, Big step semantics, Concurrency, Semantics of programming languages, Small-step semantics, Static semantics, Structural induction},
	pages = {3--15},
	file = {Plotkin_2004_The origins of structural operational semantics.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_2004_The origins of structural operational semantics.pdf:application/pdf}
}

@incollection{hewitt_behavioral_1974,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Behavioral semantics of nonrecursive control structures},
	isbn = {978-3-540-06859-4 978-3-540-37819-8},
	url = {https://link.springer.com/chapter/10.1007/3-540-06859-7_147},
	abstract = {Knowledge Based Programming is programming in an environment which has substantial knowledge of the semantic domain for which the programs are being written and of the purposes that the programs are supposed to satisfy. Actors are a semantic concept in which no active process is ever allowed to treat anything as an object; instead a polite request must be extended to accomplish what the activator desires. Using actors the PLANNER Project is constructing a Programming Apprentice to make it easier for expert programmers to do knowledge based programming. The apprentice is to aid in establishing and maintaining consistency of specifications, validating that modules meet their specifications, answering questions about behavioral dependencies between modules, and analyzing the implications of perturbations in modules and their specifications.In The course of this research we have found that we needed to make use of non-recursive control structures and to be able to rigorously formulate their semantics. Our semantics is a generalization of the mathematical semantics of Sco Scott for junctions. Thus it differs from the operational semantic models [such as the CONTOUR model and the Bobrow-Wegbreit mode] that have been proposed which are formulated in terms of operations on activation records. This paper reports some preliminary results and tentative conclusions.},
	language = {en},
	urldate = {2017-09-05},
	booktitle = {Programming {Symposium}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Hewitt, Carl and Bishop, Peter and Steiger, Richard and Greif, Irene and Smith, Brian and Matson, Todd and Hale, Roger},
	year = {1974},
	doi = {10.1007/3-540-06859-7_147},
	pages = {385--407},
	file = {Hewitt et al_1974_Behavioral semantics of nonrecursive control structures.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hewitt et al_1974_Behavioral semantics of nonrecursive control structures.pdf:application/pdf}
}

@book{winskel_formal_1993,
	address = {Cambridge, MA, USA},
	title = {The {Formal} {Semantics} of {Programming} {Languages}: {An} {Introduction}},
	isbn = {978-0-262-23169-5},
	shorttitle = {The {Formal} {Semantics} of {Programming} {Languages}},
	publisher = {MIT Press},
	author = {Winskel, Glynn},
	year = {1993}
}

@inproceedings{howard_inductive_1996,
	address = {New York, NY, USA},
	series = {{ICFP} '96},
	title = {Inductive, {Coinductive}, and {Pointed} {Types}},
	isbn = {978-0-89791-770-4},
	url = {http://doi.acm.org/10.1145/232627.232640},
	doi = {10.1145/232627.232640},
	abstract = {An extension of the simply-typed lambda calculus is presented which contains both well-structured inductive and coinductive types, and which also identifies a class of types for which general recursion is possible. The motivations for this work are certain natural constructions in category theory, in particular the notion of an algebraically bounded functor, due to Freyd. We propose that this is a particularly elegant core language in which to work with recursive objects, since the potential for general recursion is contained in a single operator which interacts well with the facilities for bounded iteration and coiteration.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the {First} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Howard, Brian T.},
	year = {1996},
	pages = {102--109},
	file = {Howard_1996_Inductive, Coinductive, and Pointed Types.pdf:/home/michael/Dropbox/zotero-pdfs/H/Howard_1996_Inductive, Coinductive, and Pointed Types.pdf:application/pdf}
}

@article{landin_correspondence_1965,
	title = {Correspondence {Between} {ALGOL} 60 and {Church}'s {Lambda}-notation: {Part} {I}},
	volume = {8},
	issn = {0001-0782},
	shorttitle = {Correspondence {Between} {ALGOL} 60 and {Church}'s {Lambda}-notation},
	url = {http://doi.acm.org/10.1145/363744.363749},
	doi = {10.1145/363744.363749},
	number = {2},
	urldate = {2017-09-05},
	journal = {Commun. ACM},
	author = {Landin, P. J.},
	month = feb,
	year = {1965},
	pages = {89--101},
	file = {Landin_1965_Correspondence Between ALGOL 60 and Church's Lambda-notation - Part I.pdf:/home/michael/Dropbox/zotero-pdfs/L/Landin_1965_Correspondence Between ALGOL 60 and Church's Lambda-notation - Part I.pdf:application/pdf}
}

@article{plotkin_call-by-name_1975,
	title = {Call-by-name, call-by-value and the λ-calculus},
	volume = {1},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397575900171},
	doi = {10.1016/0304-3975(75)90017-1},
	abstract = {This paper examines the old question of the relationship between ISWIM and the λ-calculus, using the distinction between call-by-value and call-by-name. It is held that the relationship should be mediated by a standardisation theorem. Since this leads to difficulties, a new λ-calculus is introduced whose standardisation theorem gives a good correspondence with ISWIM as given by the SECD machine, but without the letrec feature. Next a call-by-name variant of ISWIM is introduced which is in an analogous correspondence withthe usual λ-calculus. The relation between call-by-value and call-by-name is then studied by giving simulations of each language by the other and interpretations of each calculus in the other. These are obtained as another application of the continuation technique. Some emphasis is placed throughout on the notion of operational equality (or contextual equality). If terms can be proved equal in a calculus they are operationally equal in the corresponding language. Unfortunately, operational equality is not preserved by either of the simulations.},
	number = {2},
	urldate = {2017-09-05},
	journal = {Theoretical Computer Science},
	author = {Plotkin, G. D.},
	month = dec,
	year = {1975},
	pages = {125--159},
	file = {Plotkin_1975_Call-by-name, call-by-value and the λ-calculus.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_1975_Call-by-name, call-by-value and the λ-calculus.pdf:application/pdf}
}

@book{noauthor_categories_nodate,
	title = {Categories for the {Working} {Mathematician} {\textbar} {Saunders} {Mac} {Lane} {\textbar} {Springer}},
	url = {http://www.springer.com/us/book/9780387984032},
	abstract = {Categories for the Working Mathematician provides an array of general ideas useful in a wide variety of fields. Starting from the foundations, this book...},
	urldate = {2017-09-05},
	file = {Categories for the Working Mathematician Saunders Mac Lane Springer.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/Categories for the Working Mathematician Saunders Mac Lane Springer.pdf:application/pdf}
}

@article{pierce_taste_1988,
	title = {A taste of category theory for computer scientists},
	url = {http://repository.cmu.edu/cgi/viewcontent.cgi?article=2846&context=compsci},
	urldate = {2017-09-05},
	author = {Pierce, Benjamin C.},
	year = {1988},
	file = {Pierce_1988_A taste of category theory for computer scientists.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pierce_1988_A taste of category theory for computer scientists.pdf:application/pdf}
}

@article{wright_syntactic_1994,
	title = {A {Syntactic} {Approach} to {Type} {Soundness}},
	volume = {115},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/S0890540184710935},
	doi = {10.1006/inco.1994.1093},
	abstract = {We present a new approach to proving type soundness for Hindley/Milner-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the technique with a type soundness theorem for the core of Standard ML, which includes the first type soundness proof for polymorphic exceptions and continuations.},
	number = {1},
	urldate = {2017-09-05},
	journal = {Information and Computation},
	author = {Wright, A. K. and Felleisen, M.},
	month = nov,
	year = {1994},
	pages = {38--94},
	file = {Wright_Felleisen_1994_A Syntactic Approach to Type Soundness.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wright_Felleisen_1994_A Syntactic Approach to Type Soundness.pdf:application/pdf}
}

@inproceedings{tov_practical_2011,
	address = {New York, NY, USA},
	series = {{POPL} '11},
	title = {Practical {Affine} {Types}},
	isbn = {978-1-4503-0490-0},
	url = {http://doi.acm.org/10.1145/1926385.1926436},
	doi = {10.1145/1926385.1926436},
	abstract = {Alms is a general-purpose programming language that supports practical affine types. To offer the expressiveness of Girard's linear logic while keeping the type system light and convenient, Alms uses expressive kinds that minimize notation while maximizing polymorphism between affine and unlimited types. A key feature of Alms is the ability to introduce abstract affine types via ML-style signature ascription. In Alms, an interface can impose stiffer resource usage restrictions than the principal usage restrictions of its implementation. This form of sealing allows the type system to naturally and directly express a variety of resource management protocols from special-purpose type systems. We present two pieces of evidence to demonstrate the validity of our design goals. First, we introduce a prototype implementation of Alms and discuss our experience programming in the language. Second, we establish the soundness of the core language. We also use the core model to prove a principal kinding theorem.},
	urldate = {2017-09-05},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Tov, Jesse A. and Pucella, Riccardo},
	year = {2011},
	keywords = {affine types, linear logic, modules, polymorphism, type systems},
	pages = {447--458},
	file = {Tov_Pucella_2011_Practical Affine Types.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tov_Pucella_2011_Practical Affine Types.pdf:application/pdf}
}

@article{barendregt_introduction_nodate,
	title = {Introduction to {Lambda} {Calculus}},
	url = {http://gpl.internetconnection.net/mirror-lambda-calculus.pdf},
	urldate = {2017-09-05},
	author = {Barendregt, Henk and Barendsen, Erik},
	file = {Barendregt_Barendsen_Introduction to Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barendregt_Barendsen_Introduction to Lambda Calculus.pdf:application/pdf}
}

@article{klop_combinatory_1993,
	title = {Combinatory reduction systems: introduction and survey},
	volume = {121},
	issn = {0304-3975},
	shorttitle = {Combinatory reduction systems},
	url = {http://www.sciencedirect.com/science/article/pii/0304397593900917},
	doi = {10.1016/0304-3975(93)90091-7},
	abstract = {Combinatory reduction systems, or CRSs for short, were designed to combine the usual first-order format of term rewriting with the presence of bound variables as in pure λ-calculus and various typed λ-calculi. Bound variables are also present in many other rewrite systems, such as systems with simplification rules for proof normalization. The original idea of CRSs is due to Aczel, who introduced a restricted class of CRSs and, under the assumption of orthogonality, proved confluence. Orthogonality means that the rules are nonambiguous (no overlap leading to a critical pair) and left-linear (no global comparison of terms necessary). We introduce the class of orthogonal CRSs, illustrated with many examples, discuss its expressive power and give an outline of a short proof of confluence. This proof is a direct generalization of Aczel's original proof, which is close to the well-known confluence proof for λ-calculus by Tait and Martin-Löf. There is a well-known connection between the parallel reduction featuring in the latter proof and the concept of “developments”, and a classical lemma in the theory of λ-calculus is that of “finite developments”, a strong normalization result. It turns out that the notion of “parallel reduction” used in Aczel's proof gives rise to a generalized form of developments which we call “superdevelopments” and on which we will briefly comment.},
	number = {1},
	urldate = {2017-09-26},
	journal = {Theoretical Computer Science},
	author = {Klop, Jan Willem and van Oostrom, Vincent and van Raamsdonk, Femke},
	month = dec,
	year = {1993},
	pages = {279--308},
	file = {Klop et al_1993_Combinatory reduction systems - introduction and survey.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klop et al_1993_Combinatory reduction systems - introduction and survey.pdf:application/pdf}
}

@article{plotkin_lcf_1977,
	title = {{LCF} considered as a programming language},
	volume = {5},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	doi = {10.1016/0304-3975(77)90044-5},
	abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on LCF. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called “fully abstract”. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
	number = {3},
	urldate = {2017-09-26},
	journal = {Theoretical Computer Science},
	author = {Plotkin, G. D.},
	month = dec,
	year = {1977},
	pages = {223--255},
	file = {Plotkin_1977_LCF considered as a programming language.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_1977_LCF considered as a programming language.pdf:application/pdf}
}

@article{j_hyland_full_2000,
	title = {On {Full} {Abstraction} for {PCF}: {I}, {II}, and {III}},
	volume = {163},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.6172&rep=rep1&type=pdf},
	abstract = {We present an order-extensional, order (or inequationally) fully abstract model for Scott's language PCF.},
	urldate = {2017-09-26},
	journal = {Information and Computation},
	author = {{J Hyland}},
	year = {2000},
	pages = {285--408},
	file = {J Hyland_2000_On Full Abstraction for PCF - I, II, and III.pdf:/home/michael/Dropbox/zotero-pdfs/J/J Hyland_2000_On Full Abstraction for PCF - I, II, and III.pdf:application/pdf}
}

@article{abadi_dynamic_1991,
	title = {Dynamic typing in a statically typed language},
	volume = {13},
	url = {http://dl.acm.org/citation.cfm?id=103138},
	number = {2},
	urldate = {2017-09-26},
	journal = {ACM transactions on programming languages and systems (TOPLAS)},
	author = {Abadi, Martín and Cardelli, Luca and Pierce, Benjamin and Plotkin, Gordon},
	year = {1991},
	pages = {237--268},
	file = {Abadi et al_1991_Dynamic typing in a statically typed language.pdf:/home/michael/Dropbox/zotero-pdfs/A/Abadi et al_1991_Dynamic typing in a statically typed language.pdf:application/pdf}
}

@inproceedings{leroy_dynamics_1991,
	title = {Dynamics in {ML}},
	url = {http://link.springer.com/chapter/10.1007/3540543961_20},
	urldate = {2017-09-26},
	booktitle = {Conference on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer},
	author = {Leroy, Xavier and Mauny, Michel},
	year = {1991},
	pages = {406--426},
	file = {Leroy_Mauny_1991_Dynamics in ML.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leroy_Mauny_1991_Dynamics in ML.pdf:application/pdf}
}

@article{elwazeer_scalable_2013,
	title = {Scalable variable and data type detection in a binary rewriter},
	volume = {48},
	url = {http://dl.acm.org/citation.cfm?id=2462165},
	number = {6},
	urldate = {2017-09-28},
	journal = {ACM SIGPLAN Notices},
	author = {ElWazeer, Khaled and Anand, Kapil and Kotha, Aparna and Smithson, Matthew and Barua, Rajeev},
	year = {2013},
	keywords = {Typed Binary},
	pages = {51--60},
	file = {ElWazeer et al_2013_Scalable variable and data type detection in a binary rewriter.pdf:/home/michael/Dropbox/zotero-pdfs/E/ElWazeer et al_2013_Scalable variable and data type detection in a binary rewriter.pdf:application/pdf}
}

@inproceedings{mcmahan_architecture_2017,
	address = {New York, NY, USA},
	series = {{ASPLOS} '17},
	title = {An {Architecture} {Supporting} {Formal} and {Compositional} {Binary} {Analysis}},
	copyright = {All rights reserved},
	isbn = {978-1-4503-4465-4},
	url = {http://doi.acm.org/10.1145/3037697.3037733},
	doi = {10.1145/3037697.3037733},
	abstract = {Building a trustworthy life-critical embedded system requires deep reasoning about the potential effects that sequences of machine instructions can have on full system operation. Rather than trying to analyze complete binaries and the countless ways their instructions can interact with one another --- memory, side effects, control registers, implicit state, etc. --- we explore a new approach. We propose an architecture controlled by a thin computational layer designed to tightly correspond with the lambda calculus, drawing on principles of functional programming to bring the assembly much closer to myriad reasoning frameworks, such as the Coq proof assistant. This approach allows assembly-level verified versions of critical code to operate safely in tandem with arbitrary code, including imperative and unverified system components, without the need for large supporting trusted computing bases. We demonstrate that this computational layer can be built in such a way as to simultaneously provide full programmability and compact, precise, and complete semantics, while still using hardware resources comparable to normal embedded systems. To demonstrate the practicality of this approach, our FPGA-implemented prototype runs an embedded medical application which monitors and treats life-threatening arrhythmias. Though the system integrates untrusted and imperative components, our architecture allows for the formal verification of multiple properties of the end-to-end system, including a proof of correctness of the assembly-level implementation of the core algorithm, the integrity of trusted data via a non-interference proof, and a guarantee that our prototype meets critical timing requirements.},
	urldate = {2017-10-01},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {McMahan, Joseph and Christensen, Michael and Nichols, Lawton and Roesch, Jared and Guo, Sung-Yee and Hardekopf, Ben and Sherwood, Timothy},
	year = {2017},
	keywords = {functional programming, binary verification, static analysis, assembly analysis, formal methods, heterogeneous architecture, isa semantics, non-interference},
	pages = {177--191},
	file = {McMahan et al_2017_An Architecture Supporting Formal and Compositional Binary Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/M/McMahan et al_2017_An Architecture Supporting Formal and Compositional Binary Analysis.pdf:application/pdf}
}

@inproceedings{azevedo_de_amorim_verified_2014,
	address = {New York, NY, USA},
	series = {{POPL} '14},
	title = {A {Verified} {Information}-flow {Architecture}},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535839},
	doi = {10.1145/2535838.2535839},
	abstract = {SAFE is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in SAFE and an end-to-end proof of noninterference for this model.},
	urldate = {2017-10-01},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Azevedo de Amorim, Arthur and Collins, Nathan and DeHon, André and Demange, Delphine and Hriţcu, Cătălin and Pichardie, David and Pierce, Benjamin C. and Pollack, Randy and Tolmach, Andrew},
	year = {2014},
	keywords = {security, tagged architecture, formal verification, clean-slate design, information-flow control, refinement},
	pages = {165--178},
	file = {Azevedo de Amorim et al_2014_A Verified Information-flow Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/A/Azevedo de Amorim et al_2014_A Verified Information-flow Architecture.pdf:application/pdf}
}

@inproceedings{ditzel_retrospective_1980,
	address = {New York, NY, USA},
	series = {{ISCA} '80},
	title = {Retrospective on {High}-level {Language} {Computer} {Architecture}},
	url = {http://doi.acm.org/10.1145/800053.801914},
	doi = {10.1145/800053.801914},
	abstract = {High-level language computers (HLLC) have attracted interest in the architectural and programming community during the last 15 years; proposals have been made for machines directed towards the execution of various languages such as ALGOL,1,2 APL,3,4,5 BASIC,6,7 COBOL,8,9 FORTRAN,10,ll LISP,12,13 PASCAL,14 PL/I,15,16,17 SNOBOL,18,19 and a host of specialized languages. Though numerous designs have been proposed, only a handful of high-level language computers have actually been implemented.4,7,9,20,21 In examining the goals and successes of high-level language computers, the authors have found that most designs suffer from fundamental problems stemming from a misunderstanding of the issues involved in the design, use, and implementation of cost-effective computer systems. It is the intent of this paper to identify and discuss several issues applicable to high-level language computer architecture, to provide a more concrete definition of high-level language computers, and to suggest a direction for high-level language computer architectures of the future.},
	urldate = {2017-10-01},
	booktitle = {Proceedings of the 7th {Annual} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Ditzel, David R. and Patterson, David A.},
	year = {1980},
	pages = {97--104},
	file = {Ditzel_Patterson_1980_Retrospective on High-level Language Computer Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/D/Ditzel_Patterson_1980_Retrospective on High-level Language Computer Architecture.pdf:application/pdf}
}

@book{wilhelm_informatics:_2001,
	title = {Informatics: 10 {Years} {Back}. 10 {Years} {Ahead}},
	shorttitle = {Informatics},
	url = {https://books.google.com/books?hl=en&lr=&id=SEu4A0jwCUkC&oi=fnd&pg=PR1&dq=%222+discusses+two+computer+security+principles+that+suggest+the%22+%22Wilhelm+(Ed.):+Informatics.+10+Years+Back.+10+Years+Ahead,+LNCS+2000,+pp.+86%E2%80%93101,%22+%22economics+dictated+that+computer+hardware+be+shared+and,%22+&ots=KMqmWSku7V&sig=pXOgUOJz9nLKOymzWdSO4uLF1AI},
	number = {2000},
	urldate = {2017-10-01},
	publisher = {Springer Science \& Business Media},
	author = {Wilhelm, Reinhard},
	year = {2001},
	file = {Wilhelm_2001_Informatics - 10 Years Back. 10 Years Ahead.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wilhelm_2001_Informatics - 10 Years Back. 10 Years Ahead.pdf:application/pdf}
}

@incollection{schneider_language-based_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Language}-{Based} {Approach} to {Security}},
	isbn = {978-3-540-41635-7 978-3-540-44577-7},
	url = {https://link.springer.com/chapter/10.1007/3-540-44577-3_6},
	abstract = {Language-based security leverages program analysis and program rewriting to enforce security policies. The approach promises efficient enforcement of fine-grained access control policies and depends on a trusted computing base of only modest size. This paper surveys progress and prospects for the area, giving overviews of in-lined reference monitors, certifying compilers, and advances in type theory.},
	language = {en},
	urldate = {2017-10-01},
	booktitle = {Informatics},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Schneider, Fred B. and Morrisett, Greg and Harper, Robert},
	year = {2001},
	doi = {10.1007/3-540-44577-3_6},
	pages = {86--101},
	file = {Schneider et al_2001_A Language-Based Approach to Security.pdf:/home/michael/Dropbox/zotero-pdfs/S/Schneider et al_2001_A Language-Based Approach to Security.pdf:application/pdf}
}

@article{mcmillan_soul_2011,
	title = {The soul of the virtual machine},
	volume = {48},
	issn = {0018-9235},
	doi = {10.1109/MSPEC.2011.5910448},
	abstract = {Java's ability to run on many different kinds of computers grew out of software devised decades before - The enduring appeal of Java isn't hard to understand: With Java, you write code once and it can run on almost any modern computer or operating system-PC or Mac, Windows, Linux, OS X, whatever. It works that way because the Java compiler turns the source code into a kind of ersatz machine code that each of these different systems can execute when equipped with the proper run-time software. So different computers running different operating systems can all become, in programmers' parlance, Java virtual machines.},
	number = {7},
	journal = {IEEE Spectrum},
	author = {Mcmillan, W. W.},
	month = jul,
	year = {2011},
	keywords = {Java, Ersatz machine code, Java compiler, Java virtual machines, Operating systems, program compilers, Program processors, Programming, virtual machines, Virtual machining, Virtual prototyping},
	pages = {44--59},
	file = {Mcmillan_2011_The soul of the virtual machine.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mcmillan_2011_The soul of the virtual machine.pdf:application/pdf}
}

@article{wirth_programming_1985,
	title = {From {Programming} {Language} {Design} to {Computer} {Construction}},
	volume = {28},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2786.2789},
	doi = {10.1145/2786.2789},
	abstract = {From NELIAC (via ALGOL 60) to Euler and ALGOL W, to Pascal and Modula-2, and ultimately Lilith, Wirth's search for an appropriate formalism for systems programming yields intriguing insights and surprising results.},
	number = {2},
	urldate = {2017-10-01},
	journal = {Commun. ACM},
	author = {Wirth, Niklaus},
	month = feb,
	year = {1985},
	pages = {160--164},
	file = {Wirth_1985_From Programming Language Design to Computer Construction.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wirth_1985_From Programming Language Design to Computer Construction.pdf:application/pdf}
}

@article{raj_emerald:_1991,
	title = {Emerald: {A} general-purpose programming language},
	volume = {21},
	issn = {1097-024X},
	shorttitle = {Emerald},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380210107/abstract},
	doi = {10.1002/spe.4380210107},
	abstract = {Emerald is a general-purpose language with aspects of traditional object-oriented languages, such as Smalltalk, and abstract data type languages, such as Modula-2 and Ada. It is strongly typed with a non-traditional object model and type system that emphasize abstract types, allow separation of typing and implementation, and provide the flexibility of polymorphism and subtyping with compile-time checking. This paper describes the Emerald language and its programming methodology. We give examples that demonstrate Emerald's features, and compare and contrast the Emerald approach to programming with the approaches used in other similar languages.},
	language = {en},
	number = {1},
	urldate = {2017-10-01},
	journal = {Software: Practice and Experience},
	author = {Raj, Rajendra K. and Tempero, Ewan and Levy, Henry M. and Black, Andrew P. and Hutchinson, Norman C. and Jul, Eric},
	month = jan,
	year = {1991},
	keywords = {Abstract data types, Inheritance, Object-based concurrency, Object-oriented programming, Programming languages, Programming methodology},
	pages = {91--118},
	file = {Raj et al_1991_Emerald - A general-purpose programming language.pdf:/home/michael/Dropbox/zotero-pdfs/R/Raj et al_1991_Emerald - A general-purpose programming language.pdf:application/pdf}
}

@article{raj_compositional_1989,
	title = {A {Compositional} {Model} for {Software} {Reuse}},
	volume = {32},
	issn = {0010-4620},
	url = {https://academic.oup.com/comjnl/article/32/4/312/377565/A-Compositional-Model-for-Software-Reuse},
	doi = {10.1093/comjnl/32.4.312},
	abstract = {Emerald is a strongly-typed object-oriented language designed for programming distributed applications. Among other things, it provides abstract typing, type conformity, and complete separation of typing from implementation. While Emerald supports type inheritance, it does not support behaviour sharing among objects for simplifying distribution. To increase Emerald's utility in general-purpose programming, some support for software re-use is needed. Our research reveals that inheritance-based techniques commonly used in other object-oriented systems for obtaining re-use are inappropriate for Emerald. As an alternative to traditional inheritance, a compositional model, in which objects are composed from simpler entities, is proposed, outlined and analysed in this paper.},
	number = {4},
	urldate = {2017-10-01},
	journal = {The Computer Journal},
	author = {Raj, R. K. and Levy, H. M.},
	month = jan,
	year = {1989},
	pages = {312--322},
	file = {Raj_Levy_1989_A Compositional Model for Software Reuse.pdf:/home/michael/Dropbox/zotero-pdfs/R/Raj_Levy_1989_A Compositional Model for Software Reuse.pdf:application/pdf}
}

@inproceedings{black_object_1986,
	address = {New York, NY, USA},
	series = {{OOPSLA} '86},
	title = {Object {Structure} in the {Emerald} {System}},
	isbn = {978-0-89791-204-4},
	url = {http://doi.acm.org/10.1145/28697.28706},
	doi = {10.1145/28697.28706},
	abstract = {Emerald is an object-based language for the construction of distributed applications. The principal features of Emerald include a uniform object model appropriate for programming both private local objects and shared remote objects, and a type system that permits multiple user-defined and compiler-defined implementations. Emerald objects are fully mobile and can move from node to node within the network, even during an invocation. This paper discusses the structure, programming, and implementation of Emerald objects, and Emerald's use of abstract types.},
	urldate = {2017-10-01},
	booktitle = {Conference {Proceedings} on {Object}-oriented {Programming} {Systems}, {Languages} and {Applications}},
	publisher = {ACM},
	author = {Black, Andrew and Hutchinson, Norman and Jul, Eric and Levy, Henry},
	year = {1986},
	pages = {78--86},
	file = {Black et al_1986_Object Structure in the Emerald System.pdf:/home/michael/Dropbox/zotero-pdfs/B/Black et al_1986_Object Structure in the Emerald System.pdf:application/pdf}
}

@article{jul_fine-grained_1988,
	title = {Fine-grained {Mobility} in the {Emerald} {System}},
	volume = {6},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/35037.42182},
	doi = {10.1145/35037.42182},
	abstract = {Emerald is an object-based language and system designed for the construction of distributed programs. An explicit goal of Emerald is support for object mobility; objects in Emerald can freely move within the system to take advantage of distribution and dynamically changing environments. We say that Emerald has fine-grained mobility because Emerald objects can be small data objects as well as process objects. Fine-grained mobility allows us to apply mobility in new ways but presents implementation problems as well. This paper discusses the benefits of tine-grained mobility, the Emerald language and run-time mechanisms that support mobility, and techniques for implementing mobility that do not degrade the performance of local operations. Performance measurements of the current implementation are included.},
	number = {1},
	urldate = {2017-10-01},
	journal = {ACM Trans. Comput. Syst.},
	author = {Jul, Eric and Levy, Henry and Hutchinson, Norman and Black, Andrew},
	month = feb,
	year = {1988},
	pages = {109--133},
	file = {Jul et al_1988_Fine-grained Mobility in the Emerald System.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jul et al_1988_Fine-grained Mobility in the Emerald System.pdf:application/pdf}
}

@article{golm_structure_nodate,
	title = {The structure of a type safe operating system},
	url = {https://opus4.kobv.de/opus4-fau/frontdoor/index/index/docId/31},
	abstract = {The architecture of traditional operating systems relies on address-based memory protection. To achieve flexibility at a low cost operating system research has recently started to explore alternative protection mechanisms, such as type safety. This dissertation presents an operating system architecture that completely replaces address-based protection with type-based protection. Replacing such an essential part of the system leads to a novel operating system architecture with improved robustness, reusability, configurability, scalability, and security. The dissertation describes not only the design of such a system but also its prototype implementation and the performance of initial applications, such as a file system, a web server, a data base management system, and a network file server. The prototype, which is called JX, uses Java bytecode as its type-safe instruction set and is able to run existing Java programs without modifications. The system is based on a modular microkernel, which is the only part of the system that is written in an unsafe language. Light-weight protection domains replace the heavy-weight process concept of traditional systems. These domains are the unit of protection, resource management, and termination. Code is organized in components that are loaded into domains. The portal mechanism-a fast inter-domain communication mechanism-allows mutually distrusting domains to cooperate in a secure way. This dissertation shows that it is possible to build a complete and efficient general-purpose time-sharing operating system based on type safety.},
	urldate = {2017-10-01},
	author = {Golm, Michael},
	file = {Golm_The structure of a type safe operating system, Die Architektur eines.pdf:/home/michael/Dropbox/zotero-pdfs/G/Golm_The structure of a type safe operating system, Die Architektur eines.pdf:application/pdf}
}

@article{golm_java_2002,
	title = {A {Java} operating system as the foundation of a secure network operating system},
	url = {http://www4.informatik.uni-erlangen.de/DE/Projects/JX/publications/jx-sec.pdf},
	urldate = {2017-10-01},
	journal = {Technical report TR-I4–02-05, Univ. of. Erlangen, Dept. of Comp. Science, Lehrstuhl 4, Tech. Rep.},
	author = {Golm, Michael and Felser, Meik and Wawersich, Christian and Kleinöder, Jürgen},
	year = {2002},
	file = {Golm et al_2002_A Java operating system as the foundation of a secure network operating system.pdf:/home/michael/Dropbox/zotero-pdfs/G/Golm et al_2002_A Java operating system as the foundation of a secure network operating system.pdf:application/pdf}
}

@inproceedings{golm_jx_2002,
	title = {The {JX} {Operating} {System}.},
	url = {https://www.usenix.org/event/usenix02/full_papers/golm/golm.pdf},
	urldate = {2017-10-01},
	booktitle = {{USENIX} {Annual} {Technical} {Conference}, {General} {Track}},
	author = {Golm, Michael and Felser, Meik and Wawersich, Christian and Kleinöder, Jürgen},
	year = {2002},
	pages = {45--58},
	file = {Golm et al_2002_The JX Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/G/Golm et al_2002_The JX Operating System.pdf:application/pdf}
}

@article{golm_ubiquitous_2001,
	title = {Ubiquitous computing and the need for a new operating system architecture},
	url = {http://www4.informatik.uni-erlangen.de/TR/pdf/TR-I4-01-09.pdf},
	urldate = {2017-10-01},
	journal = {Online at http://www4. informatik. uni-erlangen. de/Projects/JX/Papers/ubitools01. pdf},
	author = {Golm, Michael and Kleinöder, Jürgen},
	year = {2001},
	file = {Golm_Kleinoder_2001_Ubiquitous computing and the need for a new operating system architecture.pdf:/home/michael/Dropbox/zotero-pdfs/G/Golm_Kleinoder_2001_Ubiquitous computing and the need for a new operating system architecture.pdf:application/pdf}
}

@incollection{naumann_essence_1994,
	title = {On the essence of oberon},
	url = {http://link.springer.com/chapter/10.1007/3-540-57840-4_39},
	urldate = {2017-10-01},
	booktitle = {Programming {Languages} and {System} {Architectures}},
	publisher = {Springer},
	author = {Naumann, David A.},
	year = {1994},
	pages = {313--327},
	file = {Naumann_1994_On the essence of oberon.pdf:/home/michael/Dropbox/zotero-pdfs/N/Naumann_1994_On the essence of oberon.pdf:application/pdf}
}

@book{mossenbock_extensibility_1994,
	title = {Extensibility in the {Oberon} {System}},
	abstract = {We show how an object-oriented system—and in particular the Oberon System—can be used to write software that is extensible by end users even while the software is running. Extensibility instead of completeness may be a way out of the unpleasant situation in software industry where applications still tend to become bigger every year. Oberon is both an object-oriented programming language and an operating system with new concepts such as commands and dynamic loading. The language and the system make up an environment that is similar to Smalltalk in its flexibility but offers static typechecking and is much more efficient. 1.},
	author = {Mössenböck, Hanspeter},
	year = {1994},
	file = {Mossenbock_Extensibility in the Oberon System.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mossenbock_Extensibility in the Oberon System.pdf:application/pdf}
}

@article{hunt_singularity:_2007,
	title = {Singularity: {Rethinking} the {Software} {Stack}},
	volume = {41/2},
	shorttitle = {Singularity},
	url = {https://www.microsoft.com/en-us/research/publication/singularity-rethinking-the-software-stack/},
	abstract = {Every operating system embodies a collection of design decisions. Many of the decisions behind today’s most popular operating systems have remained unchanged, even as hardware and software have evolved. Operating systems form the foundation of almost every software stack, so inadequacies in present systems have a pervasive impact. This paper describes the efforts of the …},
	urldate = {2017-10-01},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Hunt, Galen and Larus, Jim},
	month = apr,
	year = {2007},
	keywords = {CONCURRENCY},
	file = {Hunt_Larus_2007_Singularity.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hunt_Larus_2007_Singularity.pdf:application/pdf}
}

@article{yiyu_java_2006,
	title = {A {Java} processor with hardware-support object-oriented instructions},
	volume = {30},
	issn = {0141-9331},
	url = {http://www.sciencedirect.com/science/article/pii/S0141933105000967},
	doi = {10.1016/j.micpro.2005.12.007},
	abstract = {Java is widely applied from the small embedded devices to enterprise systems nowadays due to its object-oriented features and corresponding advantages of security, robustness, and platform independence. Java programs are compiled into Java Bytecodes, which are executed in the Java virtual machine. Among the current hardware or software solutions to the Java virtual machine, the object-oriented related Bytecodes are implemented by software traps or microcode, and their performance does not match well with the essential requirements of memory-constraint embedded devices, such as real-time operations and low power consumptions. In this paper, a novel Java processor named jHISC is proposed, which mainly targets Java applications in the small embedded devices. In jHISC, 94\% of Bytecodes and 83\% of the object-oriented related Bytecodes are implemented by hardware directly. Compared with PicoJava II and JOP, jHISC speeds up the overall performance about 30\% and 183\%, respectively.},
	number = {8},
	urldate = {2017-10-01},
	journal = {Microprocessors and Microsystems},
	author = {Yiyu, Tan and Wan Yiu, Lo and Chi Hang, Yau and Li, Richard and Fong, Anthony S.},
	month = dec,
	year = {2006},
	keywords = {Object-oriented programming, Bytecode, Java processor, Operand descriptor},
	pages = {469--479},
	file = {Yiyu et al_2006_A Java processor with hardware-support object-oriented instructions.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yiyu et al_2006_A Java processor with hardware-support object-oriented instructions.pdf:application/pdf}
}

@inproceedings{moon_architecture_1985,
	address = {Los Alamitos, CA, USA},
	series = {{ISCA} '85},
	title = {Architecture of the {Symbolics} 3600},
	isbn = {978-0-8186-0634-2},
	url = {http://dl.acm.org/citation.cfm?id=327010.327133},
	urldate = {2017-10-01},
	booktitle = {Proceedings of the 12th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {IEEE Computer Society Press},
	author = {Moon, David A.},
	year = {1985},
	pages = {76--83},
	file = {Moon_1985_Architecture of the Symbolics 3600.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moon_1985_Architecture of the Symbolics 3600.pdf:application/pdf}
}

@article{steele_design_1979,
	title = {Design of {LISP}-based {Processors}, or {SCHEME}: {A} {Dielectric} {LISP}, or {Finite} {Memories} {Considered} {Harmful}, or {LAMBDA}: {The} {Ultimate} {Opcode}},
	shorttitle = {Design of {LISP}-based {Processors}, or {SCHEME}},
	url = {http://dspace.mit.edu/handle/1721.1/5731},
	abstract = {We present a design for a class of computers whose 'instruction sets' are based on LISP. LISP, like traditional stored-program machine languages and unlike most high-level languages, conceptually stores programs and data in the same way and explicitly allows programs to be manipulated as data. LISP is therefore a suitable language around which to design a stored-program computer architecture. LISP differs from traditional machine languages in that the program/data storage is conceptually an unordered set of linked record structures of various sizes, rather than an ordered, indexable vector of integers or bit fields of fixed size. The record structures can be organized into trees or graphs. An instruction set can be designed for programs expressed as such trees. A processor can interpret these trees in a recursive fashion, and provide automatic storage management for the record structures. We describe here the basic ideas behind the architecture, and for concreteness give a specific instruction set (on which variations are certainly possible). We also discuss the similarities and differences between these ideas and those of traditional architectures. A prototype VLSI microprocessor has been designed and fabricated for testing. It is a small-scale version of the ideas presented here, containing a sufficiently complete instruction interpreter to execute small programs, and a rudimentary storage allocator. We intend to design and fabricate a full-scale VLSI version of this architecture in 1979.},
	language = {en\_US},
	urldate = {2017-10-01},
	author = {Steele, Guy Lewis and Sussman, Gerald Jay},
	month = mar,
	year = {1979},
	file = {Steele_Sussman_1979_Design of LISP-based Processors, or SCHEME - A Dielectric LISP, or Finite.pdf:/home/michael/Dropbox/zotero-pdfs/S/Steele_Sussman_1979_Design of LISP-based Processors, or SCHEME - A Dielectric LISP, or Finite.pdf:application/pdf}
}

@article{knight_cadr_1979,
	title = {{CADR}},
	url = {http://dspace.mit.edu/handle/1721.1/5718},
	abstract = {The CADR machine, a revised version of the  CONS machine, is a general-purpose, 32-bit  microprogrammable processor which is the  basis of the Lisp-machine system, a new  computer system being developed by the  Laboratory as a high-performance,  economical implementation of Lisp. This  paper describes the CADR processor and  some of the associated hardware and low-level software.},
	language = {en\_US},
	urldate = {2017-10-01},
	author = {Knight, Thomas F. and Moon, David A. and Holloway, Jack and Steele, Guy L.},
	month = may,
	year = {1979},
	file = {Knight et al_1979_CADR.pdf:/home/michael/Dropbox/zotero-pdfs/K/Knight et al_1979_CADR.pdf:application/pdf}
}

@article{bawden_lisp_1977,
	title = {{LISP} {Machine} {Progress} {Report}},
	url = {http://dspace.mit.edu/handle/1721.1/5751},
	abstract = {This informal paper introduces the LISP  Machine, describes the goals and current  status of the project, and explicates some of  the key ideas. It covers the LISP machine  implementation, LISP as a system language,  input/output, representation of data,  representation of programs, control  structures, storage organization, garbage  collection, the editor, and the current status of  the work.},
	language = {en\_US},
	urldate = {2017-10-01},
	author = {Bawden, Alan and Greenblatt, Richard and Holloway, Jack and Knight, Thomas and Moon, David and Weinreb, Daniel},
	month = aug,
	year = {1977},
	file = {Bawden et al_1977_LISP Machine Progress Report.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bawden et al_1977_LISP Machine Progress Report.pdf:application/pdf}
}

@inproceedings{hritcu_testing_2013,
	title = {Testing noninterference, quickly},
	volume = {48},
	url = {http://dl.acm.org/citation.cfm?id=2500574},
	urldate = {2017-10-03},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Hritcu, Catalin and Hughes, John and Pierce, Benjamin C. and Spector-Zabusky, Antal and Vytiniotis, Dimitrios and Azevedo de Amorim, Arthur and Lampropoulos, Leonidas},
	year = {2013},
	pages = {455--468},
	file = {Hritcu et al_2013_Testing noninterference, quickly.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hritcu et al_2013_Testing noninterference, quickly.pdf:application/pdf}
}

@article{shrobe_tiara:_2007,
	title = {{TIARA}: {Trust} {Management}, {Intrusion}-tolerance, {Accountability}, and {Reconstitution} {Architecture}},
	shorttitle = {{TIARA}},
	url = {http://dspace.mit.edu/handle/1721.1/37589},
	abstract = {The last 20 years have led to unprecedented improvements in chipdensity and system performance fueled mainly by Moore's Law.  Duringthe same time, system and application software have bloated, leadingto unmanageable complexity, vulnerability to attack, rigidity and lackof robustness and accountability. These problems arise from the factthat all key elements of the computational environment, from hardwarethrough system software and middleware to application code regard theworld as consisting of unconstrained ``raw seething bits''.  No elementof the entire stack is responsible for enforcing over-archingconventions of memory structuring or access control.  Outsiders mayeasily penetrate the system by exploiting vulnerabilities (e.g. bufferoverflows) arising from this lack of basic constraints. Attacks arenot easily contained, whether they originate from the clever outsiderwho penetrates the defenses or from the insider who exploits existingprivileges.  Finally, because there are no facilities for tracing theprovenance of data, even when an attack is detected, it is difficultif not impossible to tell which data are traceable to the attack andwhat data may still be trusted. We have abundant computational resources allowing us to fix thesecritical problems using a combination of hardware, system software,and programming language technology: In this report, we describe theTIARAproject, which is using these resources to design a newcomputer system thatis less vulnerable, more tolerant of intrusions, capable of recoveryfrom attacks, and accountable for their actions.  TIARA provides thesecapabilities without significant impact on overall system performance.  Itachieves these goals through the judicious use of a modest amountof extra, but reasonably generable purpose, hardware that is dedicatedto tracking the provenance of data at a very fine grained level, toenforcing access control policies, and to constructing a coherentobject-oriented model of memory.  This hardware runs in parallel withthe main data-paths of the system and operates on a set of extra bitstagging each word with data-type, bounds, access control andprovenance information. Operations that violate the intendedinvariants are trapped, while normal results are tagged withinformation derived from the tags of the input operands.This hardware level provides fine-grained support for a series ofsoftware layers that enable a variety of comprehensive access controlpolicies, self-adaptive computing, and fine-grained recoveryprocessing.  The first of these software layers establishes aconsistent object-oriented level of computing while higher layersestablish wrappers that may not be bypassed, access controls, dataprovenance tracking.  At the highest level we create the ``planlevel'' of computing in which code is executed in parallel with anabstract model (or executable specification) of the system that checkswhether the code behaves as intended.},
	urldate = {2017-10-03},
	author = {Shrobe, Howard and Knight, Thomas and Hon, Andre de},
	month = may,
	year = {2007},
	file = {Shrobe et al_2007_TIARA - Trust Management, Intrusion-tolerance, Accountability, and.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shrobe et al_2007_TIARA - Trust Management, Intrusion-tolerance, Accountability, and.pdf:application/pdf}
}

@inproceedings{freeman_refinement_1991,
	address = {New York, NY, USA},
	series = {{PLDI} '91},
	title = {Refinement {Types} for {ML}},
	isbn = {978-0-89791-428-4},
	url = {http://doi.acm.org/10.1145/113445.113468},
	doi = {10.1145/113445.113468},
	urldate = {2017-10-05},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1991 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Freeman, Tim and Pfenning, Frank},
	year = {1991},
	pages = {268--277},
	file = {Freeman_Pfenning_1991_Refinement Types for ML.pdf:/home/michael/Dropbox/zotero-pdfs/F/Freeman_Pfenning_1991_Refinement Types for ML.pdf:application/pdf}
}

@inproceedings{clement_simple_1986,
	address = {New York, NY, USA},
	series = {{LFP} '86},
	title = {A {Simple} {Applicative} {Language}: {Mini}-{ML}},
	isbn = {978-0-89791-200-6},
	shorttitle = {A {Simple} {Applicative} {Language}},
	url = {http://doi.acm.org/10.1145/319838.319847},
	doi = {10.1145/319838.319847},
	urldate = {2017-10-10},
	booktitle = {Proceedings of the 1986 {ACM} {Conference} on {LISP} and {Functional} {Programming}},
	publisher = {ACM},
	author = {Clément, Dominique and Despeyroux, Thierry and Kahn, Gilles and Despeyroux, Joëlle},
	year = {1986},
	pages = {13--27},
	file = {Clement et al_1986_A Simple Applicative Language - Mini-ML.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clement et al_1986_A Simple Applicative Language - Mini-ML.pdf:application/pdf}
}

@inproceedings{klein_run_2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {Run {Your} {Research}: {On} the {Effectiveness} of {Lightweight} {Mechanization}},
	isbn = {978-1-4503-1083-3},
	shorttitle = {Run {Your} {Research}},
	url = {http://doi.acm.org/10.1145/2103656.2103691},
	doi = {10.1145/2103656.2103691},
	abstract = {Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn't serve its purpose. One way to eliminate flaws from a model is to write it down in a mechanized formal language. It is then possible to state theorems about the model, to prove them, and to check the proofs. Over the past nine years, PLT has developed and explored a lightweight version of this approach, dubbed Redex. In a nutshell, Redex is a domain-specific language for semantic models that is embedded in the Racket programming language. The effort of creating a model in Redex is often no more burdensome than typesetting it with LaTeX; the difference is that Redex comes with tools for the semantics engineering life cycle.},
	urldate = {2017-10-11},
	publisher = {ACM},
	author = {Klein, Casey and Clements, John and Dimoulas, Christos and Eastlund, Carl and Felleisen, Matthias and Flatt, Matthew and McCarthy, Jay A. and Rafkind, Jon and Tobin-Hochstadt, Sam and Findler, Robert Bruce},
	year = {2012},
	keywords = {engineering, lightweight, semantics},
	pages = {285--296},
	file = {ACM Full Text PDF:/home/michael/Zotero/storage/SV88GQSI/Klein et al. - 2012 - Run Your Research\: On the Effectiveness of Lightwe.pdf:application/pdf}
}

@inproceedings{chang_type_2017,
	address = {New York, NY, USA},
	series = {{POPL} 2017},
	title = {Type {Systems} {As} {Macros}},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009886},
	doi = {10.1145/3009837.3009886},
	abstract = {We present Turnstile, a metalanguage for creating typed embedded languages. To implement the type system, programmers write type checking rules resembling traditional judgment syntax. To implement the semantics, they incorporate elaborations into these rules. Turnstile critically depends on the idea of linguistic reuse. It exploits a macro system in a novel way to simultaneously type check and rewrite a surface program into a target language. Reusing a macro system also yields modular implementations whose rules may be mixed and matched to create other languages. Combined with typical compiler and runtime reuse, Turnstile produces performant typed embedded languages with little effort.},
	urldate = {2017-10-19},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Chang, Stephen and Knauth, Alex and Greenman, Ben},
	year = {2017},
	keywords = {type systems, macros, typed embedded DSLs},
	pages = {694--705},
	file = {Chang et al_2017_Type Systems As Macros.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chang et al_2017_Type Systems As Macros.pdf:application/pdf}
}

@inproceedings{noonan_polymorphic_2016,
	title = {Polymorphic {Type} {Inference} for {Machine} {Code}},
	url = {http://arxiv.org/abs/1603.05495},
	abstract = {For many compiled languages, source-level types are erased very early in the compilation process. As a result, further compiler passes may convert type-safe source into type-unsafe machine code. Type-unsafe idioms in the original source and type-unsafe optimizations mean that type information in a stripped binary is essentially nonexistent. The problem of recovering high-level types by performing type inference over stripped machine code is called type reconstruction, and offers a useful capability in support of reverse engineering and decompilation. In this paper, we motivate and develop a novel type system and algorithm for machine-code type inference. The features of this type system were developed by surveying a wide collection of common source- and machine-code idioms, building a catalog of challenging cases for type reconstruction. We found that these idioms place a sophisticated set of requirements on the type system, inducing features such as recursively-constrained polymorphic types. Many of the features we identify are often seen only in expressive and powerful type systems used by high-level functional languages. Using these type-system features as a guideline, we have developed Retypd: a novel static type-inference algorithm for machine code that supports recursive types, polymorphism, and subtyping. Retypd yields more accurate inferred types than existing algorithms, while also enabling new capabilities such as reconstruction of pointer const annotations with 98\% recall. Retypd can operate on weaker program representations than the current state of the art, removing the need for high-quality points-to information that may be impractical to compute.},
	urldate = {2017-10-12},
	booktitle = {{arXiv}:1603.05495 [cs]},
	author = {Noonan, Matthew and Loginov, Alexey and Cok, David},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.05495},
	keywords = {Computer Science - Logic in Computer Science, TO-READ, Computer Science - Programming Languages, D.2.7, D.3.3, F.3.2, F.4.3, Typed Binary},
	file = {Noonan et al_2016_Polymorphic Type Inference for Machine Code.pdf:/home/michael/Dropbox/zotero-pdfs/N/Noonan et al_2016_Polymorphic Type Inference for Machine Code.pdf:application/pdf}
}

@inproceedings{dewey_fuzzing_2015,
	title = {Fuzzing the {Rust} typechecker using {CLP}},
	booktitle = {Automated {Software} {Engineering} ({ASE}), 2015 30th {IEEE}/{ACM} {International} {Conference} on},
	publisher = {IEEE},
	author = {Dewey, Kyle and Roesch, Jared and Hardekopf, Ben},
	year = {2015},
	pages = {482--493},
	file = {Dewey et al_2015_Fuzzing the Rust typechecker using CLP (T).pdf:/home/michael/Dropbox/zotero-pdfs/D/Dewey et al_2015_Fuzzing the Rust typechecker using CLP (T).pdf:application/pdf;dewey_2014_ase_fuzzing-the-rust-typechecker-using-clp.pdf:/home/michael/Zotero/storage/WZ6RXEKB/dewey_2014_ase_fuzzing-the-rust-typechecker-using-clp.pdf:application/pdf}
}

@inproceedings{lin_automatic_2010,
	address = {West Lafayette, IN},
	series = {{CERIAS} '10},
	title = {Automatic {Reverse} {Engineering} of {Data} {Structures} from {Binary} {Execution}},
	url = {http://dl.acm.org/citation.cfm?id=2788959.2788964},
	abstract = {With only the binary executable of a program, it is useful to discover the program's data structures and infer their syntactic and semantic definitions. Such knowledge is highly valuable in a variety of security and forensic applications. Although there exist efforts in program data structure inference, the existing solutions are not suitable for our targeted application scenarios. In this paper, we propose a reverse engineering technique to automatically reveal program data structures from binaries. Our technique, called REWARDS, is based on dynamic analysis. More specifically, each memory location accessed by the program is tagged with a timestamped type attribute. Following the program's runtime data flow, this attribute is propagated to other memory locations and registers that share the same type. During the propagation, a variable's type gets resolved if it is involved in a type-revealing execution point or type sink. More importantly, besides the forward type propagation, REWARDS involves a backward type resolution procedure where the types of some previously accessed variables get recursively resolved starting from a type sink. This procedure is constrained by the timestamps of relevant memory locations to disambiguate variables re-using the same memory location. In addition, REWARDS is able to reconstruct in-memory data structure layout based on the type information derived. We demonstrate that REWARDS provides unique benefits to two applications: memory image forensics and binary fuzzing for vulnerability discovery.},
	urldate = {2017-10-29},
	booktitle = {Proceedings of the 11th {Annual} {Information} {Security} {Symposium}},
	publisher = {CERIAS - Purdue University},
	author = {Lin, Zhiqiang and Zhang, Xiangyu and Xu, Dongyan},
	year = {2010},
	pages = {5:1--5:1},
	file = {Lin et al_2010_Automatic Reverse Engineering of Data Structures from Binary Execution.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lin et al_2010_Automatic Reverse Engineering of Data Structures from Binary Execution.pdf:application/pdf}
}

@article{kleene_general_1936,
	title = {General recursive functions of natural numbers},
	volume = {112},
	number = {1},
	journal = {Mathematische annalen},
	author = {Kleene, Stephen Cole},
	year = {1936},
	pages = {727--742},
	file = {BF01565439.pdf:/home/michael/Zotero/storage/KAKJKSSN/BF01565439.pdf:application/pdf}
}

@article{godel_formally_1931,
	title = {On formally undecidable propositions of {Principia} {Mathematica} and related systems {I}},
	url = {http://www.cs.virginia.edu/~evans/cs200/lectures/goedel.pdf},
	urldate = {2017-11-27},
	author = {Godel, Kurt},
	year = {1931},
	file = {goedel.pdf:/home/michael/Zotero/storage/X2UZRAEC/goedel.pdf:application/pdf}
}

@article{troelstra_constructivism_1999,
	title = {From constructivism to computer science},
	volume = {211},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397597001722},
	doi = {10.1016/S0304-3975(97)00172-2},
	number = {1},
	urldate = {2017-11-26},
	journal = {Theoretical Computer Science},
	author = {Troelstra, A. S.},
	month = jan,
	year = {1999},
	pages = {233--252},
	file = {Troelstra_1999_From constructivism to computer science.pdf:/home/michael/Dropbox/zotero-pdfs/T/Troelstra_1999_From constructivism to computer science.pdf:application/pdf;Troelstra_1999_From constructivism to computer science.pdf:/home/michael/Dropbox/zotero-pdfs/T/Troelstra_1999_From constructivism to computer science.pdf:application/pdf}
}

@article{fachini_formally_2017,
	title = {Formally {Secure} {Compilation} of {Unsafe} {Low}-{Level} {Components} ({Extended} {Abstract})},
	url = {http://arxiv.org/abs/1710.07308},
	abstract = {We propose a new formal criterion for secure compilation, providing strong security guarantees for components written in unsafe, low-level languages with C-style undefined behavior. Our criterion goes beyond recent proposals, which protect the trace properties of a single component against an adversarial context, to model dynamic compromise in a system of mutually distrustful components. Each component is protected from all the others until it receives an input that triggers an undefined behavior, causing it to become compromised and attack the remaining uncompromised components. To illustrate this model, we demonstrate a secure compilation chain for an unsafe language with buffers, procedures, and components, compiled to a simple RISC abstract machine with built-in compartmentalization. The protection guarantees offered by this abstract machine can be achieved at the machine-code level using either software fault isolation or tag-based reference monitoring. We are working on machine-checked proofs showing that this compiler satisfies our secure compilation criterion.},
	urldate = {2017-11-21},
	journal = {arXiv:1710.07308 [cs]},
	author = {Fachini, Guglielmo and Hritcu, Catalin and Stronati, Marco and Evans, Ana Nora and Laurent, Théo and de Amorim, Arthur Azevedo and Pierce, Benjamin C. and Tolmach, Andrew},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.07308},
	keywords = {Computer Science - Programming Languages, Computer Science - Cryptography and Security},
	file = {Fachini et al_2017_Formally Secure Compilation of Unsafe Low-Level Components (Extended Abstract).pdf:/home/michael/Dropbox/zotero-pdfs/F/Fachini et al_2017_Formally Secure Compilation of Unsafe Low-Level Components (Extended Abstract).pdf:application/pdf}
}

@inproceedings{walker_static_2006,
	address = {New York, NY, USA},
	series = {{ICFP} '06},
	title = {Static {Typing} for a {Faulty} {Lambda} {Calculus}},
	isbn = {978-1-59593-309-6},
	url = {http://doi.acm.org/10.1145/1159803.1159809},
	doi = {10.1145/1159803.1159809},
	abstract = {A transient hardware fault occurs when an energetic particle strikes a transistor, causing it to change state. These faults do not cause permanent damage, but may result in incorrect program execution by altering signal transfers or stored values. While the likelihood that such transient faults will cause any significant damage may seem remote, over the last several years transient faults have caused costly failures in high-end machines at America Online, eBay, and the Los Alamos Neutron Science Center, among others [6, 44, 15]. Because susceptibility to transient faults is proportional to the size and density of transistors, the problem of transient faults will become increasingly important in the coming decades.This paper defines the first formal, type-theoretic framework for studying reliable computation in the presence of transient faults. More specifically, it defines λzap, a lambda calculus that exhibits intermittent data faults. In order to detect and recover from these faults, λzap programs replicate intermediate computations and use majority voting, thereby modeling software-based fault tolerance techniques studied extensively, but informally [10, 20, 30, 31, 32, 33, 41].To ensure that programs maintain the proper invariants and use λzap primitives correctly, the paper defines a type system for the language. This type system guarantees that well-typed programs can tolerate any single data fault. To demonstrate that λzap can serve as an idealized typed intermediate language, we define a type-preserving translation from a standard simply-typed lambda calculus into λzap.},
	urldate = {2017-11-21},
	booktitle = {Proceedings of the {Eleventh} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Walker, David and Mackey, Lester and Ligatti, Jay and Reis, George A. and August, David I.},
	year = {2006},
	keywords = {typed intermediate languages, type systems, fault tolerance, lambda calculus, reliable computing, soft faults, transient hardware faults},
	pages = {38--49},
	file = {Walker et al_2006_Static Typing for a Faulty Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/W/Walker et al_2006_Static Typing for a Faulty Lambda Calculus.pdf:application/pdf}
}

@inproceedings{kaes_parametric_1988,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Parametric overloading in polymorphic programming languages},
	isbn = {978-3-540-19027-1 978-3-540-38941-5},
	url = {https://link.springer.com/chapter/10.1007/3-540-19027-9_9},
	doi = {10.1007/3-540-19027-9_9},
	abstract = {The introduction of unrestricted overloading in languages with type systems based on implicit parametric polymorphism generally destroys the principal type property: namely that the type of every expression can uniformly be represented by a single type expression over some set of type variables. As a consequence, type inference in the presence of unrestricted overloading can become a NP-complete problem. In this paper we define the concept of parametric overloading as a restricted form of overloading which is easily combined with parametric polymorphism. Parametric overloading preserves the principal type property, thereby allowing the design of efficient type inference algorithms. We present sound type deduction systems, both for predefined and programmer defined overloading. Finally we state that parametric overloading can be resolved either statically, at compile time, or dynamically, during program execution.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {{ESOP} '88},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Kaes, Stefan},
	month = mar,
	year = {1988},
	pages = {131--144},
	file = {Kaes_1988_Parametric overloading in polymorphic programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kaes_1988_Parametric overloading in polymorphic programming languages.pdf:application/pdf}
}

@inproceedings{wand_complete_1987,
	title = {Complete {Type} {Inference} for {Simple} {Objects}},
	abstract = {The problem of strong typing is considered for a model of object-oriented programming systems. These systems permit values which are records of other values, and in which fields inside these records are retrieved by name. A type system is proposed that permits classification of these kinds of values and programs by the type of their result, as is usual in strongly-typed programming languages. The type system has two important properties: it admits multiple inheritance, and it has a syntactically complete type inference system.},
	booktitle = {[{No} source information available]},
	author = {Wand, Mitchell},
	month = jan,
	year = {1987},
	pages = {37--44},
	file = {Wand_1987_Complete Type Inference for Simple Objects.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wand_1987_Complete Type Inference for Simple Objects.pdf:application/pdf}
}

@inproceedings{nelson_hyperkernel:_2017,
	title = {Hyperkernel: {Push}-{Button} {Verification} of an {OS} {Kernel}},
	isbn = {978-1-4503-5085-3},
	shorttitle = {Hyperkernel},
	url = {http://dl.acm.org/citation.cfm?doid=3132747.3132748},
	doi = {10.1145/3132747.3132748},
	language = {en},
	urldate = {2017-11-27},
	publisher = {ACM Press},
	author = {Nelson, Luke and Sigurbjarnarson, Helgi and Zhang, Kaiyuan and Johnson, Dylan and Bornholt, James and Torlak, Emina and Wang, Xi},
	year = {2017},
	pages = {252--269},
	file = {Nelson et al_2017_Hyperkernel - Push-Button Verification of an OS Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nelson et al_2017_Hyperkernel - Push-Button Verification of an OS Kernel.pdf:application/pdf}
}

@inproceedings{jones_c-:_1999,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {C-—: {A} {Portable} {Assembly} {Language} that {Supports} {Garbage} {Collection}},
	isbn = {978-3-540-66540-3 978-3-540-48164-5},
	shorttitle = {C-—},
	url = {https://link.springer.com/chapter/10.1007/10704567_1},
	doi = {10.1007/10704567_1},
	abstract = {For a compiler writer, generating good machine code for a variety of platforms is hard work. One might try to reuse a retargetable code generator, but code generators are complex and difficult to use, and they limit one’s choice of implementation language. One might try to use C as a portable assembly language, but C limits the compiler writer’s flexibility and the performance of the resulting code. The wide use of C, despite these drawbacks, argues for a portable assembly language. C-— is a new language designed expressly for this purpose. The use of a portable assembly language introduces new problems in the support of such high-level run-time services as garbage collection, exception handling, concurrency, profiling, and debugging. We address these problems by combining the C-— language with a C-—run-time interface. The combination is designed to allow the compiler writer a choice of source-language semantics and implementation techniques, while still providing good performance.},
	language = {en},
	urldate = {2017-11-30},
	booktitle = {Principles and {Practice} of {Declarative} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Jones, Simon Peyton and Ramsey, Norman and Reig, Fermin},
	month = sep,
	year = {1999},
	pages = {1--28},
	file = {Jones et al_1999_C-— - A Portable Assembly Language that Supports Garbage Collection.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones et al_1999_C-— - A Portable Assembly Language that Supports Garbage Collection.pdf:application/pdf}
}

@incollection{klein_refinement_2010,
	title = {Refinement in the {Formal} {Verification} of the {seL}4 {Microkernel}},
	isbn = {978-1-4419-1538-2 978-1-4419-1539-9},
	url = {https://link.springer.com/chapter/10.1007/978-1-4419-1539-9_11},
	abstract = {We present an overview of the different refinement frameworks used in the L4.verified project to formally prove the functional correctness of the seL4 microkernel. The verification is conducted in the interactive theorem prover Isabelle/HOL and proceeds in two large refinement steps: one proof between two monadic, functional specifications in HOL and one proof between such a monadic specification and a C program. To connect these proofs into one overall theorem, we map both refinement statements into a common overall framework.},
	language = {en},
	urldate = {2017-12-01},
	booktitle = {Design and {Verification} of {Microprocessor} {Systems} for {High}-{Assurance} {Applications}},
	publisher = {Springer, Boston, MA},
	author = {Klein, Gerwin and Sewell, Thomas and Winwood, Simon},
	year = {2010},
	doi = {10.1007/978-1-4419-1539-9_11},
	pages = {323--339},
	file = {Klein et al_2010_Refinement in the Formal Verification of the seL4 Microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_2010_Refinement in the Formal Verification of the seL4 Microkernel.pdf:application/pdf}
}

@article{turing_computable_1937,
	title = {On computable numbers, with an application to the {Entscheidungsproblem}},
	volume = {2},
	number = {1},
	journal = {Proceedings of the London mathematical society},
	author = {Turing, Alan Mathison},
	year = {1937},
	pages = {230--265},
	file = {Turing_1937_On computable numbers, with an application to the Entscheidungsproblem.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turing_1937_On computable numbers, with an application to the Entscheidungsproblem.pdf:application/pdf}
}

@inproceedings{zhao_formalizing_2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {Formalizing the {LLVM} {Intermediate} {Representation} for {Verified} {Program} {Transformations}},
	isbn = {978-1-4503-1083-3},
	url = {http://doi.acm.org/10.1145/2103656.2103709},
	doi = {10.1145/2103656.2103709},
	abstract = {This paper presents Vellvm (verified LLVM), a framework for reasoning about programs expressed in LLVM's intermediate representation and transformations that operate on it. Vellvm provides a mechanized formal semantics of LLVM's intermediate representation, its type system, and properties of its SSA form. The framework is built using the Coq interactive theorem prover. It includes multiple operational semantics and proves relations among them to facilitate different reasoning styles and proof techniques. To validate Vellvm's design, we extract an interpreter from the Coq formal semantics that can execute programs from LLVM test suite and thus be compared against LLVM reference implementations. To demonstrate Vellvm's practicality, we formalize and verify a previously proposed transformation that hardens C programs against spatial memory safety violations. Vellvm's tools allow us to extract a new, verified implementation of the transformation pass that plugs into the real LLVM infrastructure; its performance is competitive with the non-verified, ad-hoc original.},
	urldate = {2017-12-06},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Zhao, Jianzhou and Nagarakatte, Santosh and Martin, Milo M.K. and Zdancewic, Steve},
	year = {2012},
	keywords = {memory safety, Coq, LLVM},
	pages = {427--440},
	file = {Zhao et al_2012_Formalizing the LLVM Intermediate Representation for Verified Program.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhao et al_2012_Formalizing the LLVM Intermediate Representation for Verified Program.pdf:application/pdf}
}

@inproceedings{torlak_lightweight_2014,
	address = {New York, NY, USA},
	series = {{PLDI} '14},
	title = {A {Lightweight} {Symbolic} {Virtual} {Machine} for {Solver}-aided {Host} {Languages}},
	isbn = {978-1-4503-2784-8},
	url = {http://doi.acm.org/10.1145/2594291.2594340},
	doi = {10.1145/2594291.2594340},
	abstract = {Solver-aided domain-specific languages (SDSLs) are an emerging class of computer-aided programming systems. They ease the construction of programs by using satisfiability solvers to automate tasks such as verification, debugging, synthesis, and non-deterministic execution. But reducing programming tasks to satisfiability problems involves translating programs to logical constraints, which is an engineering challenge even for domain-specific languages. We have previously shown that translation to constraints can be avoided if SDSLs are implemented by (traditional) embedding into a host language that is itself solver-aided. This paper describes how to implement a symbolic virtual machine (SVM) for such a host language. Our symbolic virtual machine is lightweight because it compiles to constraints only a small subset of the host's constructs, while allowing SDSL designers to use the entire language, including constructs for DSL embedding. This lightweight compilation employs a novel symbolic execution technique with two key properties: it produces compact encodings, and it enables concrete evaluation to strip away host constructs that are outside the subset compilable to constraints. Our symbolic virtual machine architecture is at the heart of Rosette, a solver-aided language that is host to several new SDSLs.},
	urldate = {2017-12-06},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Torlak, Emina and Bodik, Rastislav},
	year = {2014},
	keywords = {solver-aided languages, symbolic virtual machine},
	pages = {530--541},
	file = {Torlak_Bodik_2014_A Lightweight Symbolic Virtual Machine for Solver-aided Host Languages.pdf:/home/michael/Dropbox/zotero-pdfs/T/Torlak_Bodik_2014_A Lightweight Symbolic Virtual Machine for Solver-aided Host Languages.pdf:application/pdf}
}

@article{reid_who_2017,
	title = {Who {Guards} the {Guards}? {Formal} {Validation} of the {Arm} {V}8-m {Architecture} {Specification}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {Who {Guards} the {Guards}?},
	url = {http://doi.acm.org/10.1145/3133912},
	doi = {10.1145/3133912},
	abstract = {Software and hardware are increasingly being formally verified against specifications, but how can we verify the specifications themselves? This paper explores what it means to formally verify a specification. We solve three challenges: (1) How to create a secondary, higher-level specification that can be effectively reviewed by processor designers who are not experts in formal verification; (2) How to avoid common-mode failures between the specifications; and (3) How to automatically verify the two specifications against each other.   One of the most important specifications for software verification is the processor specification since it defines the behaviour of machine code and of hardware protection features used by operating systems. We demonstrate our approach on ARM's v8-M Processor Specification, which is intended to improve the security of Internet of Things devices. Thus, we focus on establishing the security guarantees the architecture is intended to provide. Despite the fact that the ARM v8-M specification had previously been extensively tested, we found twelve bugs (including two security bugs) that have all been fixed by ARM.},
	number = {OOPSLA},
	urldate = {2017-12-06},
	journal = {Proc. ACM Program. Lang.},
	author = {Reid, Alastair},
	month = oct,
	year = {2017},
	keywords = {Formal Verification, ISA, Specification},
	pages = {88:1--88:24},
	file = {Reid_2017_Who Guards the Guards - Formal Validation of the Arm V8-m Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reid_2017_Who Guards the Guards - Formal Validation of the Arm V8-m Architecture.pdf:application/pdf}
}

@techreport{reed_patina:_2015,
	address = {University of Washington},
	title = {Patina: {A} {Formalization} of the {Rust} {Programming} {Language}.},
	author = {Reed, Eric},
	month = feb,
	year = {2015},
	keywords = {RUST},
	file = {Reed_2015_Patina.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reed_2015_Patina.pdf:application/pdf}
}

@inproceedings{leino_dafny:_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dafny: {An} {Automatic} {Program} {Verifier} for {Functional} {Correctness}},
	isbn = {978-3-642-17510-7 978-3-642-17511-4},
	shorttitle = {Dafny},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-17511-4_20},
	doi = {10.1007/978-3-642-17511-4_20},
	abstract = {Traditionally, the full verification of a program’s functional correctness has been obtained with pen and paper or with interactive proof assistants, whereas only reduced verification tasks, such as extended static checking, have enjoyed the automation offered by satisfiability-modulo-theories (SMT) solvers. More recently, powerful SMT solvers and well-designed program verifiers are starting to break that tradition, thus reducing the effort involved in doing full verification.This paper gives a tour of the language and verifier Dafny, which has been used to verify the functional correctness of a number of challenging pointer-based programs. The paper describes the features incorporated in Dafny, illustrating their use by small examples and giving a taste of how they are coded for an SMT solver. As a larger case study, the paper shows the full functional specification of the Schorr-Waite algorithm in Dafny.},
	language = {en},
	urldate = {2017-12-06},
	booktitle = {Logic for {Programming}, {Artificial} {Intelligence}, and {Reasoning}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Leino, K. Rustan M.},
	month = apr,
	year = {2010},
	pages = {348--370},
	file = {Leino_2010_Dafny - An Automatic Program Verifier for Functional Correctness.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leino_2010_Dafny - An Automatic Program Verifier for Functional Correctness.pdf:application/pdf}
}

@inproceedings{hawblitzel_ironclad_2014,
	title = {Ironclad {Apps}: {End}-to-{End} {Security} via {Automated} {Full}-{System} {Verification}.},
	shorttitle = {Ironclad {Apps}},
	booktitle = {{OSDI}},
	author = {Hawblitzel, Chris and Howell, Jon and Lorch, Jacob R. and Narayan, Arjun and Parno, Bryan and Zhang, Danfeng and Zill, Brian},
	year = {2014},
	pages = {165--181},
	file = {osdi14-paper-hawblitzel.pdf:/home/michael/Zotero/storage/7J8JQ4MT/osdi14-paper-hawblitzel.pdf:application/pdf}
}

@article{lee_automatically_2017,
	title = {On {Automatically} {Proving} the {Correctness} of math.h {Implementations}},
	url = {https://www.microsoft.com/en-us/research/publication/automatically-proving-correctness-math-h-implementations/},
	abstract = {Industry standard implementations of math.h claim (often without formal proof) tight bounds on floating-point errors. We demonstrate a novel static analysis that proves these bounds and verifies the correctness of these implementations. Our key insight is a reduction of this verification task to a set of mathematical optimization problems that can be solved by off-the-shelf computer algebra systems. …},
	urldate = {2017-12-14},
	journal = {Microsoft Research},
	author = {Lee, Wonyeol and Sharma, Rahul and Aiken, Alex},
	month = dec,
	year = {2017},
	file = {Lee et al_2017_On Automatically Proving the Correctness of math.h Implementations.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee et al_2017_On Automatically Proving the Correctness of math.h Implementations.pdf:application/pdf}
}

@inproceedings{ding_reconstruction_2014,
	title = {Reconstruction of data type in obfuscated binary programs},
	doi = {10.1109/ICACT.2014.6778988},
	abstract = {Recently, research community has advanced in type reconstruction technology for reverse engineering, but emerging with obfuscate technology, data type reconstruction is difficult and obfuscated code is easier to be monitored and analyzed by attacker or hacker. Therefore, we present a novel approach for automatic establish data type inference rules and reconstruct type from obfuscated binary programs using machine learning algorithm.},
	booktitle = {16th {International} {Conference} on {Advanced} {Communication} {Technology}},
	author = {Ding, W. and Gu, Z. and Gao, F.},
	month = feb,
	year = {2014},
	keywords = {Binary codes, reverse engineering, Reverse engineering, Arrays, computer crime, data type inference rules, data type reconstruction, Decision trees, Deobfuscation, Disassembly, Educational institutions, hacker, inference mechanisms, Inference Rules, learning (artificial intelligence), machine learning algorithm, Machine learning algorithms, Obfuscated Binary, obfuscated binary programs, obfuscated code analysis, obfuscated code monitoring, system monitoring, systems analysis, Type reconstruction},
	pages = {393--396},
	file = {Ding et al_2014_Reconstruction of data type in obfuscated binary programs.pdf:/home/michael/Dropbox/zotero-pdfs/D/Ding et al_2014_Reconstruction of data type in obfuscated binary programs.pdf:application/pdf}
}

@inproceedings{rosenblum_machine_2007,
	title = {Machine learning-assisted binary code analysis},
	booktitle = {{NIPS} {Workshop} on {Machine} {Learning} in {Adversarial} {Environments} for {Computer} {Security}, {Whistler}, {British} {Columbia}, {Canada}, {December}},
	author = {Rosenblum, Nathan and Zhu, Xiaojin and Miller, Barton and Hunt, Karen},
	year = {2007},
	file = {Rosenblum et al_2007_Machine learning-assisted binary code analysis.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosenblum et al_2007_Machine learning-assisted binary code analysis.pdf:application/pdf}
}

@inproceedings{bao_byteweight:_2014,
	address = {San Diego, CA},
	title = {{BYTEWEIGHT}: {Learning} to {Recognize} {Functions} in {Binary} {Code}},
	isbn = {978-1-931971-15-7},
	abstract = {Function identification is a fundamental challenge in reverse engineering and binary program analysis. For instance, binary rewriting and control flow integrity rely on accurate function detection and identification in binaries. Although many binary program analyses assume functions can be identified a priori, identifying functions in stripped binaries remains a challenge.

In this paper, we propose BYTEWEIGHT, a new automatic function identification algorithm. Our approach automatically learns key features for recognizing functions and can therefore easily be adapted to different platforms, new compilers, and new optimizations. We evaluated our tool against three well-known tools that feature function identification: IDA, BAP, and Dyninst. Our data set consists of 2,200 binaries created with three different compilers, with four different optimization levels, and across two different operating systems. In our experiments with 2,200 binaries, we found that BYTEWEIGHT missed 44,621 functions in comparison with the 266,672 functions missed by the industry-leading tool IDA. Furthermore, while IDA misidentified 459,247 functions, BYTEWEIGHT misidentified only 43,992 functions.},
	language = {eng},
	booktitle = {Proceedings of the 23rd {USENIX} {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Bao, Tiffany and Burket, Jonathan and Woo, Maverick and Turner, Rafael and Brumley, David},
	month = aug,
	year = {2014},
	note = {OCLC: 254320948},
	file = {Bao et al_2014_BYTEWEIGHT - Learning to Recognize Functions in Binary Code.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bao et al_2014_BYTEWEIGHT - Learning to Recognize Functions in Binary Code.pdf:application/pdf}
}

@article{clemens_automatic_2015,
	series = {The {Proceedings} of the {Fifteenth} {Annual} {DFRWS} {Conference}},
	title = {Automatic classification of object code using machine learning},
	volume = {14},
	issn = {1742-2876},
	url = {http://www.sciencedirect.com/science/article/pii/S1742287615000523},
	doi = {10.1016/j.diin.2015.05.007},
	abstract = {Recent research has repeatedly shown that machine learning techniques can be applied to either whole files or file fragments to classify them for analysis. We build upon these techniques to show that for samples of un-labeled compiled computer object code, one can apply the same type of analysis to classify important aspects of the code, such as its target architecture and endianess. We show that using simple byte-value histograms we retain enough information about the opcodes within a sample to classify the target architecture with high accuracy, and then discuss heuristic-based features that exploit information within the operands to determine endianess. We introduce a dataset with over 16000 code samples from 20 architectures and experimentally show that by using our features, classifiers can achieve very high accuracy with relatively small sample sizes.},
	number = {Supplement 1},
	urldate = {2017-12-16},
	journal = {Digital Investigation},
	author = {Clemens, John},
	month = aug,
	year = {2015},
	keywords = {Computer architecture, Classification, Machine learning, Malware analysis, Object code},
	pages = {S156--S162},
	file = {Clemens_2015_Automatic classification of object code using machine learning.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clemens_2015_Automatic classification of object code using machine learning.pdf:application/pdf}
}

@misc{clinger_tr133:_1983,
	title = {{TR}133: {A} {Scheme} for {Higher}-{Level} {Semantic} {Algebra}},
	url = {https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR133},
	urldate = {2018-01-08},
	author = {Clinger, William and Friedman, Daniel and Wand, Mitchell},
	month = may,
	year = {1983},
	file = {Clinger et al_TR133 - A Scheme for Higher-Level Semantic Algebra.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clinger et al_TR133 - A Scheme for Higher-Level Semantic Algebra.pdf:application/pdf}
}

@inproceedings{couprie_nom_2015,
	title = {Nom, {A} {Byte} oriented, streaming, {Zero} copy, {Parser} {Combinators} {Library} in {Rust}},
	isbn = {978-1-4799-9933-0},
	url = {http://ieeexplore.ieee.org/document/7163218/},
	doi = {10.1109/SPW.2015.31},
	urldate = {2018-01-12},
	publisher = {IEEE},
	author = {Couprie, Geoffroy},
	month = may,
	year = {2015},
	pages = {142--148},
	file = {Couprie_2015_Nom, A Byte oriented, streaming, Zero copy, Parser Combinators Library in Rust.pdf:/home/michael/Dropbox/zotero-pdfs/C/Couprie_2015_Nom, A Byte oriented, streaming, Zero copy, Parser Combinators Library in Rust.pdf:application/pdf}
}

@article{farnstrand_parallelization_2015,
	title = {Parallelization in {Rust} with fork-join and friends},
	author = {Färnstrand, Linus},
	year = {2015},
	keywords = {RUST},
	file = {FARNSTRAND_Parallelization in Rust with fork-join and friends.pdf:/home/michael/Dropbox/zotero-pdfs/F/FARNSTRAND_Parallelization in Rust with fork-join and friends.pdf:application/pdf}
}

@article{clipsham_safe_2015,
	title = {Safe, {Correct}, and {Fast} {Low}-{Level} {Networking}},
	author = {Clipsham, Robert},
	year = {2015},
	keywords = {RUST},
	file = {Clipsham_2015_Safe, Correct, and Fast Low-Level Networking.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clipsham_2015_Safe, Correct, and Fast Low-Level Networking.pdf:application/pdf}
}

@phdthesis{milewski_formalizing_2015,
	title = {Formalizing {Rust} traits},
	url = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0220521},
	abstract = {Rust is a new systems programming language designed with a focus on bare metal performance, safe concurrency and memory safety. It features a robust abstraction mechanism in the form of traits, which provide static overloading and dynamic dispatch. In this thesis, we present MiniRust—a formal model of a subset of Rust. The model focuses on the trait system and includes some advanced features of traits such as associated types and trait objects. In particular, we discuss the notion of object safety—the suitability of a particular trait for creating trait objects—and we formally determine very general conditions under which it can be guaranteed. To represent the runtime semantics of MiniRust programs, we develop an explicitly-typed internal language RustIn, for which we prove type safety, and we show that well-typed MiniRust programs can be translated to well-typed RustIn programs. Finally, we adapt the informally-described Rust trait coherence rules to our model and we show that
they are sufficient to ensure that overloads are always well-determined, even in the presence of library extensions.},
	language = {eng},
	urldate = {2018-01-12},
	school = {University of British Columbia},
	author = {Milewski, Jonatan},
	year = {2015},
	doi = {10.14288/1.0220521},
	file = {Milewski_2015_Formalizing Rust traits.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milewski_2015_Formalizing Rust traits.pdf:application/pdf}
}

@inproceedings{lin_rust_2016,
	title = {Rust as a language for high performance {GC} implementation},
	isbn = {978-1-4503-4317-6},
	url = {http://dl.acm.org/citation.cfm?doid=2926697.2926707},
	doi = {10.1145/2926697.2926707},
	language = {en},
	urldate = {2018-01-12},
	publisher = {ACM Press},
	author = {Lin, Yi and Blackburn, Stephen M. and Hosking, Antony L. and Norrish, Michael},
	year = {2016},
	keywords = {RUST},
	pages = {89--98},
	file = {Lin et al_2016_Rust as a language for high performance GC implementation.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lin et al_2016_Rust as a language for high performance GC implementation.pdf:application/pdf}
}

@article{ullrich_simple_2016,
	title = {Simple {Verification} of {Rust} {Programs} via {Functional} {Purification}},
	author = {Ullrich, Sebastian},
	month = jul,
	year = {2016},
	keywords = {RUST},
	file = {Ullrich_Simple Verification of Rust Programs via Functional Purification.pdf:/home/michael/Dropbox/zotero-pdfs/U/Ullrich_Simple Verification of Rust Programs via Functional Purification.pdf:application/pdf}
}

@inproceedings{levy_case_2017,
	title = {The {Case} for {Writing} a {Kernel} in {Rust}},
	isbn = {978-1-4503-5197-3},
	url = {http://dl.acm.org/citation.cfm?doid=3124680.3124717},
	doi = {10.1145/3124680.3124717},
	language = {en},
	urldate = {2018-01-12},
	publisher = {ACM Press},
	author = {Levy, Amit and Campbell, Bradford and Ghena, Branden and Pannuto, Pat and Dutta, Prabal and Levis, Philip},
	year = {2017},
	keywords = {RUST},
	pages = {1--7},
	file = {Levy et al_2017_The Case for Writing a Kernel in Rust.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levy et al_2017_The Case for Writing a Kernel in Rust.pdf:application/pdf}
}

@phdthesis{light_reenix:_2015,
	type = {{PhD} {Thesis}},
	title = {Reenix: {Implementing} a {Unix}-{Like} {Operating} {System} in {Rust}},
	shorttitle = {Reenix},
	school = {Master’s thesis, Brown University, Department of Computer Science},
	author = {Light, Alex},
	year = {2015},
	keywords = {RUST},
	file = {Light_2015_Reenix.pdf:/home/michael/Dropbox/zotero-pdfs/L/Light_2015_Reenix.pdf:application/pdf}
}

@article{berger_reconsidering_2002,
	title = {Reconsidering {Custom} {Memory} {Allocation}},
	volume = {48},
	shorttitle = {{OOPSLA} 2002},
	number = {4S},
	journal = {ACM SIGPLAN Notices},
	author = {Berger, Emery D. and Zorn, Benjamin G. and McKinley, Kathryn S.},
	year = {2002},
	pages = {46--57},
	file = {Berger et al_2002_Reconsidering Custom Memory Allocation.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berger et al_2002_Reconsidering Custom Memory Allocation.pdf:application/pdf}
}

@inproceedings{berger_composing_2001,
	title = {Composing high-performance memory allocators},
	volume = {36},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Berger, Emery D. and Zorn, Benjamin G. and McKinley, Kathryn S.},
	year = {2001},
	pages = {114--124},
	file = {Berger et al_2001_Composing high-performance memory allocators.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berger et al_2001_Composing high-performance memory allocators.pdf:application/pdf}
}

@inproceedings{candea_crash-only_2003,
	title = {Crash-{Only} {Software}.},
	volume = {3},
	booktitle = {{HotOS}},
	author = {Candea, George and Fox, Armando},
	year = {2003},
	keywords = {CONCURRENCY},
	pages = {67--72},
	file = {Candea_Fox_2003_Crash-Only Software.pdf:/home/michael/Dropbox/zotero-pdfs/C/Candea_Fox_2003_Crash-Only Software.pdf:application/pdf}
}

@techreport{fraser_practical_2004,
	title = {Practical lock-freedom},
	institution = {University of Cambridge, Computer Laboratory},
	author = {Fraser, Keir},
	year = {2004},
	keywords = {CONCURRENCY},
	file = {Fraser_2004_Practical lock-freedom.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fraser_2004_Practical lock-freedom.pdf:application/pdf}
}

@article{mellor-crummey_algorithms_1991,
	title = {Algorithms for scalable synchronization on shared-memory multiprocessors},
	volume = {9},
	number = {1},
	journal = {ACM Transactions on Computer Systems (TOCS)},
	author = {Mellor-Crummey, John M. and Scott, Michael L.},
	year = {1991},
	keywords = {CONCURRENCY},
	pages = {21--65},
	file = {Mellor-Crummey_Scott_1991_Algorithms for scalable synchronization on shared-memory multiprocessors.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mellor-Crummey_Scott_1991_Algorithms for scalable synchronization on shared-memory multiprocessors.pdf:application/pdf}
}

@inproceedings{turon_reagents:_2012,
	address = {New York, NY, USA},
	series = {{PLDI} '12},
	title = {Reagents: {Expressing} and {Composing} {Fine}-grained {Concurrency}},
	isbn = {978-1-4503-1205-9},
	shorttitle = {Reagents},
	url = {http://doi.acm.org/10.1145/2254064.2254084},
	doi = {10.1145/2254064.2254084},
	abstract = {Efficient communication and synchronization is crucial for fine grained parallelism. Libraries providing such features, while indispensable, are difficult to write, and often cannot be tailored or composed to meet the needs of specific users. We introduce reagents, a set of combinators for concisely expressing concurrency algorithms. Reagents scale as well as their hand-coded counterparts, while providing the composability existing libraries lack.},
	urldate = {2018-01-12},
	booktitle = {Proceedings of the 33rd {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Turon, Aaron},
	year = {2012},
	keywords = {monads, CONCURRENCY, arrows, compositional concurrency, fine-grained concurrency, nonblocking algorithms},
	pages = {157--168},
	file = {Turon_2012_Reagents - Expressing and Composing Fine-grained Concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turon_2012_Reagents - Expressing and Composing Fine-grained Concurrency.pdf:application/pdf}
}

@inproceedings{hendler_non-blocking_2002,
	title = {Non-blocking steal-half work queues},
	booktitle = {Proceedings of the twenty-first annual symposium on {Principles} of distributed computing},
	publisher = {ACM},
	author = {Hendler, Danny and Shavit, Nir},
	year = {2002},
	keywords = {CONCURRENCY},
	pages = {280--289},
	file = {Hendler_Shavit_2002_Non-blocking steal-half work queues.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hendler_Shavit_2002_Non-blocking steal-half work queues.pdf:application/pdf}
}

@inproceedings{robison_three_2010,
	address = {New York, NY, USA},
	series = {{ParaPLoP} '10},
	title = {Three {Layer} {Cake} for {Shared}-memory {Programming}},
	isbn = {978-1-4503-0127-5},
	url = {http://doi.acm.org/10.1145/1953611.1953616},
	doi = {10.1145/1953611.1953616},
	abstract = {There are many different styles of parallel programming for shared-memory hardware. Each style has strengths, but can conflict with other styles. How can we use a variety of these styles in one program and minimize their conflict and maximize performance, readability, and flexibility? This paper surveys the relative advantages and disadvantages of three styles (SIMD, fork join, and message passing), shows how to compose them hierarchically, and advises how to choose what goes at each level in the hierarchy.},
	urldate = {2018-01-12},
	booktitle = {Proceedings of the 2010 {Workshop} on {Parallel} {Programming} {Patterns}},
	publisher = {ACM},
	author = {Robison, Arch D. and Johnson, Ralph E.},
	year = {2010},
	keywords = {composition, CONCURRENCY, fork-join, message-passing, SIMD},
	pages = {5:1--5:8},
	file = {Robison_Johnson_2010_Three Layer Cake for Shared-memory Programming.pdf:/home/michael/Dropbox/zotero-pdfs/R/Robison_Johnson_2010_Three Layer Cake for Shared-memory Programming.pdf:application/pdf}
}

@inproceedings{ding_bws:_2012,
	title = {Bws: balanced work stealing for time-sharing multicores},
	shorttitle = {Bws},
	booktitle = {Proceedings of the 7th {ACM} european conference on {Computer} {Systems}},
	publisher = {ACM},
	author = {Ding, Xiaoning and Wang, Kaibo and Gibbons, Phillip B. and Zhang, Xiaodong},
	year = {2012},
	keywords = {CONCURRENCY},
	pages = {365--378},
	file = {Ding et al_2012_Bws - balanced work stealing for time-sharing multicores.pdf:/home/michael/Dropbox/zotero-pdfs/D/Ding et al_2012_Bws - balanced work stealing for time-sharing multicores.pdf:application/pdf}
}

@article{blagodurov_contention-aware_2010,
	title = {Contention-{Aware} {Scheduling} on {Multicore} {Systems}},
	volume = {28},
	issn = {07342071},
	url = {http://portal.acm.org/citation.cfm?doid=1880018.1880019},
	doi = {10.1145/1880018.1880019},
	language = {en},
	number = {4},
	urldate = {2018-01-12},
	journal = {ACM Transactions on Computer Systems},
	author = {Blagodurov, Sergey and Zhuravlev, Sergey and Fedorova, Alexandra},
	month = dec,
	year = {2010},
	keywords = {CONCURRENCY},
	pages = {1--45},
	file = {Blagodurov et al_2010_Contention-Aware Scheduling on Multicore Systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Blagodurov et al_2010_Contention-Aware Scheduling on Multicore Systems.pdf:application/pdf}
}

@article{ousterhout_scheduling_nodate,
	title = {Scheduling {Techniques} for {Concurrent} {Systems}},
	url = {http://www.cs.umd.edu/~hollings/cs818z/s00/papers/cosched.pdf},
	urldate = {2018-01-12},
	author = {Ousterhout, John},
	keywords = {CONCURRENCY},
	file = {Ousterhout_Scheduling Techniques for Concurrent Systems.pdf:/home/michael/Dropbox/zotero-pdfs/O/Ousterhout_Scheduling Techniques for Concurrent Systems.pdf:application/pdf}
}

@inproceedings{guo_work-first_2009,
	title = {Work-first and help-first scheduling policies for async-finish task parallelism},
	booktitle = {Parallel \& {Distributed} {Processing}, 2009. {IPDPS} 2009. {IEEE} {International} {Symposium} on},
	publisher = {IEEE},
	author = {Guo, Yi and Barik, Rajkishore and Raman, Raghavan and Sarkar, Vivek},
	year = {2009},
	keywords = {CONCURRENCY},
	pages = {1--12},
	file = {Guo et al_2009_Work-first and help-first scheduling policies for async-finish task parallelism.pdf:/home/michael/Dropbox/zotero-pdfs/G/Guo et al_2009_Work-first and help-first scheduling policies for async-finish task parallelism.pdf:application/pdf}
}

@inproceedings{chase_dynamic_2005,
	title = {Dynamic circular work-stealing deque},
	booktitle = {Proceedings of the seventeenth annual {ACM} symposium on {Parallelism} in algorithms and architectures},
	publisher = {ACM},
	author = {Chase, David and Lev, Yossi},
	year = {2005},
	keywords = {CONCURRENCY},
	pages = {21--28},
	file = {Chase_Lev_2005_Dynamic circular work-stealing deque.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chase_Lev_2005_Dynamic circular work-stealing deque.pdf:application/pdf}
}

@inproceedings{acar_data_2000,
	address = {New York, NY, USA},
	series = {{SPAA} '00},
	title = {The {Data} {Locality} of {Work} {Stealing}},
	isbn = {978-1-58113-185-7},
	url = {http://doi.acm.org/10.1145/341800.341801},
	doi = {10.1145/341800.341801},
	abstract = {This paper studies the data locality of the work-stealing scheduling algorithm on hardware-controlled shared-memory machines. We present lower and upper bounds on the number of cache misses using work stealing, and introduce a locality-guided work-stealing algorithm along with experimental validation.
As a lower bound, we show that there is a family of multi-threaded computations Gn each member of which requires \&THgr;(n) total instructions (work) for which when using work-stealing the number of cache misses on one processor is constant, while even on two processors the total number of cache misses is \&OHgr;(n). This implies that for general computations there is no useful bound relating multiprocessor to uninprocessor cache misses. For nested-parallel computations, however, we show that on P processors the expected additional number of cache misses beyond those on a single processor is bounded by O(C⌈m/s PT∞), where m is the execution time of an instruction incurring a cache miss, s is the steal time, C is the size of cache, and T∞ is the number of nodes on the longest chain of dependences. Based on this we give strong bounds on the total running time of nested-parallel computations using work stealing.
 For the second part of our results, we present a locality-guided work stealing algorithm that improves the data locality of multi-threaded computations by allowing a thread to have an affinity for a processor. Our initial experiments on iterative data-parallel applications show that the algorithm matches the performance of static-partitioning under traditional work loads but improves the performance up to 50\% over static partitioning under multiprogrammed work loads. Furthermore, the locality-guided work stealing improves the performance of work-stealing up to 80\%.},
	urldate = {2018-01-12},
	booktitle = {Proceedings of the {Twelfth} {Annual} {ACM} {Symposium} on {Parallel} {Algorithms} and {Architectures}},
	publisher = {ACM},
	author = {Acar, Umut A. and Blelloch, Guy E. and Blumofe, Robert D.},
	year = {2000},
	keywords = {CONCURRENCY},
	pages = {1--12},
	file = {Acar et al_2000_The Data Locality of Work Stealing.pdf:/home/michael/Dropbox/zotero-pdfs/A/Acar et al_2000_The Data Locality of Work Stealing.pdf:application/pdf}
}

@article{arora_thread_2001,
	title = {Thread scheduling for multiprogrammed multiprocessors},
	volume = {34},
	number = {2},
	journal = {Theory of computing systems},
	author = {Arora, Nimar S. and Blumofe, Robert D. and Plaxton, C. Greg},
	year = {2001},
	keywords = {CONCURRENCY},
	pages = {115--144},
	file = {Arora et al_2001_Thread scheduling for multiprogrammed multiprocessors.pdf:/home/michael/Dropbox/zotero-pdfs/A/Arora et al_2001_Thread scheduling for multiprogrammed multiprocessors.pdf:application/pdf}
}

@article{blumofe_scheduling_1999,
	title = {Scheduling {Multithreaded} {Computations} by {Work} {Stealing}},
	volume = {46},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/324133.324234},
	doi = {10.1145/324133.324234},
	abstract = {This paper studies the problem of efficiently schedulling fully strict (i.e., well-structured) multithreaded computations on parallel computers. A popular and practical method of scheduling this kind of dynamic MIMD-style computation is “work stealing,” in which processors needing work steal computational threads from other processors. In this paper, we give the first provably good work-stealing scheduler for multithreaded computations with dependencies.Specifically, our analysis shows that the expected time to execute a fully strict computation on P processors using our work-stealing scheduler is T1/P + O(T  ∞ , where  T1 is the minimum serial execution time of the multithreaded computation and (T  ∞ is the minimum execution time with an infinite number of processors. Moreover, the space required by the execution is at most S1P, where  S1 is the minimum serial space requirement. We also show that the expected total communication of the algorithm is at most O(PT  ∞ ( 1 +  nd)Smax), where Smax is the size of the largest activation record of any thread and  nd is the maximum number of times that any thread synchronizes with its parent. This communication bound justifies the folk wisdom that work-stealing schedulers are more communication efficient than their work-sharing counterparts. All three of these bounds are existentially optimal to within a constant factor.},
	number = {5},
	urldate = {2018-01-12},
	journal = {J. ACM},
	author = {Blumofe, Robert D. and Leiserson, Charles E.},
	month = sep,
	year = {1999},
	keywords = {CONCURRENCY, critical-path length, multiprocessor, multithreading, randomized algorithm, thread scheduling, work stealing},
	pages = {720--748},
	file = {Blumofe_Leiserson_1999_Scheduling Multithreaded Computations by Work Stealing.pdf:/home/michael/Dropbox/zotero-pdfs/B/Blumofe_Leiserson_1999_Scheduling Multithreaded Computations by Work Stealing.pdf:application/pdf}
}

@article{gordon_uniqueness_2012,
	title = {Uniqueness and {Reference} {Immutability} for {Safe} {Parallelism}},
	url = {https://www.microsoft.com/en-us/research/publication/uniqueness-and-reference-immutability-for-safe-parallelism/},
	abstract = {A key challenge for concurrent programming is that side-effects (memory operations) in one thread can affect the behavior of another thread. In this paper, we present a type system to restrict the updates to memory to prevent these unintended side-effects. We provide a novel combination of immutable and unique (isolated) types that ensures safe parallelism …},
	language = {en-US},
	urldate = {2018-01-12},
	journal = {Microsoft Research},
	author = {Gordon, Colin S. and Parkinson, Matthew and Parsons, Jared and Bromfield, Aleks and Duffy, Joe},
	month = oct,
	year = {2012},
	keywords = {TYPES},
	file = {Gordon et al_2012_Uniqueness and Reference Immutability for Safe Parallelism.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon et al_2012_Uniqueness and Reference Immutability for Safe Parallelism.pdf:application/pdf}
}

@inproceedings{scharli_traits:_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Traits: {Composable} {Units} of {Behaviour}},
	isbn = {978-3-540-40531-3 978-3-540-45070-2},
	shorttitle = {Traits},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-45070-2_12},
	doi = {10.1007/978-3-540-45070-2_12},
	abstract = {Despite the undisputed prominence of inheritance as the fundamental reuse mechanism in object-oriented programming languages, the main variants—single inheritance, multiple inheritance, and mixin inheritance—all suffer from conceptual and practical problems. In the first part of this paper, we identify and illustrate these problems. We then present traits, a simple compositional model for structuring object-oriented programs. A trait is essentially a group of pure methods that serves as a building block for classes and is a primitive unit of code reuse. In this model, classes are composed from a set of traits by specifying glue code that connects the traits together and accesses the necessary state. We demonstrate how traits overcome the problems arising from the different variants of inheritance, we discuss how traits can be implemented effectively, and we summarize our experience applying traits to refactor an existing class hierarchy.},
	language = {en},
	urldate = {2018-01-12},
	booktitle = {{ECOOP} 2003 – {Object}-{Oriented} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Schärli, Nathanael and Ducasse, Stéphane and Nierstrasz, Oscar and Black, Andrew P.},
	month = jul,
	year = {2003},
	keywords = {TYPES},
	pages = {248--274},
	file = {Scharli et al_2003_Traits.pdf:/home/michael/Dropbox/zotero-pdfs/S/Scharli et al_2003_Traits.pdf:application/pdf}
}

@article{flatt_macros_2012,
	title = {Macros that {Work} {Together}: {Compile}-time bindings, partial expansion, and definition contexts},
	volume = {22},
	issn = {1469-7653, 0956-7968},
	shorttitle = {Macros that {Work} {Together}},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/macros-that-work-together/375043C6746405B22014D235FA4C90C3},
	doi = {10.1017/S0956796812000093},
	abstract = {AbstractRacket is a large language that is built mostly within itself. Unlike the usual approach taken by non-Lisp languages, the self-hosting of Racket is not a matter of bootstrapping one implementation through a previous implementation, but instead a matter of building a tower of languages and libraries via macros. The upper layers of the tower include a class system, a component system, pedagogic variants of Scheme, a statically typed dialect of Scheme, and more. The demands of this language-construction effort require a macro system that is substantially more expressive than previous macro systems. In particular, while conventional Scheme macro systems handle stand-alone syntactic forms adequately, they provide weak support for macros that share information or macros that use existing syntactic forms in new contexts. This paper describes and models features of the Racket macro system, including support for general compile-time bindings, sub-form expansion and analysis, and environment management. The presentation assumes a basic familiarity with Lisp-style macros, and it takes for granted the need for macros that respect lexical scope. The model, however, strips away the pattern and template system that is normally associated with Scheme macros, isolating a core that is simpler, can support pattern and template forms themselves as macros, and generalizes naturally to Racket's other extensions.},
	language = {en},
	number = {2},
	urldate = {2018-01-12},
	journal = {Journal of Functional Programming},
	author = {Flatt, Matthew and Culpepper, Ryan and Darais, David and Findler, Robert Bruce},
	month = mar,
	year = {2012},
	keywords = {TYPES},
	pages = {181--216},
	file = {Flatt et al_2012_Macros that Work Together - Compile-time bindings, partial expansion, and.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flatt et al_2012_Macros that Work Together - Compile-time bindings, partial expansion, and.pdf:application/pdf}
}

@techreport{clarke_external_2002,
	title = {External {Uniqueness} is {Unique} {Enough}},
	url = {http://www.cs.uu.nl/research/techreps/UU-CS-2002-048.html},
	number = {UU-CS-2002-048},
	urldate = {2018-01-12},
	author = {Clarke, Dave and Wrigstad, Tobias},
	year = {2002},
	keywords = {TYPES},
	file = {Clarke_Wrigstad_2002_External Uniqueness is Unique Enough.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke_Wrigstad_2002_External Uniqueness is Unique Enough.pdf:application/pdf}
}

@article{boyland_alias_2001,
	title = {Alias burying: {Unique} variables without destructive reads},
	volume = {31},
	issn = {1097-024X},
	shorttitle = {Alias burying},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.370/abstract},
	doi = {10.1002/spe.370},
	abstract = {An unshared object can be accessed without regard to possible conflicts with other parts of a system, whether concurrent or single-threaded. A unique variable (sometimes known as a ‘free’ or ‘linear’ variable) is one that either is null or else refers to an unshared object. Being able to declare and check which variables are unique improves a programmer's ability to avoid program faults. In previously described uniqueness extensions to imperative languages, a unique variable can be accessed only with a destructive read, which nullifies it after the value is obtained. This approach suffers from several disadvantages: the use of destructive reads increases the complexity of the program which must continually restore nullified values; adding destructive reads changes the semantics of the programming language; and many of the nullifications are actually unnecessary. We demonstrate instead that uniqueness can be preserved through the use of existing language features. We give a modular static analysis that checks (nonexecutable) uniqueness annotations superimposed on an imperative programming language without destructive reads. The ‘alias-burying’ intuition is that aliases that are ‘dead’ (will never be used again) can be safely ‘buried’ (made undefined). Copyright © 2001 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {6},
	urldate = {2018-01-12},
	journal = {Software: Practice and Experience},
	author = {Boyland, John},
	month = may,
	year = {2001},
	keywords = {TYPES, borrowed, compromise, unshared},
	pages = {533--553},
	file = {Boyland_2001_Alias burying.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyland_2001_Alias burying.pdf:application/pdf}
}

@article{codd_relational_1970,
	title = {A {Relational} {Model} of {Data} for {Large} {Shared} {Data} {Banks}},
	volume = {13},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/362384.362685},
	doi = {10.1145/362384.362685},
	abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.
Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
	number = {6},
	urldate = {2018-01-15},
	journal = {Commun. ACM},
	author = {Codd, E. F.},
	month = jun,
	year = {1970},
	keywords = {security, composition, consistency, data bank, data base, data integrity, data organization, data structure, derivability, hierarchies of data, join, networks of data, predicate calculus, redundancy, relations, retrieval language},
	pages = {377--387},
	file = {Codd_1970_A Relational Model of Data for Large Shared Data Banks.pdf:/home/michael/Dropbox/zotero-pdfs/C/Codd_1970_A Relational Model of Data for Large Shared Data Banks.pdf:application/pdf}
}

@article{dijkstra_structure_1968,
	title = {The {Structure} of the “{THE}”-multiprogramming {System}},
	volume = {11},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/363095.363143},
	doi = {10.1145/363095.363143},
	number = {5},
	urldate = {2018-01-16},
	journal = {Commun. ACM},
	author = {Dijkstra, Edsger W.},
	month = may,
	year = {1968},
	keywords = {operating system, multiprogramming, cooperating sequential processes, input-output buffering, multiprocessing, multiprogramming system, processor sharing, program verification, real-time debugging, synchronizing primitives, system hierarchy, system levels, system structure},
	pages = {341--346},
	file = {Dijkstra_1968_The Structure of the “THE”-multiprogramming System.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dijkstra_1968_The Structure of the “THE”-multiprogramming System.pdf:application/pdf}
}

@article{bobrow_tenex_1972,
	title = {{TENEX}, a {Paged} {Time} {Sharing} {System} for the {PDP} - 10},
	volume = {15},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/361268.361271},
	doi = {10.1145/361268.361271},
	abstract = {TENEX is a new time sharing system implemented on a DEC PDP-10 augmented by special paging hardware developed at BBN. This report specifies a set of goals which are important for any time sharing system. It describes how the TENEX design and implementation achieve these goals. These include specifications for a powerful multiprocess large memory virtual machine, intimate terminal interaction, comprehensive uniform file and I/O capabilities, and clean flexible system structure. Although the implementation described here required some compromise to achieve a system operational within six months of hardware checkout, TENEX has met its major goals and provided reliable service at several sites and through the ARPA network.},
	number = {3},
	urldate = {2018-01-16},
	journal = {Commun. ACM},
	author = {Bobrow, Daniel G. and Burchfiel, Jerry D. and Murphy, Daniel L. and Tomlinson, Raymond S.},
	month = mar,
	year = {1972},
	keywords = {virtual machines, paging, PDP-10, process structure, scheduling algorithm, TENEX, time sharing system},
	pages = {135--143},
	file = {Bobrow et al_1972_TENEX, a Paged Time Sharing System for the PDP - 10.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bobrow et al_1972_TENEX, a Paged Time Sharing System for the PDP - 10.pdf:application/pdf}
}

@article{hansen_nucleus_1970,
	title = {The {Nucleus} of a {Multiprogramming} {System}},
	volume = {13},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/362258.362278},
	doi = {10.1145/362258.362278},
	abstract = {This paper describes the philosophy and structure of a multi-programming system that can be extended with a hierarchy of operating systems to suit diverse requirements of program scheduling and resource allocation. The system nucleus simulates an environment in which program execution and input/output are handled uniformly as parallel, cooperating processes. A fundamental set of primitives allows the dynamic creation and control of a hierarchy of processes as well as the communication among them.},
	number = {4},
	urldate = {2018-01-16},
	journal = {Commun. ACM},
	author = {Hansen, Per Brinch},
	month = apr,
	year = {1970},
	keywords = {operating systems, message buffering, multiprogramming, parallel processes, process communication, process concept, process creation, process hierarchy, process removal},
	pages = {238--241},
	file = {Hansen_1970_The Nucleus of a Multiprogramming System.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hansen_1970_The Nucleus of a Multiprogramming System.pdf:application/pdf;Hansen_1970_The Nucleus of a Multiprogramming System.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hansen_1970_The Nucleus of a Multiprogramming System.pdf:application/pdf}
}

@article{ritchie_unix_1974,
	title = {The {UNIX} {Time}-sharing {System}},
	volume = {17},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/361011.361061},
	doi = {10.1145/361011.361061},
	abstract = {UNIX is a general-purpose, multi-user, interactive operating system for the Digital Equipment Corporation PDP-11/40 and 11/45 computers. It offers a number of features seldom found even in larger operating systems, including: (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language selectable on a per-user basis; and (5) over 100 subsystems including a dozen languages. This paper discusses the nature and implementation of the file system and of the user command interface.},
	number = {7},
	urldate = {2018-01-16},
	journal = {Commun. ACM},
	author = {Ritchie, Dennis M. and Thompson, Ken},
	month = jul,
	year = {1974},
	keywords = {command language, file system, operating system, PDP-11, time-sharing},
	pages = {365--375},
	file = {Ritchie_Thompson_1974_The UNIX Time-sharing System.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ritchie_Thompson_1974_The UNIX Time-sharing System.pdf:application/pdf;Ritchie_Thompson_1974_The UNIX Time-sharing System.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ritchie_Thompson_1974_The UNIX Time-sharing System.pdf:application/pdf}
}

@article{mckusick_fast_1984,
	title = {A {Fast} {File} {System} for {UNIX}},
	volume = {2},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/989.990},
	doi = {10.1145/989.990},
	number = {3},
	urldate = {2018-01-16},
	journal = {ACM Trans. Comput. Syst.},
	author = {McKusick, Marshall K. and Joy, William N. and Leffler, Samuel J. and Fabry, Robert S.},
	month = aug,
	year = {1984},
	keywords = {application program interface, file system design, file system organization, file system performance, UNIX},
	pages = {181--197},
	file = {McKusick et al_1984_A Fast File System for UNIX.pdf:/home/michael/Dropbox/zotero-pdfs/M/McKusick et al_1984_A Fast File System for UNIX.pdf:application/pdf}
}

@article{rosenblum_design_1992,
	title = {The {Design} and {Implementation} of a {Log}-structured {File} {System}},
	volume = {10},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/146941.146943},
	doi = {10.1145/146941.146943},
	abstract = {This paper presents a new technique for disk storage management called a log-structured file system. A log-structured file system writes all modifications to disk sequentially in a log-like structure, thereby speeding up both file writing and crash recovery. The log is the only structure on disk; it contains indexing information so that files can be read back from the log efficiently. In order to maintain large free areas on disk for fast writing, we divide the log intosegmentsand use a segment cleaner to compress the live information from heavily fragmented segments. We present a series of simulations that demonstrate the efficiency of a simple cleaning policy based on cost and benefit. We have implemented a prototype  log-structured file system called Sprite LFS; it outperforms current Unix file systems by an order of magnitude for small-file writes while matching or exceeding Unix performance for reads and large writes. Even when the overhead for cleaning is included, Sprite LFS can use 70\% of the disk bandwidth for writing, whereas Unix file systems typically can use only 5–10\%.},
	number = {1},
	urldate = {2018-01-16},
	journal = {ACM Trans. Comput. Syst.},
	author = {Rosenblum, Mendel and Ousterhout, John K.},
	month = feb,
	year = {1992},
	keywords = {Unix, file system organization, file system performance, disk storage management, fast crash recovery, high write performance, log-structured, logging},
	pages = {26--52},
	file = {Rosenblum_Ousterhout_1992_The Design and Implementation of a Log-structured File System.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosenblum_Ousterhout_1992_The Design and Implementation of a Log-structured File System.pdf:application/pdf}
}

@inproceedings{walker_locus_1983,
	address = {New York, NY, USA},
	series = {{SOSP} '83},
	title = {The {LOCUS} {Distributed} {Operating} {System}},
	isbn = {978-0-89791-115-3},
	url = {http://doi.acm.org/10.1145/800217.806615},
	doi = {10.1145/800217.806615},
	abstract = {LOCUS is a distributed operating system which supports transparent access to data through a network wide filesystem, permits automatic replication of storage, supports transparent distributed process execution, supplies a number of high reliability functions such as nested transactions, and is upward compatible with Unix. Partitioned operation of subnet's and their dynamic merge is also supported.   The system has been operational for about two years at UCLA and extensive experience in its use has been obtained. The complete system architecture is outlined in this paper, and that experience is summarized.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the {Ninth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Walker, Bruce and Popek, Gerald and English, Robert and Kline, Charles and Thiel, Greg},
	year = {1983},
	pages = {49--70},
	file = {Walker et al_1983_The LOCUS Distributed Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/W/Walker et al_1983_The LOCUS Distributed Operating System.pdf:application/pdf}
}

@inproceedings{accetta_mach:_1986,
	title = {Mach: {A} {New} {Kernel} {Foundation} for {UNIX} {Development}},
	shorttitle = {Mach},
	abstract = {Mach is a multiprocessor operating system kernel and environment under development at Carnegie Mellon University. Mach provides a new foundation for UNIX development that spans networks of uniprocessors and multiprocessors. This paper describes Mach and the motivations that led to its design. Also described are some of the details of its implementation and current status. 1},
	author = {Accetta, Mike and Baron, Robert and Bolosky, William and Golub, David and Rashid, Richard and Tevanian, Avadis and Young, Michael},
	year = {1986},
	pages = {93--112},
	file = {Accetta et al_1986_Mach - A New Kernel Foundation for UNIX Development.pdf:/home/michael/Dropbox/zotero-pdfs/A/Accetta et al_1986_Mach - A New Kernel Foundation for UNIX Development.pdf:application/pdf}
}

@article{saltzer_end--end_1984,
	title = {End-to-end {Arguments} in {System} {Design}},
	volume = {2},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/357401.357402},
	doi = {10.1145/357401.357402},
	number = {4},
	urldate = {2018-01-16},
	journal = {ACM Trans. Comput. Syst.},
	author = {Saltzer, J. H. and Reed, D. P. and Clark, D. D.},
	month = nov,
	year = {1984},
	keywords = {data communication, design principles, protocol design},
	pages = {277--288},
	file = {Saltzer et al_1984_End-to-end Arguments in System Design.pdf:/home/michael/Dropbox/zotero-pdfs/S/Saltzer et al_1984_End-to-end Arguments in System Design.pdf:application/pdf}
}

@inproceedings{clark_structuring_1985,
	address = {New York, NY, USA},
	series = {{SOSP} '85},
	title = {The {Structuring} of {Systems} {Using} {Upcalls}},
	isbn = {978-0-89791-174-0},
	url = {http://doi.acm.org/10.1145/323647.323645},
	doi = {10.1145/323647.323645},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the {Tenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Clark, David D.},
	year = {1985},
	pages = {171--180},
	file = {Clark_1985_The Structuring of Systems Using Upcalls.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clark_1985_The Structuring of Systems Using Upcalls.pdf:application/pdf}
}

@inproceedings{engler_exokernel:_1995,
	address = {New York, NY, USA},
	series = {{SOSP} '95},
	title = {Exokernel: {An} {Operating} {System} {Architecture} for {Application}-level {Resource} {Management}},
	isbn = {978-0-89791-715-5},
	shorttitle = {Exokernel},
	url = {http://doi.acm.org/10.1145/224056.224076},
	doi = {10.1145/224056.224076},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Engler, D. R. and Kaashoek, M. F. and O'Toole, Jr., J.},
	month = dec,
	year = {1995},
	pages = {251--266},
	file = {Engler et al_1995_Exokernel - An Operating System Architecture for Application-level Resource.pdf:/home/michael/Dropbox/zotero-pdfs/E/Engler et al_1995_Exokernel - An Operating System Architecture for Application-level Resource.pdf:application/pdf}
}

@inproceedings{barham_xen_2003,
	address = {New York, NY, USA},
	series = {{SOSP} '03},
	title = {Xen and the {Art} of {Virtualization}},
	isbn = {978-1-58113-757-6},
	url = {http://doi.acm.org/10.1145/945445.945462},
	doi = {10.1145/945445.945462},
	abstract = {Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100\% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be ported with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the {Nineteenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Barham, Paul and Dragovic, Boris and Fraser, Keir and Hand, Steven and Harris, Tim and Ho, Alex and Neugebauer, Rolf and Pratt, Ian and Warfield, Andrew},
	month = oct,
	year = {2003},
	keywords = {hypervisors, paravirtualization, virtual machine monitors},
	pages = {164--177},
	file = {Barham et al_2003_Xen and the Art of Virtualization.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barham et al_2003_Xen and the Art of Virtualization.pdf:application/pdf;Barham et al_2003_Xen and the Art of Virtualization.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barham et al_2003_Xen and the Art of Virtualization.pdf:application/pdf}
}

@misc{rosen_resource_2013,
	title = {Resource {Management}, {Linux} {Kernel} {Namespaces}, and {CGroups}},
	url = {https://www.cs.ucsb.edu/~rich/class/cs293b-cloud/papers/lxc-namespace.pdf},
	urldate = {2018-01-16},
	author = {Rosen, Rami},
	month = may,
	year = {2013},
	file = {Rosen_Resource Management, Linux Kernel Namespaces, and CGroups.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosen_Resource Management, Linux Kernel Namespaces, and CGroups.pdf:application/pdf}
}

@inproceedings{bermbach_eventual_2011,
	title = {Eventual consistency: {How} soon is eventual? {An} evaluation of {Amazon} {S}3's consistency behavior},
	shorttitle = {Eventual consistency},
	booktitle = {Proceedings of the 6th {Workshop} on {Middleware} for {Service} {Oriented} {Computing}},
	publisher = {ACM},
	author = {Bermbach, David and Tai, Stefan},
	month = dec,
	year = {2011},
	pages = {1},
	file = {Bermbach_Tai_2011_Eventual consistency - How soon is eventual - An evaluation of Amazon S3's.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bermbach_Tai_2011_Eventual consistency - How soon is eventual - An evaluation of Amazon S3's.pdf:application/pdf}
}

@inproceedings{kivity_kvm:_2007,
	title = {{KVM}: the {Linux} {Virtual} {Machine} {Monitor}},
	shorttitle = {{KVM}},
	abstract = {Virtualization is a hot topic in operating systems these days. It is useful in many scenarios: server consolida-tion, virtual test environments, and for Linux enthusiasts who still can not decide which distribution is best. Re-cently, hardware vendors of commodity x86 processors have added virtualization extensions to the instruction set that can be utilized to write relatively simple virtual machine monitors. The Kernel-based Virtual Machine, or kvm, is a new Linux subsystem which leverages these virtualization extensions to add a virtual machine monitor (or hyper-visor) capability to Linux. Using kvm, one can create and run multiple virtual machines. These virtual ma-chines appear as normal Linux processes and integrate seamlessly with the rest of the system. 1},
	booktitle = {In {Proceedings} of the 2007 {Ottawa} {Linux} {Symposium} ({OLS}’-07},
	author = {Kivity, Avi and Kamay, Yaniv and Laor, Dor and Lublin, Uri and Liguori, Anthony},
	year = {2007},
	file = {Kivity et al_2007_KVM - the Linux Virtual Machine Monitor.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kivity et al_2007_KVM - the Linux Virtual Machine Monitor.pdf:application/pdf}
}

@article{hill_amdahls_2008,
	title = {Amdahl's {Law} in the {Multicore} {Era}},
	volume = {41},
	issn = {0018-9162},
	doi = {10.1109/MC.2008.209},
	abstract = {Augmenting Amdahl's law with a corollary for multicore hardware makes it relevant to future generations of chips with multiple processor cores. Obtaining optimal multicore performance will require further research in both extracting more parallelism and making sequential cores faster.},
	number = {7},
	journal = {Computer},
	author = {Hill, M. D. and Marty, M. R.},
	month = jul,
	year = {2008},
	keywords = {Computer architecture, Equations, Amdahl's law, chip multiprocessors (CMPs), Costs, Energy management, Hardware, multicore chips, Multicore processing, Multiprocessor interconnection networks, Parallel processing, Pipelines, Roads},
	pages = {33--38},
	file = {Hill_Marty_2008_Amdahl's Law in the Multicore Era.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hill_Marty_2008_Amdahl's Law in the Multicore Era.pdf:application/pdf}
}

@article{mudge_power:_2001,
	title = {Power: a first-class architectural design constraint},
	volume = {34},
	issn = {0018-9162},
	shorttitle = {Power},
	doi = {10.1109/2.917539},
	abstract = {Power is a design constraint not only for portable computers and mobile communication devices but also for high-end systems, and the design process should not subordinate it to performance},
	number = {4},
	journal = {Computer},
	author = {Mudge, T.},
	month = apr,
	year = {2001},
	keywords = {performance, Equations, architectural design constraint, CMOS logic circuits, computer architecture, computer power supplies, design process, Energy consumption, Frequency, high-end systems, logic design, mobile communication, mobile communication devices, portable computers, Portable computers, power consumption, Power system modeling, Semiconductor device modeling, Switches, Voltage, Web server},
	pages = {52--58},
	file = {Mudge_2001_Power - a first-class architectural design constraint.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mudge_2001_Power - a first-class architectural design constraint.pdf:application/pdf}
}

@article{amdahl_architecture_1964,
	title = {Architecture of the {IBM} {System}/360},
	volume = {8},
	issn = {0018-8646},
	url = {http://dx.doi.org/10.1147/rd.82.0087},
	doi = {10.1147/rd.82.0087},
	abstract = {The architecture* of the newly announced IBM System/360 features four innovations: 1. An approach to storage which permits and exploits very large capacities, hierarchies of speeds, readonly storage for microprogram control, flexible storage protection, and simple program relocation. 2. An input/output system offering new degrees of concurrent operation, compatible channel operation, data rates approaching 5,000,000 characters/second, integrated design of hardware and software, a new low-cost, multiple-channel package sharing main-frame hardware, new provisions for device status information, and a standard channel interface between central processing unit and input/output devices. 3. A truly general-purpose machine organization offering new supervisory facilities, powerful logical processing operations, and a wide variety of data formats. 4. Strict upward and downward machine-language compatibility over a line of six models having a performance range factor of 50. This paper discusses in detail the objectives of the design and the rationale for the main features of the architecture. Emphasis is given to the problems raised by the need for compatibility among central processing units of various size and by the conflicting demands of commercial, scientific, real-time, and logical information processing. A tabular summary of the architecture is shown in the Appendices.},
	number = {2},
	urldate = {2018-01-16},
	journal = {IBM J. Res. Dev.},
	author = {Amdahl, G. M. and Blaauw, G. A. and Brooks, F. P.},
	month = apr,
	year = {1964},
	pages = {87--101},
	file = {Amdahl et al_1964_Architecture of the IBM System-360.pdf:/home/michael/Dropbox/zotero-pdfs/A/Amdahl et al_1964_Architecture of the IBM System-360.pdf:application/pdf}
}

@article{moore_cramming_1998,
	title = {Cramming {More} {Components} {Onto} {Integrated} {Circuits}},
	volume = {86},
	issn = {0018-9219},
	doi = {10.1109/JPROC.1998.658762},
	abstract = {Not Available},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Moore, G. E.},
	month = jan,
	year = {1998},
	keywords = {Costs, Portable computers, Switches, Aerospace electronics, Home computing, Integrated circuit reliability, Integrated circuit technology, Semiconductor films, Space technology, Telephony},
	pages = {82--85},
	file = {Moore_1998_Cramming More Components Onto Integrated Circuits.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moore_1998_Cramming More Components Onto Integrated Circuits.pdf:application/pdf}
}

@article{tomasulo_efficient_1967,
	title = {An {Efficient} {Algorithm} for {Exploiting} {Multiple} {Arithmetic} {Units}},
	volume = {11},
	issn = {0018-8646},
	doi = {10.1147/rd.111.0025},
	abstract = {This paper describes the methods employed in the floating-point area of the System/360 Model 91 to exploit the existence of multiple execution units. Basic to these techniques is a simple common data busing and register tagging scheme which permits simultaneous execution of independent instructions while preserving the essential precedences inherent in the instruction stream. The common data bus improves performance by efficiently utilizing the execution units without requiring specially optimized code. Instead, the hardware, by ‘looking ahead’ about eight instructions, automatically optimizes the program execution on a local basis. The application of these techniques is not limited to floating-point arithmetic or System/360 architecture. It may be used in almost any computer having multiple execution units and one or more ‘accumulators.’ Both of the execution units, as well as the associated storage buffers, multiple accumulators and input/output buses, are extensively checked.},
	number = {1},
	journal = {IBM Journal of Research and Development},
	author = {Tomasulo, R. M.},
	month = jan,
	year = {1967},
	pages = {25--33},
	file = {Tomasulo_1967_An Efficient Algorithm for Exploiting Multiple Arithmetic Units.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tomasulo_1967_An Efficient Algorithm for Exploiting Multiple Arithmetic Units.pdf:application/pdf}
}

@article{fisher_instruction-level_1991,
	title = {Instruction-level parallel processing},
	volume = {253},
	issn = {0036-8075},
	doi = {10.1126/science.253.5025.1233},
	abstract = {The performance of microprocessors has increased steadily over the past 20 years at a rate of about 50\% per year. This is the cumulative result of architectural improvements as well as increases in circuit speed. Moreover, this improvement has been obtained in a transparent fashion, that is, without requiring programmers to rethink their algorithms and programs, thereby enabling the tremendous proliferation of computers that we see today. To continue this performance growth, microprocessor designers have incorporated instruction-level parallelism (ILP) into new designs. ILP utilizes the parallel execution ofthe lowest level computer operations-adds, multiplies, loads, and so on-to increase performance transparently. The use of ILP promises to make possible, within the next few years, microprocessors whose performance is many times that of a CRAY-IS. This article provides an overview of ILP, with an emphasis on ILP architectures-superscalar, VLIW, and dataflow processors-and the compiler techniques necessary to make ILP work well.},
	language = {eng},
	number = {5025},
	journal = {Science (New York, N.Y.)},
	author = {Fisher, J. A. and Rau, R.},
	month = sep,
	year = {1991},
	pmid = {17831442},
	pages = {1233--1241},
	file = {Fisher_Rau_1991_Instruction-level parallel processing.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fisher_Rau_1991_Instruction-level parallel processing.pdf:application/pdf}
}

@article{patterson_case_1980,
	title = {The case for the reduced instruction set computer},
	volume = {8},
	number = {6},
	journal = {ACM SIGARCH Computer Architecture News},
	author = {Patterson, David A. and Ditzel, David R.},
	year = {1980},
	pages = {25--33},
	file = {Patterson_Ditzel_1980_The case for the reduced instruction set computer.pdf:/home/michael/Dropbox/zotero-pdfs/P/Patterson_Ditzel_1980_The case for the reduced instruction set computer.pdf:application/pdf}
}

@inproceedings{smith_study_1981,
	title = {A study of branch prediction strategies},
	booktitle = {Proceedings of the 8th annual symposium on {Computer} {Architecture}},
	publisher = {IEEE Computer Society Press},
	author = {Smith, James E.},
	year = {1981},
	pages = {135--148},
	file = {Smith_1981_A study of branch prediction strategies.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_1981_A study of branch prediction strategies.pdf:application/pdf}
}

@techreport{mcfarling_combining_1993,
	title = {Combining branch predictors},
	institution = {Technical Report TN-36, Digital Western Research Laboratory},
	author = {McFarling, Scott},
	year = {1993},
	file = {McFarling_1993_Combining branch predictors.pdf:/home/michael/Dropbox/zotero-pdfs/M/McFarling_1993_Combining branch predictors.pdf:application/pdf}
}

@inproceedings{rotenberg_trace_1996,
	title = {Trace cache: a low latency approach to high bandwidth instruction fetching},
	shorttitle = {Trace cache},
	booktitle = {Proceedings of the 29th annual {ACM}/{IEEE} international symposium on {Microarchitecture}},
	publisher = {IEEE Computer Society},
	author = {Rotenberg, Eric and Bennett, Steve and Smith, James E.},
	year = {1996},
	pages = {24--35},
	file = {Rotenberg et al_1996_Trace cache - a low latency approach to high bandwidth instruction fetching.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rotenberg et al_1996_Trace cache - a low latency approach to high bandwidth instruction fetching.pdf:application/pdf}
}

@inproceedings{jouppi_improving_1990,
	title = {Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers},
	booktitle = {Computer {Architecture}, 1990. {Proceedings}., 17th {Annual} {International} {Symposium} on},
	publisher = {IEEE},
	author = {Jouppi, Norman P.},
	year = {1990},
	pages = {364--373},
	file = {Jouppi_1990_Improving direct-mapped cache performance by the addition of a small.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jouppi_1990_Improving direct-mapped cache performance by the addition of a small.pdf:application/pdf}
}

@article{drepper_what_2007,
	title = {What every programmer should know about memory},
	volume = {11},
	journal = {Red Hat, Inc},
	author = {Drepper, Ulrich},
	year = {2007},
	pages = {2007},
	file = {Drepper_2007_What every programmer should know about memory.pdf:/home/michael/Dropbox/zotero-pdfs/D/Drepper_2007_What every programmer should know about memory.pdf:application/pdf}
}

@article{smith_microarchitecture_1995,
	title = {The microarchitecture of superscalar processors},
	volume = {83},
	number = {12},
	journal = {Proceedings of the IEEE},
	author = {Smith, James E. and Sohi, Gurindar S.},
	year = {1995},
	pages = {1609--1624},
	file = {Smith_Sohi_1995_The microarchitecture of superscalar processors.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_Sohi_1995_The microarchitecture of superscalar processors.pdf:application/pdf}
}

@inproceedings{tullsen_simultaneous_1995,
	title = {Simultaneous multithreading: {Maximizing} on-chip parallelism},
	volume = {23},
	shorttitle = {Simultaneous multithreading},
	booktitle = {{ACM} {SIGARCH} {Computer} {Architecture} {News}},
	publisher = {ACM},
	author = {Tullsen, Dean M. and Eggers, Susan J. and Levy, Henry M.},
	year = {1995},
	pages = {392--403},
	file = {Tullsen et al_1995_Simultaneous multithreading - Maximizing on-chip parallelism.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tullsen et al_1995_Simultaneous multithreading - Maximizing on-chip parallelism.pdf:application/pdf}
}

@article{memory_wrl_nodate,
	title = {{WRL} {Research} {Report} 95/7},
	author = {Memory, Shared},
	file = {Memory_WRL Research Report 95-7.pdf:/home/michael/Dropbox/zotero-pdfs/M/Memory_WRL Research Report 95-7.pdf:application/pdf}
}

@inproceedings{hammond_transactional_2004,
	title = {Transactional memory coherence and consistency},
	volume = {32},
	booktitle = {{ACM} {SIGARCH} {Computer} {Architecture} {News}},
	publisher = {IEEE Computer Society},
	author = {Hammond, Lance and Wong, Vicky and Chen, Mike and Carlstrom, Brian D. and Davis, John D. and Hertzberg, Ben and Prabhu, Manohar K. and Wijaya, Honggo and Kozyrakis, Christos and Olukotun, Kunle},
	year = {2004},
	pages = {102},
	file = {Hammond et al_2004_Transactional memory coherence and consistency.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hammond et al_2004_Transactional memory coherence and consistency.pdf:application/pdf}
}

@article{carlstrom_atomos_2006,
	title = {The {Atomos} transactional programming language},
	volume = {41},
	number = {6},
	journal = {ACM SIGPLAN Notices},
	author = {Carlstrom, Brian D. and McDonald, Austen and Chafi, Hassan and Chung, JaeWoong and Minh, Chi Cao and Kozyrakis, Christos and Olukotun, Kunle},
	year = {2006},
	pages = {1--13},
	file = {Carlstrom et al_2006_The Atomos transactional programming language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Carlstrom et al_2006_The Atomos transactional programming language.pdf:application/pdf}
}

@inproceedings{tiwari_complete_2009,
	title = {Complete information flow tracking from the gates up},
	volume = {44},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Tiwari, Mohit and Wassel, Hassan MG and Mazloom, Bita and Mysore, Shashidhar and Chong, Frederic T. and Sherwood, Timothy},
	year = {2009},
	pages = {109--120},
	file = {Tiwari et al_2009_Complete information flow tracking from the gates up.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tiwari et al_2009_Complete information flow tracking from the gates up.pdf:application/pdf}
}

@article{nickolls_graphics_2009,
	title = {Graphics and computing {GPUs}},
	journal = {Computer Organization and Design: The Hardware/Software Interface, DA Patterson and JL Hennessy, 4th ed., Morgan Kaufmann},
	author = {Nickolls, John and Kirk, David},
	year = {2009},
	pages = {A2--A77},
	file = {Nickolls_Kirk_2009_Graphics and computing GPUs.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nickolls_Kirk_2009_Graphics and computing GPUs.pdf:application/pdf}
}

@article{lee_debunking_2010,
	title = {Debunking the 100X {GPU} vs. {CPU} myth: an evaluation of throughput computing on {CPU} and {GPU}},
	volume = {38},
	shorttitle = {Debunking the 100X {GPU} vs. {CPU} myth},
	number = {3},
	journal = {ACM SIGARCH computer architecture news},
	author = {Lee, Victor W. and Kim, Changkyu and Chhugani, Jatin and Deisher, Michael and Kim, Daehyun and Nguyen, Anthony D. and Satish, Nadathur and Smelyanskiy, Mikhail and Chennupaty, Srinivas and Hammarlund, Per},
	year = {2010},
	pages = {451--460},
	file = {Lee et al_2010_Debunking the 100X GPU vs. CPU myth - an evaluation of throughput computing on.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee et al_2010_Debunking the 100X GPU vs. CPU myth - an evaluation of throughput computing on.pdf:application/pdf}
}

@article{popek_formal_1974,
	title = {Formal requirements for virtualizable third generation architectures},
	volume = {17},
	number = {7},
	journal = {Communications of the ACM},
	author = {Popek, Gerald J. and Goldberg, Robert P.},
	year = {1974},
	pages = {412--421},
	file = {Popek_Goldberg_1974_Formal requirements for virtualizable third generation architectures.pdf:/home/michael/Dropbox/zotero-pdfs/P/Popek_Goldberg_1974_Formal requirements for virtualizable third generation architectures.pdf:application/pdf}
}

@article{colwell_instruction_1985,
	title = {Instruction {Sets} and {Beyond}: {Computers}, {Complexity}, and {Controversy}},
	volume = {18},
	issn = {0018-9162},
	shorttitle = {Instruction {Sets} and {Beyond}},
	url = {http://dx.doi.org/10.1109/MC.1985.1663000},
	doi = {10.1109/MC.1985.1663000},
	abstract = {First Page of the Article},
	number = {9},
	urldate = {2018-01-16},
	journal = {Computer},
	author = {Colwell, Robert P. and Hitchcock, III, Charles Y. and Jensen, E. D. and Brinkley Sprunt, H. M. and Kollar, Charles P.},
	month = sep,
	year = {1985},
	pages = {8--19},
	file = {Colwell et al_1985_Instruction Sets and Beyond - Computers, Complexity, and Controversy.pdf:/home/michael/Dropbox/zotero-pdfs/C/Colwell et al_1985_Instruction Sets and Beyond - Computers, Complexity, and Controversy.pdf:application/pdf}
}

@article{wilton_cacti:_1996,
	title = {{CACTI}: an enhanced cache access and cycle time model},
	volume = {31},
	issn = {0018-9200},
	shorttitle = {{CACTI}},
	doi = {10.1109/4.509850},
	abstract = {This paper describes an analytical model for the access and cycle times of on-chip direct-mapped and set-associative caches. The inputs to the model are the cache size, block size, and associativity, as well as array organization and process parameters. The model gives estimates that are within 6\% of Hspice results for the circuits we have chosen. This model extends previous models and fixes many of their major shortcomings. New features include models for the tag array, comparator, and multiplexor drivers, nonstep stage input slopes, rectangular stacking of memory subarrays, a transistor-level decoder model, column-multiplexed bitlines controlled by an additional array organizational parameter, load-dependent size transistors for wordline drivers, and output of cycle times as well as access times. Software implementing the model is available via ftp},
	number = {5},
	journal = {IEEE Journal of Solid-State Circuits},
	author = {Wilton, S. J. E. and Jouppi, N. P.},
	month = may,
	year = {1996},
	keywords = {Computer architecture, Equations, Costs, access times, analytical model, Analytical models, bitlines, cache storage, CACTI, comparator, content-addressable storage, Councils, cycle times, decoder, Decoding, Delay estimation, direct-mapped caches, Driver circuits, ftp software, integrated memory circuits, memory architecture, multiplexor driver, on-chip memory circuits, set-associative caches, Stacking, tag array, Wiring, wordlines},
	pages = {677--688},
	file = {Wilton_Jouppi_1996_CACTI - an enhanced cache access and cycle time model.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wilton_Jouppi_1996_CACTI - an enhanced cache access and cycle time model.pdf:application/pdf}
}

@inproceedings{alverson_tera_1990,
	address = {New York, NY, USA},
	series = {{ICS} '90},
	title = {The {Tera} {Computer} {System}},
	isbn = {978-0-89791-369-0},
	url = {http://doi.acm.org/10.1145/77726.255132},
	doi = {10.1145/77726.255132},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Supercomputing}},
	publisher = {ACM},
	author = {Alverson, Robert and Callahan, David and Cummings, Daniel and Koblenz, Brian and Porterfield, Allan and Smith, Burton},
	year = {1990},
	pages = {1--6},
	file = {Alverson et al_1990_The Tera Computer System.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alverson et al_1990_The Tera Computer System.pdf:application/pdf}
}

@misc{noauthor_intel_nodate,
	title = {Intel {Guide} for {Developing} {Multithreaded} {Applications} {\textbar} {Intel}® {Software}},
	url = {https://software.intel.com/en-us/articles/intel-guide-for-developing-multithreaded-applications},
	urldate = {2018-01-16},
	file = {Intel Guide for Developing Multithreaded Applications Intel® Software.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/Intel Guide for Developing Multithreaded Applications Intel® Software.pdf:application/pdf}
}

@misc{nvidia_gpus_nodate,
	title = {{GPUs} are only up to 14 times faster},
	author = {Nvidia},
	file = {Nvidia_GPUs are only up to 14 times faster.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nvidia_GPUs are only up to 14 times faster.pdf:application/pdf}
}

@misc{vmware_vmware_nodate,
	title = {{VMware} {Virtualization} {Overview}},
	author = {VMware},
	file = {VMware_VMware Virtualization Overview.pdf:/home/michael/Dropbox/zotero-pdfs/V/VMware_VMware Virtualization Overview.pdf:application/pdf}
}

@inproceedings{madhavapeddy_unikernels:_2013-1,
	address = {New York, NY, USA},
	series = {{ASPLOS} '13},
	title = {Unikernels: {Library} {Operating} {Systems} for the {Cloud}},
	isbn = {978-1-4503-1870-9},
	shorttitle = {Unikernels},
	url = {http://doi.acm.org/10.1145/2451116.2451167},
	doi = {10.1145/2451116.2451167},
	abstract = {We present unikernels, a new approach to deploying cloud services via applications written in high-level source code. Unikernels are single-purpose appliances that are compile-time specialised into standalone kernels, and sealed against modification when deployed to a cloud platform. In return they offer significant reduction in image sizes, improved efficiency and security, and should reduce operational costs. Our Mirage prototype compiles OCaml code into unikernels that run on commodity clouds and offer an order of magnitude reduction in code size without significant performance penalty. The architecture combines static type-safety with a single address-space layout that can be made immutable via a hypervisor extension. Mirage contributes a suite of type-safe protocol libraries, and our results demonstrate that the hypervisor is a platform that overcomes the hardware compatibility issues that have made past library operating systems impractical to deploy in the real-world.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the {Eighteenth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Madhavapeddy, Anil and Mortier, Richard and Rotsos, Charalampos and Scott, David and Singh, Balraj and Gazagnaire, Thomas and Smith, Steven and Hand, Steven and Crowcroft, Jon},
	year = {2013},
	keywords = {microkernel, functional programming, TO-READ, hypervisor, MIRAGE-OS, OCAML},
	pages = {461--472},
	file = {Madhavapeddy et al_2013_Unikernels - Library Operating Systems for the Cloud.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madhavapeddy et al_2013_Unikernels - Library Operating Systems for the Cloud.pdf:application/pdf}
}

@misc{noauthor_unikernels:_nodate,
	title = {Unikernels: {Rise} of the {Virtual} {Library} {Operating} {System} - {ACM} {Queue}},
	url = {http://queue.acm.org/detail.cfm?id=2566628},
	urldate = {2018-01-16},
	file = {Unikernels - Rise of the Virtual Library Operating System - ACM Queue.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/Unikernels - Rise of the Virtual Library Operating System - ACM Queue.pdf:application/pdf}
}

@misc{feng_certified_2017,
	address = {PLOS},
	title = {Certified {Preemptive} {OS} {Kernels}},
	url = {https://ess.cs.tu-dortmund.de/workshops/plos/2017/presentations/feng-plos2017.pdf},
	urldate = {2018-01-16},
	author = {Feng, Xinyu},
	month = oct,
	year = {2017},
	file = {Feng_2017_Certified Preemptive OS Kernels.pdf:/home/michael/Dropbox/zotero-pdfs/F/Feng_2017_Certified Preemptive OS Kernels.pdf:application/pdf}
}

@inproceedings{turon_logical_2013,
	address = {New York, NY, USA},
	series = {{POPL} '13},
	title = {Logical {Relations} for {Fine}-grained {Concurrency}},
	isbn = {978-1-4503-1832-7},
	url = {http://doi.acm.org/10.1145/2429069.2429111},
	doi = {10.1145/2429069.2429111},
	abstract = {Fine-grained concurrent data structures (or FCDs) reduce the granularity of critical sections in both time and space, thus making it possible for clients to access different parts of a mutable data structure in parallel. However, the tradeoff is that the implementations of FCDs are very subtle and tricky to reason about directly. Consequently, they are carefully designed to be contextual refinements of their coarse-grained counterparts, meaning that their clients can reason about them as if all access to them were sequentialized. In this paper, we propose a new semantic model, based on Kripke logical relations, that supports direct proofs of contextual refinement in the setting of a type-safe high-level language. The key idea behind our model is to provide a simple way of expressing the "local life stories" of individual pieces of an FCD's hidden state by means of protocols that the threads concurrently accessing that state must follow. By endowing these protocols with a simple yet powerful transition structure, as well as the ability to assert invariants on both heap states and specification code, we are able to support clean and intuitive refinement proofs for the most sophisticated types of FCDs, such as conditional compare-and-set (CCAS).},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 40th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Turon, Aaron J. and Thamsborg, Jacob and Ahmed, Amal and Birkedal, Lars and Dreyer, Derek},
	year = {2013},
	keywords = {separation logic, logical relations, refinement, fine-grained concurrency, data abstraction, linearizability, local state},
	pages = {343--356},
	file = {Turon et al_2013_Logical Relations for Fine-grained Concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turon et al_2013_Logical Relations for Fine-grained Concurrency.pdf:application/pdf}
}

@inproceedings{xu_practical_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Practical} {Verification} {Framework} for {Preemptive} {OS} {Kernels}},
	isbn = {978-3-319-41539-0 978-3-319-41540-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-41540-6_4},
	doi = {10.1007/978-3-319-41540-6_4},
	abstract = {We propose a practical verification framework for preemptive OS kernels. The framework models the correctness of API implementations in OS kernels as contextual refinement of their abstract specifications. It provides a specification language for defining the high-level abstract model of OS kernels, a program logic for refinement verification of concurrent kernel code with multi-level hardware interrupts, and automated tactics for developing mechanized proofs. The whole framework is developed for a practical subset of the C language. We have successfully applied it to verify key modules of a commercial preemptive OS μC/OS-IIμC/OS-II{\textbackslash}mu {\textbackslash}text \{C/OS-II\} [2], including the scheduler, interrupt handlers, message queues, and mutexes etc. We also verify the priority-inversion-freedom (PIF) in μC/OS-IIμC/OS-II{\textbackslash}mu {\textbackslash}text \{C/OS-II\}. All the proofs are mechanized in Coq. To our knowledge, our work is the first to verify the functional correctness of a practical preemptive OS kernel with machine-checkable proofs.},
	language = {en},
	urldate = {2018-01-16},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Cham},
	author = {Xu, Fengwei and Fu, Ming and Feng, Xinyu and Zhang, Xiaoran and Zhang, Hui and Li, Zhaohui},
	month = jul,
	year = {2016},
	pages = {59--79},
	file = {Xu et al_2016_A Practical Verification Framework for Preemptive OS Kernels.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xu et al_2016_A Practical Verification Framework for Preemptive OS Kernels.pdf:application/pdf}
}

@inproceedings{chen_cogent_2017,
	address = {New York, NY, USA},
	series = {{PLOS}'17},
	title = {The {Cogent} {Case} for {Property}-{Based} {Testing}},
	isbn = {978-1-4503-5153-9},
	url = {http://doi.acm.org/10.1145/3144555.3144556},
	doi = {10.1145/3144555.3144556},
	abstract = {Property-based testing can play an important role in reducing the cost of formal verification: It has been demonstrated to be effective at detecting bugs and finding inconsistencies in specifications, and thus can eliminate effort wasted on fruitless proof attempts. We argue that in addition, property-based testing enables an incremental approach to a fully verified system, by allowing replacement of automatically generated tests of properties stated in the specification by formal proofs. We demonstrate this approach on the verification of systems code, discuss the implications on systems design, and outline the integration of property-based testing into the Cogent framework.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 9th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Chen, Zilin and O'Connor, Liam and Keller, Gabriele and Klein, Gerwin and Heiser, Gernot},
	year = {2017},
	keywords = {Formal methods, Cogent, QuickCheck, Refinement, Systems software},
	pages = {1--7},
	file = {Chen et al_2017_The Cogent Case for Property-Based Testing.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chen et al_2017_The Cogent Case for Property-Based Testing.pdf:application/pdf}
}

@inproceedings{friesel_annotations_2017,
	address = {New York, NY, USA},
	series = {{PLOS}'17},
	title = {Annotations in {Operating} {Systems} with {Custom} {AspectC}++ {Attributes}},
	isbn = {978-1-4503-5153-9},
	url = {http://doi.acm.org/10.1145/3144555.3144561},
	doi = {10.1145/3144555.3144561},
	abstract = {Aspect Oriented Programming (AOP) supports the modular implementation of crosscutting concerns, which are woven into program parts designated by pointcuts, e.g. calls to specific functions. The release of AspectC++ 2.2 introduces the ability to express pointcuts based on C++11-style attributes as well as the definition of custom attributes for annotation purposes. In this paper, we propose the use of such attributes for operating system development. We cover three examples: Replacing non-portable compiler attributes and extending portable ones with domain-specific knowledge, providing implementation-independent joinpoint APIs to core operating system functions, and compile-time support for co-development of source code and corresponding models. We discuss the implementation effort and code size overhead of our ideas on the operating systems CocoOS and RIOT and show that annotations with custom attributes are a helpful addition for system development.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 9th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Friesel, Daniel and Buschhoff, Markus and Spinczyk, Olaf},
	year = {2017},
	pages = {36--42},
	file = {Friesel et al_2017_Annotations in Operating Systems with Custom AspectC++ Attributes.pdf:/home/michael/Dropbox/zotero-pdfs/F/Friesel et al_2017_Annotations in Operating Systems with Custom AspectC++ Attributes.pdf:application/pdf}
}

@inproceedings{boos_theseus:_2017,
	address = {New York, NY, USA},
	series = {{PLOS}'17},
	title = {Theseus: {A} {State} {Spill}-free {Operating} {System}},
	isbn = {978-1-4503-5153-9},
	shorttitle = {Theseus},
	url = {http://doi.acm.org/10.1145/3144555.3144560},
	doi = {10.1145/3144555.3144560},
	abstract = {In prior work, we have shown that the underdiagnosed problem of state spill remains a barrier to realizing complex systems that are easy to maintain, evolve, and run reliably. This paper shares our early experience building Theseus from scratch, an OS with the guiding principle of eliminating state spill. Theseus takes inspiration from distributed systems to rethink state management, and leverages Rust language features for maximum safety, code reuse, and efficient isolation. We intend to demonstrate Theseus as a runtime composable OS, in which entities are easily interchangeable and can evolve independently without reconfiguring or rebooting.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 9th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Boos, Kevin and Zhong, Lin},
	year = {2017},
	pages = {29--35},
	file = {Boos_Zhong_2017_Theseus - A State Spill-free Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boos_Zhong_2017_Theseus - A State Spill-free Operating System.pdf:application/pdf}
}

@inproceedings{david_building_2007,
	title = {Building a {Self}-{Healing} {Operating} {System}},
	doi = {10.1109/DASC.2007.22},
	abstract = {User applications and data in volatile memory are usually lost when an operating system crashes because of errors caused by either hardware or software faults. This is because most operating systems are designed to stop working when some internal errors are detected despite the possibility that user data and applications might still be intact and recoverable. Techniques like exception handling, code reloading, operating system component isolation, micro-rebooting, automatic system service restarts, watchdog timer based recovery and transactional components can be applied to attempt self-healing of an operating system from a wide variety of errors. Fault injection experiments show that these techniques can be used to continue running user applications after transparently recovering the operating system in a large percentage of cases. In cases where transparent recovery is not possible, individual process recovery can be attempted as a last resort.},
	booktitle = {Third {IEEE} {International} {Symposium} on {Dependable}, {Autonomic} and {Secure} {Computing} ({DASC} 2007)},
	author = {David, F. M. and Campbell, R. H.},
	month = sep,
	year = {2007},
	keywords = {Application software, Computer science, Operating systems, Hardware, automatic system service restart, code reloading, Computer bugs, Computer crashes, Computer errors, Error correction, Error correction codes, exception handling, hardware fault, micro-rebooting, operating systems (computers), self-healing operating system, Signal processing, software fault, system recovery, transactional component, user application, volatile memory, watchdog timer based recovery},
	pages = {3--10},
	file = {David_Campbell_2007_Building a Self-Healing Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/D/David_Campbell_2007_Building a Self-Healing Operating System.pdf:application/pdf}
}

@inproceedings{humbel_towards_2017,
	address = {New York, NY, USA},
	series = {{PLOS}'17},
	title = {Towards {Correct}-by-{Construction} {Interrupt} {Routing} on {Real} {Hardware}},
	isbn = {978-1-4503-5153-9},
	url = {http://doi.acm.org/10.1145/3144555.3144557},
	doi = {10.1145/3144555.3144557},
	abstract = {In this paper we address the problem of correctly configuring interrupts. The interrupt subsystem of a computer is increasingly complex: a zoo of different controllers with varying constraints and capabilities form a network with limited connectivity. An OS which aspires to provable correctness must manage a limited set of interrupt vectors, delegate interrupts to device drivers and configure the controllers correctly. No well-specified approach exists. As a foundation for applying language-level techniques like program sketching and synthesis to this problem, we present a formal model for interrupt routing which can capture all the system topologies and interrupt controllers we have encountered in the wild, show applications of such a model not possible with informal, ad-hoc approaches like DeviceTrees, and finally discuss an implementation based on the model which forms the new interrupt subsystem of the Barrelfish OS.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 9th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Humbel, Lukas and Achermann, Reto and Cock, David and Roscoe, Timothy},
	year = {2017},
	keywords = {Eclipse/CLP, Hardware abstraction, Hardware configuration, Interrupt routing},
	pages = {8--14},
	file = {Humbel et al_2017_Towards Correct-by-Construction Interrupt Routing on Real Hardware.pdf:/home/michael/Dropbox/zotero-pdfs/H/Humbel et al_2017_Towards Correct-by-Construction Interrupt Routing on Real Hardware.pdf:application/pdf}
}

@article{yanok_tapir:_2015,
	title = {Tapir: {A} {Language} for {Verified} {OS} {Kernel} {Probes}},
	volume = {49},
	issn = {0163-5980},
	shorttitle = {Tapir},
	url = {http://doi.acm.org/10.1145/2883591.2883602},
	doi = {10.1145/2883591.2883602},
	abstract = {Kernel probes allow code to be inserted into a running operating system kernel to gather information for debugging or profiling. Inserting code into the kernel raises a number of safety issues. Current solutions follow one of the two paths: a VM-based approach, where safety properties are checked dynamically by an interpreter, or a static-analysis approach, where probe code is guaranteed to be safe statically. While more attractive, existing static solutions depend on ad-hoc and error-prone analysis. We propose to explore enforcing safety properties using a type system, thus building our analysis on top of the well-studied ground of type theory.},
	number = {2},
	urldate = {2018-01-16},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Yanok, Ilya and Nystrom, Nathaniel},
	month = oct,
	year = {2015},
	keywords = {dependent types, type systems, kernel probes},
	pages = {51--56},
	file = {Yanok_Nystrom_2016_Tapir - A Language for Verified OS Kernel Probes.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yanok_Nystrom_2016_Tapir - A Language for Verified OS Kernel Probes.pdf:application/pdf}
}

@inproceedings{madhavapeddy_melange:_2007,
	address = {New York, NY, USA},
	series = {{EuroSys} '07},
	title = {Melange: {Creating} a "{Functional}" {Internet}},
	isbn = {978-1-59593-636-3},
	shorttitle = {Melange},
	url = {http://doi.acm.org/10.1145/1272996.1273009},
	doi = {10.1145/1272996.1273009},
	abstract = {Most implementations of critical Internet protocols are written in type-unsafe languages such as C or C++ and are regularly vulnerable to serious security and reliability problems. Type-safe languages eliminate many errors but are not used to due to the perceived performance overheads. We combine two techniques to eliminate this performance penalty in a practical fashion: strong static typing and generative meta-programming. Static typing eliminates run-time type information by checking safety at compile-time and minimises dynamic checks. Meta-programming uses a single specification to abstract the low-level code required to transmit and receive packets. Our domain-specific language, MPL, describes Internet packet protocols and compiles into fast, zero-copy code for both parsing and creating these packets. MPL is designed for implementing quirky Internet protocols ranging from the low-level: Ethernet, IPv4, ICMP and TCP; to the complex application-level: SSH, DNS and BGP; and even file-system protocols such as 9P. We report on fully-featured SSH and DNS servers constructed using MPL and our OCaml framework Melange, and measure greater throughput, lower latency, better flexibility and more succinct source code than their C equivalents OpenSSH and BIND. Our quantitative analysis shows that the benefits of MPL-generated code overcomes the additional overheads of automatic garbage collection and dynamic bounds checking. Qualitatively, the flexibility of our approach shows that dramatic optimisations are easily possible.},
	urldate = {2018-01-16},
	booktitle = {Proceedings of the 2Nd {ACM} {SIGOPS}/{EuroSys} {European} {Conference} on {Computer} {Systems} 2007},
	publisher = {ACM},
	author = {Madhavapeddy, Anil and Ho, Alex and Deegan, Tim and Scott, David and Sohan, Ripduman},
	year = {2007},
	pages = {101--114},
	file = {Madhavapeddy et al_2007_Melange - Creating a Functional Internet.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madhavapeddy et al_2007_Melange - Creating a Functional Internet.pdf:application/pdf}
}

@article{denning_fault_1976,
	title = {Fault {Tolerant} {Operating} {Systems}},
	volume = {8},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/356678.356680},
	doi = {10.1145/356678.356680},
	number = {4},
	urldate = {2018-01-16},
	journal = {ACM Comput. Surv.},
	author = {Denning, Peter J.},
	month = dec,
	year = {1976},
	pages = {359--389},
	file = {Denning_1976_Fault Tolerant Operating Systems.pdf:/home/michael/Dropbox/zotero-pdfs/D/Denning_1976_Fault Tolerant Operating Systems.pdf:application/pdf}
}

@inproceedings{david_curios:_2008,
	title = {{CuriOS}: {Improving} {Reliability} through {Operating} {System} {Structure}.},
	volume = {8},
	shorttitle = {{CuriOS}},
	booktitle = {{OSDI}},
	author = {David, Francis M. and Chan, Ellick and Carlyle, Jeffrey C. and Campbell, Roy H.},
	year = {2008},
	pages = {59--72},
	file = {David et al_2008_CuriOS - Improving Reliability through Operating System Structure.pdf:/home/michael/Dropbox/zotero-pdfs/D/David et al_2008_CuriOS - Improving Reliability through Operating System Structure.pdf:application/pdf}
}

@inproceedings{madhavapeddy_combining_2009,
	title = {Combining static model checking with dynamic enforcement using the statecall policy language},
	booktitle = {International {Conference} on {Formal} {Engineering} {Methods}},
	publisher = {Springer},
	author = {Madhavapeddy, Anil},
	year = {2009},
	pages = {446--465},
	file = {Madhavapeddy_2009_Combining static model checking with dynamic enforcement using the statecall.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madhavapeddy_2009_Combining static model checking with dynamic enforcement using the statecall.pdf:application/pdf}
}

@misc{mattklein123_meltdown_2018,
	title = {Meltdown and {Spectre}, explained},
	url = {https://medium.com/@mattklein123/meltdown-spectre-explained-6bc8634cc0c2},
	abstract = {Although these days I’m mostly known for application level networking and distributed systems, I spent the first part of my career working…},
	urldate = {2018-01-16},
	journal = {mattklein123},
	author = {mattklein123},
	month = jan,
	year = {2018}
}

@article{newcombe_how_2015,
	title = {How {Amazon} {Web} {Services} {Uses} {Formal} {Methods}},
	volume = {58},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2699417},
	doi = {10.1145/2699417},
	abstract = {Engineers use TLA+ to prevent serious but subtle bugs from reaching production.},
	number = {4},
	urldate = {2018-01-17},
	journal = {Commun. ACM},
	author = {Newcombe, Chris and Rath, Tim and Zhang, Fan and Munteanu, Bogdan and Brooker, Marc and Deardeuff, Michael},
	month = mar,
	year = {2015},
	keywords = {1-18},
	pages = {66--73},
	file = {Newcombe et al_2015_How Amazon Web Services Uses Formal Methods.pdf:/home/michael/Dropbox/zotero-pdfs/N/Newcombe et al_2015_How Amazon Web Services Uses Formal Methods.pdf:application/pdf}
}

@inproceedings{ball_slam2:_2010,
	address = {Austin, TX},
	series = {{FMCAD} '10},
	title = {{SLAM}2: {Static} {Driver} {Verification} with {Under} 4\% {False} {Alarms}},
	shorttitle = {{SLAM}2},
	url = {http://dl.acm.org/citation.cfm?id=1998496.1998508},
	abstract = {In theory, counterexample-guided abstraction refinement (CEGAR) uses spurious counterexamples to refine overapproximations so as to eliminate provably false alarms. In practice, CEGAR can report false alarms because: (1) the underlying problem CEGAR is trying to solve is undecidable; (2) approximations introduced for optimization purposes may cause CEGAR to be unable to eliminate a false alarm; (3) CEGAR has no termination guarantee - if it runs out of time or memory then the last counterexample generated is provably a false alarm. We report on advances in the SLAM analysis engine, which implements CEGAR for C programs using predicate abstraction, that greatly reduce the false alarm rate. SLAM is used by the Static Driver Verifier (SDV) tool. Compared to the first version of SLAM (SLAM1, shipped in SDV 1.6), the improved version (SLAM2, shipped in SDV 2.0) reduces the percentage of false alarms from 25.7\% to under 4\% for the WDM class of device drivers. For the KMDF class of device drivers, SLAM2 has under 0.05\% false alarms. The variety and the volume of our experiments of SDV with SLAM2, significantly exceed those performed for other CEGAR-based model checkers. These results made it possible for SDV 2.0 to be applied as an automatic and required quality gate for Windows 7 device drivers.},
	urldate = {2018-01-17},
	booktitle = {Proceedings of the 2010 {Conference} on {Formal} {Methods} in {Computer}-{Aided} {Design}},
	publisher = {FMCAD Inc},
	author = {Ball, Thomas and Bounimova, Ella and Kumar, Rahul and Levin, Vladimir},
	year = {2010},
	pages = {35--42},
	file = {Ball et al_2010_SLAM2 - Static Driver Verification with Under 4% False Alarms.pdf:/home/michael/Dropbox/zotero-pdfs/B/Ball et al_2010_SLAM2 - Static Driver Verification with Under 4% False Alarms.pdf:application/pdf}
}

@article{bessey_few_2010,
	title = {A {Few} {Billion} {Lines} of {Code} {Later}: {Using} {Static} {Analysis} to {Find} {Bugs} in the {Real} {World}},
	volume = {53},
	issn = {0001-0782},
	shorttitle = {A {Few} {Billion} {Lines} of {Code} {Later}},
	url = {http://doi.acm.org/10.1145/1646353.1646374},
	doi = {10.1145/1646353.1646374},
	abstract = {How Coverity built a bug-finding tool, and a business, around the unlimited supply of bugs in software systems.},
	number = {2},
	urldate = {2018-01-17},
	journal = {Commun. ACM},
	author = {Bessey, Al and Block, Ken and Chelf, Ben and Chou, Andy and Fulton, Bryan and Hallem, Seth and Henri-Gros, Charles and Kamsky, Asya and McPeak, Scott and Engler, Dawson},
	month = feb,
	year = {2010},
	pages = {66--75},
	file = {Bessey et al_2010_A Few Billion Lines of Code Later - Using Static Analysis to Find Bugs in the.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bessey et al_2010_A Few Billion Lines of Code Later - Using Static Analysis to Find Bugs in the.pdf:application/pdf}
}

@inproceedings{ball_automatically_2001,
	address = {New York, NY, USA},
	series = {{SPIN} '01},
	title = {Automatically {Validating} {Temporal} {Safety} {Properties} of {Interfaces}},
	isbn = {978-3-540-42124-5},
	url = {http://dl.acm.org/citation.cfm?id=380921.380932},
	abstract = {We present a process for validating temporal safety properties of software that uses a well-defined interface. The process requires only that the user state the property of interest. It then automatically creates abstractions of C code using iterative refinement, based on the given property. The process is realized in the SLAM toolkit, which consists of a model checker, predicate abstraction tool and predicate discovery tool. We have applied the SLAM toolkit to a number of Windows NT device drivers to validate critical safety properties such as correct locking behavior. We have found that the process converges on a set of predicates powerful enough to validate properties in just a few iterations.},
	urldate = {2018-01-17},
	booktitle = {Proceedings of the 8th {International} {SPIN} {Workshop} on {Model} {Checking} of {Software}},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Ball, Thomas and Rajamani, Sriram K.},
	year = {2001},
	pages = {103--122},
	file = {Ball_Rajamani_2001_Automatically Validating Temporal Safety Properties of Interfaces.pdf:/home/michael/Dropbox/zotero-pdfs/B/Ball_Rajamani_2001_Automatically Validating Temporal Safety Properties of Interfaces.pdf:application/pdf}
}

@inproceedings{eriksen_your_2013,
	title = {Your server as a function},
	isbn = {978-1-4503-2460-1},
	url = {http://dl.acm.org/citation.cfm?doid=2525528.2525538},
	doi = {10.1145/2525528.2525538},
	language = {en},
	urldate = {2018-01-17},
	publisher = {ACM Press},
	author = {Eriksen, Marius},
	year = {2013},
	pages = {1--7},
	file = {Eriksen_2013_Your server as a function.pdf:/home/michael/Dropbox/zotero-pdfs/E/Eriksen_2013_Your server as a function.pdf:application/pdf}
}

@inproceedings{merillon_devil:_2000,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'00},
	title = {Devil: {An} {IDL} for {Hardware} {Programming}},
	shorttitle = {Devil},
	url = {http://dl.acm.org/citation.cfm?id=1251229.1251231},
	abstract = {To keep up with the frantic pace at which devices come out, drivers need to be quickly developed, debugged and tested. Although a driver is a critical system component, the driver development process has made little (if any) progress. The situation is particularly disastrous when considering the hardware operating code (i.e., the layer interacting with the device). Writing this code often relies on inaccurate or incomplete device documentation and involves assembly-level operations. As a result, hard-ware operating code is tedious to write, prone to errors, and hard to debug and maintain. This paper presents a new approach to developing hardware operating code based on an Interface Definition Language (IDL) for hard-ware functionalities, named Devil. This IDL allows a high-level definition of the communication with a device. A compiler automatically checks the consistency of a Devil definition and generates efficient low-level code. Because the Devil compiler checks safety critical properties, the long-awaited notion of robustness for hardware operating code is made possible. Finally, the wide variety of devices that we have already specified (mouse, sound, DMA, interrupt, Ethernet, video, and IDE disk controllers) demonstrates the expressiveness of the Devil language.},
	urldate = {2018-01-17},
	booktitle = {Proceedings of the 4th {Conference} on {Symposium} on {Operating} {System} {Design} \& {Implementation} - {Volume} 4},
	publisher = {USENIX Association},
	author = {Mérillon, Fabrice and Réveillère, Laurent and Consel, Charles and Marlet, Renaud and Muller, Gilles},
	year = {2000},
	file = {Merillon et al_2000_Devil - An IDL for Hardware Programming.pdf:/home/michael/Dropbox/zotero-pdfs/M/Merillon et al_2000_Devil - An IDL for Hardware Programming.pdf:application/pdf}
}

@inproceedings{ryzhyk_automatic_2009,
	address = {New York, NY, USA},
	series = {{SOSP} '09},
	title = {Automatic {Device} {Driver} {Synthesis} with {Termite}},
	isbn = {978-1-60558-752-3},
	url = {http://doi.acm.org/10.1145/1629575.1629583},
	doi = {10.1145/1629575.1629583},
	abstract = {Faulty device drivers cause significant damage through down time and data loss. The problem can be mitigated by an improved driver development process that guarantees correctness by construction. We achieve this by synthesising drivers automatically from formal specifications of device interfaces, thus reducing the impact of human error on driver reliability and potentially cutting down on development costs. We present a concrete driver synthesis approach and tool called Termite. We discuss the methodology, the technical and practical limitations of driver synthesis, and provide an evaluation of non-trivial drivers for Linux, generated using our tool. We show that the performance of the generated drivers is on par with the equivalent manually developed drivers. Furthermore, we demonstrate that device specifications can be reused across different operating systems by generating a driver for FreeBSD from the same specification as used for Linux.},
	urldate = {2018-01-17},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 22Nd {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Ryzhyk, Leonid and Chubb, Peter and Kuz, Ihor and Le Sueur, Etienne and Heiser, Gernot},
	year = {2009},
	keywords = {device drivers, domain-specific languages, software synthesis, two-player games},
	pages = {73--86},
	file = {Ryzhyk et al_2009_Automatic Device Driver Synthesis with Termite.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ryzhyk et al_2009_Automatic Device Driver Synthesis with Termite.pdf:application/pdf}
}

@misc{heiser_role_2011,
	address = {PLOS},
	title = {The role of language technology in trustworthy operating systems},
	url = {https://ess.cs.tu-dortmund.de/workshops/plos/2011/presentations/heiser.pdf},
	author = {Heiser, Gernot},
	year = {2011},
	file = {Heiser_2011_The role of language technology in trustworthy operating systems.pdf:/home/michael/Dropbox/zotero-pdfs/H/Heiser_2011_The role of language technology in trustworthy operating systems.pdf:application/pdf}
}

@incollection{mcloughlin_imperative_1990,
	series = {Workshops in {Computing}},
	title = {Imperative {Effects} from a {Pure} {Functional} {Language}},
	isbn = {978-3-540-19609-9 978-1-4471-3166-3},
	url = {https://link.springer.com/chapter/10.1007/978-1-4471-3166-3_11},
	abstract = {In most conventional programming languages a programmer has access to a large number of libraries of general and special purpose functions. In particular for performing various kinds of input and output operations. This paper shows a way in which these libraries can be accessed within the framework of a pure functional programming language.Since the original motivation for the work was to be able to perform I/O in a pure way the arguments for our approach will be given from that point of view. Once this is done it is possible to use the same mechanism to call functions from most existing foreign programming languages.An implementation of the functional programming language Elope, see [2] and [11], uses this technique, which has proven succesful in practice.},
	language = {en},
	urldate = {2018-01-17},
	booktitle = {Functional {Programming}},
	publisher = {Springer, London},
	author = {McLoughlin, L. and Hayes, E. S.},
	year = {1990},
	doi = {10.1007/978-1-4471-3166-3_11},
	pages = {157--169}
}

@article{backus_can_1978,
	title = {Can {Programming} {Be} {Liberated} from the {Von} {Neumann} {Style}?: {A} {Functional} {Style} and {Its} {Algebra} of {Programs}},
	volume = {21},
	issn = {0001-0782},
	shorttitle = {Can {Programming} {Be} {Liberated} from the {Von} {Neumann} {Style}?},
	url = {http://doi.acm.org/10.1145/359576.359579},
	doi = {10.1145/359576.359579},
	abstract = {Conventional programming languages are growing ever more enormous, but not stronger. Inherent defects at the most basic level cause them to be both fat and weak: their primitive word-at-a-time style of programming inherited from their common ancestor—the von Neumann computer, their close coupling of semantics to state transitions, their division of programming into a world of expressions and a world of statements, their inability to effectively use powerful combining forms for building new programs from existing ones, and their lack of useful mathematical properties for reasoning about programs.
An alternative functional style of programming is founded on the use of combining forms for creating programs. Functional programs deal with structured data, are often nonrepetitive and nonrecursive, are hierarchically constructed, do not name their arguments, and do not require the complex machinery of procedure declarations to become generally applicable. Combining forms can use high level programs to build still higher level ones in a style not possible in conventional languages.
Associated with the functional style of programming is an algebra of programs whose variables range over programs and whose operations are combining forms. This algebra can be used to transform programs and to solve equations whose “unknowns” are programs in much the same way one transforms equations in high school algebra. These transformations are given by algebraic laws and are carried out in the same language in which programs are written. Combining forms are chosen not only for their programming power but also for the power of their associated algebraic laws. General theorems of the algebra give the detailed behavior and termination conditions for large classes of programs.
 A new class of computing systems uses the functional programming style both in its programming language and in its state transition rules. Unlike von Neumann languages, these systems have semantics loosely coupled to states—only one state transition occurs per major computation.},
	number = {8},
	urldate = {2018-01-17},
	journal = {Commun. ACM},
	author = {Backus, John},
	month = aug,
	year = {1978},
	keywords = {programming languages, functional programming, program correctness, algebra of programs, applicative computing systems, applicative state transition systems, combining forms, functional forms, metacomposition, models of computing systems, program termination, program transformation, von Neumann computers, von Neumann languages},
	pages = {613--641},
	file = {Backus_1978_Can Programming Be Liberated from the Von Neumann Style - - A Functional Style.pdf:/home/michael/Dropbox/zotero-pdfs/B/Backus_1978_Can Programming Be Liberated from the Von Neumann Style - - A Functional Style.pdf:application/pdf}
}

@inproceedings{turner_miranda:_1985,
	address = {New York, NY, USA},
	title = {Miranda: {A} {Non}-strict {Functional} {Language} with {Polymorphic} {Types}},
	shorttitle = {Miranda},
	url = {http://dl.acm.org/citation.cfm?id=5280.5281},
	urldate = {2018-01-17},
	booktitle = {Proc. {Of} a {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Turner, D. A.},
	year = {1985},
	pages = {1--16}
}

@techreport{hudak_expressiveness_1989,
	title = {On the {Expressiveness} of {Purely} {Functional} {I}/{O} {Systems}},
	abstract = {Functional programming languages have traditionally lacked complete, flexible, and yet referentially transparent I/O mechanisms. Previous proposals for I/O have used either the notion of lazy streams or continuations to model interaction with the external world. We discuss and generalize these models and introduce a third, which we call the systems model, to perform I/O. The expressiveness of the styles are compared by means of an example. We then give a series of surprisingly simple translations between the three models, demonstrating that they are not as different as their programming styles suggest, and implying that the styles could be mixed within a single program. The need to express non-deterministic behavior in a functional language is well recognized. So is the problem of doing so without destroying referential transparency. We survey past approaches to this problem, and suggest a solution in the context of the I/O models described. The I/O system of the purely functional lang...},
	author = {Hudak, Paul and Sundaresh, Raman S.},
	year = {1989},
	file = {Hudak_Sundaresh_1989_On the Expressiveness of Purely Functional I-O Systems.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hudak_Sundaresh_1989_On the Expressiveness of Purely Functional I-O Systems.pdf:application/pdf}
}

@inproceedings{williams_sacrificing_1988,
	address = {New York, NY, USA},
	series = {{POPL} '88},
	title = {Sacrificing {Simplicity} for {Convenience}: {Where} {Do} {You} {Draw} the {Line}?},
	isbn = {978-0-89791-252-5},
	shorttitle = {Sacrificing {Simplicity} for {Convenience}},
	url = {http://doi.acm.org/10.1145/73560.73575},
	doi = {10.1145/73560.73575},
	abstract = {The designers of (functional) programming languages are faced with two occasionally conflicting goals: programmer convenience and semantic simplicity. For example, it is convenient to treat I/O operations as primitive “functions” with side effects, but doing so destroys referential transparency.
FL is a functional language that is designed to trade some of the semantic simplicity of a pure language for some of the convenience of a procedural language, by treating I/O operations as primitives with “side effects”, but by using a structuring technique that localizes the scope of those effects. In this way, surprisingly little of the semantic simplicity is lost, as can be seen by comparing the underlying algebraic laws of FL with those of its pure counterpart. FP.
This paper describes that comparison and shows that, in fact, for programs involving I/O, the structures of the algebraic laws of the two languages are identical! It concludes by showing that this technique cannot be extended to allow assignment statements without incurring a massive loss in the expressiveness and simplicity of the underlying algebra.},
	urldate = {2018-01-17},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Williams, J. H. and Wimmers, E. L.},
	year = {1988},
	pages = {169--179},
	file = {Williams_Wimmers_1988_Sacrificing Simplicity for Convenience - Where Do You Draw the Line.pdf:/home/michael/Dropbox/zotero-pdfs/W/Williams_Wimmers_1988_Sacrificing Simplicity for Convenience - Where Do You Draw the Line.pdf:application/pdf}
}

@inproceedings{honda_secure_2000,
	title = {Secure information flow as typed process behaviour},
	volume = {1782},
	booktitle = {{ESOP}},
	publisher = {Springer},
	author = {Honda, Kohei and Vasconcelos, Vasco and Yoshida, Nobuko},
	year = {2000},
	pages = {180--199},
	file = {Honda et al_2000_Secure information flow as typed process behaviour.pdf:/home/michael/Dropbox/zotero-pdfs/H/Honda et al_2000_Secure information flow as typed process behaviour.pdf:application/pdf}
}

@article{igarashi_polymorphic_2017,
	title = {On {Polymorphic} {Gradual} {Typing}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110284},
	doi = {10.1145/3110284},
	abstract = {We study an extension of gradual typingâa method to integrate dynamic typing and static typing smoothly in a single languageâto parametric polymorphism and its theoretical properties, including conservativity of typing and semantics over both statically and dynamically typed languages, type safety, blame-subtyping theorem, and the gradual guaranteeâthe so-called refined criteria, advocated by Siek et al. We develop System FG, which is a gradually typed extension of System F with the dynamic type and a new type consistency relation, and translation to a new polymorphic blame calculus System FC, which is based on previous polymorphic blame calculi by Ahmed et al. The design of System FG and System FC, geared to the criteria, is influenced by the distinction between static and gradual type variables, first observed by Garcia and Cimini. This distinction is also useful to execute statically typed code without incurring additional overhead to manage type names as in the prior calculi. We prove that System FG satisfies most of the criteria: all but the hardest property of the gradual guarantee on semantics. We show that a key conjecture to prove the gradual guarantee leads to the Jack-of-All-Trades property, conjectured as an important property of the polymorphic blame calculus by Ahmed et al.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Igarashi, Yuu and Sekiyama, Taro and Igarashi, Atsushi},
	month = aug,
	year = {2017},
	keywords = {gradual typing, gradual guarantee, parametric polymorphism},
	pages = {40:1--40:29},
	file = {Igarashi et al_2017_On Polymorphic Gradual Typing.pdf:/home/michael/Dropbox/zotero-pdfs/I/Igarashi et al_2017_On Polymorphic Gradual Typing.pdf:application/pdf}
}

@article{st-amour_herbarium_2017,
	title = {Herbarium {Racketensis}: {A} {Stroll} {Through} the {Woods} ({Functional} {Pearl})},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {Herbarium {Racketensis}},
	url = {http://doi.acm.org/10.1145/3110245},
	doi = {10.1145/3110245},
	abstract = {Domain-specific languages are the ultimate abstraction, dixit Paul Hudak. But what abstraction should we use to build such ultimate abstractions? What is sauce for the goose is sauce for the gander: a language, of course!   Racket is the ultimate abstraction-abstraction, a platform for quickly and easily building new ultimate abstractions. This pearl demonstrates Racket's power by taking a leisurely walk through the implementation of a DSL for Lindenmayer systems, the computational model par excellence of theoretical botany.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {St-Amour, Vincent and Feltey, Daniel and Florence, Spencer P. and You, Shu-Hung and Findler, Robert Bruce},
	month = aug,
	year = {2017},
	keywords = {Lindenmayer systems, Racket},
	pages = {1:1--1:15},
	file = {St-Amour et al_2017_Herbarium Racketensis - A Stroll Through the Woods (Functional Pearl).pdf:/home/michael/Dropbox/zotero-pdfs/S/St-Amour et al_2017_Herbarium Racketensis - A Stroll Through the Woods (Functional Pearl).pdf:application/pdf}
}

@article{protzenko_verified_2017,
	title = {Verified {Low}-level {Programming} {Embedded} in {F}*},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110261},
	doi = {10.1145/3110261},
	abstract = {We present Low*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low* is a shallow embedding of a small, sequential, well-behaved subset of C in F*, a dependently- typed variant of ML aimed at program verification. Departing from ML, Low* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model à la CompCert, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low* program is memory safe. In addition, the programmer can make full use of the verification power of F* to write high-level specifications and verify the functional correctness of Low* code using a combination of SMT automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code. We show that our Low* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Protzenko, Jonathan and Zinzindohoué, Jean-Karim and Rastogi, Aseem and Ramananandro, Tahina and Wang, Peng and Zanella-Béguelin, Santiago and Delignat-Lavaud, Antoine and Hriţcu, Cătălin and Bhargavan, Karthikeyan and Fournet, Cédric and Swamy, Nikhil},
	month = aug,
	year = {2017},
	keywords = {Compilers, Functional languages, Semantics, Software verifcation, Source code generation, Type theory, źSoftware and its engineering ź Correctness, źTheory of computation ź Hoare logic},
	pages = {17:1--17:29},
	file = {Protzenko et al_2017_Verified Low-level Programming Embedded in F.pdf:/home/michael/Dropbox/zotero-pdfs/P/Protzenko et al_2017_Verified Low-level Programming Embedded in F.pdf:application/pdf}
}

@article{owens_verifying_2017,
	title = {Verifying {Efficient} {Function} {Calls} in {CakeML}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110262},
	doi = {10.1145/3110262},
	abstract = {We have designed an intermediate language (IL) for the CakeML compiler that supports the verified, efficient compilation of functions and calls. Verified compilation steps include batching of multiple curried arguments, detecting calls to statically known functions, and specialising calls to known functions with no free variables. Finally, we verify the translation to a lower-level IL that only supports closed, first-order functions.   These compilation steps resemble those found in other compilers (especially OCaml). Our contribution here is the design of the semantics of the IL, and the demonstration that our verification techniques over this semantics work well in practice at this scale. The entire development was carried out in the HOL4 theorem prover.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Owens, Scott and Norrish, Michael and Kumar, Ramana and Myreen, Magnus O. and Tan, Yong Kiam},
	month = aug,
	year = {2017},
	keywords = {Compiler verification, ML, verified optimisations},
	pages = {18:1--18:27},
	file = {Owens et al_2017_Verifying Efficient Function Calls in CakeML.pdf:/home/michael/Dropbox/zotero-pdfs/O/Owens et al_2017_Verifying Efficient Function Calls in CakeML.pdf:application/pdf}
}

@article{mainland_better_2017,
	title = {Better {Living} {Through} {Operational} {Semantics}: {An} {Optimizing} {Compiler} for {Radio} {Protocols}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {Better {Living} {Through} {Operational} {Semantics}},
	url = {http://doi.acm.org/10.1145/3110263},
	doi = {10.1145/3110263},
	abstract = {Software-defined radio (SDR) promises to bring the flexibility and rapid iterative workflow of software to radio protocol design. Many factors make achieving this promise challenging, not least of which are the high data rates and timing requirements of real-world radio protocols. The Ziria language and accompanying compiler demonstrated that a high-level language can compete in this demanding space, but extracting reusable lessons from this success is difficult due to Ziria's lack of a formal semantics. Our first contribution is a core language, operational semantics, and type system for Ziria.   The insight we gained through developing this operational semantics led to our second contribution, consisting of two program transformations. The first is fusion, which can eliminate intermediate queues in Ziria programs. Fusion subsumes many one-off optimizations performed by the original Ziria compiler. The second transformation is pipeline coalescing, which reduces execution overhead by batching IO. Pipeline coalescing relies critically on fusion and provides a much simpler story for the original Ziria compiler's "vectorization" transformation. These developments serve as the basis of our third contribution, a new compiler for Ziria that produces significantly faster code than the original compiler. The new compiler leverages our intermediate language to help eliminate unnecessary memory traffic.   As well as providing a firm foundation for the Ziria language, our work on an operational semantics resulted in very real software engineering benefits. These benefits need not be limited to SDR---the core language and accompanying transformations we present are applicable to other domains that require processing streaming data at high speed.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Mainland, Geoffrey},
	month = aug,
	year = {2017},
	keywords = {compilers, operational semantics, domain-specific languages, software-defined radio},
	pages = {19:1--19:26},
	file = {Mainland_2017_Better Living Through Operational Semantics - An Optimizing Compiler for Radio.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mainland_2017_Better Living Through Operational Semantics - An Optimizing Compiler for Radio.pdf:application/pdf}
}

@article{choi_kami:_2017,
	title = {Kami: {A} {Platform} for {High}-level {Parametric} {Hardware} {Specification} and {Its} {Modular} {Verification}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {Kami},
	url = {http://doi.acm.org/10.1145/3110268},
	doi = {10.1145/3110268},
	abstract = {It has become fairly standard in the programming-languages research world to verify functional programs in proof assistants using induction, algebraic simplification, and rewriting. In this paper, we introduce Kami, a Coq library that enables similar expressive and modular reasoning for hardware designs expressed in the style of the Bluespec language. We can specify, implement, and verify realistic designs entirely within Coq, ending with automatic extraction into a pipeline that bottoms out in FPGAs. Our methodology, using labeled transition systems, has been evaluated in a case study verifying an infinite family of multicore systems, with cache-coherent shared memory and pipelined cores implementing (the base integer subset of) the RISC-V instruction set.},
	number = {ICFP},
	urldate = {2018-01-17},
	journal = {Proc. ACM Program. Lang.},
	author = {Choi, Joonwon and Vijayaraghavan, Muralidaran and Sherman, Benjamin and Chlipala, Adam and {Arvind}},
	month = aug,
	year = {2017},
	keywords = {formal verification, hardware, proof assistants},
	pages = {24:1--24:30},
	file = {Choi et al_2017_Kami - A Platform for High-level Parametric Hardware Specification and Its.pdf:/home/michael/Dropbox/zotero-pdfs/C/Choi et al_2017_Kami - A Platform for High-level Parametric Hardware Specification and Its.pdf:application/pdf}
}

@inproceedings{gerakios_dynamic_2011,
	title = {Dynamic deadlock avoidance in systems code using statically inferred effects},
	booktitle = {Proceedings of the 6th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Gerakios, Prodromos and Papaspyrou, Nikolaos and Sagonas, Konstantinos and Vekris, Panagiotis},
	year = {2011},
	pages = {5},
	file = {Gerakios et al_2011_Dynamic deadlock avoidance in systems code using statically inferred effects.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gerakios et al_2011_Dynamic deadlock avoidance in systems code using statically inferred effects.pdf:application/pdf}
}

@inproceedings{bieschke_eliminating_2017,
	title = {Eliminating {Input}-{Based} {Attacks} by {Deriving} {Automated} {Encoders} and {Decoders} from {Context}-{Free} {Grammars}},
	isbn = {978-1-5386-1968-1},
	url = {http://ieeexplore.ieee.org/document/8227294/},
	doi = {10.1109/SPW.2017.32},
	urldate = {2018-01-17},
	publisher = {IEEE},
	author = {Bieschke, Tobias and Hermerschmidt, Lars and Rumpe, Bernhard and Stanchev, Peter},
	month = may,
	year = {2017},
	pages = {93--101},
	file = {Bieschke et al_2017_Eliminating Input-Based Attacks by Deriving Automated Encoders and Decoders.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bieschke et al_2017_Eliminating Input-Based Attacks by Deriving Automated Encoders and Decoders.pdf:application/pdf}
}

@article{barrett_formal_1989,
	title = {Formal methods applied to a floating-point number system},
	volume = {15},
	issn = {0098-5589},
	doi = {10.1109/32.24710},
	abstract = {A formalization of the IEEE standard for binary floating-point arithmetic (ANSI/IEEE Std. 754-1985) is presented in the set-theoretic specification language Z. The formal specification is refined into four sequential components, which unpack the operands, perform the arithmetic, and pack and round the result. This refinement follows proven rules and so demonstrates a mathematically rigorous method of program development. In the course of the proofs, useful internal representations of floating-point numbers are specified. The procedures presented form the basis for the floating-point unit of the Inmos IMS T800 transputer},
	number = {5},
	journal = {IEEE Transactions on Software Engineering},
	author = {Barrett, G.},
	month = may,
	year = {1989},
	keywords = {formal specification, formal methods, Costs, Formal specifications, Algorithm design and analysis, ANSI/IEEE Std. 754-1985, binary floating-point arithmetic, digital arithmetic, Floating-point arithmetic, floating-point number system, floating-point unit, Formal verification, formalization, Helium, IEEE standard, Inmos IMS T800 transputer, internal representations, mathematically rigorous method, Natural languages, operands, pack, Packaging, program development, proven rules, round, sequential components, set-theoretic specification language, specification languages, Specification languages, Testing, unpack, Z},
	pages = {611--621},
	file = {Barrett_1989_Formal methods applied to a floating-point number system.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barrett_1989_Formal methods applied to a floating-point number system.pdf:application/pdf}
}

@book{gries_science_1981,
	edition = {1},
	series = {Monographs in {Computer} {Science}},
	title = {The {Science} of {Programming}},
	isbn = {978-0-387-96480-5},
	url = {//www.springer.com/us/book/9780387964805},
	language = {en},
	urldate = {2018-01-18},
	publisher = {Springer-Verlag New York},
	author = {Gries, David},
	year = {1981},
	note = {DOI: 
10.1007/978-1-4612-5983-1},
	file = {Gries_1981_The Science of Programming.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gries_1981_The Science of Programming.pdf:application/pdf}
}

@book{jones_systematic_1986,
	address = {Englewood Cliffs, NJ},
	title = {Systematic {Software} {Development} using {VDM}},
	url = {http://homepages.cs.ncl.ac.uk/cliff.jones/publications/Jones1990.pdf},
	urldate = {2018-01-18},
	publisher = {Prentice-Hall},
	author = {Jones, Cliff},
	year = {1986},
	file = {Jones_1986_Systematic Software Development using VDM.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_1986_Systematic Software Development using VDM.pdf:application/pdf}
}

@article{hall_seven_1990,
	title = {Seven myths of formal methods},
	volume = {7},
	issn = {0740-7459},
	doi = {10.1109/52.57887},
	abstract = {Seven widely held conceptions about formal methods are challenged. These beliefs are variants of the following: formal methods can guarantee that software is perfect; they work by proving that the programs are correct; only highly critical systems benefit from their use; they involve complex mathematics; they increase the cost of development; they are incomprehensible to clients; and nobody uses them for real projects. The arguments are based on the author's experiences. They address the bounds of formal methods, identify the central role of specifications in the development process, and cover education and training.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Software},
	author = {Hall, A.},
	month = sep,
	year = {1990},
	keywords = {formal specification, formal methods, Costs, complex mathematics, Computer aided software engineering, development process, education, Financial management, Formal specifications, highly critical systems, Instruction sets, Mathematics, Project management, specifications, Terminology, training},
	pages = {11--19},
	file = {Hall_1990_Seven myths of formal methods.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hall_1990_Seven myths of formal methods.pdf:application/pdf}
}

@book{lamport_principles_nodate,
	title = {Principles and {Specifications} of {Concurrent} {Systems}},
	author = {Lamport, Leslie}
}

@article{derrin_secure_2005,
	title = {A {Secure} {Microkernel}},
	journal = {Diss. UNIVERSITY OF NEW SOUTH WALES},
	author = {Derrin, Philip Geoffrey},
	year = {2005},
	file = {Derrin_2005_A Secure Microkernel.pdf:/home/michael/Dropbox/zotero-pdfs/D/Derrin_2005_A Secure Microkernel.pdf:application/pdf}
}

@techreport{ladkin_possibility_1989,
	address = {Berkeley, CA, USA},
	title = {The {Possibility} of an {Executable} {Specification} {Language}},
	url = {http://www.icsi.berkeley.edu/pubs/techreports/tr-89-40},
	abstract = {We consider what it tkes to build an executable specification language for concurrent systems. The key ingredients are executability and very-high-level specification. Many researchers have concluded that one can't have both in any reasonable way. We consider the number of criteria for an executable specification language. We conclude that it is possible to build such a langauge, and thus that executability should be a criterion for evaluating any specification language for concurrent systems.},
	language = {en},
	number = {TR-89-040},
	urldate = {2018-01-19},
	institution = {Inernational Computer Science Institute},
	author = {Ladkin, Peter},
	month = jul,
	year = {1989},
	pages = {10},
	file = {tr-89-40.pdf:/home/michael/Zotero/storage/RAEDT7EY/tr-89-40.pdf:application/pdf}
}

@article{chou_executable_1996,
	title = {An executable specification language for specification understanding in object-oriented specification reuse},
	volume = {38},
	issn = {0950-5849},
	url = {http://www.sciencedirect.com/science/article/pii/0950584995010807},
	doi = {10.1016/0950-5849(95)01080-7},
	abstract = {System analysis time can be reduced through specification reuse which, however, requires specification understanding. This paper presents an object-oriented executable specification language which reduces understanding time through executing specifications. In addition to being executable, the specification language hides as many classes as possible within subsystems, and explicitly specifies relationships between specification components. This facilitates specification modification. Moreover, the language explicitly specifies interface parameters of specification components. This facilitates specification composition.},
	number = {6},
	urldate = {2018-01-19},
	journal = {Information and Software Technology},
	author = {Chou, Shih-Chien and Chen, Jen-Yen and Chung, Chyan-Goei},
	month = jun,
	year = {1996},
	keywords = {Executable specification language, Specification behavior, Specification reuse},
	pages = {419--434},
	file = {Chou et al_1996_An executable specification language for specification understanding in.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chou et al_1996_An executable specification language for specification understanding in.pdf:application/pdf}
}

@inproceedings{yu_model_1999,
	title = {Model checking {TLA}+ specifications},
	volume = {99},
	booktitle = {{CHARME}},
	publisher = {Springer},
	author = {Yu, Yuan and Manolios, Panagiotis and Lamport, Leslie},
	year = {1999},
	pages = {54--66},
	file = {Yu et al_1999_Model checking TLA+ specifications.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yu et al_1999_Model checking TLA+ specifications.pdf:application/pdf}
}

@article{lamport_summary_2000,
	title = {A {Summary} of {TLA}},
	author = {Lamport, Leslie},
	year = {2000},
	file = {Lamport_2000_A Summary of TLA.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lamport_2000_A Summary of TLA.pdf:application/pdf}
}

@techreport{akhiani_tla+_1999,
	title = {{TLA}+ {Verification} of {Cache}-{Coherence} {Protocols}},
	language = {en},
	author = {Akhiani, Homayoon and Doligez, Damien and Harter, Paul and Lamport, Leslie and Tuttle, Mark and Yu, Yuan and Scheid, Joshua},
	month = feb,
	year = {1999},
	pages = {1--22},
	file = {Akhiani et al_1999_TLA+ Verification of Cache-Coherence Protocols.pdf:/home/michael/Dropbox/zotero-pdfs/A/Akhiani et al_1999_TLA+ Verification of Cache-Coherence Protocols.pdf:application/pdf}
}

@techreport{adve_shared_1995,
	title = {Shared {Memory} {Consistency} {Models}: {A} {Tutorial}},
	author = {Adve, Sarita and Gharachorloo, Kourosh},
	month = sep,
	year = {1995},
	file = {Adve_Gharachorloo_1995_Shared Memory Consistency Models - A Tutorial.pdf:/home/michael/Dropbox/zotero-pdfs/A/Adve_Gharachorloo_1995_Shared Memory Consistency Models - A Tutorial.pdf:application/pdf}
}

@incollection{dillig_abstract_2018,
	address = {Cham},
	title = {Abstract {Code} {Injection}},
	volume = {10747},
	isbn = {978-3-319-73720-1 978-3-319-73721-8},
	url = {http://link.springer.com/10.1007/978-3-319-73721-8_6},
	urldate = {2018-01-22},
	booktitle = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer International Publishing},
	author = {Buro, Samuele and Mastroeni, Isabella},
	editor = {Dillig, Isil and Palsberg, Jens},
	year = {2018},
	doi = {10.1007/978-3-319-73721-8_6},
	pages = {116--137},
	file = {Buro_Mastroeni_2018_Abstract Code Injection.pdf:/home/michael/Dropbox/zotero-pdfs/B/Buro_Mastroeni_2018_Abstract Code Injection.pdf:application/pdf}
}

@article{jung_rustbelt:_2017,
	title = {{RustBelt}: securing the foundations of the rust programming language},
	volume = {2},
	issn = {24751421},
	shorttitle = {{RustBelt}},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158154},
	doi = {10.1145/3158154},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
	month = dec,
	year = {2017},
	pages = {1--34},
	file = {Jung et al_2017_RustBelt.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jung et al_2017_RustBelt.pdf:application/pdf}
}

@article{wang_program_2017,
	title = {Program {Synthesis} using {Abstraction} {Refinement}},
	journal = {arXiv preprint arXiv:1710.07740},
	author = {Wang, Xinyu and Dillig, Isil and Singh, Rishabh},
	year = {2017},
	file = {Wang et al_2017_Program Synthesis using Abstraction Refinement.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang et al_2017_Program Synthesis using Abstraction Refinement.pdf:application/pdf}
}

@article{ko_axiomatic_2017,
	title = {An axiomatic basis for bidirectional programming},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158129},
	doi = {10.1145/3158129},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Ko, Hsiang-Shang and Hu, Zhenjiang},
	month = dec,
	year = {2017},
	pages = {1--29},
	file = {Ko_Hu_2017_An axiomatic basis for bidirectional programming.pdf:/home/michael/Dropbox/zotero-pdfs/K/Ko_Hu_2017_An axiomatic basis for bidirectional programming.pdf:application/pdf}
}

@inproceedings{odersky_simplicitly:_nodate,
	title = {Simplicitly: {Foundations} and {Applications} of {Implicit} {Function} {Types}},
	url = {https://infoscience.epfl.ch/record/229878/files/simplicitly_1.pdf?version=2},
	urldate = {2018-01-22},
	author = {Odersky, Martin and Biboudis, Aggelos and Liu, Fengyun and Blanvillain, Olivier and Miller, Heather},
	pages = {29},
	file = {Odersky et al_Simplicitly - Foundations and Applications of Implicit Function Types.pdf:/home/michael/Dropbox/zotero-pdfs/O/Odersky et al_Simplicitly - Foundations and Applications of Implicit Function Types.pdf:application/pdf}
}

@article{mciver_new_2017,
	title = {A {New} {Proof} {Rule} for {Almost}-{Sure} {Termination}},
	url = {http://arxiv.org/abs/1711.03588},
	abstract = {An important question for a probabilistic program is whether the probability mass of all its diverging runs is zero, that is that it terminates "almost surely". Proving that can be hard, and this paper presents a new method for doing so; it is expressed in a program logic, and so applies directly to source code. The programs may contain both probabilistic- and demonic choice, and the probabilistic choices may depend on the current state. As do other researchers, we use variant functions (a.k.a. "super-martingales") that are real-valued and probabilistically might decrease on each loop iteration; but our key innovation is that the amount as well as the probability of the decrease are parametric. We prove the soundness of the new rule, indicate where its applicability goes beyond existing rules, and explain its connection to classical results on denumerable (non-demonic) Markov chains.},
	urldate = {2018-01-22},
	journal = {arXiv:1711.03588 [cs]},
	author = {McIver, Annabelle and Morgan, Carroll and Kaminski, Benjamin Lucien and Katoen, Joost-Pieter},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.03588},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	file = {McIver et al_2017_A New Proof Rule for Almost-Sure Termination.pdf:/home/michael/Dropbox/zotero-pdfs/M/McIver et al_2017_A New Proof Rule for Almost-Sure Termination.pdf:application/pdf}
}

@article{melo_inference_2017,
	title = {Inference of static semantics for incomplete {C} programs},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158117},
	doi = {10.1145/3158117},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Melo, Leandro T. C. and Ribeiro, Rodrigo G. and de Araújo, Marcus R. and Pereira, Fernando Magno Quintão},
	month = dec,
	year = {2017},
	pages = {1--28},
	file = {Melo et al_2017_Inference of static semantics for incomplete C programs.pdf:/home/michael/Dropbox/zotero-pdfs/M/Melo et al_2017_Inference of static semantics for incomplete C programs.pdf:application/pdf}
}

@misc{popl2018_principles_nodate,
	title = {Some {Principles} of {Differentiable} {Programming} {Languages}},
	url = {https://www.youtube.com/watch?v=qhPBfysSYI8},
	urldate = {2018-01-22},
	author = {{POPL2018}}
}

@article{kuncar_safety_2017,
	title = {Safety and conservativity of definitions in {HOL} and {Isabelle}/{HOL}},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158112},
	doi = {10.1145/3158112},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Kunčar, Ondřej and Popescu, Andrei},
	month = dec,
	year = {2017},
	pages = {1--26},
	file = {Kuncar_Popescu_2017_Safety and conservativity of definitions in HOL and Isabelle-HOL.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kuncar_Popescu_2017_Safety and conservativity of definitions in HOL and Isabelle-HOL.pdf:application/pdf}
}

@article{dongol_transactions_2017,
	title = {Transactions in {Relaxed} {Memory} {Architectures}},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158106},
	doi = {10.1145/3158106},
	abstract = {The integration of transactions into hardware relaxed memory architectures is a topic of current research both in industry and academia. In this paper, we provide a general architectural framework for the introduction of transactions into models of relaxed memory in hardware, including the SC, TSO, ARMv8 and PPC models. Our framework incorporates flexible and expressive forms of transaction aborts and execution that have hitherto been in the realm of software transactional memory. In contrast to software transactional memory, we account for the characteristics of relaxed memory as a restricted form of distributed system, without a notion of global time. We prove abstraction theorems to demonstrate that the programmer API matches the intuitions and expectations about transactions.},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proc. ACM Program. Lang.},
	author = {Dongol, Brijesh and Jagadeesan, Radha and Riely, James},
	month = dec,
	year = {2017},
	keywords = {Hardware Transactional Memory, Relaxed Memory Models},
	pages = {18:1--18:29},
	file = {Dongol et al_2017_Transactions in Relaxed Memory Architectures.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dongol et al_2017_Transactions in Relaxed Memory Architectures.pdf:application/pdf}
}

@article{pulte_simplifying_2017,
	title = {Simplifying {ARM} concurrency: multicopy-atomic axiomatic and operational models for {ARMv}8},
	volume = {2},
	issn = {24751421},
	shorttitle = {Simplifying {ARM} concurrency},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158107},
	doi = {10.1145/3158107},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Pulte, Christopher and Flur, Shaked and Deacon, Will and French, Jon and Sarkar, Susmit and Sewell, Peter},
	month = dec,
	year = {2017},
	pages = {1--29},
	file = {Pulte et al_2017_Simplifying ARM concurrency - multicopy-atomic axiomatic and operational models.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pulte et al_2017_Simplifying ARM concurrency - multicopy-atomic axiomatic and operational models.pdf:application/pdf}
}

@article{bernardy_linear_2017,
	title = {Linear {Haskell}: practical linearity in a higher-order polymorphic language},
	volume = {2},
	issn = {24751421},
	shorttitle = {Linear {Haskell}},
	url = {http://arxiv.org/abs/1710.09756},
	doi = {10.1145/3158093},
	abstract = {Linear type systems have a long and storied history, but not a clear path forward to integrate with existing languages such as OCaml or Haskell. In this paper, we study a linear type system designed with two crucial properties in mind: backwards-compatibility and code reuse across linear and non-linear users of a library. Only then can the benefits of linear types permeate conventional functional programming. Rather than bifurcate types into linear and non-linear counterparts, we instead attach linearity to function arrows. Linear functions can receive inputs from linearly-bound values, but can also operate over unrestricted, regular values. To demonstrate the efficacy of our linear type system - both how easy it can be integrated in an existing language implementation and how streamlined it makes it to write programs with linear types - we implemented our type system in GHC, the leading Haskell compiler, and demonstrate two kinds of applications of linear types: mutable data with pure interfaces; and enforcing protocols in I/O-performing functions.},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Bernardy, Jean-Philippe and Boespflug, Mathieu and Newton, Ryan R. and Jones, Simon Peyton and Spiwack, Arnaud},
	month = dec,
	year = {2017},
	note = {arXiv: 1710.09756},
	keywords = {Computer Science - Programming Languages},
	pages = {1--29},
	file = {Bernardy et al_2017_Linear Haskell - practical linearity in a higher-order polymorphic language.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bernardy et al_2017_Linear Haskell - practical linearity in a higher-order polymorphic language.pdf:application/pdf}
}

@article{bach_poulsen_intrinsically-typed_2017,
	title = {Intrinsically-typed {Definitional} {Interpreters} for {Imperative} {Languages}},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158104},
	doi = {10.1145/3158104},
	abstract = {A definitional interpreter defines the semantics of an object language in terms of the (well-known) semantics of a host language, enabling understanding and validation of the semantics through execution. Combining a definitional interpreter with a separate type system requires a separate type safety proof. An alternative approach, at least for pure object languages, is to use a dependently-typed language to encode the object language type system in the definition of the abstract syntax. Using such intrinsically-typed abstract syntax definitions allows the host language type checker to verify automatically that the interpreter satisfies type safety. Does this approach scale to larger and more realistic object languages, and in particular to languages with mutable state and objects?  In this paper, we describe and demonstrate techniques and libraries in Agda that successfully scale up intrinsically-typed definitional interpreters to handle rich object languages with non-trivial binding structures and mutable state. While the resulting interpreters are certainly more complex than the simply-typed λ-calculus interpreter we start with, we claim that they still meet the goals of being concise, comprehensible, and executable, while guaranteeing type safety for more elaborate object languages. We make the following contributions: (1) A dependent-passing style technique for hiding the weakening of indexed values as they propagate through monadic code. (2) An Agda library for programming with scope graphs and frames, which provides a uniform approach to dealing with name binding in intrinsically-typed interpreters. (3) Case studies of intrinsically-typed definitional interpreters for the simply-typed λ-calculus with references (STLC+Ref) and for a large subset of Middleweight Java (MJ).},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proc. ACM Program. Lang.},
	author = {Bach Poulsen, Casper and Rouvoet, Arjen and Tolmach, Andrew and Krebbers, Robbert and Visser, Eelco},
	month = dec,
	year = {2017},
	keywords = {type safety, Java, dependent types, Agda, definitional interpreters, mechanized semantics, scope graphs},
	pages = {16:1--16:34},
	file = {Bach Poulsen et al_2017_Intrinsically-typed Definitional Interpreters for Imperative Languages.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bach Poulsen et al_2017_Intrinsically-typed Definitional Interpreters for Imperative Languages.pdf:application/pdf}
}

@article{campora_migrating_2017,
	title = {Migrating gradual types},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158103},
	doi = {10.1145/3158103},
	language = {en},
	number = {POPL},
	urldate = {2018-01-22},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Campora, John Peter and Chen, Sheng and Erwig, Martin and Walkingshaw, Eric},
	month = dec,
	year = {2017},
	pages = {1--29},
	file = {Campora et al_2017_Migrating gradual types.pdf:/home/michael/Dropbox/zotero-pdfs/C/Campora et al_2017_Migrating gradual types.pdf:application/pdf}
}

@misc{popl2018_milner_nodate,
	title = {Milner {Award} {Lecture}: {The} {Type} {Soundness} {Theorem} {That} {You} {Really} {Want} to {Prove} (and now you can)},
	shorttitle = {Milner {Award} {Lecture}},
	url = {https://www.youtube.com/watch?v=8Xyk_dGcAwk},
	urldate = {2018-01-22},
	author = {{POPL2018}}
}

@inproceedings{dylus_probabilistic_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Probabilistic {Functional} {Logic} {Programming}},
	isbn = {978-3-319-73304-3 978-3-319-73305-0},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-73305-0_1},
	doi = {10.1007/978-3-319-73305-0_1},
	abstract = {This paper presents PFLP, a library for probabilistic programming in the functional logic programming language Curry. It demonstrates how the concepts of a functional logic programming language support the implementation of a library for probabilistic programming. In fact, the paradigms of functional logic and probabilistic programming are closely connected. That is, we can apply techniques from one area to the other and vice versa. We will see that an implementation based on the concepts of functional logic programming can have benefits with respect to performance compared to a standard list-based implementation.},
	language = {en},
	urldate = {2018-01-22},
	booktitle = {Practical {Aspects} of {Declarative} {Languages}},
	publisher = {Springer, Cham},
	author = {Dylus, Sandra and Christiansen, Jan and Teegen, Finn},
	month = jan,
	year = {2018},
	pages = {3--19},
	file = {Dylus et al_2018_Probabilistic Functional Logic Programming.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dylus et al_2018_Probabilistic Functional Logic Programming.pdf:application/pdf}
}

@inproceedings{frumin_finite_2018,
	address = {Los Angeles, CA},
	title = {Finite {Sets} in {Homotopy} {Type} {Theory}},
	isbn = {978-1-4503-5586-5},
	doi = {10.1145/3167085},
	abstract = {We study different formalizations of finite sets in homotopy
type theory to obtain a general definition that exhibits both
the computational facilities and the proof principles expected
from finite sets. We use higher inductive types to define the
type
K(
A
)
of “finite sets over type
A
”
à la
Kuratowski without
assuming that
A
has decidable equality. We show how to
define basic functions and prove basic properties after which
we give two applications of our definition.},
	language = {No Linguistic Content},
	author = {Frumin, Dan and Geuvers, Herman},
	month = jan,
	year = {2018},
	note = {OCLC: 7279776468},
	file = {Frumin_Geuvers_2018_Finite Sets in Homotopy Type Theory.pdf:/home/michael/Dropbox/zotero-pdfs/F/Frumin_Geuvers_2018_Finite Sets in Homotopy Type Theory.pdf:application/pdf}
}

@misc{noauthor_simple_nodate,
	title = {The {Simple} {Essence} of {Automatic} {Differentiation} ({Invited} {Talk}) - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/pepm-2018-the-simple-essence-of-automatic-differentiation-invited-talk-},
	urldate = {2018-01-22}
}

@inproceedings{amani_towards_2018,
	address = {Los Angeles, CA},
	title = {Towards {Verifying} {Ethereum} {Smart} {Contract} {Bytecode} in {Isabelle}/{HOL}},
	isbn = {78-1-4503-5586-5},
	url = {http://www.ssrg.nicta.com.au/publications/csiro_full_text//Amani_BSB_18.pdf},
	doi = {10.1145/3167084},
	urldate = {2018-01-22},
	author = {Amani, Sidney and Bortin, Maksym and Bege, Myriam and Staples, Mark},
	month = jan,
	year = {2018},
	file = {Amani et al_2018_Towards Verifying Ethereum Smart Contract Bytecode in Isabelle-HOL.pdf:/home/michael/Dropbox/zotero-pdfs/A/Amani et al_2018_Towards Verifying Ethereum Smart Contract Bytecode in Isabelle-HOL.pdf:application/pdf}
}

@article{watt_mechanising_nodate,
	title = {Mechanising and {Verifying} the {WebAssembly} {Specification}},
	author = {Watt, Conrad},
	file = {Watt_Mechanising and Verifying the WebAssembly Specification.pdf:/home/michael/Dropbox/zotero-pdfs/W/Watt_Mechanising and Verifying the WebAssembly Specification.pdf:application/pdf}
}

@inproceedings{dahiya_automatic_2018,
	title = {Automatic {Verification} of {Intermittent} {Systems}},
	booktitle = {International {Conference} on {Verification}, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer},
	author = {Dahiya, Manjeet and Bansal, Sorav},
	year = {2018},
	pages = {161--182},
	file = {Dahiya_Bansal_2018_Automatic Verification of Intermittent Systems.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dahiya_Bansal_2018_Automatic Verification of Intermittent Systems.pdf:application/pdf}
}

@inproceedings{vazou_refinement_2014,
	title = {Refinement types for {Haskell}},
	volume = {49},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit and Vytiniotis, Dimitrios and Peyton-Jones, Simon},
	year = {2014},
	pages = {269--282},
	file = {Vazou et al_2014_Refinement types for Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/V/Vazou et al_2014_Refinement types for Haskell.pdf:application/pdf}
}

@inproceedings{cheriton_distributed_1983,
	address = {New York, NY, USA},
	series = {{SOSP} '83},
	title = {The {Distributed} {V} {Kernel} and {Its} {Performance} for {Diskless} {Workstations}},
	isbn = {978-0-89791-115-3},
	url = {http://doi.acm.org/10.1145/800217.806621},
	doi = {10.1145/800217.806621},
	abstract = {The distributed V kernel is a message-oriented kernel that provides uniform local and network interprocess communication. It is primarily being used in an environment of diskless workstations connected by a high-speed local network to a set of file servers. We describe a performance evaluation of the kernel, with particular emphasis on the cost of network file access. Our results show that over a local network: 1. Diskless workstations can access remote files with minimal performance penalty. 2. The V message facility can be used to access remote files at comparable cost to any well-tuned specialized file access protocol. We conclude that it is feasible to build a distributed system with all network communication using the V message facility even when most of the network nodes have no secondary storage.},
	urldate = {2018-01-22},
	booktitle = {Proceedings of the {Ninth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Cheriton, David R. and Zwaenepoel, Willy},
	year = {1983},
	pages = {129--140},
	file = {Cheriton_Zwaenepoel_1983_The Distributed V Kernel and Its Performance for Diskless Workstations.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cheriton_Zwaenepoel_1983_The Distributed V Kernel and Its Performance for Diskless Workstations.pdf:application/pdf}
}

@inproceedings{flatt_programming_1999,
	address = {New York, NY, USA},
	series = {{ICFP} '99},
	title = {Programming {Languages} {As} {Operating} {Systems} (or {Revenge} of the {Son} of the {Lisp} {Machine})},
	isbn = {978-1-58113-111-6},
	url = {http://doi.acm.org/10.1145/317636.317793},
	doi = {10.1145/317636.317793},
	abstract = {The MrEd virtual machine serves both as the implementation platform for the DrScheme programming environment, and as the underlying Scheme engine for executing expressions and programs entered into DrScheme's read-eval-print loop. We describe the key elements of the MrEd virtual machine for building a programming environment, and we step through the implementation of a miniature version of DrScheme in MrEd. More generally, we show how MrEd defines a high-level operating system for graphical programs.},
	urldate = {2018-01-22},
	booktitle = {Proceedings of the {Fourth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Flatt, Matthew and Findler, Robert Bruce and Krishnamurthi, Shriram and Felleisen, Matthias},
	year = {1999},
	pages = {138--147},
	file = {Flatt et al_1999_Programming Languages As Operating Systems (or Revenge of the Son of the Lisp.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flatt et al_1999_Programming Languages As Operating Systems (or Revenge of the Son of the Lisp.pdf:application/pdf}
}

@article{flatt_kill-safe_2004,
	title = {Kill-safe synchronization abstractions},
	volume = {39},
	number = {6},
	journal = {ACM SIGPLAN Notices},
	author = {Flatt, Matthew and Findler, Robert Bruce},
	year = {2004},
	pages = {47--58},
	file = {pldi04-ff.pdf:/home/michael/Zotero/storage/TU68PBM8/pldi04-ff.pdf:application/pdf}
}

@inproceedings{flatt_adding_2007,
	title = {Adding delimited and composable control to a production programming environment},
	volume = {42},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Flatt, Matthew and Yu, Gang and Findler, Robert Bruce and Felleisen, Matthias},
	year = {2007},
	pages = {165--176},
	file = {icfp07-fyff.pdf:/home/michael/Zotero/storage/UJW2FDWV/icfp07-fyff.pdf:application/pdf}
}

@inproceedings{wick_memory_2004,
	title = {Memory accounting without partitions},
	booktitle = {Proceedings of the 4th international symposium on {Memory} management},
	publisher = {ACM},
	author = {Wick, Adam and Flatt, Matthew},
	year = {2004},
	pages = {120--130},
	file = {ismm04-wf.pdf:/home/michael/Zotero/storage/EYMHZMSH/ismm04-wf.pdf:application/pdf}
}

@incollection{dillig_gradual_2018,
	address = {Cham},
	title = {Gradual {Program} {Verification}},
	volume = {10747},
	isbn = {978-3-319-73720-1 978-3-319-73721-8},
	url = {http://link.springer.com/10.1007/978-3-319-73721-8_2},
	urldate = {2018-01-22},
	booktitle = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer International Publishing},
	author = {Bader, Johannes and Aldrich, Jonathan and Tanter, Éric},
	editor = {Dillig, Isil and Palsberg, Jens},
	year = {2018},
	doi = {10.1007/978-3-319-73721-8_2},
	pages = {25--46},
	file = {Bader et al_2018_Gradual Program Verification.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bader et al_2018_Gradual Program Verification.pdf:application/pdf}
}

@misc{pfenning_message-passing_2018,
	address = {Los Angeles, CA},
	title = {Message-{Passing} {Concurency} {Substructural} {Logics}},
	url = {http://www.cs.cmu.edu/~fp/talks/popl18-talk.pdf},
	urldate = {2018-01-22},
	author = {Pfenning, Frank},
	month = jan,
	year = {2018},
	file = {Pfenning_2018_Message-Passing Concurency Substructural Logics.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_2018_Message-Passing Concurency Substructural Logics.pdf:application/pdf}
}

@article{chatterjee_optimal_2017,
	title = {Optimal {Dyck} {Reachability} for {Data}-dependence and {Alias} {Analysis}},
	volume = {2},
	number = {POPL},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Chatterjee, Krishnendu and Choudhary, Bhavya and Pavlogiannis, Andreas},
	year = {2017},
	pages = {30},
	file = {Chatterjee et al_2017_Optimal Dyck Reachability for Data-dependence and Alias Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chatterjee et al_2017_Optimal Dyck Reachability for Data-dependence and Alias Analysis.pdf:application/pdf}
}

@misc{noauthor_recursive_nodate,
	title = {Recursive {Programs} in {Normal} {Form} ({Short} {Paper}) - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/pepm-2018-recursive-programs-in-normal-form-short-paper-},
	urldate = {2018-01-22}
}

@article{hagiya_meta-circular_1989,
	title = {Meta-circular interpreter for a strongly typed language},
	volume = {8},
	issn = {0747-7171},
	url = {http://www.sciencedirect.com/science/article/pii/S0747717189800665},
	doi = {10.1016/S0747-7171(89)80066-5},
	abstract = {A functional language is introduced, whose type system is defined by its meta-circular interpreter. The functional language is an extension of λ-calculus augmented with the rule for conditional terms that allows the condition of a conditional term to be used for reducing its branches. This makes it possible to deduce the well-typing of terms with dependent types including the meta-circular interpreter. In the type system built by the interpreter, types are represented by ordinary terms, which reflects the recent object-oriented programming languages, in which classes are manipulated as ordinary objects. The paper first discusses the untyped system of the functional language and its consistency, then develops the representation of types and the representation of terms, and define a meta-circular interpreter, by which the well-typing of the language is defined and also discusses the extensibility of the interpreter and the type system.},
	number = {6},
	urldate = {2018-01-23},
	journal = {Journal of Symbolic Computation},
	author = {Hagiya, Masami},
	month = dec,
	year = {1989},
	keywords = {TO-READ},
	pages = {651--680},
	file = {Hagiya_1989_Meta-circular interpreter for a strongly typed language.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hagiya_1989_Meta-circular interpreter for a strongly typed language.pdf:application/pdf}
}

@inproceedings{carette_symbolic_2005-1,
	title = {Symbolic {Interpretation} of {Legacy} {Assembly} {Language}},
	isbn = {978-0-7695-2474-0},
	url = {http://ieeexplore.ieee.org/document/1566143/},
	doi = {10.1109/WCRE.2005.31},
	urldate = {2018-01-23},
	publisher = {IEEE},
	author = {Carette, J. and Chowdhury, P.K.},
	year = {2005},
	pages = {23--32},
	file = {CARETTE-CHOWHURY_symbolic-interpretation-of-legacy-assembly-language_2005_wcre.pdf:/home/michael/Zotero/storage/G9NWURLJ/CARETTE-CHOWHURY_symbolic-interpretation-of-legacy-assembly-language_2005_wcre.pdf:application/pdf}
}

@article{blanchet_introduction_2002,
	title = {Introduction to abstract interpretation},
	journal = {lecture script},
	author = {Blanchet, Bruno},
	year = {2002},
	file = {blanchet_2002_introduction-to-abstract-interpretation.pdf:/home/michael/Zotero/storage/262R7VQV/blanchet_2002_introduction-to-abstract-interpretation.pdf:application/pdf}
}

@inproceedings{blanchet_static_2003,
	title = {A static analyzer for large safety-critical software},
	volume = {38},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Blanchet, Bruno and Cousot, Patrick and Cousot, Radhia and Feret, Jérome and Mauborgne, Laurent and Miné, Antoine and Monniaux, David and Rival, Xavier},
	year = {2003},
	pages = {196--207},
	file = {blanchet-cousot-mine_a-static-analyzer-for-large-safety-critical-software_2003_PLDI.pdf:/home/michael/Zotero/storage/Q8RGPVRJ/blanchet-cousot-mine_a-static-analyzer-for-large-safety-critical-software_2003_PLDI.pdf:application/pdf}
}

@incollection{blanchet_design_2002,
	title = {Design and implementation of a special-purpose static program analyzer for safety-critical real-time embedded software},
	booktitle = {The {Essence} of {Computation}},
	publisher = {Springer},
	author = {Blanchet, Bruno and Cousot, Patrick and Cousot, Radhia and Feret, Jérôme and Mauborgne, Laurent and Miné, Antoine and Monniaux, David and Rival, Xavier},
	year = {2002},
	pages = {85--108},
	file = {blanchet-cousot-mine_design-and-impl-of-special-purpose-static-program-analyzer-for-safety-embedded_2002_ECCAT.pdf:/home/michael/Zotero/storage/NFEL38B6/blanchet-cousot-mine_design-and-impl-of-special-purpose-static-program-analyzer-for-safety-embedded_2002_ECCAT.pdf:application/pdf}
}

@inproceedings{cortesi_widening_2008,
	title = {Widening operators for abstract interpretation},
	booktitle = {Software {Engineering} and {Formal} {Methods}, 2008. {SEFM}'08. {Sixth} {IEEE} {International} {Conference} on},
	publisher = {IEEE},
	author = {Cortesi, Agostino},
	year = {2008},
	pages = {31--40},
	file = {cortesi_widening-operators-for-abstract-interpretation.pdf:/home/michael/Zotero/storage/DQ5L88WE/cortesi_widening-operators-for-abstract-interpretation.pdf:application/pdf}
}

@article{cousot_abstract_1992,
	title = {Abstract interpretation frameworks},
	volume = {2},
	number = {4},
	journal = {Journal of logic and computation},
	author = {Cousot, Patrick and Cousot, Radhia},
	year = {1992},
	pages = {511--547},
	file = {cousot_1992_abstract-interpretation-frameworks_j-log-comp.pdf:/home/michael/Zotero/storage/NWHDFZ7W/cousot_1992_abstract-interpretation-frameworks_j-log-comp.pdf:application/pdf}
}

@article{cousot_partial_2000,
	title = {Partial completeness of abstract fixpoint checking},
	journal = {Abstraction, Reformulation, and Approximation},
	author = {Cousot, Patrick},
	year = {2000},
	pages = {1--25},
	file = {cousot_partial-completeness-of-abstract-fixpoint-checking_2000_SARA.pdf:/home/michael/Zotero/storage/TJGP5M83/cousot_partial-completeness-of-abstract-fixpoint-checking_2000_SARA.pdf:application/pdf}
}

@inproceedings{das_esp:_2002,
	title = {{ESP}: {Path}-sensitive program verification in polynomial time},
	volume = {37},
	shorttitle = {{ESP}},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Das, Manuvir and Lerner, Sorin and Seigle, Mark},
	year = {2002},
	pages = {57--68},
	file = {das_2009_pldi_esp-path-sensitive-program-verification-in-polynomial-time.pdf:/home/michael/Zotero/storage/4HFYI7L3/das_2009_pldi_esp-path-sensitive-program-verification-in-polynomial-time.pdf:application/pdf}
}

@article{granger_static_1989,
	title = {Static analysis of arithmetical congruences},
	volume = {30},
	issn = {0020-7160, 1029-0265},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00207168908803778},
	doi = {10.1080/00207168908803778},
	language = {en},
	number = {3-4},
	urldate = {2018-01-23},
	journal = {International Journal of Computer Mathematics},
	author = {Granger, Philippe},
	month = jan,
	year = {1989},
	pages = {165--190},
	file = {granger_static-analysis-of-arithmetical-congruences_1989_ijcm.pdf:/home/michael/Zotero/storage/JQ7HIAQF/granger_static-analysis-of-arithmetical-congruences_1989_ijcm.pdf:application/pdf}
}

@article{hardekopf_tunable_nodate,
	title = {Tunable {Control}-{Flow} {Sensitivity} for {Abstract} {Interpretation}},
	author = {Hardekopf, Ben and Churchill, Berkeley and Kashyap, Vineeth and Wiedermann, Ben},
	file = {hardekopf_2012_tunable-control-flow-sensitivity-for-abstract-interpretation.pdf:/home/michael/Zotero/storage/3FX38M8T/hardekopf_2012_tunable-control-flow-sensitivity-for-abstract-interpretation.pdf:application/pdf}
}

@book{abrial_b-book:_nodate,
	address = {Cambridge},
	title = {The {B}-book: assigning programs to meanings},
	isbn = {978-0-521-02175-3},
	shorttitle = {The {B}-book},
	publisher = {Cambridge University Press},
	author = {Abrial, Jean-Raymond},
	keywords = {B method (Computer science)},
	file = {henry-monniaux-moy_PAGAI-a-path-sensitive-static-analyzer_2012.pdf:/home/michael/Zotero/storage/ZYPK5ANF/henry-monniaux-moy_PAGAI-a-path-sensitive-static-analyzer_2012.pdf:application/pdf}
}

@inproceedings{van_horn_abstracting_2010,
	title = {Abstracting abstract machines},
	volume = {45},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Van Horn, David and Might, Matthew},
	year = {2010},
	pages = {51--62},
	file = {HORN-MIGHT_2010_abstracting-abstract-machines_ICFP.pdf:/home/michael/Zotero/storage/356HEMT2/HORN-MIGHT_2010_abstracting-abstract-machines_ICFP.pdf:application/pdf;vanhorn-might_2010_icfp_abstracting-abstract-machines.pdf:/home/michael/Zotero/storage/STZJ3NB2/vanhorn-might_2010_icfp_abstracting-abstract-machines.pdf:application/pdf}
}

@article{karr_affine_1976,
	title = {Affine relationships among variables of a program},
	volume = {6},
	number = {2},
	journal = {Acta Informatica},
	author = {Karr, Michael},
	year = {1976},
	pages = {133--151},
	file = {karr_affine-relationships-among-variables-of-a-program_1974_acta-informatica.pdf:/home/michael/Zotero/storage/BHJ2IHMJ/karr_affine-relationships-among-variables-of-a-program_1974_acta-informatica.pdf:application/pdf}
}

@article{lim_citation_2012,
	title = {Citation {TR}1775 {Date} {Oct} 02, 2012},
	author = {Lim, Junghee and Reps, Thomas},
	year = {2012},
	file = {LIM-REPS_tls-a-system-for-generating-abstract-interpreters-and-its-application-to-machine-code-analysis_2013_toplas.pdf:/home/michael/Zotero/storage/DA4TYBER/LIM-REPS_tls-a-system-for-generating-abstract-interpreters-and-its-application-to-machine-code-analysis_2013_toplas.pdf:application/pdf}
}

@incollection{mine_new_2001,
	title = {A new numerical abstract domain based on difference-bound matrices},
	booktitle = {Programs as {Data} {Objects}},
	publisher = {Springer},
	author = {Miné, Antoine},
	year = {2001},
	pages = {155--172},
	file = {mine_a-new-numerical-abstract-domain-based-on-difference-bound-matrices_2001_PADO.pdf:/home/michael/Zotero/storage/B5HACNMN/mine_a-new-numerical-abstract-domain-based-on-difference-bound-matrices_2001_PADO.pdf:application/pdf}
}

@article{mine_octagon_2006,
	title = {The octagon abstract domain},
	volume = {19},
	number = {1},
	journal = {Higher-order and symbolic computation},
	author = {Miné, Antoine},
	year = {2006},
	pages = {31--100},
	file = {mine_octagon-abstract-domain_2006.pdf:/home/michael/Zotero/storage/8H2RYVS9/mine_octagon-abstract-domain_2006.pdf:application/pdf}
}

@inproceedings{mine_relational_2004,
	title = {Relational abstract domains for the detection of floating-point run-time errors},
	volume = {4},
	booktitle = {{ESOP}},
	publisher = {Springer},
	author = {Miné, Antoine},
	year = {2004},
	pages = {3--17},
	file = {mine_relational-abstract-domains-for-the-detection-of-floating-point-run-time-errors_2005.pdf:/home/michael/Zotero/storage/2FYRJKWJ/mine_relational-abstract-domains-for-the-detection-of-floating-point-run-time-errors_2005.pdf:application/pdf}
}

@article{salcianu_notes_2001,
	title = {Notes on {Abstract} {Interpretation}},
	journal = {Unpublished manuscript},
	author = {Salcianu, Alexandru},
	year = {2001},
	file = {salcianu_2001_notes-on-abstract-interpretation.pdf:/home/michael/Zotero/storage/K9KUYVA3/salcianu_2001_notes-on-abstract-interpretation.pdf:application/pdf}
}

@phdthesis{shivers_control-flow_1991,
	type = {{PhD} {Thesis}},
	title = {Control-flow analysis of higher-order languages},
	school = {PhD thesis, Carnegie Mellon University},
	author = {Shivers, Olin},
	year = {1991},
	file = {SHIVERS_1991_control-flow-analysis-of-higher-order-languages-or-turing-lambda.pdf:/home/michael/Zotero/storage/G4B82GVE/SHIVERS_1991_control-flow-analysis-of-higher-order-languages-or-turing-lambda.pdf:application/pdf}
}

@inproceedings{yovine_model_1996,
	title = {Model checking timed automata},
	booktitle = {School organized by the {European} {Educational} {Forum}},
	publisher = {Springer},
	author = {Yovine, Sergio},
	year = {1996},
	pages = {114--152},
	file = {yovine_model-checking-timed-automate_1998_LNCS.pdf:/home/michael/Zotero/storage/BZ5ZHUUK/yovine_model-checking-timed-automate_1998_LNCS.pdf:application/pdf}
}

@inproceedings{liang_hash-flow_2012,
	address = {Beijing, China},
	title = {Hash-{Flow} {Taint} {Analysis} of {Higher}-{Order} {Programs}},
	language = {English},
	author = {Liang, Shuying and Might, Matthew},
	year = {2012},
	note = {OCLC: 881350183},
	file = {Liang_Might_2012_Hash-Flow Taint Analysis of Higher-Order Programs.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liang_Might_2012_Hash-Flow Taint Analysis of Higher-Order Programs.pdf:application/pdf}
}

@inproceedings{riecke_complete_1990,
	title = {A complete and decidable proof system for call-by-value equalities},
	booktitle = {International {Colloquium} on {Automata}, {Languages}, and {Programming}},
	publisher = {Springer},
	author = {Riecke, Jon G.},
	year = {1990},
	pages = {20--31},
	file = {Riecke_1990_A complete and decidable proof system for call-by-value equalities.pdf:/home/michael/Dropbox/zotero-pdfs/R/Riecke_1990_A complete and decidable proof system for call-by-value equalities.pdf:application/pdf}
}

@article{pitts_relational_1995,
	title = {Relational {Properties} of {Domains}},
	journal = {Information and Computation},
	author = {Pitts, Andrew},
	month = jan,
	year = {1995},
	file = {Pitts_1995_Relational Properties of Domains.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pitts_1995_Relational Properties of Domains.pdf:application/pdf}
}

@article{volpano_type-based_1997,
	title = {A type-based approach to program security},
	journal = {TAPSOFT'97: Theory and Practice of Software Development},
	author = {Volpano, Dennis and Smith, Geoffrey},
	year = {1997},
	pages = {607--621},
	file = {[63]_VOLPANO-SMITH_a-type-based-approach-to-program-security_1997_lncs-tapsoft.pdf:/home/michael/Zotero/storage/7F5J9727/[63]_VOLPANO-SMITH_a-type-based-approach-to-program-security_1997_lncs-tapsoft.pdf:application/pdf}
}

@inproceedings{goguen_unwinding_1984,
	title = {Unwinding and inference control},
	booktitle = {Security and {Privacy}, 1984 {IEEE} {Symposium} on},
	publisher = {IEEE},
	author = {Goguen, Joseph A. and Meseguer, José},
	year = {1984},
	pages = {75--75},
	file = {[48]_GOGUEN-MESEGUER_unwinding-and-inference-control_1984_issp.pdf:/home/michael/Zotero/storage/X4QNH35Y/[48]_GOGUEN-MESEGUER_unwinding-and-inference-control_1984_issp.pdf:application/pdf}
}

@inproceedings{wahbe_efficient_1994,
	title = {Efficient software-based fault isolation},
	volume = {27},
	booktitle = {{ACM} {SIGOPS} {Operating} {Systems} {Review}},
	publisher = {ACM},
	author = {Wahbe, Robert and Lucco, Steven and Anderson, Thomas E. and Graham, Susan L.},
	year = {1994},
	pages = {203--216},
	file = {Wahbe et al_1994_Efficient software-based fault isolation.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wahbe et al_1994_Efficient software-based fault isolation.pdf:application/pdf}
}

@inproceedings{banerjee_secure_2002,
	title = {Secure {Information} {Flow} and {Pointer} {Confinement} in a {Java}-like {Language}.},
	volume = {2},
	booktitle = {{CSFW}},
	author = {Banerjee, Anindya and Naumann, David A.},
	year = {2002},
	pages = {253},
	file = {[13]_BANERJEE-NAUMANN_secure-information-flow-and-pointer-confinement-in-a-java-like-language_2002_icsfw.pdf:/home/michael/Zotero/storage/QZW44YVA/[13]_BANERJEE-NAUMANN_secure-information-flow-and-pointer-confinement-in-a-java-like-language_2002_icsfw.pdf:application/pdf}
}

@article{zdancewic_secure_2001,
	title = {Secure information flow and {CPS}},
	volume = {2028},
	journal = {Lecture Notes in Computer Science},
	author = {Zdancewic, Steve and Myers, Andrew C.},
	year = {2001},
	pages = {46--61},
	file = {[12]_ZDANCEWIC-MYERS_secure-information-flow-and-cps_2001_esp.pdf:/home/michael/Zotero/storage/T77N83Y9/[12]_ZDANCEWIC-MYERS_secure-information-flow-and-cps_2001_esp.pdf:application/pdf}
}

@book{partridge_innovations_1988,
	address = {Norwood, MA},
	series = {The {Artech} {House} telecommunication library},
	title = {Innovations in internetworking},
	isbn = {978-0-89006-337-8},
	publisher = {Artech House},
	editor = {Partridge, Craig},
	year = {1988},
	keywords = {Computer networks, Internetworking (Telecommunication)},
	file = {[1]_SALTZER-REED-CLARK_end-to-end-arguments-in-system-design_1984_acmtcs.pdf:/home/michael/Zotero/storage/3FGEK7VQ/[1]_SALTZER-REED-CLARK_end-to-end-arguments-in-system-design_1984_acmtcs.pdf:application/pdf}
}

@inproceedings{heintze_slam_1998,
	title = {The {SLam} calculus: programming with secrecy and integrity},
	shorttitle = {The {SLam} calculus},
	booktitle = {Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages},
	publisher = {ACM},
	author = {Heintze, Nevin and Riecke, Jon G.},
	year = {1998},
	pages = {365--377},
	file = {HEINTZE-RIECKE_the-SLam-calculus-programming-with-secrecy-and-integrity_popl_1998.pdf:/home/michael/Zotero/storage/KGKZ7DE6/HEINTZE-RIECKE_the-SLam-calculus-programming-with-secrecy-and-integrity_popl_1998.pdf:application/pdf}
}

@inproceedings{hammond_towards_2006,
	title = {Towards formally verifiable {WCET} analysis for a functional programming language},
	volume = {4},
	booktitle = {{OASIcs}-{OpenAccess} {Series} in {Informatics}},
	publisher = {Schloss Dagstuhl-Leibniz-Zentrum für Informatik},
	author = {Hammond, Kevin and Ferdinand, Christian and Heckmann, Reinhold and Dyckhoff, Roy and Hofman, Martin and Jost, Steffen and Loidl, Hans-Wolfgang and Michaelson, Greg and Pointon, Robert and Scaife, Norman},
	year = {2006},
	file = {HAMMOND-FERDINAND-HECKMANN_towards-formally-verifiable-wcet-analysis-for-a-functional-programming-language_2006_ecrts.pdf:/home/michael/Zotero/storage/77M9YZ29/HAMMOND-FERDINAND-HECKMANN_towards-formally-verifiable-wcet-analysis-for-a-functional-programming-language_2006_ecrts.pdf:application/pdf}
}

@inproceedings{giacobazzi_proving_2004,
	title = {Proving abstract non-interference},
	booktitle = {International {Workshop} on {Computer} {Science} {Logic}},
	publisher = {Springer},
	author = {Giacobazzi, Roberto and Mastroeni, Isabella},
	year = {2004},
	pages = {280--294},
	file = {GIACOBAZZI-MASTROENI_proving-abstract-non-interference.pdf:/home/michael/Zotero/storage/W46GM657/GIACOBAZZI-MASTROENI_proving-abstract-non-interference.pdf:application/pdf}
}

@inproceedings{besson_certified_2009,
	title = {Certified {Static} {Analysis} by {Abstract} {Interpretation}.},
	volume = {5705},
	booktitle = {{FOSAD}},
	publisher = {Springer},
	author = {Besson, Frédéric and Cachera, David and Jensen, Thomas P. and Pichardie, David},
	year = {2009},
	pages = {223--257},
	file = {BESSON-CACHERA-JENSEN_certified-static-analysis- by-abstract-interpretation.pdf:/home/michael/Zotero/storage/5DEZHZ47/BESSON-CACHERA-JENSEN_certified-static-analysis- by-abstract-interpretation.pdf:application/pdf}
}

@inproceedings{austin_functional_2012,
	title = {A {Functional} {View} of {Imperative} {Information} {Flow}.},
	booktitle = {{APLAS}},
	publisher = {Springer},
	author = {Austin, Thomas H. and Flanagan, Cormac and Abadi, Martín},
	year = {2012},
	pages = {34--49},
	file = {AUSTIN-FLANAGAN-ABADI_a-funtional-view-of-imperative-information-flow_2012_asplas.pdf:/home/michael/Zotero/storage/4DEGUPSJ/AUSTIN-FLANAGAN-ABADI_a-funtional-view-of-imperative-information-flow_2012_asplas.pdf:application/pdf}
}

@book{blazy_static_2015,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Static {Analysis}},
	volume = {9291},
	isbn = {978-3-662-48287-2 978-3-662-48288-9},
	url = {http://link.springer.com/10.1007/978-3-662-48288-9},
	urldate = {2018-01-24},
	publisher = {Springer Berlin Heidelberg},
	editor = {Blazy, Sandrine and Jensen, Thomas},
	year = {2015},
	doi = {10.1007/978-3-662-48288-9},
	file = {ALDOUS-MIGHT_static-analysis-of-non-interference-in-expressive-low-level-languages_2015_springer-cs.pdf:/home/michael/Zotero/storage/RMI29HJD/ALDOUS-MIGHT_static-analysis-of-non-interference-in-expressive-low-level-languages_2015_springer-cs.pdf:application/pdf}
}

@inproceedings{li_encoding_2006,
	title = {Encoding information flow in {Haskell}},
	booktitle = {Computer {Security} {Foundations} {Workshop}, 2006. 19th {IEEE}},
	publisher = {IEEE},
	author = {Li, Peng and Zdancewic, Steve},
	year = {2006},
	pages = {12--pp},
	file = {[1]_LI-ZDANCEWIC_encoding-information-flow-in-haskell_2006_csfw.pdf:/home/michael/Zotero/storage/54PDVYUL/[1]_LI-ZDANCEWIC_encoding-information-flow-in-haskell_2006_csfw.pdf:application/pdf}
}

@inproceedings{abadi_core_1999,
	title = {A core calculus of dependency},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages},
	publisher = {ACM},
	author = {Abadi, Martín and Banerjee, Anindya and Heintze, Nevin and Riecke, Jon G.},
	year = {1999},
	pages = {147--160},
	file = {[0]_ABADI-BANERJEE-HEINTZE-RIECKE_a-core-calculus-of-dependency_1999_popl.pdf:/home/michael/Zotero/storage/I2C5BPWS/[0]_ABADI-BANERJEE-HEINTZE-RIECKE_a-core-calculus-of-dependency_1999_popl.pdf:application/pdf}
}

@incollection{zheng_dynamic_2005,
	title = {Dynamic security labels and noninterference},
	booktitle = {Formal {Aspects} in {Security} and {Trust}},
	publisher = {Springer},
	author = {Zheng, Lantian and Myers, Andrew C.},
	year = {2005},
	pages = {27--40},
	file = {ZHENG-MYERS_dynamic-security-labels-and-non-interference_2007_jis.pdf:/home/michael/Zotero/storage/6GIEFRHI/ZHENG-MYERS_dynamic-security-labels-and-non-interference_2007_jis.pdf:application/pdf}
}

@article{volpano_sound_1996,
	title = {A sound type system for secure flow analysis},
	volume = {4},
	number = {2-3},
	journal = {Journal of computer security},
	author = {Volpano, Dennis and Irvine, Cynthia and Smith, Geoffrey},
	year = {1996},
	pages = {167--187},
	file = {VOLPANO_a-sound-type-system-for-secure-flow-analysis_1996_jcs.pdf:/home/michael/Zotero/storage/U8DAAGJQ/VOLPANO_a-sound-type-system-for-secure-flow-analysis_1996_jcs.pdf:application/pdf}
}

@inproceedings{tse_translating_2004,
	title = {Translating dependency into parametricity},
	volume = {39},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Tse, Stephen and Zdancewic, Steve},
	year = {2004},
	pages = {115--125},
	file = {TSE-ZDANCEWIC_translating-dependency-into-parametricity_2001.pdf:/home/michael/Zotero/storage/ZIRF3GWS/TSE-ZDANCEWIC_translating-dependency-into-parametricity_2001.pdf:application/pdf}
}

@inproceedings{pottier_information_2002,
	title = {Information flow inference for {ML}},
	volume = {37},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Pottier, François and Simonet, Vincent},
	year = {2002},
	pages = {319--330},
	file = {POTTIER-SIMONET_information-flow-inference-for-ml_2002_popl.pdf:/home/michael/Zotero/storage/J5WZLGNX/POTTIER-SIMONET_information-flow-inference-for-ml_2002_popl.pdf:application/pdf}
}

@article{myers_proof_2009,
	title = {A proof of noninterference for a while-language using small-step operational semantics},
	author = {Myers, Andrew},
	year = {2009},
	file = {MYERS_proving-non-interference-for-a-while-language-using-small-step-operational-semantics_2011.pdf:/home/michael/Zotero/storage/TDCTGEYX/MYERS_proving-non-interference-for-a-while-language-using-small-step-operational-semantics_2011.pdf:application/pdf}
}

@phdthesis{myers_mostly-static_1999,
	type = {{PhD} {Thesis}},
	title = {Mostly-static decentralized information flow control},
	school = {Massachusetts Institute of Technology},
	author = {Myers, Andrew Clifford},
	year = {1999},
	file = {MYERS_mostly-static-decentralized-information-flow-control_1999_phd-thesis.pdf:/home/michael/Zotero/storage/8ZDFZ38Y/MYERS_mostly-static-decentralized-information-flow-control_1999_phd-thesis.pdf:application/pdf}
}

@book{association_for_computing_machinery_proceedings_2009,
	address = {New York, NY},
	title = {Proceedings of the 2009 {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}: {August} 31 - {September} 2, 2009, {Edinburgh}, {Scotland}},
	isbn = {978-1-60558-332-7},
	shorttitle = {Proceedings of the 2009 {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	language = {eng},
	publisher = {ACM},
	editor = {Association for Computing Machinery},
	year = {2009},
	note = {OCLC: 633260486},
	file = {MALECHA-CHONG_a-more-precise-security-type-system-for-dynamic-security-tests_2010_plas.pdf:/home/michael/Zotero/storage/E49N8Q2X/MALECHA-CHONG_a-more-precise-security-type-system-for-dynamic-security-tests_2010_plas.pdf:application/pdf}
}

@article{cook_proving_2011,
	title = {Proving program termination},
	volume = {54},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=1941487.1941509},
	doi = {10.1145/1941487.1941509},
	language = {en},
	number = {5},
	urldate = {2018-01-24},
	journal = {Communications of the ACM},
	author = {Cook, Byron and Podelski, Andreas and Rybalchenko, Andrey},
	month = may,
	year = {2011},
	pages = {88},
	file = {COOK_proving-program-termination_2011_comm-acm.pdf:/home/michael/Zotero/storage/H74QF3M5/COOK_proving-program-termination_2011_comm-acm.pdf:application/pdf}
}

@article{ahmed_semantic_2010,
	title = {Semantic foundations for typed assembly languages},
	volume = {32},
	issn = {01640925},
	url = {http://portal.acm.org/citation.cfm?doid=1709093.1709094},
	doi = {10.1145/1709093.1709094},
	language = {en},
	number = {3},
	urldate = {2018-01-24},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Ahmed, Amal and Appel, Andrew W. and Richards, Christopher D. and Swadi, Kedar N. and Tan, Gang and Wang, Daniel C.},
	month = mar,
	year = {2010},
	pages = {1--67},
	file = {AHMED-APPEL-RICHARDS_semantic-foundations-for-typed-assembly-languages_2010_pls.pdf:/home/michael/Zotero/storage/HELP8NRP/AHMED-APPEL-RICHARDS_semantic-foundations-for-typed-assembly-languages_2010_pls.pdf:application/pdf}
}

@book{melham_higher_1993,
	address = {Cambridge ; New York},
	series = {Cambridge tracts in theoretical computer science},
	title = {Higher order logic and hardware verification},
	isbn = {978-0-521-41718-1},
	number = {31},
	publisher = {Cambridge University Press},
	author = {Melham, T. F.},
	year = {1993},
	keywords = {Logic, Symbolic and mathematical, Integrated circuits, Very large scale integration Data processing},
	file = {GORDON_relating-event-and-trace-semantics-of-hardware-description-languages_2002_tcj.pdf:/home/michael/Zotero/storage/CJAK4HWJ/GORDON_relating-event-and-trace-semantics-of-hardware-description-languages_2002_tcj.pdf:application/pdf}
}

@article{wathen_prospective_2004,
	title = {Prospective {Randomized} {Multicenter} {Trial} of {Empirical} {Antitachycardia} {Pacing} {Versus} {Shocks} for {Spontaneous} {Rapid} {Ventricular} {Tachycardia} in {Patients} {With} {Implantable} {Cardioverter}-{Defibrillators}: {Pacing} {Fast} {Ventricular} {Tachycardia} {Reduces} {Shock} {Therapies} ({PainFREE} {Rx} {II}) {Trial} {Results}},
	volume = {110},
	issn = {0009-7322, 1524-4539},
	shorttitle = {Prospective {Randomized} {Multicenter} {Trial} of {Empirical} {Antitachycardia} {Pacing} {Versus} {Shocks} for {Spontaneous} {Rapid} {Ventricular} {Tachycardia} in {Patients} {With} {Implantable} {Cardioverter}-{Defibrillators}},
	url = {http://circ.ahajournals.org/cgi/doi/10.1161/01.CIR.0000145610.64014.E4},
	doi = {10.1161/01.CIR.0000145610.64014.E4},
	language = {en},
	number = {17},
	urldate = {2018-01-24},
	journal = {Circulation},
	author = {Wathen, M. S.},
	month = oct,
	year = {2004},
	pages = {2591--2596},
	file = {WATHEN-DEGROOT-SWEENEY_prospective-randomized-multicenter-trial-of-empirical-antitachycardia-pacing_2004.pdf:/home/michael/Zotero/storage/UFS9KQYA/WATHEN-DEGROOT-SWEENEY_prospective-randomized-multicenter-trial-of-empirical-antitachycardia-pacing_2004.pdf:application/pdf}
}

@article{shuja_formal_2015,
	title = {A {Formal} {Verification} {Methodology} for {DDD} {Mode} {Pacemaker} {Control} {Programs}},
	volume = {2015},
	issn = {2090-0147, 2090-0155},
	url = {http://www.hindawi.com/journals/jece/2015/939028/},
	doi = {10.1155/2015/939028},
	language = {en},
	urldate = {2018-01-24},
	journal = {Journal of Electrical and Computer Engineering},
	author = {Shuja, Sana and Srinivasan, Sudarshan K. and Jabeen, Shaista and Nawarathna, Dharmakeerthi},
	year = {2015},
	pages = {1--10},
	file = {SHUJA-SRINIVASAN-JABEEN_a-formal-verificaton-methodology-for-ddd-mode-pacemaker-control-programs_2015_jece.pdf:/home/michael/Zotero/storage/9C8YUFM2/SHUJA-SRINIVASAN-JABEEN_a-formal-verificaton-methodology-for-ddd-mode-pacemaker-control-programs_2015_jece.pdf:application/pdf}
}

@article{tuch_formal_2009-1,
	title = {Formal {Verification} of {C} {Systems} {Code}: {Structured} {Types}, {Separation} {Logic} and {Theorem} {Proving}},
	volume = {42},
	issn = {0168-7433, 1573-0670},
	shorttitle = {Formal {Verification} of {C} {Systems} {Code}},
	url = {http://link.springer.com/10.1007/s10817-009-9120-2},
	doi = {10.1007/s10817-009-9120-2},
	language = {en},
	number = {2-4},
	urldate = {2018-01-24},
	journal = {Journal of Automated Reasoning},
	author = {Tuch, Harvey},
	month = apr,
	year = {2009},
	pages = {125--187},
	file = {[63]_TUCH_formal-verification-of-c-systems-code-structured-types-separation-logic-and-theorem-proving_2009_jar.pdf:/home/michael/Zotero/storage/TTXPTUYS/[63]_TUCH_formal-verification-of-c-systems-code-structured-types-separation-logic-and-theorem-proving_2009_jar.pdf:application/pdf}
}

@book{kaufmann_computer-aided_2000,
	address = {Boston},
	series = {Advances in formal methods},
	title = {Computer-aided reasoning: an approach},
	isbn = {978-0-7923-7744-3},
	shorttitle = {Computer-aided reasoning},
	number = {3},
	publisher = {Kluwer Academic Publishers},
	author = {Kaufmann, Matt and Manolios, Panagiotis and Moore, J. Strother},
	year = {2000},
	keywords = {Expert systems (Computer science), Formal methods (Computer science), Sotware engineering},
	file = {[31]_HARDIN-SMITH-YOUNG_a-robust-machine-code-proof-framework-for-highly-secure-applications_2006_acl.pdf:/home/michael/Zotero/storage/QWS7J4Y9/[31]_HARDIN-SMITH-YOUNG_a-robust-machine-code-proof-framework-for-highly-secure-applications_2006_acl.pdf:application/pdf}
}

@book{broenink_communicating_2003,
	address = {Amsterdam ; Washington, DC},
	series = {Concurrent systems engineering series},
	title = {Communicating process architectures 2003: {WoTUG}-26: proceedings of the 26th {WoTUG} {Technical} {Meeting}, 7-10 {September} 2003, {University} of {Twente}, {The} {Netherlands}},
	isbn = {978-1-58603-381-1},
	shorttitle = {Communicating process architectures 2003},
	number = {v. 61},
	publisher = {IOS Press},
	editor = {Broenink, Jan F. and Hilderink, Gerald H.},
	year = {2003},
	keywords = {Occam (Computer program language), Telecommunication systems, Transputers},
	file = {[23]_FAHNDRICH-AIKEN-HAWBLITZEL_language-support-for-fast-and-reliable-message-based-communication-in-singularity-os_2006_eurosys-conf.pdf:/home/michael/Zotero/storage/K672FCTA/[23]_FAHNDRICH-AIKEN-HAWBLITZEL_language-support-for-fast-and-reliable-message-based-communication-in-singularity-os_2006_eurosys-conf.pdf:application/pdf}
}

@article{leroy_safety_2011,
	title = {Safety first!: technical perspective},
	volume = {54},
	issn = {00010782},
	shorttitle = {Safety first!},
	url = {http://dl.acm.org/citation.cfm?doid=2043174.2043196},
	doi = {10.1145/2043174.2043196},
	language = {en},
	number = {12},
	urldate = {2018-01-24},
	journal = {Communications of the ACM},
	author = {Leroy, Xavier},
	month = dec,
	year = {2011},
	pages = {122},
	file = {LEROY_safety-first_2011_comm-acm.pdf:/home/michael/Zotero/storage/52D3NSA6/LEROY_safety-first_2011_comm-acm.pdf:application/pdf}
}

@book{pena_implementation_2003,
	address = {New York},
	series = {Lecture notes in computer science},
	title = {Implementation of functional languages: 14th international workshop, {IFL} 2002, {Madrid}, {Spain}, {September} 16-18, 2002: revised papers},
	isbn = {978-3-540-40190-2},
	shorttitle = {Implementation of functional languages},
	number = {2670},
	publisher = {Springer},
	editor = {Peña, Ricardo and Arts, Thomas},
	year = {2003},
	keywords = {Functional programming languages},
	file = {implementation-of-functional-languages_2002_ifl.pdf:/home/michael/Zotero/storage/FGM3FI5K/implementation-of-functional-languages_2002_ifl.pdf:application/pdf}
}

@book{dubin_rapid_2000,
	address = {Tampa, Fla},
	edition = {6. ed},
	title = {Rapid interpretation of {EKG}'s: an interactive course},
	isbn = {978-0-912912-06-6},
	shorttitle = {Rapid interpretation of {EKG}'s},
	language = {eng},
	publisher = {Cover Publ},
	author = {Dubin, Dale B.},
	year = {2000},
	note = {OCLC: 254206292},
	file = {PATEL-GAKARE-CHEERAN_real-time-ecg-feature-extraction-and-arrhythmia-detection-on-a-mobile-platform_2012_ijca.pdf:/home/michael/Zotero/storage/K7ZM7ZM7/PATEL-GAKARE-CHEERAN_real-time-ecg-feature-extraction-and-arrhythmia-detection-on-a-mobile-platform_2012_ijca.pdf:application/pdf}
}

@article{hidalgo-herrero_dealing_2005,
	title = {Dealing {Denotationally} {With} {Stream}-based {Communication}},
	volume = {137},
	issn = {15710661},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105050826},
	doi = {10.1016/j.entcs.2005.01.039},
	language = {en},
	number = {1},
	urldate = {2018-01-24},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Hidalgo-Herrero, Mercedes and Ortega-Mallén, Yolanda},
	month = jul,
	year = {2005},
	pages = {47--68},
	file = {HIDALGO-HERRORO_dealing-denotationally-with-stream-based-communication_2005_entcs.pdf:/home/michael/Zotero/storage/MEMWUAHR/HIDALGO-HERRORO_dealing-denotationally-with-stream-based-communication_2005_entcs.pdf:application/pdf}
}

@article{v._wilkes_best_1981,
	title = {The best way to design an automatic calculating machine},
	volume = {8},
	issn = {0-262-23136-0},
	doi = {10.1016/0165-6074(81)90018-1},
	abstract = {An abstract is not available.},
	journal = {Microprocessing and Microprogramming},
	author = {V. Wilkes, M},
	month = oct,
	year = {1981},
	pages = {182--184},
	file = {V. Wilkes_1981_The best way to design an automatic calculating machine.pdf:/home/michael/Dropbox/zotero-pdfs/V/V. Wilkes_1981_The best way to design an automatic calculating machine.pdf:application/pdf}
}

@article{feng_certifying_2009,
	title = {Certifying {Low}-{Level} {Programs} with {Hardware} {Interrupts} and {Preemptive} {Threads}},
	volume = {42},
	issn = {0168-7433, 1573-0670},
	url = {https://link.springer.com/article/10.1007/s10817-009-9118-9},
	doi = {10.1007/s10817-009-9118-9},
	abstract = {Hardware interrupts are widely used in the world’s critical software systems to support preemptive threads, device drivers, operating system kernels, and hypervisors. Handling interrupts properly is an essential component of low-level system programming. Unfortunately, interrupts are also extremely hard to reason about: they dramatically alter the program control flow and complicate the invariants in low-level concurrent code (e.g., implementation of synchronization primitives). Existing formal verification techniques—including Hoare logic, typed assembly language, concurrent separation logic, and the assume-guarantee method—have consistently ignored the issues of interrupts; this severely limits the applicability and power of today’s program verification systems. In this paper we present a novel Hoare-logic-like framework for certifying low-level system programs involving both hardware interrupts and preemptive threads. We show that enabling and disabling interrupts can be formalized precisely using simple ownership-transfer semantics, and the same technique also extends to the concurrent setting. By carefully reasoning about the interaction among interrupt handlers, context switching, and synchronization libraries, we are able to—for the first time—successfully certify a preemptive thread implementation and a large number of common synchronization primitives. Our work provides a foundation for reasoning about interrupt-based kernel programs and makes an important advance toward building fully certified operating system kernels and hypervisors.},
	language = {en},
	number = {2-4},
	urldate = {2018-01-24},
	journal = {Journal of Automated Reasoning},
	author = {Feng, Xinyu and Shao, Zhong and Guo, Yu and Dong, Yuan},
	month = apr,
	year = {2009},
	keywords = {TO-READ},
	pages = {301--347},
	file = {Feng et al_2009_Certifying Low-Level Programs with Hardware Interrupts and Preemptive Threads.pdf:/home/michael/Dropbox/zotero-pdfs/F/Feng et al_2009_Certifying Low-Level Programs with Hardware Interrupts and Preemptive Threads.pdf:application/pdf}
}

@inproceedings{trippel_tricheck:_2017,
	title = {{TriCheck}: {Memory} {Model} {Verification} at the {Trisection} of {Software}, {Hardware}, and {ISA}},
	isbn = {978-1-4503-4465-4},
	shorttitle = {{TriCheck}},
	url = {http://dl.acm.org/citation.cfm?doid=3037697.3037719},
	doi = {10.1145/3037697.3037719},
	language = {en},
	urldate = {2018-01-24},
	publisher = {ACM Press},
	author = {Trippel, Caroline and Manerkar, Yatin A. and Lustig, Daniel and Pellauer, Michael and Martonosi, Margaret},
	year = {2017},
	pages = {119--133},
	file = {ctrippel_ASPLOS17.pdf:/home/michael/Zotero/storage/HD2YTE78/ctrippel_ASPLOS17.pdf:application/pdf}
}

@inproceedings{zhai_hardware_nodate,
	title = {Hardware {Synthesis} from a {Recursive} {Functional} {Language}},
	abstract = {Abstraction in hardware description languages stalled at the register-transfer level decades ago, yet few alternatives have had much success, in part because they provide only mod-est gains in expressivity. We propose to make a much larger jump: a compiler that synthesizes hardware from behavioral functional specifications. Our compiler translates general Haskell programs into a restricted intermediate representa-tion before applying a series of semantics-preserving trans-formations, concluding with a simple syntax-directed trans-lation to SystemVerilog. Here, we present the overall frame-work for this compiler, focusing on the intermediate repre-sentations involved and our method for translating general recursive functions into equivalent hardware. We conclude with experimental results that depict the performance and resource usage of the circuitry generated with our compiler.},
	author = {Zhai, Kuangya and Townsend, Richard and Lairmore, Lianne and Kim, Martha A. and Edwards, Stephen A.},
	file = {hardware-codes15.pdf:/home/michael/Zotero/storage/K4LBXLCJ/hardware-codes15.pdf:application/pdf}
}

@book{lamport_specifying_2002,
	address = {Microsoft Research},
	edition = {1e},
	title = {Specifying {Systems}},
	isbn = {0-321-14306-X},
	url = {http://lamport.azurewebsites.net/tla/book-02-08-08.pdf},
	abstract = {The TLA+ Language and Tools for Hardware and Software Engineers},
	urldate = {2018-01-26},
	publisher = {Addison Wesley},
	author = {Lamport, Leslie},
	month = jun,
	year = {2002},
	file = {Lamport_2002_Specifying Systems.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lamport_2002_Specifying Systems.pdf:application/pdf}
}

@article{lamport_how_1995,
	title = {How to write a proof},
	volume = {102},
	number = {7},
	journal = {The American mathematical monthly},
	author = {Lamport, Leslie},
	year = {1995},
	pages = {600--608},
	file = {Lamport_1995_How to write a proof.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lamport_1995_How to write a proof.pdf:application/pdf}
}

@article{prasad_survey_2005,
	title = {A survey of recent advances in {SAT}-based formal verification},
	volume = {7},
	issn = {1433-2779, 1433-2787},
	url = {http://link.springer.com/10.1007/s10009-004-0183-4},
	doi = {10.1007/s10009-004-0183-4},
	language = {en},
	number = {2},
	urldate = {2018-01-29},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Prasad, Mukul R. and Biere, Armin and Gupta, Aarti},
	month = apr,
	year = {2005},
	pages = {156--173},
	file = {10.1007s10009-004-0183-4.pdf:/home/michael/Zotero/storage/XEJ9BYJH/10.1007s10009-004-0183-4.pdf:application/pdf}
}

@article{pike_plan_1990,
	title = {Plan 9 from {Bell} {Labs}},
	url = {https://pdos.csail.mit.edu/archive/6.824-2012/papers/plan9.pdf},
	urldate = {2018-01-29},
	journal = {EUUG Newsletter 10},
	author = {Pike, R and Presotto, D and Thompson, K and Trickey, H},
	year = {1990},
	file = {plan9.pdf:/home/michael/Zotero/storage/PPDTLJC2/plan9.pdf:application/pdf}
}

@article{pike_use_1993,
	title = {The {Use} of {Name} {Spaces} in {Plan} 9},
	volume = {27},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/155848.155861},
	doi = {10.1145/155848.155861},
	abstract = {Plan 9 is a distributed system built at the Computing Sciences Research Center of AT\&amp;T Bell Laboratories over the last few years. Its goal is to provide a production-quality system for software development and general computation using heterogeneous hardware and minimal software. A Plan 9 system comprises CPU and file servers in a central location connected together by fast networks. Slower networks fan out to workstation-class machines that serve as user terminals. Plan 9 argues that given a few carefully implemented abstractions it is possible to produce a small operating system that provides support for the largest systems on a variety of architectures and networks. The foundations of the system are built on two ideas: a per-process name space and a simple message-oriented file system protocol.},
	number = {2},
	urldate = {2018-01-29},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Pike, Rob and Presotto, Dave and Thompson, Ken and Trickey, Howard and Winterbottom, Phil},
	month = apr,
	year = {1993},
	pages = {72--76},
	file = {Pike et al_1993_The Use of Name Spaces in Plan 9.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pike et al_1993_The Use of Name Spaces in Plan 9.pdf:application/pdf}
}

@techreport{noauthor_serial_2009,
	title = {Serial {Atached} {SCSI} ({SAS}) {Interface} {Manual}},
	url = {https://www.seagate.com/staticfiles/support/disc/manuals/Interface%20manuals/100293071c.pdf},
	urldate = {2018-01-29},
	institution = {Seagate},
	month = dec,
	year = {2009},
	file = {100293071c.pdf:/home/michael/Zotero/storage/I75QLJTY/100293071c.pdf:application/pdf}
}

@techreport{ballesteros_introduction_2007,
	title = {Introduction to {Operatng} {Systems} {Abstractions} -- {Using} {Plan} 9 from {Bell} {Labs}},
	url = {https://lsub.org/who/nemo/9.intro.pdf},
	urldate = {2018-01-29},
	author = {Ballesteros, Francisco},
	month = sep,
	year = {2007},
	file = {9.intro.pdf:/home/michael/Zotero/storage/IJEJ35QM/9.intro.pdf:application/pdf}
}

@misc{noauthor_hurd_nodate,
	title = {The {Hurd} {Hacking} {Guide}},
	url = {https://www.gnu.org/software/hurd/hacking-guide/hhg.html},
	urldate = {2018-01-29}
}

@misc{noauthor_towards_nodate,
	title = {Towards a {New} {Strategy} of {OS} {Design}, an architectural overview by {Thomas} {Bushnell}, {BSG}.},
	url = {https://www.gnu.org/software/hurd/hurd-paper.html},
	urldate = {2018-01-29},
	file = {Towards a New Strategy of OS Design, an architectural overview by Thomas Bushnell, BSG.:/home/michael/Zotero/storage/K5IF5ALL/hurd-paper.html:text/html}
}

@inproceedings{gay_nesc_2003,
	address = {New York, NY, USA},
	series = {{PLDI} '03},
	title = {The {nesC} {Language}: {A} {Holistic} {Approach} to {Networked} {Embedded} {Systems}},
	isbn = {978-1-58113-662-3},
	shorttitle = {The {nesC} {Language}},
	url = {http://doi.acm.org/10.1145/781131.781133},
	doi = {10.1145/781131.781133},
	abstract = {We present nesC, a programming language for networked embedded systems that represent a new design space for application developers. An example of a networked embedded system is a sensor network, which consists of (potentially) thousands of tiny, low-power "motes," each of which execute concurrent, reactive programs that must operate with severe memory and power constraints.nesC's contribution is to support the special needs of this domain by exposing a programming model that incorporates event-driven execution, a flexible concurrency model, and component-oriented application design. Restrictions on the programming model allow the nesC compiler to perform whole-program analyses, including data-race detection (which improves reliability) and aggressive function inlining (which reduces resource consumption).nesC has been used to implement TinyOS, a small operating system for sensor networks, as well as several significant sensor applications. nesC and TinyOS have been adopted by a large number of sensor network research groups, and our experience and evaluation of the language shows that it is effective at supporting the complex, concurrent programming style demanded by this new class of deeply networked systems.},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2003 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Gay, David and Levis, Philip and von Behren, Robert and Welsh, Matt and Brewer, Eric and Culler, David},
	year = {2003},
	keywords = {data races, concurrency, programming languages, C, modules, components, first-order, nesC, TinyOS},
	pages = {1--11},
	file = {Gay et al_2003_The nesC Language.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay et al_2003_The nesC Language.pdf:application/pdf}
}

@inproceedings{hill_system_2000,
	address = {New York, NY, USA},
	series = {{ASPLOS} {IX}},
	title = {System {Architecture} {Directions} for {Networked} {Sensors}},
	isbn = {978-1-58113-317-2},
	url = {http://doi.acm.org/10.1145/378993.379006},
	doi = {10.1145/378993.379006},
	abstract = {Technological progress in integrated, low-power, CMOS communication devices and sensors makes a rich design space of networked sensors viable. They can be deeply embedded in the physical world and spread throughout our environment like smart dust. The missing elements are an overall system architecture and a methodology for systematic advance. To this end, we identify key requirements, develop a small device that is representative of the class, design a tiny event-driven operating system, and show that it provides support for efficient modularity and concurrency-intensive operation. Our operating system fits in 178 bytes of memory, propagates events in the time it takes to copy 1.25 bytes of memory, context switches in the time it takes to copy 6 bytes of memory and supports two level scheduling. The analysis lays a groundwork for future architectural advances.},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the {Ninth} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Hill, Jason and Szewczyk, Robert and Woo, Alec and Hollar, Seth and Culler, David and Pister, Kristofer},
	year = {2000},
	pages = {93--104},
	file = {Hill et al_2000_System Architecture Directions for Networked Sensors.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hill et al_2000_System Architecture Directions for Networked Sensors.pdf:application/pdf}
}

@article{levis_tinyos_2006,
	title = {{TinyOS} programming},
	author = {Levis, Philip},
	year = {2006},
	file = {tinyos-programming-1-0.pdf:/home/michael/Zotero/storage/TQTMQHEN/tinyos-programming-1-0.pdf:application/pdf}
}

@misc{culler_tinyos:_2006,
	title = {{TinyOS}: {Operating} {System} {Design} for {Wireless} {Sensor} {Networks} {\textbar} {Sensors} {Magazine}},
	url = {https://www.sensorsmag.com/iot-wireless/tinyos-operating-system-design-for-wireless-sensor-networks},
	urldate = {2018-01-29},
	author = {Culler, David},
	month = may,
	year = {2006}
}

@techreport{levis_t2:_2005,
	title = {T2: {A} second generation {OS} for embedded sensor networks},
	shorttitle = {T2},
	institution = {Technical Report TKN-05-007, Telecommunication Networks Group, Technische Universitat Berlin},
	author = {Levis, Philip and Gay, David and Handziski, Vlado and Hauer, Jan-Hinrich and Greenstein, Ben and Turon, Martin and Hui, Jonathan and Klues, Kevin and Sharp, Cory and Szewczyk, Robert},
	year = {2005},
	file = {tinyos2-tr.pdf:/home/michael/Zotero/storage/G7LVHQ4L/tinyos2-tr.pdf:application/pdf}
}

@inproceedings{simon_squawk_2005,
	address = {New York, NY, USA},
	series = {{OOPSLA} '05},
	title = {The {Squawk} {Virtual} {Machine}: {Java}™ on the {Bare} {Metal}},
	isbn = {978-1-59593-193-1},
	shorttitle = {The {Squawk} {Virtual} {Machine}},
	url = {http://doi.acm.org/10.1145/1094855.1094908},
	doi = {10.1145/1094855.1094908},
	abstract = {The Squawk virtual machine is a small Java(TM) VM written in Java that runs without an OS on small devices. Squawk implements an isolate mechanism allowing applications to be reified. Multiple isolates can run in the one VM, and isolates can be migrated between different instances of the VM.},
	urldate = {2018-01-29},
	booktitle = {Companion to the 20th {Annual} {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Simon, Doug and Cifuentes, Cristina},
	year = {2005},
	pages = {150--151},
	file = {Simon_Cifuentes_2005_The Squawk Virtual Machine - Java™ on the Bare Metal.pdf:/home/michael/Dropbox/zotero-pdfs/S/Simon_Cifuentes_2005_The Squawk Virtual Machine - Java™ on the Bare Metal.pdf:application/pdf}
}

@inproceedings{shaylor_java_2003,
	address = {New York, NY, USA},
	series = {{LCTES} '03},
	title = {A {Java} {Virtual} {Machine} {Architecture} for {Very} {Small} {Devices}},
	isbn = {978-1-58113-647-0},
	url = {http://doi.acm.org/10.1145/780732.780738},
	doi = {10.1145/780732.780738},
	abstract = {The smallest complete Java™ virtual machine implementations in use today are based on the CLDC standard and are deployed in mobile phones and PDAs. These implementations require several tens of kilobytes. Smaller Java-like implementations also exist, but these involve compromises in Java semantics. This paper describes a JVM™ architecture designed for very small devices. It supports all the CLDC Java platform semantics, including exact garbage collection, dynamic class loading, and verification. For portability and ease of debugging, the entire system is written in the Java language, with key components automatically translated into C and compiled for the target device. The resulting system will run on the next generation of smart cards, and has performance comparable to the reference CLDC implementation available from Sun™.},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the 2003 {ACM} {SIGPLAN} {Conference} on {Language}, {Compiler}, and {Tool} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Shaylor, Nik and Simon, Douglas N. and Bush, William R.},
	year = {2003},
	keywords = {JVM, java, CLDC, limited-memory devices, next generation smart cards},
	pages = {34--41},
	file = {Shaylor et al_2003_A Java Virtual Machine Architecture for Very Small Devices.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shaylor et al_2003_A Java Virtual Machine Architecture for Very Small Devices.pdf:application/pdf}
}

@inproceedings{palacz_engineering_2003,
	address = {New York, NY, USA},
	series = {{IVME} '03},
	title = {Engineering a {Customizable} {Intermediate} {Representation}},
	isbn = {978-1-58113-655-5},
	url = {http://doi.acm.org/10.1145/858570.858578},
	doi = {10.1145/858570.858578},
	abstract = {The Ovm framework is a set of tools and components for building language runtimes. We present the intermediate representation and software design patterns used throughout the framework. One of the main themes in this work has been to support experimentation with new linguistic constructs and implementation techniques. To this end, framework components were designed to be parametric with respect to the instruction set on which they operate. We argue that our approach eases the task of writing new components without sacrificing efficiency.},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the 2003 {Workshop} on {Interpreters}, {Virtual} {Machines} and {Emulators}},
	publisher = {ACM},
	author = {Palacz, K. and Baker, J. and Flack, C. and Grothoff, C. and Yamauchi, H. and Vitek, J.},
	year = {2003},
	pages = {67--76},
	file = {Palacz et al_2003_Engineering a Customizable Intermediate Representation.pdf:/home/michael/Dropbox/zotero-pdfs/P/Palacz et al_2003_Engineering a Customizable Intermediate Representation.pdf:application/pdf}
}

@inproceedings{alpern_implementing_1999,
	address = {New York, NY, USA},
	series = {{OOPSLA} '99},
	title = {Implementing {Jalapeño} in {Java}},
	isbn = {978-1-58113-238-0},
	url = {http://doi.acm.org/10.1145/320384.320418},
	doi = {10.1145/320384.320418},
	abstract = {Jalapeño is a virtual machine for Java™ servers written in Java.A running Java program involves four layers of functionality: the user code, the virtual-machine, the operating system, and the hardware. By drawing the Java / non-Java boundary below the virtual machine rather than above it, Jalapeño reduces the boundary-crossing overhead and opens up more opportunities for optimization.To get Jalapeño started, a boot image of a working Jalapeño virtual machine is concocted and written to a file. Later, this file can be loaded into memory and executed. Because the boot image consists entirely of Java objects, it can be concocted by a Java program that runs in any JVM. This program uses reflection to convert the boot image into Jalapeño's object format.A special MAGIC class allows unsafe casts and direct access to the hardware. Methods of this class are recognized by Jalapeño's three compilers, which ignore their bytecodes and emit special-purpose machine code. User code will not be allowed to call MAGIC methods so Java's integrity is preserved.A small non-Java program is used to start up a boot image and as an interface to the operating system.Java's programming features — object orientation, type safety, automatic memory management — greatly facilitated development of Jalapeño. However, we also discovered some of the language's limitations.},
	urldate = {2018-01-29},
	booktitle = {Proceedings of the 14th {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Alpern, Bowen and Attanasio, C. R. and Cocchi, Anthony and Lieber, Derek and Smith, Stephen and Ngo, Ton and Barton, John J. and Hummel, Susan Flynn and Sheperd, Janice C. and Mergen, Mark},
	year = {1999},
	pages = {314--324},
	file = {Alpern et al_1999_Implementing JalapeNO in Java.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alpern et al_1999_Implementing JalapeNO in Java.pdf:application/pdf}
}

@article{biere_conflict-driven_2009,
	title = {Conflict-driven clause learning {SAT} solvers},
	journal = {Handbook of Satisfiability, Frontiers in Artificial Intelligence and Applications},
	author = {Biere, Armin and Heule, Marijn and van Maaren, Hans and Walsh, Toby},
	year = {2009},
	pages = {131--153},
	file = {Biere et al_2009_Conflict-driven clause learning SAT solvers.pdf:/home/michael/Dropbox/zotero-pdfs/B/Biere et al_2009_Conflict-driven clause learning SAT solvers.pdf:application/pdf}
}

@inproceedings{burrows_run-time_2003,
	title = {Run-time type checking for binary programs},
	booktitle = {International {Conference} on {Compiler} {Construction}},
	publisher = {Springer},
	author = {Burrows, Michael and Freund, Stephen N. and Wiener, Janet L.},
	year = {2003},
	pages = {90--105},
	file = {Burrows et al_2003_Run-time type checking for binary programs.pdf:/home/michael/Dropbox/zotero-pdfs/B/Burrows et al_2003_Run-time type checking for binary programs.pdf:application/pdf}
}

@article{wilhelm_determining_2005,
	title = {Determining {Bounds} on {Execution} {Times}.},
	volume = {2},
	journal = {Embedded Systems Handbook},
	author = {Wilhelm, Reinhard},
	year = {2005},
	file = {Wilhelm_2005_Determining Bounds on Execution Times.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wilhelm_2005_Determining Bounds on Execution Times.pdf:application/pdf}
}

@inproceedings{myers_jflow:_1999,
	address = {San Antonio, Texas, USA},
	title = {{JFlow}: {Practical} {Mostly}-{Static} {Information} {Flow} {Control}},
	abstract = {A promising technique for protecting privacy and integrity of sensitive data is to statically check information flow within programs that manipulate the data. While previous work has proposed programming language extensions to allow this static checking, the resulting languages are too restrictive for practical use and have not been implemented. In this paper, we describe the new language JFlow, an extension to the Java language that adds statically-checked information flow annotations. JFlow provides several new features that make information flow checking more flexible and convenient than in previous models: a decentralized label model, label polymorphism, run-time label checking, and automatic label inference. JFlow also supports many language features that have never been integrated successfully with static information flow control, including objects, subclassing, dynamic type tests, access control, and exceptions. This paper defines the JFlow language and presents formal rules that are used to check JFlow programs for correctness. Because most checking is static, there is little code space, data space, or run-time overhead in the JFlow implementation.},
	booktitle = {Proceedings of the 26th {ACM} {Symposium} on {Principles} of {Programming} {Languages}},
	author = {Myers, Andrew},
	month = jan,
	year = {1999},
	file = {Myers_1999_JFlow - Practical Mostly-Static Information Flow Control.pdf:/home/michael/Dropbox/zotero-pdfs/M/Myers_1999_JFlow - Practical Mostly-Static Information Flow Control.pdf:application/pdf}
}

@inproceedings{abadi_analysis_1996,
	title = {Analysis and {Caching} of {Dependencies}},
	author = {Abadi, Martín and Lampson, Butler and Levy, Jean-Jacques},
	year = {1996},
	file = {Abadi et al_1996_Analysis and Caching of Dependencies.pdf:/home/michael/Dropbox/zotero-pdfs/A/Abadi et al_1996_Analysis and Caching of Dependencies.pdf:application/pdf}
}

@inproceedings{austin_efficient_2009,
	title = {Efficient purely-dynamic information flow analysis},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} {Fourth} {Workshop} on {Programming} {Languages} and {Analysis} for {Security}},
	publisher = {ACM},
	author = {Austin, Thomas H. and Flanagan, Cormac},
	year = {2009},
	pages = {113--124},
	file = {Austin_Flanagan_2009_Efficient purely-dynamic information flow analysis.pdf:/home/michael/Dropbox/zotero-pdfs/A/Austin_Flanagan_2009_Efficient purely-dynamic information flow analysis.pdf:application/pdf}
}

@article{simonet_fine-grained_nodate,
	title = {Fine-grained {Information} {Flow} {Analysis} for a-calculus with {Sum} {Types}},
	author = {Simonet, Vincent},
	file = {Simonet_Fine-grained Information Flow Analysis for a-calculus with Sum Types.pdf:/home/michael/Dropbox/zotero-pdfs/S/Simonet_Fine-grained Information Flow Analysis for a-calculus with Sum Types.pdf:application/pdf}
}

@article{shikuma_proving_2008,
	title = {Proving {Noninterference} {By} {A} {Fully} {Complete} {Translation} {To} {The} {Simply} {Typed} {Lambda}-{Calculus}},
	doi = {10.2168/LMCS-4 (3:10)},
	journal = {Logical Methods in Computer Science},
	author = {Shikuma, Naokata and Igarashi, Atsushi},
	month = sep,
	year = {2008},
	file = {Shikuma_Igarashi_2008_Proving Noninterference By A Fully Complete Translation To The Simply Typed.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shikuma_Igarashi_2008_Proving Noninterference By A Fully Complete Translation To The Simply Typed.pdf:application/pdf}
}

@article{sabelfeld_language-based_2003,
	title = {Language-{Based} {Information}-{Flow} {Security}},
	volume = {21},
	number = {1},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Sabelfeld, Andrei and Myers, Andrew},
	month = jan,
	year = {2003},
	keywords = {TO-READ},
	file = {Sabelfeld_Myers_2003_Language-Based Information-Flow Security.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sabelfeld_Myers_2003_Language-Based Information-Flow Security.pdf:application/pdf}
}

@inproceedings{medel_typed_2005,
	title = {A typed assembly language for non-interference},
	booktitle = {Italian {Conference} on {Theoretical} {Computer} {Science}},
	publisher = {Springer},
	author = {Medel, Ricardo and Compagnoni, Adriana and Bonelli, Eduardo},
	year = {2005},
	pages = {360--374},
	file = {Medel et al_2005_A typed assembly language for non-interference.pdf:/home/michael/Dropbox/zotero-pdfs/M/Medel et al_2005_A typed assembly language for non-interference.pdf:application/pdf}
}

@inproceedings{kashyap_timing-and_2011,
	title = {Timing-and termination-sensitive secure information flow: {Exploring} a new approach},
	shorttitle = {Timing-and termination-sensitive secure information flow},
	booktitle = {Security and {Privacy} ({SP}), 2011 {IEEE} {Symposium} on},
	publisher = {IEEE},
	author = {Kashyap, Vineeth and Wiedermann, Ben and Hardekopf, Ben},
	year = {2011},
	pages = {413--428},
	file = {Kashyap et al_2011_Timing-and termination-sensitive secure information flow - Exploring a new.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kashyap et al_2011_Timing-and termination-sensitive secure information flow - Exploring a new.pdf:application/pdf}
}

@article{mag_towards_nodate,
	title = {Towards a {Large}-{Grain} {FFP} {Machine}},
	author = {Mag, Gyula A. and Singh, Raj K. and Chi, Vernon L.},
	file = {Mag et al_Towards a Large-Grain FFP Machine.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mag et al_Towards a Large-Grain FFP Machine.pdf:application/pdf}
}

@inproceedings{assmann_design_1995,
	title = {On the design of systems of cooperating functional processes},
	booktitle = {Reliable {Distributed} {Systems}, 1995. {Proceedings}., 14th {Symposium} on},
	publisher = {IEEE},
	author = {Assmann, Claus and Kluge, Werner E.},
	year = {1995},
	pages = {52--61},
	file = {Assmann_Kluge_1995_On the design of systems of cooperating functional processes.pdf:/home/michael/Dropbox/zotero-pdfs/A/Assmann_Kluge_1995_On the design of systems of cooperating functional processes.pdf:application/pdf}
}

@inproceedings{danvy_rational_2004,
	title = {A rational deconstruction of {Landin}’s {SECD} machine},
	booktitle = {Symposium on {Implementation} and {Application} of {Functional} {Languages}},
	publisher = {Springer},
	author = {Danvy, Olivier},
	year = {2004},
	pages = {52--71},
	file = {Danvy_2004_A rational deconstruction of Landin’s SECD machine.pdf:/home/michael/Dropbox/zotero-pdfs/D/Danvy_2004_A rational deconstruction of Landin’s SECD machine.pdf:application/pdf}
}

@incollection{kluge_reduction_1987,
	title = {Reduction languages and reduction systems},
	booktitle = {Future {Parallel} {Computers}},
	publisher = {Springer},
	author = {Kluge, Werner and Schmittgen, Claudia},
	year = {1987},
	pages = {153--184},
	file = {Kluge_Schmittgen_1987_Reduction languages and reduction systems.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kluge_Schmittgen_1987_Reduction languages and reduction systems.pdf:application/pdf}
}

@inproceedings{clarke_skim-s_1980,
	title = {Skim-the s, k, i reduction machine},
	booktitle = {Proceedings of the 1980 {ACM} conference on {LISP} and functional programming},
	publisher = {ACM},
	author = {Clarke, T. J. W. and Gladstone, P. J. S. and MacLean, C. D. and Norman, A. C.},
	year = {1980},
	pages = {128--135},
	file = {Clarke et al_1980_Skim-the s, k, i reduction machine.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke et al_1980_Skim-the s, k, i reduction machine.pdf:application/pdf}
}

@article{mago_network_1979,
	title = {A network of microprocessors to execute reduction languages, part {II}},
	volume = {8},
	number = {6},
	journal = {International Journal of Computer \& Information Sciences},
	author = {Magó, Gyula A.},
	year = {1979},
	pages = {435--471},
	file = {Mago_1979_A network of microprocessors to execute reduction languages, part II.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mago_1979_A network of microprocessors to execute reduction languages, part II.pdf:application/pdf}
}

@article{mago_network_1979-1,
	title = {A network of microprocessors to execute reduction languages, {Part} {I}},
	volume = {8},
	number = {5},
	journal = {International Journal of Computer \& Information Sciences},
	author = {Mago, Gyula A.},
	year = {1979},
	pages = {349--385},
	file = {Mago_1979_A network of microprocessors to execute reduction languages, Part I.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mago_1979_A network of microprocessors to execute reduction languages, Part I.pdf:application/pdf}
}

@article{sabry_reasoning_1993,
	title = {Reasoning about programs in continuation-passing style},
	volume = {6},
	number = {3-4},
	journal = {Lisp and symbolic computation},
	author = {Sabry, Amr and Felleisen, Matthias},
	year = {1993},
	pages = {289--360},
	file = {Sabry_Felleisen_1993_Reasoning about programs in continuation-passing style.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sabry_Felleisen_1993_Reasoning about programs in continuation-passing style.pdf:application/pdf}
}

@article{reynolds_definitional_1998,
	title = {Definitional interpreters for higher-order programming languages},
	volume = {11},
	number = {4},
	journal = {Higher-order and symbolic computation},
	author = {Reynolds, John C.},
	year = {1998},
	keywords = {classic-PL},
	pages = {363--397},
	file = {Reynolds_1998_Definitional interpreters for higher-order programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reynolds_1998_Definitional interpreters for higher-order programming languages.pdf:application/pdf}
}

@inproceedings{curzon_verified_1991,
	title = {A {Verified} {Compiler} for a {Structured} {Assembly} {Language}.},
	booktitle = {{TPHOLs}},
	author = {Curzon, Paul and Curzon, P.},
	year = {1991},
	pages = {253--262},
	file = {Curzon_Curzon_1991_A Verified Compiler for a Structured Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Curzon_Curzon_1991_A Verified Compiler for a Structured Assembly Language.pdf:application/pdf}
}

@article{fischer_lambda-calculus_1993,
	title = {Lambda-calculus schemata},
	volume = {6},
	number = {3-4},
	journal = {Lisp and symbolic computation},
	author = {Fischer, Michael J.},
	year = {1993},
	pages = {259--287},
	file = {Fischer_1993_Lambda-calculus schemata.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fischer_1993_Lambda-calculus schemata.pdf:application/pdf}
}

@inproceedings{austin_efficient_1994,
	address = {New York, NY, USA},
	series = {{PLDI} '94},
	title = {Efficient {Detection} of {All} {Pointer} and {Array} {Access} {Errors}},
	isbn = {978-0-89791-662-2},
	url = {http://doi.acm.org/10.1145/178243.178446},
	doi = {10.1145/178243.178446},
	abstract = {We present a pointer and array access checking technique that provides complete error coverage through a simple set of program transformations. Our technique, based on an extended safe pointer representation, has a number of novel aspects. Foremost, it is the first technique that detects all spatial and temporal access errors. Its use is not limited by the expressiveness of the language; that is, it can be applied successfully to compiled or interpreted languages with subscripted and mutable pointers, local references, and explicit and typeless dynamic storage management, e.g., C. Because it is a source level transformation, it is amenable to both compile- and run-time optimization. Finally, its performance, even without compile-time optimization, is quite good. We implemented a prototype translator for the C language and analyzed the checking overheads of six non-trivial, pointer intensive programs. Execution overheads range from 130\% to 540\%; with text and data size overheads typically below 100\%.},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1994 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Austin, Todd M. and Breach, Scott E. and Sohi, Gurindar S.},
	year = {1994},
	pages = {290--301},
	file = {Austin et al_1994_Efficient Detection of All Pointer and Array Access Errors.pdf:/home/michael/Dropbox/zotero-pdfs/A/Austin et al_1994_Efficient Detection of All Pointer and Array Access Errors.pdf:application/pdf}
}

@inproceedings{chandra_physical_1999,
	address = {New York, NY, USA},
	series = {{PASTE} '99},
	title = {Physical {Type} {Checking} for {C}},
	isbn = {978-1-58113-137-6},
	url = {http://doi.acm.org/10.1145/316158.316183},
	doi = {10.1145/316158.316183},
	abstract = {The effectiveness of traditional type checking in C is limited by the presence of type conversions using type casts. Because the C standard allows arbitrary type conversions between pointer types, neither C compilers, nor tools such as lint, can guarantee type safety in the presence of such type conversions. In particular, by using casts involving pointers to structures (C structs), a programmer can interpret any memory region to be of any desired type, further compromising C's weak type system. Not only do type casts make a program vulnerable to type errors, they hinder program comprehension and maintenance by creating latent dependencies between seemingly independent pieces of code.To address these problems, we have developed a stronger form of type checking for C programs, called physical type checking. Physical type checking takes into account the layout of C struct fields in memory. This paper describes an inference-based physical type checking algorithm. Our algorithm can be used to perform static safety checks, as well as compute useful information for software engineering applications.},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the 1999 {ACM} {SIGPLAN}-{SIGSOFT} {Workshop} on {Program} {Analysis} for {Software} {Tools} and {Engineering}},
	publisher = {ACM},
	author = {Chandra, Satish and Reps, Thomas},
	year = {1999},
	pages = {66--75},
	file = {Chandra_Reps_1999_Physical Type Checking for C.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chandra_Reps_1999_Physical Type Checking for C.pdf:application/pdf}
}

@inproceedings{hastings_purify:_1991,
	title = {Purify: {Fast} detection of memory leaks and access errors},
	shorttitle = {Purify},
	abstract = {This paper describes Purifyru, a software testing and quality assurance Ool that detects memory leaks and access erors. Purify inserts additional checking instructions directly into the object code produced by existing compilers. These instructions check every memory read and write performed by the program-under-test and detect several types of access errors, such as reading uninitialized memory or witing to freed memory. Purify inserts checking logic into all of the code in a program, including third-party and vendor object-code libraries, and verifies system call interfaces. In addition, Purify tracks memory usage and identifies individual memory leals using a novel adaptation of garbage collection techniques. Purify produce standard executable files compatible with existing debuggers, and currently runs on Sun Microsystems ' SPARC family of workstations. Purify's neafly-comprehensive memory access checking slows the target program down typically by less than a facor of three and has resulted in significantly more reliable software for several development goups. L.},
	booktitle = {In {Proc}. of the {Winter} 1992 {USENIX} {Conference}},
	author = {Hastings, Reed and Joyce, Bob},
	year = {1991},
	pages = {125--138},
	file = {Hastings_Joyce_1991_Purify - Fast detection of memory leaks and access errors.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hastings_Joyce_1991_Purify - Fast detection of memory leaks and access errors.pdf:application/pdf}
}

@inproceedings{mycroft_type-based_1999,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Type-{Based} {Decompilation} (or {Program} {Reconstruction} via {Type} {Reconstruction})},
	isbn = {978-3-540-65699-9 978-3-540-49099-9},
	url = {https://link.springer.com/chapter/10.1007/3-540-49099-X_14},
	doi = {10.1007/3-540-49099-X_14},
	abstract = {We describe a system which decompiles (reverse engineers) C programs from target machine code by type-inference techniques. This extends recent trends in the converse process of compiling high-level languages whereby type information is preserved during compilation. The algorithms remain independent of the particular architecture by virtue of treating target instructions as register-transfer specifications. Target code expressed in such RTL form is then transformed into SSA form (undoing register colouring etc.); this then generates a set of type constraints. Iteration and recursion over data-structures causes synthesis of appropriate recursive C structs; this is triggered by and resolves occurs-check constraint violation. Other constraint violations are resolved by C’s casts and unions. In the limit we use heuristics to select between equally suitable C code — a good GUI would clearly facilitate its professional use.},
	language = {en},
	urldate = {2018-02-01},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Mycroft, Alan},
	month = mar,
	year = {1999},
	pages = {208--223},
	file = {Mycroft_1999_Type-Based Decompilation (or Program Reconstruction via Type Reconstruction).pdf:/home/michael/Dropbox/zotero-pdfs/M/Mycroft_1999_Type-Based Decompilation (or Program Reconstruction via Type Reconstruction).pdf:application/pdf}
}

@article{necula_ccured:_2005,
	title = {{CCured}: {Type}-safe {Retrofitting} of {Legacy} {Software}},
	volume = {27},
	issn = {0164-0925},
	shorttitle = {{CCured}},
	url = {http://doi.acm.org/10.1145/1065887.1065892},
	doi = {10.1145/1065887.1065892},
	abstract = {This article describes CCured, a program transformation system that adds type safety guarantees to existing C programs. CCured attempts to verify statically that memory errors cannot occur, and it inserts run-time checks where static verification is insufficient.CCured extends C's type system by separating pointer types according to their usage, and it uses a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs. CCured uses physical subtyping to recognize and verify a large number of type casts at compile time. Additional type casts are verified using run-time type information. CCured uses two instrumentation schemes, one that is optimized for performance and one in which metadata is stored in a separate data structure whose shape mirrors that of the original user data. This latter scheme allows instrumented programs to invoke external functions directly on the program's data without the use of a wrapper function.We have used CCured on real-world security-critical network daemons to produce instrumented versions without memory-safety vulnerabilities, and we have found several bugs in these programs. The instrumented code is efficient enough to be used in day-to-day operations.},
	number = {3},
	urldate = {2018-02-01},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Necula, George C. and Condit, Jeremy and Harren, Matthew and McPeak, Scott and Weimer, Westley},
	month = may,
	year = {2005},
	keywords = {libraries, Memory safety, pointer qualifier, subtyping},
	pages = {477--526},
	file = {Necula et al_2005_CCured - Type-safe Retrofitting of Legacy Software.pdf:/home/michael/Dropbox/zotero-pdfs/N/Necula et al_2005_CCured - Type-safe Retrofitting of Legacy Software.pdf:application/pdf}
}

@book{xu_typestate_2000,
	title = {Typestate {Checking} of {Machine} {Code}},
	abstract = {ly interpreting the instructions from line 10 to line 14 reveals that SF[96,100] stores an integer. The second time the typestate-checking algorithm visits the loop entry, \%g3 points to either SF:96 or SF:104. We now have a candidate for a local array. The reasoning runs as follows: if we create two C program SPARC Machine Language First Time Second Time  typedef struct \{  int f;  int g;  \} s;  int main() \{  s a[10];  s *p = \&a[0];  int i=0;  while (p{\textless}a+10) \{  (p++)-{\textgreater}f = i++;  \}  \}  1:  2:  3:  4:  5:  6:  7:  8:  9:  10:  11:  12:  13:  14:  15:  16:  17:  main:  add \%sp,-192,\%sp  add \%sp,96,\%g3  mov 0,\%o0  add \%sp,176,\%g2  cmp \%g3,\%g2  bgeu .LL3  mov \%g2,\%o1  .LL4:  st \%o0,[\%g3]  add \%g3,8,\%g3  cmp \%g3,\%o1  blu .LL4  add \%o0,1,\%o0  .LL3:  retl  sub \%sp,-192,\%sp  Figure 8: Inferring the Type and Size of a Local Array.  The label .LL4 represents the entry of the while loop.  \%sp  \%g3  192  176  96  \%g2  \%o1  \%sp  \%g3  192  176  96  \%g2  \%o1  104  int  A  B  Page 9 July 14, 2000  fictit...},
	author = {Xu, Zhichen and Reps, Tom and Miller, Bart},
	year = {2000},
	file = {Xu et al_2000_Typestate Checking of Machine Code.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xu et al_2000_Typestate Checking of Machine Code.pdf:application/pdf}
}

@article{benveniste_synchronous_1991,
	title = {Synchronous programming with events and relations: the {SIGNAL} language and its semantics},
	volume = {16},
	issn = {0167-6423},
	shorttitle = {Synchronous programming with events and relations},
	url = {http://www.sciencedirect.com/science/article/pii/016764239190001E},
	doi = {10.1016/0167-6423(91)90001-E},
	abstract = {In this paper, systems which interact permanently with their environment are considered. Such systems are encountered, for instance, in real-time control or signal processing systems, C3-systems, man-machine interfaces, to mention just a few. The design and implementation of such systems require a concurrent programming language which can be used to verify and synthesize the synchronization mechanisms, and to perform transformations of the concurrent source code to match a particular target architecture. Synchronous languages are convenient tools for such a purpose: they rely on the assumption that: (1) internal actions of synchronous systems are instantaneous, and (2) communication with the environment is performed via instantaneous flashes involving some external stimuli. In this paper, we present a synchronous programming language: SIGNAL. A SIGNAL program specifies dynamical relations between (internal and external) signal flows. The SIGNAL compiler checks deadlock and determinism of the program, and produces an intermediate level code equivalent to a nested family of concurrent automata. The compilation algorithm is supported by: (1) a behavioural semantics of SIGNAL programs in terms of conditional rewriting rules, (2) the coding of this semantics into the skew product of a dynamical system over the field of integers modulo 3 and directed graphs, (3) an algebraic algorithm to transform the above coding into an equivalent executable one, which provides by the way an execution semantics of the language. We briefly discuss the implementation aspects, and explain the capabilities and limitations of the current version of the SIGNAL compiler.},
	number = {2},
	urldate = {2018-02-01},
	journal = {Science of Computer Programming},
	author = {Benveniste, Albert and Le Guernic, Paul and Jacquemot, Christian},
	month = sep,
	year = {1991},
	pages = {103--149},
	file = {Benveniste et al_1991_Synchronous programming with events and relations - the SIGNAL language and its.pdf:/home/michael/Dropbox/zotero-pdfs/B/Benveniste et al_1991_Synchronous programming with events and relations - the SIGNAL language and its.pdf:application/pdf}
}

@article{boussinot_esterel_1991,
	title = {The {Esterel} language},
	volume = {79},
	doi = {10.1109/5.97299},
	abstract = {The authors present the basics of the ESTEREL reactive model of synchronous parallel systems. The ESTEREL programming style, based on instantaneous communications and decisions, is illustrated through the example of a mouse handler. The ESTEREL formal semantics is described, and it is shown how programs can be compiled into finite state
sequential machines for efficient execution. The implementation is described with the ESTEREL environment, including simulation, and verification and validation tools. Some ESTEREL uses in various contexts are reported},
	journal = {Proceedings of the IEEE},
	author = {Boussinot, Frédéric and Simone, Robert},
	month = oct,
	year = {1991},
	pages = {1293--1304},
	file = {Boussinot_Simone_1991_The Esterel language.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boussinot_Simone_1991_The Esterel language.pdf:application/pdf}
}

@article{halbwachs_synchronous_2000,
	title = {The synchronous dataflow programming language {LUSTRE}},
	abstract = {This paper describes the language Lustre, which is a dataflow synchronous language, designed for programming reactive systems --- such as automatic control and monitoring systems --- as well as for describing hardware. The dataflow aspect of Lustre makes it very close to usual description tools in these domains (block-diagrams, networks of operators, dynamical samples-systems, etc: : : ), and its synchronous interpretation makes it well suited for handling time in programs. Moreover, this synchronous interpretation allows it to be compiled into an efficient sequential program. Finally, the Lustre formalism is very similar to temporal logics. This allows the language to be used for both writing programs and expressing program properties, which results in an original program verification methodology. 1 Introduction Reactive systems Reactive systems have been defined as computing systems which continuously interact with a given physical environment, when this environment is ...},
	author = {Halbwachs, Nicolas and Caspi, P and Raymond, Pascal and Pilaud, D},
	month = jan,
	year = {2000},
	file = {Halbwachs et al_2000_The synchronous dataflow programming language LUSTRE.pdf:/home/michael/Dropbox/zotero-pdfs/H/Halbwachs et al_2000_The synchronous dataflow programming language LUSTRE.pdf:application/pdf}
}

@inproceedings{henzinger_embedded_2001,
	address = {New York, NY, USA},
	series = {{OM} '01},
	title = {Embedded {Control} {Systems} {Development} with {Giotto}},
	isbn = {978-1-58113-426-1},
	url = {http://doi.acm.org/10.1145/384198.384208},
	doi = {10.1145/384198.384208},
	abstract = {Giotto is a principled, tool-supported design methodology for implementing embedded control systems on platforms of possibly distributed sensors, actuators, CPUs, and networks. Giotto is based on the principle that time-triggered task invocations plus time-triggered mode switches can form the abstract essence of programming real-time control systems. Giotto consists of a programming language with a formal semantics, and a retargetable compiler and runtime library. Giotto supports the automation of control system design by strictly separating platform-independent functionality and timing concerns from platform-dependent scheduling and communication issues. The time-triggered predictability of Giotto makes it particularly suitable for safety-critical applications with hard real-time constraints. We illustrate the platform-independence and time-triggered execution of Giotto by coordinating a heterogeneous flock of Intel x86 robots and Lego Mindstorms robots.},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the 2001 {ACM} {SIGPLAN} {Workshop} on {Optimization} of {Middleware} and {Distributed} {Systems}},
	publisher = {ACM},
	author = {Henzinger, Thomas A. and Horowitz, Benjamin and Kirsch, Christoph Meyer},
	year = {2001},
	pages = {64--72},
	file = {Henzinger et al_2001_Embedded Control Systems Development with Giotto.pdf:/home/michael/Dropbox/zotero-pdfs/H/Henzinger et al_2001_Embedded Control Systems Development with Giotto.pdf:application/pdf}
}

@book{mitchell_mesa_1979,
	address = {Palo Alot, CA},
	edition = {5.0},
	title = {Mesa {Language} {Manual}},
	url = {http://bitsavers.informatik.uni-stuttgart.de/pdf/xerox/parc/techReports/CSL-79-3_Mesa_Language_Manual_Version_5.0.pdf},
	urldate = {2018-02-01},
	publisher = {Xerox},
	author = {Mitchell, James and Maybury, William and Sweet, Richard},
	month = apr,
	year = {1979},
	note = {CSL-79-3},
	file = {Mitchell et al_1979_Mesa Language Manual.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mitchell et al_1979_Mesa Language Manual.pdf:application/pdf}
}

@inproceedings{wan_event-driven_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Event-{Driven} {FRP}},
	isbn = {978-3-540-43092-6 978-3-540-45587-5},
	url = {https://link.springer.com/chapter/10.1007/3-540-45587-6_11},
	doi = {10.1007/3-540-45587-6_11},
	abstract = {Functional Reactive Programming (FRP) is a high-level declarative language for programming reactive systems. Previous work on FRP has demonstrated its utility in a wide range of application domains, including animation, graphical user interfaces, and robotics. FRP has an elegant continuous-time denotational semantics. However, it guarantees no bounds on execution time or space, thus making it unsuitable for many embedded real-time applications. To alleviate this problem, we recently developed Real-Time FRP (RT-FRP), whose operational semantics permits us to formally guarantee bounds on both execution time and space.In this paper we present a formally verifiable compilation strategy from a new language based on RT-FRP into imperative code. The new language, called Event-Driven FRP (E-FRP), is more tuned to the paradigm of having multiple external events. While it is smaller than RT-FRP, it features a key construct that allows us to compile the language into efficient code. We have used this language and its compiler to generate code for a small robot controller that runs on a PIC16C66 micro-controller. Because the formal specification of compilation was crafted more for clarity and for technical convenience, we describe an implementation that produces more efficient code.},
	language = {en},
	urldate = {2018-02-01},
	booktitle = {Practical {Aspects} of {Declarative} {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Wan, Zhanyong and Taha, Walid and Hudak, Paul},
	month = jan,
	year = {2002},
	pages = {155--172},
	file = {Wan et al_2002_Event-Driven FRP.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wan et al_2002_Event-Driven FRP.pdf:application/pdf}
}

@inproceedings{ford_flux_1997,
	address = {New York, NY, USA},
	series = {{SOSP} '97},
	title = {The {Flux} {OSKit}: {A} {Substrate} for {Kernel} and {Language} {Research}},
	isbn = {978-0-89791-916-6},
	shorttitle = {The {Flux} {OSKit}},
	url = {http://doi.acm.org/10.1145/268998.266642},
	doi = {10.1145/268998.266642},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the {Sixteenth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Ford, Bryan and Back, Godmar and Benson, Greg and Lepreau, Jay and Lin, Albert and Shivers, Olin},
	year = {1997},
	pages = {38--51},
	file = {Ford et al_1997_The Flux OSKit - A Substrate for Kernel and Language Research.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ford et al_1997_The Flux OSKit - A Substrate for Kernel and Language Research.pdf:application/pdf}
}

@inproceedings{chaudron_framework_2001,
	title = {A framework for formal component-based software architecting},
	booktitle = {Proceedings of {Specification} and {Verification} of {Component}-{Based} {Systems} {Workshop}},
	author = {Chaudron, M. R. V. and Eskenazi, E. M. and Fioukov, A. V. and Hammer, D. K.},
	year = {2001},
	pages = {73--80},
	file = {Chaudron et al_2001_A framework for formal component-based software architecting.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chaudron et al_2001_A framework for formal component-based software architecting.pdf:application/pdf}
}

@inproceedings{flatt_units:_1998,
	address = {New York, NY, USA},
	series = {{PLDI} '98},
	title = {Units: {Cool} {Modules} for {HOT} {Languages}},
	isbn = {978-0-89791-987-6},
	shorttitle = {Units},
	url = {http://doi.acm.org/10.1145/277650.277730},
	doi = {10.1145/277650.277730},
	abstract = {A module system ought to enable assembly-line programming using separate compilation and an expressive linking language. Separate compilation allows programmers to develop parts of a program independently. A linking language gives programmers precise control over the assembly of parts into a whole. This paper presents models of program units, MzScheme's module language for assembly-line programming. Units support separate compilation, independent module reuse, cyclic dependencies, hierarchical structuring, and dynamic linking. The models explain how to integrate units with untyped and typed languages such as Scheme and ML.},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1998 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Flatt, Matthew and Felleisen, Matthias},
	year = {1998},
	pages = {236--248},
	file = {Flatt_Felleisen_1998_Units - Cool Modules for HOT Languages.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flatt_Felleisen_1998_Units - Cool Modules for HOT Languages.pdf:application/pdf}
}

@article{kohler_click_2000,
	title = {The {Click} {Modular} {Router}},
	volume = {18},
	issn = {0734-2071},
	url = {http://doi.acm.org/10.1145/354871.354874},
	doi = {10.1145/354871.354874},
	abstract = {Clicks is a new software architecture for building flexible and configurable routers. A Click router is assembled from packet processing modules called elements. Individual elements implement simple router functions like packet classification, queuing, scheduling, and interfacing with network devices. A router configurable is a directed graph with elements at the vertices; packets flow along the edges of the graph. Several features make individual elements more powerful and complex configurations easier to write, including pull connections, which model packet flow drivn by transmitting hardware devices, and flow-based router context, which helps an element locate other interesting elements. Click configurations are modular and easy to extend. A standards-compliant Click IP router has 16 elements on its forwarding path; some of its elements are also useful in Ethernet switches and IP tunnelling configurations. Extending the IP router to support dropping policies, fairness among flows, or Differentiated Services simply requires adding a couple of element at the right place. On conventional PC hardware, the Click IP router achieves a maximum loss-free forwarding rate of 333,000 64-byte packets per second, demonstrating that Click's modular and flexible architecture is compatible with good performance.},
	number = {3},
	urldate = {2018-02-01},
	journal = {ACM Trans. Comput. Syst.},
	author = {Kohler, Eddie and Morris, Robert and Chen, Benjie and Jannotti, John and Kaashoek, M. Frans},
	month = aug,
	year = {2000},
	keywords = {component systems, routers, software router performance},
	pages = {263--297},
	file = {Kohler et al_2000_The Click Modular Router.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kohler et al_2000_The Click Modular Router.pdf:application/pdf}
}

@inproceedings{mosberger_making_1996,
	title = {Making {Paths} {Explicit} in the {Scout} {Operating} {System}},
	abstract = {This paper makes a case for paths as an explicit abstraction in operating system design. Paths provide a unifying infrastructure for several OS mechanisms that have been introduced in the last several years, including fbufs, integrated layer processing, packet classifiers, code specialization, and migrating threads. This paper articulates the potential advantages of a path-based OS structure, describes the specific path architecture implemented in the Scout OS, and demonstrates the advantages in a particular application domain---receiving, decoding, and displaying MPEG-compressed video. Department of Computer Science The University of Arizona Tucson, AZ  1 Introduction  Layering is a fundamental structuring technique with a long history in system design. From early work on layered operating systems and network architectures [HFC76, Zim80], to more recent advances in stackable systems [Rit84, HP91, HP94, RBF  +  95], layering has played a central role in managing complexity, isolating ...},
	author = {Mosberger, David and Peterson, Larry},
	year = {1996},
	pages = {153--167},
	file = {Mosberger_Peterson_1996_Making Paths Explicit in the Scout Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mosberger_Peterson_1996_Making Paths Explicit in the Scout Operating System.pdf:application/pdf}
}

@inproceedings{hutchinson_design_1988,
	address = {New York, NY, USA},
	series = {{SIGCOMM} '88},
	title = {Design of the {X}-kernel},
	isbn = {978-0-89791-279-2},
	url = {http://doi.acm.org/10.1145/52324.52332},
	doi = {10.1145/52324.52332},
	abstract = {The x-kernel is a configurable operating system kernel designed to support experimentation in interprocess communication and distributed programming. The x-kernel's underlying architecture provides a rich set of abstractions that are used to construct and compose communication protocols. The architecture is interesting because the abstractions are both general enough to accommodate a wide range of protocols and efficient enough to provide a useful testbed in which protocol performance can be accurately measured.},
	urldate = {2018-02-01},
	booktitle = {Symposium {Proceedings} on {Communications} {Architectures} and {Protocols}},
	publisher = {ACM},
	author = {Hutchinson, N. and Peterson, L.},
	year = {1988},
	pages = {65--75},
	file = {Hutchinson_Peterson_1988_Design of the X-kernel.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hutchinson_Peterson_1988_Design of the X-kernel.pdf:application/pdf}
}

@inproceedings{fassino_think:_2002,
	address = {Berkeley, CA, USA},
	series = {{ATEC} '02},
	title = {Think: {A} {Software} {Framework} for {Component}-based {Operating} {System} {Kernels}},
	isbn = {978-1-880446-00-3},
	shorttitle = {Think},
	url = {http://dl.acm.org/citation.cfm?id=647057.713860},
	urldate = {2018-02-01},
	booktitle = {Proceedings of the {General} {Track} of the {Annual} {Conference} on {USENIX} {Annual} {Technical} {Conference}},
	publisher = {USENIX Association},
	author = {Fassino, Jean-Philippe and Stefani, Jean-Bernard and Lawall, Julia L. and Muller, Gilles},
	year = {2002},
	pages = {73--86},
	file = {Fassino et al_2002_Think - A Software Framework for Component-based Operating System Kernels.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fassino et al_2002_Think - A Software Framework for Component-based Operating System Kernels.pdf:application/pdf}
}

@inproceedings{martin_formal_2000,
	title = {Formal construction of the {Mathematically} {Analyzed} {Separation} {Kernel}},
	doi = {10.1109/ASE.2000.873658},
	abstract = {Describes the formal specification and development of a separation kernel. The Mathematically Analyzed Separation Kernel (MASK), has been used by Motorola on a smartcard project, and as part of a hardware cryptographic platform called the Advanced INFOSEC (INFOrmation SECurity) Machine (AIM). Both MASK and AIM were jointly developed by Motorola and the National Security Agency (NSA). This paper first describes the separation kernel concept and its importance to information security. Next, it illustrates the Specware formal development methodology that was used in the development of MASK. Experiences and lessons learned from this formal development process are discussed. Finally, the results of the MASK development process are described, project successes are discussed, and related MASK research is highlighted.},
	booktitle = {Proceedings {ASE} 2000. {Fifteenth} {IEEE} {International} {Conference} on {Automated} {Software} {Engineering}},
	author = {Martin, W. and White, P. and Taylor, F. S. and Goldberg, A.},
	month = sep,
	year = {2000},
	keywords = {Information security, formal specification, Operating systems, Hardware, Advanced INFOSEC Machine, AIM, Books, Certification, Context, cryptography, Cryptography, Data security, firmware, hardware cryptographic platform, information security, Kernel, MASK development process, Mathematically Analyzed Separation Kernel, Motorola, National security, National Security Agency, operating system kernels, smart cards, smartcard project, Specware formal development methodology},
	pages = {133--141},
	file = {Martin et al_2000_Formal construction of the Mathematically Analyzed Separation Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/M/Martin et al_2000_Formal construction of the Mathematically Analyzed Separation Kernel.pdf:application/pdf}
}

@inproceedings{krohn_noninterference_2009,
	title = {Noninterference for a {Practical} {DIFC}-{Based} {Operating} {System}},
	doi = {10.1109/SP.2009.23},
	abstract = {The Flume system is an implementation of decentralized information flow control (DIFC) at the operating system level. Prior work has shown Flume can be implemented as a practical extension to the Linux operating system, allowing real Web applications to achieve useful security guarantees. However, the question remains if the Flume system is actually secure. This paper compares Flume with other recent DIFC systems like Asbestos, arguing that the latter is inherently susceptible to certain wide-bandwidth covert channels, and proving their absence in Flume by means of a noninterference proof in the communicating sequential processes formalism.},
	booktitle = {2009 30th {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Krohn, M. and Tromer, E.},
	month = may,
	year = {2009},
	keywords = {Information security, Privacy, security of data, Linux, Control systems, Operating systems, operating systems (computers), Data security, Kernel, Artificial intelligence, Asbestos, communicating sequential processes, Communicating Sequential Processes, Communication system security, covert channels, decentralized information flow control, Dynamic programming, Flume system, Information flow control, Internet, Linux operating system, noninterference, noninterference proof, practical DIFC-based operating system, Web applications},
	pages = {61--76},
	file = {Krohn_Tromer_2009_Noninterference for a Practical DIFC-Based Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/K/Krohn_Tromer_2009_Noninterference for a Practical DIFC-Based Operating System.pdf:application/pdf}
}

@misc{green_hill_software_integrity_nodate,
	title = {{INTEGRITY} {Real}-time {Operating} {System}},
	url = {https://www.ghs.com/products/rtos/integrity.html},
	urldate = {2018-02-08},
	author = {Green Hill Software}
}

@misc{martonosi_check_nodate,
	title = {Check {Research} {Tools} and {Papers}},
	url = {http://check.cs.princeton.edu/},
	urldate = {2018-02-06},
	author = {Martonosi, Margaret}
}

@inproceedings{hangal_tsotool:_2004,
	address = {Washington, DC, USA},
	series = {{ISCA} '04},
	title = {{TSOtool}: {A} {Program} for {Verifying} {Memory} {Systems} {Using} the {Memory} {Consistency} {Model}},
	isbn = {978-0-7695-2143-5},
	shorttitle = {{TSOtool}},
	url = {http://dl.acm.org/citation.cfm?id=998680.1006710},
	abstract = {In this paper, we describe TSOtool, a program to check thebehavior of the memory subsystem in a shared memorymultiprocessor. TSOtool runs pseudo-randomly generatedprograms with data races on a system compliant with theTotal Store Order (TSO) memory consistency model; it thenchecks the results of the program against the formal TSOspecification. Such analysis can expose subtle memory errorslike data corruption, atomicity violation and illegalinstruction ordering.While verifying TSO compliance completely is an NP-completeproblem, we describe a new polynomial timealgorithm which is incorporated in TSOtool. In spite of beingincomplete, it has been successful in detecting several bugs inthe design of commercial microprocessors and systems,during both pre-silicon and post-silicon phases of validation.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the 31st {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {IEEE Computer Society},
	author = {Hangal, Sudheendra and Vahia, Durgam and Manovit, Chaiyasit and Lu, Juin-Yeu Joseph},
	year = {2004},
	keywords = {Memory consistency models, Multiprocessor verification, Sequential Consistency, Total Store Order},
	pages = {114--},
	file = {Hangal et al_2004_TSOtool.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hangal et al_2004_TSOtool.pdf:application/pdf}
}

@book{sarkar_synchronising_2012,
	title = {Synchronising {C}/{C}++ and {POWER}},
	abstract = {Shared memory concurrency relies on synchronisation primitives: compare-and-swap, load-reserve/store-conditional (aka LL/SC), language-level mutexes, and so on. In a sequentially consistent setting, or even in the TSO setting of x86 and Sparc, these have well-understood semantics. But in the very relaxed settings of IBM R ○ POWER R ○ , ARM, or C/C++, it remains surprisingly unclear exactly what the programmer can depend on. This paper studies relaxed-memory synchronisation. On the hardware side, we give a clear semantic characterisation of the load-reserve/store-conditional primitives as provided by POWER multiprocessors, for the first time since they were introduced 20 years ago; we cover their interaction with relaxed loads, stores, barriers, and dependencies. Our model, while not officially sanctioned by the vendor, is validated by extensive testing, comparing actual implementation behaviour against an oracle generated from the model, and by detailed discussion with IBM staff. We believe the ARM semantics to be similar. On the software side, we prove sound a proposed compilation scheme of the C/C++ synchronisation constructs to POWER, including C/C++ spinlock mutexes, fences, and read-modify-write operations, together with the simpler atomic operations for which soundness is already known from our previous work; this is a first step in verifying concurrent algorithms that use load-reserve/storeconditional with respect to a realistic semantics. We also build confidence in the C/C++ model in its own terms, fixing some omissions and contributing to the C standards committee adoption of the C++11 concurrency model.},
	author = {Sarkar, Susmit and Memarian, Kayvan and Owens, Scott and Batty, Mark and Sewell, Peter and Maranget, Luc and Alglave, Jade and Williams, Derek},
	year = {2012},
	file = {Sarkar et al_2012_Synchronising C-C++ and POWER.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sarkar et al_2012_Synchronising C-C++ and POWER.pdf:application/pdf}
}

@book{nipkow_proof_2008,
	title = {A {Proof} {Assistant} {For} {Higher} {Order} {Logic}},
	abstract = {This volume is a self-contained introduction to interactive proof in higherorder logic (HOL), using the proof assistant Isabelle. It is written for potential users rather than for our colleagues in the research world. The book has three parts. – The first part, Elementary Techniques, shows how to model functional programs in higher-order logic. Early examples involve lists and the natural numbers. Most proofs are two steps long, consisting of induction on a chosen variable followed by the auto tactic. But even this elementary part covers such advanced topics as nested and mutual recursion. – The second part, Logic and Sets, presents a collection of lower-level tactics that you can use to apply rules selectively. It also describes Isabelle/HOL’s treatment of sets, functions and relations and explains how to define sets inductively. One of the examples concerns the theory of model checking, and another is drawn from a classic textbook on formal languages. – The third part, Advanced Material, describes a variety of other topics.},
	author = {Nipkow, Tobias and Paulson, Lawrence C. and Wenzel, Markus},
	year = {2008},
	file = {Nipkow et al_2008_A Proof Assistant For Higher Order Logic.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nipkow et al_2008_A Proof Assistant For Higher Order Logic.pdf:application/pdf}
}

@inproceedings{mulligan_lem:_2014,
	address = {New York, NY, USA},
	series = {{ICFP} '14},
	title = {Lem: {Reusable} {Engineering} of {Real}-world {Semantics}},
	isbn = {978-1-4503-2873-9},
	shorttitle = {Lem},
	url = {http://doi.acm.org/10.1145/2628136.2628143},
	doi = {10.1145/2628136.2628143},
	abstract = {Recent years have seen remarkable successes in rigorous engineering: using mathematically rigorous semantic models (not just idealised calculi) of real-world processors, programming languages, protocols, and security mechanisms, for testing, proof, analysis, and design. Building these models is challenging, requiring experimentation, dialogue with vendors or standards bodies, and validation; their scale adds engineering issues akin to those of programming to the task of writing clear and usable mathematics. But language and tool support for specification is lacking. Proof assistants can be used but bring their own difficulties, and a model produced in one, perhaps requiring many person-years effort and maintained over an extended period, cannot be used by those familiar with another. We introduce Lem, a language for engineering reusable large-scale semantic models. The Lem design takes inspiration both from functional programming languages and from proof assistants, and Lem definitions are translatable into OCaml for testing, Coq, HOL4, and Isabelle/HOL for proof, and LaTeX and HTML for presentation. This requires a delicate balance of expressiveness, careful library design, and implementation of transformations - akin to compilation, but subject to the constraint of producing usable and human-readable code for each target. Lem's effectiveness is demonstrated by its use in practice.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Mulligan, Dominic P. and Owens, Scott and Gray, Kathryn E. and Ridge, Tom and Sewell, Peter},
	year = {2014},
	keywords = {proof assistants, specification languages, lem, real-world semantics},
	pages = {175--188},
	file = {Mulligan et al_2014_Lem.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mulligan et al_2014_Lem.pdf:application/pdf}
}

@inproceedings{batty_mathematizing_2011,
	address = {New York, NY, USA},
	series = {{POPL} '11},
	title = {Mathematizing {C}++ {Concurrency}},
	isbn = {978-1-4503-0490-0},
	url = {http://doi.acm.org/10.1145/1926385.1926394},
	doi = {10.1145/1926385.1926394},
	abstract = {Shared-memory concurrency in C and C++ is pervasive in systems programming, but has long been poorly defined. This motivated an ongoing shared effort by the standards committees to specify concurrent behaviour in the next versions of both languages. They aim to provide strong guarantees for race-free programs, together with new (but subtle) relaxed-memory atomic primitives for high-performance concurrent code. However, the current draft standards, while the result of careful deliberation, are not yet clear and rigorous definitions, and harbour substantial problems in their details. In this paper we establish a mathematical (yet readable) semantics for C++ concurrency. We aim to capture the intent of the current (`Final Committee') Draft as closely as possible, but discuss changes that fix many of its problems. We prove that a proposed x86 implementation of the concurrency primitives is correct with respect to the x86-TSO model, and describe our Cppmem tool for exploring the semantics of examples, using code generated from our Isabelle/HOL definitions. Having already motivated changes to the draft standard, this work will aid discussion of any further changes, provide a correctness condition for compilers, and give a much-needed basis for analysis and verification of concurrent C and C++ programs.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the 38th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Batty, Mark and Owens, Scott and Sarkar, Susmit and Sewell, Peter and Weber, Tjark},
	year = {2011},
	keywords = {semantics, relaxed memory models},
	pages = {55--66},
	file = {Batty et al_2011_Mathematizing C++ Concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/B/Batty et al_2011_Mathematizing C++ Concurrency.pdf:application/pdf}
}

@inproceedings{batty_overhauling_2016,
	address = {New York, NY, USA},
	series = {{POPL} '16},
	title = {Overhauling {SC} {Atomics} in {C}11 and {OpenCL}},
	isbn = {978-1-4503-3549-2},
	url = {http://doi.acm.org/10.1145/2837614.2837637},
	doi = {10.1145/2837614.2837637},
	abstract = {Despite the conceptual simplicity of sequential consistency (SC), the semantics of SC atomic operations and fences in the C11 and OpenCL memory models is subtle, leading to convoluted prose descriptions that translate to complex axiomatic formalisations. We conduct an overhaul of SC atomics in C11, reducing the associated axioms in both number and complexity. A consequence of our simplification is that the SC operations in an execution no longer need to be totally ordered. This relaxation enables, for the first time, efficient and exhaustive simulation of litmus tests that use SC atomics. We extend our improved C11 model to obtain the first rigorous memory model formalisation for OpenCL (which extends C11 with support for heterogeneous many-core programming). In the OpenCL setting, we refine the SC axioms still further to give a sensible semantics to SC operations that employ a ‘memory scope’ to restrict their visibility to specific threads. Our overhaul requires slight strengthenings of both the C11 and the OpenCL memory models, causing some behaviours to become disallowed. We argue that these strengthenings are natural, and that all of the formalised C11 and OpenCL compilation schemes of which we are aware (Power and x86 CPUs for C11, AMD GPUs for OpenCL) remain valid in our revised models. Using the HERD memory model simulator, we show that our overhaul leads to an exponential improvement in simulation time for C11 litmus tests compared with the original model, making *exhaustive* simulation competitive, time-wise, with the *non-exhaustive* CDSChecker tool.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the 43rd {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Batty, Mark and Donaldson, Alastair F. and Wickerson, John},
	year = {2016},
	keywords = {Formal methods, graphics processing unit (GPU), heterogeneous programming, HOL theorem prover, language design, program simulation, weak memory models},
	pages = {634--648},
	file = {Batty et al_2016_Overhauling SC Atomics in C11 and OpenCL.pdf:/home/michael/Dropbox/zotero-pdfs/B/Batty et al_2016_Overhauling SC Atomics in C11 and OpenCL.pdf:application/pdf}
}

@book{petri_cooking_nodate,
	title = {Cooking the {Books}: {Formalizing} {JMM} {Implementation} {Recipes}∗},
	shorttitle = {Cooking the {Books}},
	abstract = {The Java Memory Model (JMM) is intended to characterize the meaning of concurrent Java programs. Because of the model’s complexity, however, its definition cannot be easily trans-planted within an optimizing Java compiler, even though an important rationale for its design was to ensure Java compiler optimizations are not unduly hampered because of the language’s concurrency features. In response, the JSR-133 Cookbook for Compiler Writers [15], an informal guide to realizing the principles underlying the JMM on different (relaxed-memory) platforms was developed. The goal of the cookbook is to give compiler writers a relatively simple, yet reasonably efficient, set of reordering-based recipes that satisfy JMM constraints. In this paper, we present the first formalization of the cookbook, providing a semantic basis upon which the relationship between the recipes defined by the cookbook and the guarantees enforced by the JMM can be rigorously established. Notably, one artifact of our investigation is that the rules defined by the cookbook for compiling Java onto Power are inconsistent with the requirements of the JMM, a surprising result, and one which justifies our belief in the need for formally provable definitions to reason about sophisticated (and racy) concurrency patterns in Java, and their implementation on modern-day relaxed-memory hardware. Our formalization enables simulation arguments between an architecture-independent inter-mediate representation of the kind suggested by [15] with machine abstractions for Power and x86. Moreover, we provide fixes for cookbook recipes that are inconsistent with the behaviors admitted by the target platform, and prove the correctness of these repairs.},
	author = {Petri, Gustavo and Vitek, Jan and Jagannathan, Suresh},
	file = {Petri et al_Cooking the Books.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petri et al_Cooking the Books.pdf:application/pdf}
}

@inproceedings{batty_clarifying_2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {Clarifying and {Compiling} {C}/{C}++ {Concurrency}: {From} {C}++11 to {POWER}},
	isbn = {978-1-4503-1083-3},
	shorttitle = {Clarifying and {Compiling} {C}/{C}++ {Concurrency}},
	url = {http://doi.acm.org/10.1145/2103656.2103717},
	doi = {10.1145/2103656.2103717},
	abstract = {The upcoming C and C++ revised standards add concurrency to the languages, for the first time, in the form of a subtle *relaxed memory model* (the *C++11 model*). This aims to permit compiler optimisation and to accommodate the differing relaxed-memory behaviours of mainstream multiprocessors, combining simple semantics for most code with high-performance *low-level atomics* for concurrency libraries. In this paper, we first establish two simpler but provably equivalent models for C++11, one for the full language and another for the subset without consume operations. Subsetting further to the fragment without low-level atomics, we identify a subtlety arising from atomic initialisation and prove that, under an additional condition, the model is equivalent to sequential consistency for race-free programs. We then prove our main result, the correctness of two proposed compilation schemes for the C++11 load and store concurrency primitives to Power assembly, having noted that an earlier proposal was flawed. (The main ideas apply also to ARM, which has a similar relaxed memory architecture.) This should inform the ongoing development of production compilers for C++11 and C1x, clarifies what properties of the machine architecture are required, and builds confidence in the C++11 and Power semantics.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Batty, Mark and Memarian, Kayvan and Owens, Scott and Sarkar, Susmit and Sewell, Peter},
	year = {2012},
	keywords = {semantics, relaxed memory models},
	pages = {509--520},
	file = {Batty et al_2012_Clarifying and Compiling C-C++ Concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/B/Batty et al_2012_Clarifying and Compiling C-C++ Concurrency.pdf:application/pdf}
}

@inproceedings{lustig_coatcheck:_2016,
	address = {New York, NY, USA},
	series = {{ASPLOS} '16},
	title = {{COATCheck}: {Verifying} {Memory} {Ordering} at the {Hardware}-{OS} {Interface}},
	isbn = {978-1-4503-4091-5},
	shorttitle = {{COATCheck}},
	url = {http://doi.acm.org/10.1145/2872362.2872399},
	doi = {10.1145/2872362.2872399},
	abstract = {Modern computer systems include numerous compute elements, from CPUs to GPUs to accelerators. Harnessing their full potential requires well-defined, properly-implemented memory consistency models (MCMs), and low-level system functionality such as virtual memory and address translation (AT). Unfortunately, it is difficult to specify and implement hardware-OS interactions correctly; in the past, many hardware and OS specification mismatches have resulted in implementation bugs in commercial processors. In an effort to resolve this verification gap, this paper makes the following contributions. First, we present COATCheck, an address translation-aware framework for specifying and statically verifying memory ordering enforcement at the microarchitecture and operating system levels. We develop a domain-specific language for specifying ordering enforcement, for including ordering-related OS events and hardware micro-operations, and for programmatically enumerating happens-before graphs. Using a fast and automated static constraint solver, COATCheck can efficiently analyze interesting and important memory ordering scenarios for modern, high-performance, out-of-order processors. Second, we show that previous work on Virtual Address Memory Consistency (VAMC) does not capture every translation-related ordering scenario of interest, and that some such cases even fall outside the traditional scope of consistency. We therefore introduce the term transistency model to describe the superset of consistency which captures all translation-aware sets of ordering rules.},
	urldate = {2018-02-06},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Lustig, Daniel and Sethi, Geet and Martonosi, Margaret and Bhattacharjee, Abhishek},
	year = {2016},
	keywords = {verification, memory consistency models, virtual memory, computer architecture, address translation},
	pages = {233--247},
	file = {Lustig et al_2016_COATCheck.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lustig et al_2016_COATCheck.pdf:application/pdf}
}

@inproceedings{lustig_pipecheck:_2014,
	title = {{PipeCheck}: {Specifying} and verifying microarchitectural enforcement of memory consistency models},
	shorttitle = {{PipeCheck}},
	booktitle = {Proceedings of the 47th {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture}},
	publisher = {IEEE Computer Society},
	author = {Lustig, Daniel and Pellauer, Michael and Martonosi, Margaret},
	year = {2014},
	pages = {635--646},
	file = {Lustig et al_2014_PipeCheck.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lustig et al_2014_PipeCheck.pdf:application/pdf}
}

@book{jackson_software_2006,
	title = {Software {Abstractions}: {Logic}, {Language}, and {Analysis}},
	isbn = {978-0-262-10114-1},
	shorttitle = {Software {Abstractions}},
	publisher = {The MIT Press},
	author = {Jackson, Daniel},
	year = {2006}
}

@inproceedings{lahav_repairing_2017,
	title = {Repairing sequential consistency in {C}/{C}++ 11},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Lahav, Ori and Vafeiadis, Viktor and Kang, Jeehoon and Hur, Chung-Kil and Dreyer, Derek},
	year = {2017},
	pages = {618--632},
	file = {Lahav et al_2017_Repairing sequential consistency in C-C++ 11.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lahav et al_2017_Repairing sequential consistency in C-C++ 11.pdf:application/pdf}
}

@inproceedings{boehm_foundations_2008,
	title = {Foundations of the {C}++ concurrency memory model},
	volume = {43},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Boehm, Hans-J. and Adve, Sarita V.},
	year = {2008},
	pages = {68--78},
	file = {Boehm_Adve_2008_Foundations of the C++ concurrency memory model.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boehm_Adve_2008_Foundations of the C++ concurrency memory model.pdf:application/pdf}
}

@article{alglave_herding_2014,
	title = {Herding {Cats}: {Modelling}, {Simulation}, {Testing}, and {Data} {Mining} for {Weak} {Memory}},
	volume = {36},
	issn = {0164-0925},
	shorttitle = {Herding {Cats}},
	url = {http://doi.acm.org/10.1145/2627752},
	doi = {10.1145/2627752},
	abstract = {We propose an axiomatic generic framework for modelling weak memory. We show how to instantiate this framework for Sequential Consistency (SC), Total Store Order (TSO), C++ restricted to release-acquire atomics, and Power. For Power, we compare our model to a preceding operational model in which we found a flaw. To do so, we define an operational model that we show equivalent to our axiomatic model. We also propose a model for ARM. Our testing on this architecture revealed a behaviour later acknowledged as a bug by ARM, and more recently, 31 additional anomalies. We offer a new simulation tool, called herd, which allows the user to specify the model of his choice in a concise way. Given a specification of a model, the tool becomes a simulator for that model. The tool relies on an axiomatic description; this choice allows us to outperform all previous simulation tools. Additionally, we confirm that verification time is vastly improved, in the case of bounded model checking. Finally, we put our models in perspective, in the light of empirical data obtained by analysing the C and C++ code of a Debian Linux distribution. We present our new analysis tool, called mole, which explores a piece of code to find the weak memory idioms that it uses.},
	number = {2},
	urldate = {2018-02-06},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Alglave, Jade and Maranget, Luc and Tautschnig, Michael},
	month = jul,
	year = {2014},
	keywords = {Concurrency, weak memory models, software verification},
	pages = {7:1--7:74},
	file = {Alglave et al_2014_Herding Cats.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alglave et al_2014_Herding Cats.pdf:application/pdf}
}

@techreport{arm_cortex-a9_2011,
	title = {Cortex-{A}9 {MPCore} {Programmer} {Advice} {Notice}: {Read}-after-{Read} {Hazards}},
	url = {http://infocenter.arm.com/help/topic/com.arm.doc.uan0004a/UAN0004A_a9_read_read.pdf},
	urldate = {2018-02-06},
	institution = {ARM},
	author = {ARM},
	year = {2011},
	file = {UAN0004A_a9_read_read.pdf:/home/michael/Zotero/storage/EFVFZDF5/UAN0004A_a9_read_read.pdf:application/pdf}
}

@inproceedings{tiwari_execution_2009,
	title = {Execution leases: {A} hardware-supported mechanism for enforcing strong non-interference},
	shorttitle = {Execution leases},
	booktitle = {Microarchitecture, 2009. {MICRO}-42. 42nd {Annual} {IEEE}/{ACM} {International} {Symposium} on},
	publisher = {IEEE},
	author = {Tiwari, Mohit and Li, Xun and Wassel, Hassan MG and Chong, Frederic T. and Sherwood, Timothy},
	year = {2009},
	pages = {493--504},
	file = {Tiwari et al_2009_Execution leases.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tiwari et al_2009_Execution leases.pdf:application/pdf}
}

@article{pullicino_jif:_2014,
	title = {Jif: {Language}-based {Information}-flow {Security} in {Java}},
	shorttitle = {Jif},
	url = {http://arxiv.org/abs/1412.8639},
	abstract = {In this report, we examine Jif, a Java extension which augments the language with features related to security. Jif adds support for security labels to Java's type system such that the developer can specify confidentiality and integrity policies to the various variables used in their program. We list the main features of Jif and discuss the information flow problem that Jif helps to solve. We see how the information flow problem occurs in real-world systems by looking at two examples: Civitas, a ballot/voting system where voters do not necessarily trust voting agents, and SIF, a web application container implemented using Jif. Finally, we implement a small program that simulates information flow in a booking system containing sensitive data and discuss the usefulness of Jif based on this program.},
	urldate = {2018-02-08},
	journal = {arXiv:1412.8639 [cs]},
	author = {Pullicino, Kyle},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.8639},
	keywords = {Computer Science - Programming Languages, Computer Science - Cryptography and Security},
	file = {Pullicino_2014_Jif.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pullicino_2014_Jif.pdf:application/pdf}
}

@book{wirth_project_2013,
	title = {Project {Oberon}: {The} {Design} of an {Operating} {System}, a {Compiler}, and a {Computer}},
	isbn = {0-201-54428-8},
	author = {Wirth, Niklaus and Gutknecht, Jürg},
	year = {2013},
	file = {Wirth_Gutknecht_2013_Project Oberon - The Design of an Operating System, a Compiler, and a Computer.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wirth_Gutknecht_2013_Project Oberon - The Design of an Operating System, a Compiler, and a Computer.pdf:application/pdf}
}

@misc{noauthor_eth_nodate,
	title = {{ETH} {Zürich} / {Oberon} {Bibliography}},
	url = {http://www.ethoberon.ethz.ch/books.html},
	urldate = {2018-02-09}
}

@book{reiser_programming_1992,
	address = {New York},
	title = {Programming in {Oberon}: {Steps} {Beyond} {Pascal} and {Modula}},
	isbn = {0-201-56543-9},
	url = {http://www.ethoberon.ethz.ch/WirthPubl/ProgInOberonWR.pdf},
	urldate = {2018-02-09},
	publisher = {Addison-Wesley},
	author = {Reiser, Martin and Wirth, Niklaus},
	year = {1992},
	file = {Reiser_Wirth_1992_Programming in Oberon - Steps Beyond Pascal and Modula.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reiser_Wirth_1992_Programming in Oberon - Steps Beyond Pascal and Modula.pdf:application/pdf}
}

@book{reiser_oberon_1991,
	address = {New York},
	title = {The {Oberon} system: user guide and programmer's manual},
	isbn = {0-201-54422-9},
	url = {http://oberoncore.ru/_media/library/mros1991.pdf},
	urldate = {2018-02-10},
	publisher = {Addison-Wesley},
	author = {Reiser, Martin},
	year = {1991},
	file = {Reiser_1991_The Oberon system - user guide and programmer's manual.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reiser_1991_The Oberon system - user guide and programmer's manual.pdf:application/pdf}
}

@article{wirth_programming_1988,
	title = {The programming language oberon},
	volume = {18},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380180707/abstract},
	doi = {10.1002/spe.4380180707},
	abstract = {This is the defining report of the programming language Oberon.},
	language = {en},
	number = {7},
	urldate = {2018-02-10},
	journal = {Software: Practice and Experience},
	author = {Wirth, N.},
	month = jul,
	year = {1988},
	keywords = {Programming language, Type extension},
	pages = {671--690},
	file = {Wirth_1988_The programming language oberon.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wirth_1988_The programming language oberon.pdf:application/pdf}
}

@article{reynolds_discoveries_1993,
	title = {The discoveries of continuations},
	volume = {6},
	number = {3-4},
	journal = {Lisp and symbolic computation},
	author = {Reynolds, John C.},
	year = {1993},
	pages = {233--247},
	file = {REYNOLDS_the-discoveries-of-continuations_1993_lisp-and-symbolic-computation.pdf:/home/michael/Zotero/storage/9IKKPNHI/REYNOLDS_the-discoveries-of-continuations_1993_lisp-and-symbolic-computation.pdf:application/pdf}
}

@article{hindley_principle_1969,
	title = {The principle type-scheme of an object in combinatory logic},
	volume = {146},
	journal = {Transactions of the american mathematical society},
	author = {Hindley, Roger},
	year = {1969},
	pages = {29--60},
	file = {HINDLEY_the-principal-type-scheme-of-an-object-in-combinatory-logic_1969_tams.pdf:/home/michael/Zotero/storage/ZJNL85BM/HINDLEY_the-principal-type-scheme-of-an-object-in-combinatory-logic_1969_tams.pdf:application/pdf}
}

@article{matz_system_2013,
	title = {System {V} application binary interface},
	volume = {99},
	journal = {AMD64 Architecture Processor Supplement, Draft v0},
	author = {Matz, Michael and Hubicka, Jan and Jaeger, Andreas and Mitchell, Mark},
	year = {2013},
	file = {mpx-linux64-abi.pdf:/home/michael/Zotero/storage/WC86NRTZ/mpx-linux64-abi.pdf:application/pdf}
}

@inproceedings{jagannathan_type-directed_1997,
	title = {Type-directed flow analysis for typed intermediate languages},
	booktitle = {International {Static} {Analysis} {Symposium}},
	publisher = {Springer},
	author = {Jagannathan, Suresh and Weeks, Stephen and Wright, Andrew},
	year = {1997},
	pages = {232--249},
	file = {JAGANNATHAN_type-directed-flow-analysis-for-typed-intermediate-languages.pdf:/home/michael/Zotero/storage/LGKWFFTV/JAGANNATHAN_type-directed-flow-analysis-for-typed-intermediate-languages.pdf:application/pdf}
}

@article{daley_virtual_1968,
	title = {Virtual memory, processes, and sharing in {Multics}},
	volume = {11},
	number = {5},
	journal = {Communications of the ACM},
	author = {Daley, Robert C. and Dennis, Jack B.},
	year = {1968},
	pages = {306--312},
	file = {DALEY-DENNIS_virtual-memory-processes-and-sharing-in-multics_1968.pdf:/home/michael/Zotero/storage/V9ZF7DIT/DALEY-DENNIS_virtual-memory-processes-and-sharing-in-multics_1968.pdf:application/pdf}
}

@article{dean_mapreduce:_nodate,
	title = {{MapReduce}: simplified data processing on large clusters},
	volume = {51},
	shorttitle = {{MapReduce}},
	number = {1},
	journal = {Com-munications ofthe ACM},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	pages = {107--l},
	file = {DEAN-GHEMAWAT_map-reduce-simpled-data-processing-on-large-clusters_2004.pdf:/home/michael/Zotero/storage/NH359HEM/DEAN-GHEMAWAT_map-reduce-simpled-data-processing-on-large-clusters_2004.pdf:application/pdf}
}

@inproceedings{shacham_geometry_2007,
	title = {The geometry of innocent flesh on the bone: {Return}-into-libc without function calls (on the x86)},
	shorttitle = {The geometry of innocent flesh on the bone},
	booktitle = {Proceedings of the 14th {ACM} conference on {Computer} and communications security},
	publisher = {ACM},
	author = {Shacham, Hovav},
	year = {2007},
	pages = {552--561},
	file = {SHACHAM_the-geometry-of-innocent-flesh-on-the-bone-return-into-libc-without-function-calls_2007.pdf:/home/michael/Zotero/storage/NWX4WDZD/SHACHAM_the-geometry-of-innocent-flesh-on-the-bone-return-into-libc-without-function-calls_2007.pdf:application/pdf}
}

@article{clark_design_1995,
	title = {The design philosophy of the {DARPA} internet protocols},
	volume = {25},
	number = {1},
	journal = {ACM SIGCOMM Computer Communication Review},
	author = {Clark, David D.},
	year = {1995},
	pages = {102--111},
	file = {CLARK_the-design-philosophy-of-the-darpa-internet-protocols.pdf:/home/michael/Zotero/storage/W68KG7BS/CLARK_the-design-philosophy-of-the-darpa-internet-protocols.pdf:application/pdf}
}

@article{diffie_new_1976,
	title = {New directions in cryptography},
	volume = {22},
	number = {6},
	journal = {IEEE transactions on Information Theory},
	author = {Diffie, Whitfield and Hellman, Martin},
	year = {1976},
	pages = {644--654},
	file = {[1]_DIFFIE-HELLMAN_new-directions-in-crytography_1976.pdf:/home/michael/Zotero/storage/4LZJCGJ6/[1]_DIFFIE-HELLMAN_new-directions-in-crytography_1976.pdf:application/pdf}
}

@article{diffie_first_1988,
	title = {The first ten years of public-key cryptography},
	volume = {76},
	number = {5},
	journal = {Proceedings of the IEEE},
	author = {Diffie, Whitfield},
	year = {1988},
	pages = {560--577},
	file = {[0]_DIFFIE_the-first-ten-years-of-public-key-crytography_1988.pdf:/home/michael/Zotero/storage/R5A5B7ND/[0]_DIFFIE_the-first-ten-years-of-public-key-crytography_1988.pdf:application/pdf}
}

@techreport{wirth_design_2015,
	title = {The {Design} of a {RISC} {Architecture} and its {Implementation} with an {FPGA}},
	url = {https://www.inf.ethz.ch/personal/wirth/FPGA-relatedWork/RISC.pdf},
	urldate = {2018-02-10},
	author = {Wirth, Niklaus},
	month = jan,
	year = {2015},
	pages = {24},
	file = {RISC.pdf:/home/michael/Zotero/storage/6NRM76PJ/RISC.pdf:application/pdf}
}

@article{wirth_oberon_1989,
	title = {The oberon system},
	volume = {19},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380190905/abstract},
	doi = {10.1002/spe.4380190905},
	abstract = {In this paper we describe an operating system for a workstation designed and implemented by the authors within two and a half years. It includes memory management and module loader, a file system, a viewer system, editors for text and graphics, a compiler, a server interface and various tools. The primary motivation was to demonstrate the feasibility of a small, yet highly flexible and powerful, system, a system that is a (decimal) order of magnitude smaller than commonly used operating systems. This is possible due to regularity of concepts and concentration on the essential. The benefits are not only fewer resources needed, but elegance and generality of concepts resulting in transparency and convenience of use and increased reliability. A corner-stone of this approach is genuine extensibility, which is achieved by a new language, in particular by a facility called type extension. It allows for the integration of variables (objects) of a new, extended type in structures of elements of an existing base type.},
	language = {en},
	number = {9},
	urldate = {2018-02-10},
	journal = {Software: Practice and Experience},
	author = {Wirth, N. and Gutknecht, J.},
	month = sep,
	year = {1989},
	keywords = {Operating system, Object-oriented programming, Multi-tasking, Persistent data structures, Storage management, Viewer system},
	pages = {857--893},
	file = {Wirth_Gutknecht_1989_The oberon system.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wirth_Gutknecht_1989_The oberon system.pdf:application/pdf}
}

@article{backus_revised_1963,
	title = {Revised {Report} on the {Algorithm} {Language} {ALGOL} 60},
	volume = {6},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/366193.366201},
	doi = {10.1145/366193.366201},
	number = {1},
	urldate = {2018-02-10},
	journal = {Commun. ACM},
	author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M.},
	editor = {Naur, P.},
	month = jan,
	year = {1963},
	pages = {1--17},
	file = {Backus et al_1963_Revised Report on the Algorithm Language ALGOL 60.pdf:/home/michael/Dropbox/zotero-pdfs/B/Backus et al_1963_Revised Report on the Algorithm Language ALGOL 60.pdf:application/pdf}
}

@article{hoare_axiomatic_1973,
	title = {An axiomatic definition of the programming language {PASCAL}},
	volume = {2},
	number = {4},
	journal = {Acta Informatica},
	author = {Hoare, Charles Antony Richard and Wirth, Niklaus},
	year = {1973},
	pages = {335--355},
	file = {Hoare_Wirth_1973_An axiomatic definition of the programming language PASCAL.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_Wirth_1973_An axiomatic definition of the programming language PASCAL.pdf:application/pdf}
}

@phdthesis{szyperski_insight_1992,
	type = {Doctoral {Thesis}},
	title = {Insight {ETHOS}: on object-orientation in operating systems},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
	shorttitle = {Insight {ETHOS}},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/140827},
	language = {en},
	urldate = {2018-02-10},
	school = {ETH Zurich},
	author = {Szyperski, Clemens},
	year = {1992},
	doi = {10.3929/ethz-a-000666071},
	file = {Full Text PDF:/home/michael/Zotero/storage/UCVCJNF9/Szyperski - 1992 - Insight ETHOS on object-orientation in operating .pdf:application/pdf}
}

@inproceedings{elias_wheres_2017,
	title = {Where's {The} {Bear}?: {Automating} {Wildlife} {Image} {Processing} {Using} {IoT} and {Edge} {Cloud} {Systems}},
	isbn = {978-1-4503-4966-6},
	shorttitle = {Where's {The} {Bear}?},
	url = {http://dl.acm.org/citation.cfm?doid=3054977.3054986},
	doi = {10.1145/3054977.3054986},
	language = {en},
	urldate = {2018-02-12},
	publisher = {ACM Press},
	author = {Elias, Andy Rosales and Golubovic, Nevena and Krintz, Chandra and Wolski, Rich},
	year = {2017},
	pages = {247--258},
	file = {Elias et al_2017_Where's The Bear - - Automating Wildlife Image Processing Using IoT and Edge.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elias et al_2017_Where's The Bear - - Automating Wildlife Image Processing Using IoT and Edge.pdf:application/pdf}
}

@inproceedings{krintz_smartfarm:_2016,
	title = {{SmartFarm}: {Improving} {Agriculture} {Sustainability} {Using} {Modern} {Information} {Technology}},
	url = {http://www.cs.ucsb.edu/~ckrintz/papers/dsfew16.pdf},
	doi = {10.1145/1235},
	abstract = {In  this  paper,  we  overview  our  work  on  an  open  source,
hybrid cloud approach to agriculture analytics for enabling
sustainable farming practices.
SmartFarm
integrates dis-
parate  environmental  sensor  technologies  into  an  on-farm,
private  cloud  software  infrastructure  that  provides  farm-
ers  with  a  secure,  easy  to  use,  low-cost  data  analysis  sys-
tem.
SmartFarm
couples data from external cloud sources
(weather  predictions,  satellite  imagery,  state  and  national
datasets,  etc) with farm-local  statistics,  provides  an inter-
face into which custom analytics apps can be plugged, and
ensures that all private data remain under grower control},
	urldate = {2018-02-12},
	author = {Krintz, Chandra and Wolski, Rich and Golubovic, Nevena and Lampel, Benji and Kulkarni, Varun and Sethuramasamyraja, Balaji and Roberts, Bruce and Liu, Bo},
	year = {2016},
	file = {Krintz et al_2016_SmartFarm - Improving Agriculture Sustainability Using Modern Information.pdf:/home/michael/Dropbox/zotero-pdfs/K/Krintz et al_2016_SmartFarm - Improving Agriculture Sustainability Using Modern Information.pdf:application/pdf}
}

@techreport{chef_continuous_2018,
	title = {Continuous {Automation} for the {Continuous} {Enterprise}},
	url = {https://pages.chef.io/rs/255-VFB-268/images/Continuous-Automation-for-the-Continuous-Enterprise.pdf},
	urldate = {2018-02-13},
	institution = {Chef},
	author = {Chef},
	year = {2018},
	file = {Continuous-Automation-for-the-Continuous-Enterprise.pdf:/home/michael/Zotero/storage/5T8KTHEC/Continuous-Automation-for-the-Continuous-Enterprise.pdf:application/pdf}
}

@article{tanenbaum_amoeba_1991,
	title = {The {Amoeba} {Distributed} {Operating} {System} - {A} {Status} {Report}},
	volume = {14},
	abstract = {As the price of CPU chips continues to fall rapidly, it will soon be economically feasible to build computer systems containing a large number of processors. The question of how this computing power should be organized, and what kind of operating system is appropriate then arises. Our research during the past decade has focused on these issues and led to the design of a distributed operating system, called Amoeba, that is intended for systems with large numbers of computers. In this paper we describe Amoeba, its philosophy, its design, its applications, and some experience with it. 1. INTRODUCTION  The cost of CPU chips is expected to continue declining during the coming decade, leading to systems containing a large number of processors. Connecting all these processors using standard technology (e.g., a LAN) is easy. The hard part is designing and implementing software to manage and use all of this computing power in a convenient way. In this paper we describe a distributed operating s...},
	journal = {Computer Communications},
	author = {Tanenbaum, Andrew S. and Kaashoek, M. Frans and Renesse, Robbert Van and Bal, Henri E.},
	year = {1991},
	pages = {324--335},
	file = {Tanenbaum et al_1991_The Amoeba Distributed Operating System - A Status Report.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tanenbaum et al_1991_The Amoeba Distributed Operating System - A Status Report.pdf:application/pdf}
}

@book{stanley-marbell_inferno_2003,
	address = {Chichester},
	title = {Inferno programming with {Limbo}},
	isbn = {978-0-470-84352-9},
	publisher = {John Wiley \& Sons},
	author = {Stanley-Marbell, Phillip},
	year = {2003},
	keywords = {Inferno (Electronic resource), Limbo (Computer program language)},
	file = {Stanley-Marbell_2003_Inferno programming with Limbo.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stanley-Marbell_2003_Inferno programming with Limbo.pdf:application/pdf}
}

@misc{john_k._ousterhout_sprite_1988,
	title = {The {Sprite} {Network} {Operating} {System}},
	url = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/1987/6229.html},
	urldate = {2018-02-15},
	author = {{John K. Ousterhout} and Cherenson, Andrew R. and Douglis, Frederick and Nelson, Michael N. and Welch, Brent B.},
	month = feb,
	year = {1988},
	file = {John K. Ousterhout et al_1988_The Sprite Network Operating System.pdf:/home/michael/Dropbox/zotero-pdfs/J/John K. Ousterhout et al_1988_The Sprite Network Operating System.pdf:application/pdf}
}

@article{douglis_comparison_1991,
	title = {A {Comparison} of {Two} {Distributed} {Systems}: {Amoeba} and {Sprite}},
	volume = {4},
	shorttitle = {A {Comparison} of {Two} {Distributed} {Systems}},
	abstract = {This paper compares two distributed operating systems, Amoeba and Sprite. Although the systems share many goals, they diverged on two philosophical grounds: whether to emphasize a distributed computing model or traditional UNIX-style y applications, and whether to use a workstation-centered model of computation or a combination of terminals and a shared processor pool. Many of the most prominent features of the systems (both positive and negative) follow from the philosophical differences. For example, Amoeba provides a high-performance user-level IPC mechanism, while Sprite's RPC mechanism is only available for kernel use; Sprite's file access performance benefits from client-level caching, while Amoeba caches files only on servers; and Sprite uses a process migration model to share compute power, while Amoeba uses a centralized server to allocate processors and distribute load automatically. 1 Introduction The shift from time-sharing computers to collections of processors connecte...},
	journal = {ACM Transactions on Computer Systems},
	author = {Douglis, Fred and Kaashoek, M. Frans and Ousterhout, John K. and Tanenbaum, Andrew S.},
	year = {1991},
	pages = {Fall},
	file = {Douglis et al_1991_A Comparison of Two Distributed Systems - Amoeba and Sprite.pdf:/home/michael/Dropbox/zotero-pdfs/D/Douglis et al_1991_A Comparison of Two Distributed Systems - Amoeba and Sprite.pdf:application/pdf}
}

@inproceedings{pike_acme:_1994,
	title = {Acme: {A} {User} {Interface} for {Programmers}.},
	shorttitle = {Acme},
	booktitle = {{USENIX} {Winter}},
	author = {Pike, Rob},
	year = {1994},
	pages = {223--234},
	file = {pike.pdf:/home/michael/Zotero/storage/3GYSS9L7/pike.pdf:application/pdf}
}

@article{swinehart_structural_1986,
	title = {A structural view of the {Cedar} programming environment},
	volume = {8},
	abstract = {This paper presents an overview of the Cedar programming environment, focusing on its overall structure-that is, the major components of Cedar and the way they are organized. Cedar supports the development of programs written in a single programming language, also called Cedar. Its primary purpose is to increase the productivity of programmers whose activities include experimental pro-gramming and the development of prototype software systems for a high-performance personal computer. The paper emphasizes the extent to which the Cedar language, with run-time support, has influenced the organization, flexibility, usefulness, and stability of the Cedar environment. It high-lights the novel system features of Cedar, including automatic storage management of dynamically allocated typed values, a run-time type system that provides run-time access to Cedar data type definitions and allows interpretive manipulation of typed values, and a powerful deuice-independent imaging model that supports the user interface facilities. Using these discussions to set the context, the paper addresses the language and system features and the methodologies used to facilitate the integration of Cedar applications. A comparison of Cedar with other programming environments further identifies areas where Cedar excels and areas where work remains to be done.},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Swinehart, Daniel C. and Zellweger, Polle T. and Beach, Richard J. and Hagmann, Robert B.},
	year = {1986},
	pages = {419--490},
	file = {Swinehart et al_1986_A structural view of the Cedar programming environment.pdf:/home/michael/Dropbox/zotero-pdfs/S/Swinehart et al_1986_A structural view of the Cedar programming environment.pdf:application/pdf}
}

@techreport{intel_intel_2018,
	title = {Intel {Analysis} of {Speculative} {Execution} {Side} {Channels}},
	url = {https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf},
	number = {336983-001},
	urldate = {2018-02-15},
	institution = {Intel},
	author = {Intel},
	month = jan,
	year = {2018},
	file = {Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf:/home/michael/Zotero/storage/QHHGI4BE/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf:application/pdf}
}

@misc{noauthor_x86:_nodate,
	title = {x86: {Supervisor} {Mode} {Access} {Prevention} [{LWN}.net]},
	url = {https://lwn.net/Articles/517251/},
	urldate = {2018-02-15}
}

@misc{horn_project_2018,
	title = {Project {Zero}: {Reading} privileged memory with a side-channel},
	url = {https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html},
	urldate = {2018-02-15},
	author = {Horn, Jann},
	month = jan,
	year = {2018}
}

@article{ierusalimschy_passing_2011,
	title = {Passing a language through the eye of a needle},
	volume = {9},
	number = {5},
	journal = {Queue},
	author = {Ierusalimschy, Roberto and De Figueiredo, Luiz Henrique and Celes, Waldemar},
	year = {2011},
	pages = {20},
	file = {p20-ierusalimchy.pdf:/home/michael/Zotero/storage/XL5JHX82/p20-ierusalimchy.pdf:application/pdf}
}

@inproceedings{li_sapper:_2014,
	address = {New York, NY, USA},
	series = {{ASPLOS} '14},
	title = {Sapper: {A} {Language} for {Hardware}-level {Security} {Policy} {Enforcement}},
	isbn = {978-1-4503-2305-5},
	shorttitle = {Sapper},
	url = {http://doi.acm.org/10.1145/2541940.2541947},
	doi = {10.1145/2541940.2541947},
	abstract = {Privacy and integrity are important security concerns. These concerns are addressed by controlling information flow, i.e., restricting how information can flow through a system. Most proposed systems that restrict information flow make the implicit assumption that the hardware used by the system is fully ``correct'' and that the hardware's instruction set accurately describes its behavior in all circumstances. The truth is more complicated: modern hardware designs defy complete verification; many aspects of the timing and ordering of events are left totally unspecified; and implementation bugs present themselves with surprising frequency. In this work we describe Sapper, a novel hardware description language for designing security-critical hardware components. Sapper seeks to address these problems by using static analysis at compile-time to automatically insert dynamic checks in the resulting hardware that provably enforce a given information flow policy at execution time. We present Sapper's design and formal semantics along with a proof sketch of its security. In addition, we have implemented a compiler for Sapper and used it to create a non-trivial secure embedded processor with many modern microarchitectural features. We empirically evaluate the resulting hardware's area and energy overhead and compare them with alternative designs.},
	urldate = {2018-02-15},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Li, Xun and Kashyap, Vineeth and Oberg, Jason K. and Tiwari, Mohit and Rajarathinam, Vasanth Ram and Kastner, Ryan and Sherwood, Timothy and Hardekopf, Ben and Chong, Frederic T.},
	year = {2014},
	keywords = {hardware description language, non-interference},
	pages = {97--112},
	file = {Li et al_2014_Sapper - A Language for Hardware-level Security Policy Enforcement.pdf:/home/michael/Dropbox/zotero-pdfs/L/Li et al_2014_Sapper - A Language for Hardware-level Security Policy Enforcement.pdf:application/pdf}
}

@inproceedings{tiwari_crafting_2011,
	address = {New York, NY, USA},
	series = {{ISCA} '11},
	title = {Crafting a {Usable} {Microkernel}, {Processor}, and {I}/{O} {System} with {Strict} and {Provable} {Information} {Flow} {Security}},
	isbn = {978-1-4503-0472-6},
	url = {http://doi.acm.org/10.1145/2000064.2000087},
	doi = {10.1145/2000064.2000087},
	abstract = {High assurance systems used in avionics, medical implants, and cryptographic devices often rely on a small trusted base of hardware and software to manage the rest of the system. Crafting the core of such a system in a way that achieves flexibility, security, and performance requires a careful balancing act. Simple static primitives with hard partitions of space and time are easier to analyze formally, but strict approaches to the problem at the hardware level have been extremely restrictive, failing to allow even the simplest of dynamic behaviors to be expressed. Our approach to this problem is to construct a minimal but configurable architectural skeleton. This skeleton couples a critical slice of the low level hardware implementation with a microkernel in a way that allows information flow properties of the entire construction to be statically verified all the way down to its gate-level implementation. This strict structure is then made usable by a runtime system that delivers more traditional services (e.g. communication interfaces and long-living contexts) in a way that is decoupled from the information flow properties of the skeleton. To test the viability of this approach we design, test, and statically verify the information-flow security of a hardware/software system complete with support for unbounded operation, inter-process communication, pipelined operation, and I/O with traditional devices. The resulting system is provably sound even when adversaries are allowed to execute arbitrary code on the machine, yet is flexible enough to allow caching, pipelining, and other common case optimizations.},
	urldate = {2018-02-15},
	booktitle = {Proceedings of the 38th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {ACM},
	author = {Tiwari, Mohit and Oberg, Jason K. and Li, Xun and Valamehr, Jonathan and Levin, Timothy and Hardekopf, Ben and Kastner, Ryan and Chong, Frederic T. and Sherwood, Timothy},
	year = {2011},
	keywords = {non-interference, gate level information flow tracking, high assurance systems},
	pages = {189--200},
	file = {Tiwari et al_2011_Crafting a Usable Microkernel, Processor, and I-O System with Strict and.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tiwari et al_2011_Crafting a Usable Microkernel, Processor, and I-O System with Strict and.pdf:application/pdf}
}

@techreport{galois_cryptol:_2016,
	title = {Cryptol: {The} {Language} of {Cryptography}},
	institution = {Galois, Inc.},
	author = {Galois},
	year = {2016},
	pages = {124},
	file = {Galois_2016_Cryptol - The Language of Cryptography.pdf:/home/michael/Dropbox/zotero-pdfs/G/Galois_2016_Cryptol - The Language of Cryptography.pdf:application/pdf}
}

@article{leinster_basic_2016,
	title = {Basic {Category} {Theory}},
	url = {http://arxiv.org/abs/1612.09375},
	abstract = {This short introduction to category theory is for readers with relatively little mathematical background. At its heart is the concept of a universal property, important throughout mathematics. After a chapter introducing the basic definitions, separate chapters present three ways of expressing universal properties: via adjoint functors, representable functors, and limits. A final chapter ties the three together. For each new categorical concept, a generous supply of examples is provided, taken from different parts of mathematics. At points where the leap in abstraction is particularly great (such as the Yoneda lemma), the reader will find careful and extensive explanations.},
	urldate = {2018-02-16},
	journal = {arXiv:1612.09375 [math]},
	author = {Leinster, Tom},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.09375},
	keywords = {Mathematics - Algebraic Topology, Mathematics - Category Theory, Mathematics - Logic},
	file = {Leinster_2016_Basic Category Theory.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leinster_2016_Basic Category Theory.pdf:application/pdf}
}

@inproceedings{erkok_hardware/software_2009,
	title = {Hardware/software co-verification of cryptographic algorithms using {Cryptol}},
	doi = {10.1109/FMCAD.2009.5351121},
	abstract = {Cryptol is a programming language designed for specifying cryptographic algorithms. Despite its high-level modeling nature, Cryptol programs are fully executable. Further, a large subset of Cryptol can be automatically synthesized to hardware. To meet the inherent high-assurance requirements of cryptographic systems, Cryptol comes with a suite of formal-methods based tools that enable users to perform various program verification tasks. In this paper, we provide an overview of Cryptol and its verification toolset, especially focusing on the co-verification of third-party VHDL implementations against highlevel Cryptol specifications. As a case study, we demonstrate the technique on two hand-written VHDL implementations of the Skein hash algorithm.},
	booktitle = {2009 {Formal} {Methods} in {Computer}-{Aided} {Design}},
	author = {Erkök, L. and Carlsson, M. and Wick, A.},
	month = nov,
	year = {2009},
	keywords = {programming languages, Runtime, Computer languages, program verification, Hardware, Algorithm design and analysis, cryptography, Cryptography, Arithmetic, Availability, cryptographic algorithms, Domain specific languages, Equivalence checking, formal-methods based tool, hardware description languages, hardware-software co-verification, high-level Cryptol specification, HW/SW Co-verification, programming language, Safety, Skein hash algorithm, Software algorithms, Specification and Verification, third-party VHDL implementations},
	pages = {188--191},
	file = {Erkok et al_2009_Hardware-software co-verification of cryptographic algorithms using Cryptol.pdf:/home/michael/Dropbox/zotero-pdfs/E/Erkok et al_2009_Hardware-software co-verification of cryptographic algorithms using Cryptol.pdf:application/pdf}
}

@inproceedings{lewis_cryptol:_2003,
	title = {Cryptol: high assurance, retargetable crypto development and validation},
	volume = {2},
	shorttitle = {Cryptol},
	doi = {10.1109/MILCOM.2003.1290218},
	abstract = {As cryptography becomes more vital to the infrastructure of computing systems, it becomes increasingly vital to be able to rapidly and correctly produce new implementations of cryptographic algorithms. To address these challenges, we introduce a new, formal methods-based approach to the specification and implementation of cryptography, present a number of scenarios of use, an overview of the language, and present part of a specification of the advanced encryption standard.},
	booktitle = {{IEEE} {Military} {Communications} {Conference}, 2003. {MILCOM} 2003.},
	author = {Lewis, J. R. and Martin, B.},
	month = oct,
	year = {2003},
	keywords = {Information security, Hardware, Algorithm design and analysis, Specification languages, cryptography, Cryptography, National security, cryptographic algorithms, advanced encryption standard, computing systems, cryptol, Libraries, retargetable crypto development, Software systems, Software testing, System testing},
	pages = {820--825 Vol.2},
	file = {Lewis_Martin_2003_Cryptol - high assurance, retargetable crypto development and validation.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lewis_Martin_2003_Cryptol - high assurance, retargetable crypto development and validation.pdf:application/pdf}
}

@inproceedings{erkok_pragmatic_2008,
	address = {New York, NY, USA},
	series = {{PLPV} '09},
	title = {Pragmatic {Equivalence} and {Safety} {Checking} in {Cryptol}},
	isbn = {978-1-60558-330-3},
	url = {http://doi.acm.org/10.1145/1481848.1481860},
	doi = {10.1145/1481848.1481860},
	abstract = {Cryptol is programming a language designed for specifying and programming cryptographic algorithms. In order to meet high-assurance requirements, Cryptol comes with a suite of formal-methods based tools allowing users to perform various program verification tasks. In the fully automated mode, Cryptol uses modern off-the-shelf SAT and SMT solvers to perform verification in a push-button manner. In the manual mode, Cryptol produces Isabelle/HOL specifications that can be interactively verified using the Isabelle theorem prover. In this paper, we provide an overview of Cryptol's verification toolset, describing our experiences with building a practical programming environment with dedicated support for formal verification.},
	urldate = {2018-02-16},
	booktitle = {Proceedings of the 3rd {Workshop} on {Programming} {Languages} {Meets} {Program} {Verification}},
	publisher = {ACM},
	author = {Erkök, Levent and Matthews, John},
	year = {2008},
	keywords = {theorem proving, equivalence checking, formal methods, cryptography, sat/smt solving, size polymorphism},
	pages = {73--82},
	file = {Erkok_Matthews_2008_Pragmatic Equivalence and Safety Checking in Cryptol.pdf:/home/michael/Dropbox/zotero-pdfs/E/Erkok_Matthews_2008_Pragmatic Equivalence and Safety Checking in Cryptol.pdf:application/pdf}
}

@inproceedings{pike_verifying_2006,
	address = {New York, NY, USA},
	series = {{ACL}2 '06},
	title = {A {Verifying} {Core} for a {Cryptographic} {Language} {Compiler}},
	isbn = {978-0-9788493-0-6},
	url = {http://doi.acm.org/10.1145/1217975.1217977},
	doi = {10.1145/1217975.1217977},
	abstract = {A verifying compiler is one that emits both object code and a proof of correspondence between object and source code.1 We report the use of ACL2 in building a verifying compiler for μCryptol, a stream-based language for encryption algorithm specification that targets Rockwell Collins' AAMP7 microprocessor (and is designed to compile efficiently to hardware, too). This paper reports on our success in verifying the "core" transformations of the compiler -- those transformations over the sub-language of μCryptol that begin after "higher-order" aspects of the language are compiled away, and finish just before hardware or software specific transformations are exercised. The core transformations are responsible for aggressive optimizations. We have written an ACL2 macro that automatically generates both the correspondence theorems and their proofs. The compiler also supplies measure functions that ACL2 uses to automatically prove termination of μCryptol programs, including programs with mutually-recursive cliques of streams. Our verifying compiler has proved the correctness of its core transformations for multiple algorithms, including TEA, RC6, and AES. Finally, we describe an ACL2 book of primitive operations for the general specification and verification of encryption algorithms.},
	urldate = {2018-02-16},
	booktitle = {Proceedings of the {Sixth} {International} {Workshop} on the {ACL}2 {Theorem} {Prover} and {Its} {Applications}},
	publisher = {ACM},
	author = {Pike, Lee and Shields, Mark and Matthews, John},
	year = {2006},
	keywords = {cryptography, ACL2, certification, certifying compiler, high-assurance, optimizing compiler, verifying compiler},
	pages = {1--10},
	file = {Pike et al_2006_A Verifying Core for a Cryptographic Language Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pike et al_2006_A Verifying Core for a Cryptographic Language Compiler.pdf:application/pdf}
}

@inproceedings{brayton_abc:_2010,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{ABC}: {An} {Academic} {Industrial}-{Strength} {Verification} {Tool}},
	isbn = {978-3-642-14294-9 978-3-642-14295-6},
	shorttitle = {{ABC}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-14295-6_5},
	doi = {10.1007/978-3-642-14295-6_5},
	abstract = {ABC is a public-domain system for logic synthesis and formal verification of binary logic circuits appearing in synchronous hardware designs. ABC combines scalable logic transformations based on And-Inverter Graphs (AIGs), with a variety of innovative algorithms. A focus on the synergy of sequential synthesis and sequential verification leads to improvements in both domains. This paper introduces ABC, motivates its development, and illustrates its use in formal verification.},
	language = {en},
	urldate = {2018-02-16},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Brayton, Robert and Mishchenko, Alan},
	month = jul,
	year = {2010},
	pages = {24--40},
	file = {Brayton_Mishchenko_2010_ABC - An Academic Industrial-Strength Verification Tool.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brayton_Mishchenko_2010_ABC - An Academic Industrial-Strength Verification Tool.pdf:application/pdf}
}

@article{kemmerer_shared_1983,
	title = {Shared resource matrix methodology: {An} approach to identifying storage and timing channels},
	volume = {1},
	shorttitle = {Shared resource matrix methodology},
	number = {3},
	journal = {ACM Transactions on Computer Systems (TOCS)},
	author = {Kemmerer, Richard A.},
	year = {1983},
	pages = {256--277},
	file = {Kemmerer_1983_Shared resource matrix methodology.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kemmerer_1983_Shared resource matrix methodology.pdf:application/pdf}
}

@inproceedings{jones_matchmaker:_1985,
	address = {New York, NY, USA},
	series = {{POPL} '85},
	title = {Matchmaker: {An} {Interface} {Specification} {Language} for {Distributed} {Processing}},
	isbn = {978-0-89791-147-4},
	shorttitle = {Matchmaker},
	url = {http://doi.acm.org/10.1145/318593.318644},
	doi = {10.1145/318593.318644},
	abstract = {Matchmaker, a language used to specify and automate the generation of interprocess communication interfaces, is presented. The process of and reasons for the evolution of Matchmaker are described. Performance and usage statistics are presented. Comparisons are made between Matchmaker and other related systems. Possible future directions are examined.},
	urldate = {2018-02-18},
	booktitle = {Proceedings of the 12th {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Jones, Michael B. and Rashid, Richard F. and Thompson, Mary R.},
	year = {1985},
	keywords = {distributed systems, interface specification language, interprocess communication, multi-targeted compiler, object-oriented languages, remote procedure call},
	pages = {225--235},
	file = {Jones et al_1985_Matchmaker.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones et al_1985_Matchmaker.pdf:application/pdf}
}

@book{wulf_hydra/c._1981,
	title = {{HYDRA}/{C}. mmp, an experimental computer system},
	publisher = {McGraw-Hill Companies},
	author = {Wulf, William Allan and Levin, Roy and Harbison, Samuel P.},
	year = {1981}
}

@inproceedings{jones_staros_1979,
	address = {New York, NY, USA},
	series = {{SOSP} '79},
	title = {{StarOS}, a {Multiprocessor} {Operating} {System} for the {Support} of {Task} {Forces}},
	isbn = {978-0-89791-009-5},
	url = {http://doi.acm.org/10.1145/800215.806579},
	doi = {10.1145/800215.806579},
	abstract = {StarOS is a message-based, object-oriented, multiprocessor operating system, specifically designed to support task forces, large collections of concurrently executing processes that cooperate to accomplish a single purpose. StarOS has been implemented at Carnegie-Mellon University for the 50 processor Cm* multi-microprocessor computer.},
	urldate = {2018-02-18},
	booktitle = {Proceedings of the {Seventh} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Jones, Anita K. and Chansler, Jr., Robert J. and Durham, Ivor and Schwans, Karsten and Vegdahl, Steven R.},
	year = {1979},
	pages = {117--127},
	file = {Jones et al_1979_StarOS, a Multiprocessor Operating System for the Support of Task Forces.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones et al_1979_StarOS, a Multiprocessor Operating System for the Support of Task Forces.pdf:application/pdf}
}

@incollection{jones_object_1978,
	title = {The object model: {A} conceptual tool for structuring software},
	shorttitle = {The object model},
	booktitle = {Operating {Systems}},
	publisher = {Springer},
	author = {Jones, Anita K.},
	year = {1978},
	pages = {7--16},
	file = {3-540-08755-9_2.pdf:/home/michael/Zotero/storage/L54PHM8K/3-540-08755-9_2.pdf:application/pdf}
}

@book{satyanarayanan_itc_nodate,
	title = {The {ITC} {Distributed} {File} {System}" {Principles} and {Design}},
	abstract = {null},
	author = {Satyanarayanan, M. and Howard, John H. and Nichols, David A.},
	file = {Satyanarayanan et al_The ITC Distributed File System Principles and Design.pdf:/home/michael/Dropbox/zotero-pdfs/S/Satyanarayanan et al_The ITC Distributed File System Principles and Design.pdf:application/pdf}
}

@inproceedings{rashid_accent:_1981,
	address = {New York, NY, USA},
	series = {{SOSP} '81},
	title = {Accent: {A} {Communication} {Oriented} {Network} {Operating} {System} {Kernel}},
	isbn = {978-0-89791-062-0},
	shorttitle = {Accent},
	url = {http://doi.acm.org/10.1145/800216.806593},
	doi = {10.1145/800216.806593},
	abstract = {Accent is a communication oriented operating system kernel being built at Carnegie-Mellon University to support the distributed personal computing project, Spice, and the development of a fault-tolerant distributed sensor network (DSN). Accent is built around a single, powerful abstraction of communication between processes, with all kernel functions, such as device access and virtual memory management accessible through messages and distributable throughout a network. In this paper, specific attention is given to system supplied facilities which support transparent network access and fault-tolerant behavior. Many of these facilities are already being provided under a modified version of VAX/UNIX. The Accent system itself is currently being implemented on the Three Rivers Corp. PERQ.},
	urldate = {2018-02-18},
	booktitle = {Proceedings of the {Eighth} {ACM} {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Rashid, Richard F. and Robertson, George G.},
	year = {1981},
	keywords = {Paging, Operating systems, UNIX, Distributed computation, Inter-process communication, Network, Networking, PERQ, VAX, Virtual memory},
	pages = {64--75},
	file = {Rashid_Robertson_1981_Accent.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rashid_Robertson_1981_Accent.pdf:application/pdf}
}

@article{cheriton_v_1988,
	title = {The {V} {Distributed} {System}},
	volume = {31},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/42392.42400},
	doi = {10.1145/42392.42400},
	abstract = {The V distributed System was developed at Stanford University as part of a research project to explore issues in distributed systems. Aspects of the design suggest important directions for the design of future operating systems and communication systems.},
	number = {3},
	urldate = {2018-02-18},
	journal = {Commun. ACM},
	author = {Cheriton, David},
	month = mar,
	year = {1988},
	pages = {314--333},
	file = {Cheriton_1988_The V Distributed System.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cheriton_1988_The V Distributed System.pdf:application/pdf}
}

@inproceedings{ewens_tunis:_1985,
	title = {Tunis: {A} distributed multiprocessor operating system},
	shorttitle = {Tunis},
	booktitle = {{USENIX} {Association} {Conference} {Proceedings}},
	author = {Ewens, Peter and Blythe, David R. and Funkenhauser, Mark and Holt, Richard C.},
	year = {1985},
	pages = {247--254}
}

@article{boule_chorus_1988,
	title = {Chorus distributed operating systems},
	volume = {1},
	number = {4},
	journal = {Computing Systems},
	author = {Boule, I. and Gien, M. and Guillemont, M.},
	year = {1988},
	file = {Boule et al_1988_Chorus distributed operating systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boule et al_1988_Chorus distributed operating systems.pdf:application/pdf}
}

@inproceedings{levis_experiences_2012,
	title = {Experiences from a {Decade} of {TinyOS} {Development}.},
	booktitle = {{OSDI}},
	author = {Levis, Philip},
	year = {2012},
	pages = {207--220},
	file = {Levis_2012_Experiences from a Decade of TinyOS Development.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levis_2012_Experiences from a Decade of TinyOS Development.pdf:application/pdf}
}

@inproceedings{ramanathan_sympathy_2005,
	address = {New York, NY, USA},
	series = {{SenSys} '05},
	title = {Sympathy for the {Sensor} {Network} {Debugger}},
	isbn = {978-1-59593-054-5},
	url = {http://doi.acm.org/10.1145/1098918.1098946},
	doi = {10.1145/1098918.1098946},
	abstract = {Being embedded in the physical world, sensor networks present a wide range of bugs and misbehavior qualitatively different from those in most distributed systems. Unfortunately, due to resource constraints, programmers must investigate these bugs with only limited visibility into the application. This paper presents the design and evaluation of Sympathy, a tool for detecting and debugging failures in sensor networks. Sympathy has selected metrics that enable efficient failure detection, and includes an algorithm that root-causes failures and localizes their sources in order to reduce overall failure notifications and point the user to a small number of probable causes. We describe Sympathy and evaluate its performance through fault injection and by debugging an active application, ESS, in simulation and deployment. We show that for a broad class of data gathering applications, it is possible to detect and diagnose failures by collecting and analyzing a minimal set of metrics at a centralized sink. We have found that there is a tradeoff between notification latency and detection accuracy; that additional metrics traffic does not always improve notification latency; and that Sympathy's process of failure localization reduces.},
	urldate = {2018-02-20},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {ACM},
	author = {Ramanathan, Nithya and Chang, Kevin and Kapur, Rahul and Girod, Lewis and Kohler, Eddie and Estrin, Deborah},
	year = {2005},
	keywords = {debugging, failure detection, failure localization, root causes, sensor networks},
	pages = {255--267},
	file = {Ramanathan et al_2005_Sympathy for the Sensor Network Debugger.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ramanathan et al_2005_Sympathy for the Sensor Network Debugger.pdf:application/pdf}
}

@inproceedings{dunkels_contiki_2004,
	title = {Contiki - a lightweight and flexible operating system for tiny networked sensors},
	doi = {10.1109/LCN.2004.38},
	abstract = {Wireless sensor networks are composed of large numbers of tiny networked devices that communicate untethered. For large scale networks, it is important to be able to download code into the network dynamically. We present Contiki, a lightweight operating system with support for dynamic loading and replacement of individual programs and services. Contiki is built around an event-driven kernel but provides optional preemptive multithreading that can be applied to individual processes. We show that dynamic loading and unloading is feasible in a resource constrained environment, while keeping the base system lightweight and compact.},
	booktitle = {29th {Annual} {IEEE} {International} {Conference} on {Local} {Computer} {Networks}},
	author = {Dunkels, A. and Gronvall, B. and Voigt, T.},
	month = nov,
	year = {2004},
	keywords = {Computer science, Operating systems, data communication, Kernel, operating system kernels, Libraries, Contiki, dynamic code loading, event-driven kernel, flexible operating system, Large-scale systems, lightweight operating system, Microcontrollers, multi-threading, Multithreading, network operating systems, preemptive multithreading, Read-write memory, Sensor systems, wireless sensor networks, Wireless sensor networks},
	pages = {455--462},
	file = {Dunkels et al_2004_Contiki - a lightweight and flexible operating system for tiny networked sensors.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dunkels et al_2004_Contiki - a lightweight and flexible operating system for tiny networked sensors.pdf:application/pdf}
}

@inproceedings{cao_declarative_2008,
	title = {Declarative tracepoints: a programmable and application independent debugging system for wireless sensor networks},
	shorttitle = {Declarative tracepoints},
	booktitle = {Proceedings of the 6th {ACM} conference on {Embedded} network sensor systems},
	publisher = {ACM},
	author = {Cao, Qing and Abdelzaher, Tarek and Stankovic, John and Whitehouse, Kamin and Luo, Liqian},
	year = {2008},
	pages = {85--98},
	file = {Cao et al_2008_Declarative tracepoints - a programmable and application independent debugging.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cao et al_2008_Declarative tracepoints - a programmable and application independent debugging.pdf:application/pdf}
}

@inproceedings{bonwick_slab_1994,
	title = {The {Slab} {Allocator}: {An} {Object}-{Caching} {Kernel} {Memory} {Allocator}.},
	volume = {16},
	shorttitle = {The {Slab} {Allocator}},
	booktitle = {{USENIX} summer},
	publisher = {Boston, MA, USA},
	author = {Bonwick, Jeff},
	year = {1994},
	file = {Bonwick_1994_The Slab Allocator - An Object-Caching Kernel Memory Allocator.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bonwick_1994_The Slab Allocator - An Object-Caching Kernel Memory Allocator.pdf:application/pdf}
}

@inproceedings{lamowski_sandcrust:_2017,
	address = {New York, NY, USA},
	series = {{PLOS}'17},
	title = {Sandcrust: {Automatic} {Sandboxing} of {Unsafe} {Components} in {Rust}},
	isbn = {978-1-4503-5153-9},
	shorttitle = {Sandcrust},
	url = {http://doi.acm.org/10.1145/3144555.3144562},
	doi = {10.1145/3144555.3144562},
	abstract = {System-level development has been dominated by traditional programming languages such as C and C++ for decades. These languages are inherently unsafe regarding memory management. Even experienced developers make mistakes that open up security holes or compromise the safety properties of software. The Rust programming language is targeted at the systems domain and aims to eliminate memory-related programming errors by enforcing a strict memory model at the language and compiler level. Unfortunately, these compile-time guarantees no longer hold when a Rust program is linked against a library written in unsafe C, which is commonly required for functionality where an implementation in Rust is not yet available. In this paper, we present Sandcrust, an easy-to-use sand-boxing solution for isolating code and data of a C library in a separate process. This isolation protects the Rust-based main program from any memory corruption caused by bugs in the unsafe library, which would otherwise invalidate the memory safety guarantees of Rust. Sandcrust is based on the Rust macro system and requires no modification to the compiler or runtime, but only straightforward annotation of functions that call the library's API.},
	urldate = {2018-02-21},
	booktitle = {Proceedings of the 9th {Workshop} on {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Lamowski, Benjamin and Weinhold, Carsten and Lackorzynski, Adam and Härtig, Hermann},
	year = {2017},
	pages = {51--57},
	file = {Lamowski et al_2017_Sandcrust - Automatic Sandboxing of Unsafe Components in Rust.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lamowski et al_2017_Sandcrust - Automatic Sandboxing of Unsafe Components in Rust.pdf:application/pdf}
}

@techreport{tartiti_checked_nodate,
	title = {Checked {C}},
	url = {https://www.microsoft.com/en-us/research/project/checked-c/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Fcheckedc%2Fdefault.aspx},
	author = {Tartiti, David},
	file = {Tartiti_C Cured.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tartiti_C Cured.pdf:application/pdf}
}

@inproceedings{bruni_code_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Code {Obfuscation} {Against} {Abstract} {Model} {Checking} {Attacks}},
	isbn = {978-3-319-73720-1 978-3-319-73721-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-73721-8_5},
	doi = {10.1007/978-3-319-73721-8_5},
	abstract = {Code protection technologies require anti reverse engineering transformations to obfuscate programs in such a way that tools and methods for program analysis become ineffective. We introduce the concept of model deformation inducing an effective code obfuscation against attacks performed by abstract model checking. This means complicating the model in such a way a high number of spurious traces are generated in any formal verification of the property to disclose about the system under attack. We transform the program model in order to make the removal of spurious counterexamples by abstraction refinement maximally inefficient. A measure of the quality of the obfuscation obtained by model deformation is given together with a corresponding best obfuscation strategy for abstract model checking based on partition refinement.},
	language = {en},
	urldate = {2018-02-21},
	booktitle = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer, Cham},
	author = {Bruni, Roberto and Giacobazzi, Roberto and Gori, Roberta},
	month = jan,
	year = {2018},
	pages = {94--115},
	file = {Bruni et al_2018_Code Obfuscation Against Abstract Model Checking Attacks.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bruni et al_2018_Code Obfuscation Against Abstract Model Checking Attacks.pdf:application/pdf}
}

@inproceedings{mitchell_automated_1997,
	title = {Automated {Analysis} of {Cryptographic} {Protocols} {Using} {Murphi}},
	abstract = {A methodology is presented for using a generalpurpose state enumeration tool, Murphi, to analyze cryptographic and security-related protocols. We illustrate the feasibility of the approach by analyzing the Needham-Schroeder protocol, finding a known bug in a few seconds of computation time, and analyzing variants of Kerberos and the faulty TMN protocol used in another comparative study. The efficiency of Murphi allows us to examine multiple runs of relatively short protocols, giving us the ability to detect replay attacks, or errors resulting from confusion between independent execution of a protocol by independent parties.},
	publisher = {IEEE Computer Society Press},
	author = {Mitchell, John C. and Mitchell, Mark and Stern, Ulrich},
	year = {1997},
	pages = {141--151},
	file = {Mitchell et al_1997_Automated Analysis of Cryptographic Protocols Using Murphi.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mitchell et al_1997_Automated Analysis of Cryptographic Protocols Using Murphi2.pdf:application/pdf}
}

@techreport{galois_cryptol_2008,
	title = {From {Cryptol} to {FPGA}: {A} {Tutorial}},
	url = {http://gauss.ececs.uc.edu/Courses/c626/lectures/Cryptol/Cryptol-Tutorial.pdf},
	urldate = {2018-02-23},
	institution = {Galois, Inc.},
	author = {Galois},
	month = oct,
	year = {2008},
	file = {Cryptol-Tutorial.pdf:/home/michael/Zotero/storage/4N4734A8/Cryptol-Tutorial.pdf:application/pdf}
}

@techreport{subramanyan_formal_2017,
	title = {A {Formal} {Foundation} for {Secure} {Remote} {Execution} of {Enclaves}},
	url = {http://eprint.iacr.org/2017/565},
	abstract = {Recent proposals for trusted hardware platforms, such as Intel SGX and the MIT Sanctum processor, offer compelling security features but lack formal guarantees. We introduce a verification methodology based on a trusted abstract platform (TAP) that formally models idealized enclaves and a parameterized adversary. We present machine-checked proofs showing that the TAP satisfies the three key security properties needed for secure remote execution: integrity, confidentiality and secure measurement. We then present machine-checked proofs showing that SGX and Sanctum are refinements of the TAP under certain parameterizations of the adversary, demonstrating that these systems implement secure enclaves for the stated adversary models.},
	number = {565},
	urldate = {2018-02-27},
	author = {Subramanyan, Pramod and Sinha, Rohit and Lebedev, Ilia and Devadas, Srinivas and Seshia, Sanjit},
	year = {2017},
	keywords = {applications},
	file = {Subramanyan et al_2017_A Formal Foundation for Secure Remote Execution of Enclaves.pdf:/home/michael/Dropbox/zotero-pdfs/S/Subramanyan et al_2017_A Formal Foundation for Secure Remote Execution of Enclaves.pdf:application/pdf}
}

@inproceedings{maas_phantom:_2013,
	address = {New York, NY, USA},
	series = {{CCS} '13},
	title = {{PHANTOM}: {Practical} {Oblivious} {Computation} in a {Secure} {Processor}},
	isbn = {978-1-4503-2477-9},
	shorttitle = {{PHANTOM}},
	url = {http://doi.acm.org/10.1145/2508859.2516692},
	doi = {10.1145/2508859.2516692},
	abstract = {We introduce PHANTOM [1] a new secure processor that obfuscates its memory access trace. To an adversary who can observe the processor's output pins, all memory access traces are computationally indistinguishable (a property known as obliviousness). We achieve obliviousness through a cryptographic construct known as Oblivious RAM or ORAM. We first improve an existing ORAM algorithm and construct an empirical model for its trusted storage requirement. We then present PHANTOM, an oblivious processor whose novel memory controller aggressively exploits DRAM bank parallelism to reduce ORAM access latency and scales well to a large number of memory channels. Finally, we build a complete hardware implementation of PHANTOM on a commercially available FPGA-based server, and through detailed experiments show that PHANTOM is efficient in both area and performance. Accessing 4KB of data from a 1GB ORAM takes 26.2us (13.5us for the data to be available), a 32x slowdown over accessing 4KB from regular memory, while SQLite queries on a population database see 1.2-6x slowdown. PHANTOM is the first demonstration of a practical, oblivious processor and can provide strong confidentiality guarantees when offloading computation to the cloud.},
	urldate = {2018-02-27},
	booktitle = {Proceedings of the 2013 {ACM} {SIGSAC} {Conference} on {Computer} \& {Communications} {Security}},
	publisher = {ACM},
	author = {Maas, Martin and Love, Eric and Stefanov, Emil and Tiwari, Mohit and Shi, Elaine and Asanovic, Krste and Kubiatowicz, John and Song, Dawn},
	year = {2013},
	keywords = {fpgas, oblivious ram, path oram, secure processors},
	pages = {311--324},
	file = {Maas et al_2013_PHANTOM - Practical Oblivious Computation in a Secure Processor.pdf:/home/michael/Dropbox/zotero-pdfs/M/Maas et al_2013_PHANTOM - Practical Oblivious Computation in a Secure Processor.pdf:application/pdf}
}

@inproceedings{wassel_surfnoc:_2013,
	title = {{SurfNoC}: a low latency and provably non-interfering approach to secure networks-on-chip},
	volume = {41},
	shorttitle = {{SurfNoC}},
	booktitle = {{ACM} {SIGARCH} {Computer} {Architecture} {News}},
	publisher = {ACM},
	author = {Wassel, Hassan MG and Gao, Ying and Oberg, Jason K. and Huffmire, Ted and Kastner, Ryan and Chong, Frederic T. and Sherwood, Timothy},
	year = {2013},
	pages = {583--594},
	file = {Wassel et al_2013_SurfNoC - a low latency and provably non-interfering approach to secure.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wassel et al_2013_SurfNoC - a low latency and provably non-interfering approach to secure.pdf:application/pdf}
}

@article{walker_typed_2000,
	title = {Typed {Memory} {Management} via {Static} {Capabilities}},
	volume = {22},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/363911.363923},
	doi = {10.1145/363911.363923},
	abstract = {Region-based memory management is an alternative to standard tracing garbage collection that makes operation such as memory deallocation explicit but verifiably safe. In this article, we present a new compiler intermediate language, called the Capability Language (CL), that supports region-based memory management and enjoys a provably safe type systems. Unlike previous region-based type system, region lifetimes need not be lexically scoped, and yet the language may be checked for safety without complex analyses. Therefore, our type system may be deployed in settings such as extensible operating systems where both the performance and safety of untrusted code is important. The central novelty of the language is the use of static capabilities to specify the permissibility of various operations, such as memory access and deallocation. In order to ensure capabilities are relinquished properly, the type system tracks aliasing information using a form of bounded quantification. Moreover, unlike previous work on region-based type systems, the proof of soundness of our type system is relatively simple, employing only standard syntactic techniques. In order to show how our language may be used in practice, we show how to translate a variant of Tofte and Talpin's high-level type-and-effects system for region-based memory management into our language. When combined with known region inference algorithms, this translation provides a way to compile source-level languages to CL.},
	number = {4},
	urldate = {2018-02-27},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Walker, David and Crary, Karl and Morrisett, Greg},
	month = jul,
	year = {2000},
	keywords = {certified code, type-directed compilation, typed intermediate languages, region-based memory management},
	pages = {701--771},
	file = {Walker et al_2000_Typed Memory Management via Static Capabilities.pdf:/home/michael/Dropbox/zotero-pdfs/W/Walker et al_2000_Typed Memory Management via Static Capabilities.pdf:application/pdf}
}

@inproceedings{necula_ccured:_2002,
	address = {New York, NY, USA},
	series = {{POPL} '02},
	title = {{CCured}: {Type}-safe {Retrofitting} of {Legacy} {Code}},
	isbn = {978-1-58113-450-6},
	shorttitle = {{CCured}},
	url = {http://doi.acm.org/10.1145/503272.503286},
	doi = {10.1145/503272.503286},
	abstract = {In this paper we propose a scheme that combines type inference and run-time checking to make existing C programs type safe. We describe the CCured type system, which extends that of C by separating pointer types according to their usage. This type system allows both pointers whose usage can be verified statically to be type safe, and pointers whose safety must be checked at run time. We prove a type soundness result and then we present a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs.Our experience with the CCured system shows that the inference is very effective for many C programs, as it is able to infer that most or all of the pointers are statically verifiable to be type safe. The remaining pointers are instrumented with efficient run-time checks to ensure that they are used safely. The resulting performance loss due to run-time checks is 0-150\%, which is several times better than comparable approaches that use only dynamic checking. Using CCured we have discovered programming bugs in established C programs such as several SPECINT95 benchmarks.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 29th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Necula, George C. and McPeak, Scott and Weimer, Westley},
	year = {2002},
	pages = {128--139},
	file = {Necula et al_2002_CCured - Type-safe Retrofitting of Legacy Code.pdf:/home/michael/Dropbox/zotero-pdfs/N/Necula et al_2002_CCured - Type-safe Retrofitting of Legacy Code.pdf:application/pdf}
}

@book{tofte_programming_1997,
	title = {Programming with {Regions} in the {ML} {Kit}},
	abstract = {Machine Kit Abstract Machine, 29, 167  kit architecture, 168  kitdemo directory, 42  Lambda, 30, 35, 165 lambda abstraction, 117, 118 Lambda optimiser, 30  Layout, 167 leaving the Kit, 163 length of list, 105  let, 64 let floating, 68  letregion, 28, 38, 39, 65, 91, 98  Lf, 83  life, 22 Life, game of, 19 lifetime, 64--67 list, 47 live variable analysis, see variable  ln, 44  local, 64, 101  .log, 143  log directory, 168 log file, 42, 165  makeCONS, 181  makeCONSProf, 182  makeNIL, 181  makeNILProf, 182  malloc, 14 matching, 165 merge sort, 59, 107  -microsec option, 155 ML Kit Version 1, 8 Version 2, 8 with Regions, 8  MlConvert.h, 175  mod, 43  msort, 59, 107  MulExp, 30, 165 multiplicity, 28 multiplicity analysis, 30, 38  my lib.c, 185  -name option, 160  nil, 47  nthgen, 22  o, 135  -object option, 159 object profile,  INDEX 189 convertStringToMLProfiling, 182  cos, 44  cp, 59  datatype, 83 declaration local, 64 of value, 63 sequential, 63  decon, 48  dir, 186  div, 43 double copyi...},
	author = {Tofte, Mads and Profile, Stack and Option, Stat},
	year = {1997},
	file = {Tofte et al_1997_Programming with Regions in the ML Kit.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte et al_1997_Programming with Regions in the ML Kit.pdf:application/pdf}
}

@inproceedings{gay_language_2001,
	address = {New York, NY, USA},
	series = {{PLDI} '01},
	title = {Language {Support} for {Regions}},
	isbn = {978-1-58113-414-8},
	url = {http://doi.acm.org/10.1145/378795.378815},
	doi = {10.1145/378795.378815},
	abstract = {Region-based memory management systems structure memory by grouping objects in regions under program control. Memory is reclaimed by deleting regions, freeing all objects stored therein. Our compiler for C with regions, RC, prevents unsafe region deletions by keeping a count of references to each region. Using type annotations that make the structure of a program's regions more explicit, we reduce the overhead of reference counting from a maximum of 27\% to a maximum of 11\% on a suite of realistic benchmarks. We generalise these annotations in a region type system whose main novelty is the use of existentially quantified abstract regions to represent pointers to objects whose region is partially or totally unknown. A distribution of RC is available at http://www.cs.berkeley.edu/{\textasciitilde}dgay/rc.tar.gz.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2001 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Gay, David and Aiken, Alex},
	year = {2001},
	pages = {70--80},
	file = {Gay_Aiken_2001_Language Support for Regions.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay_Aiken_2001_Language Support for Regions.pdf:application/pdf}
}

@inproceedings{cooprider_efficient_2007,
	address = {New York, NY, USA},
	series = {{SenSys} '07},
	title = {Efficient {Memory} {Safety} for {TinyOS}},
	isbn = {978-1-59593-763-6},
	url = {http://doi.acm.org/10.1145/1322263.1322283},
	doi = {10.1145/1322263.1322283},
	abstract = {Reliable sensor network software is difficult to create: applications are concurrent and distributed, hardware-based memory protection is unavailable, and severe resource constraints necessitate the use of unsafe, low-level languages. Our work improves this situation by providing efficient memory and type safety for TinyOS 2 applications running on the Mica2, MicaZ, and TelosB platforms. Safe execution ensures that array and pointer errors are caught before they can corrupt RAM. Our contributions include showing that aggressive optimizations can make safe execution practical in terms of resource usage; developing a technique for efficiently enforcing safety under interrupt-driven concurrency; extending the nesC language and compiler to support safety annotations; finding previously unknown bugs in TinyOS; and, finally, showing that safety can be exploited to increase the availability of sensor networks applications even when memory errors are left unfixed.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Embedded} {Networked} {Sensor} {Systems}},
	publisher = {ACM},
	author = {Cooprider, Nathan and Archer, Will and Eide, Eric and Gay, David and Regehr, John},
	year = {2007},
	keywords = {type safety, memory safety, nesC, TinyOS, wireless sensor networks, cXprop, deputy, safe TinyOS},
	pages = {205--218},
	file = {Cooprider et al_2007_Efficient Memory Safety for TinyOS.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cooprider et al_2007_Efficient Memory Safety for TinyOS.pdf:application/pdf}
}

@inproceedings{hasabnis_light-weight_2012,
	address = {New York, NY, USA},
	series = {{CGO} '12},
	title = {Light-weight {Bounds} {Checking}},
	isbn = {978-1-4503-1206-6},
	url = {http://doi.acm.org/10.1145/2259016.2259034},
	doi = {10.1145/2259016.2259034},
	abstract = {Memory errors in C and C++ programs continue to be one of the dominant sources of security problems, accounting for over a third of the high severity vulnerabilities reported in 2011. Wide-spread deployment of defenses such as address-space layout randomization (ASLR) have made memory exploit development more difficult, but recent trends indicate that attacks are evolving to overcome this defense. Techniques for systematic detection and blocking of memory errors can provide more comprehensive protection that can stand up to skilled adversaries, but unfortunately, these techniques introduce much higher overheads and provide significantly less compatibility than ASLR. We propose a new memory error detection technique that explores a part of the design space that trades off some ability to detect bounds errors in order to obtain good performance and excellent backwards compatibility. On the SPECINT 2000 benchmark, the runtime overheads of our technique is about half of that reported by the fastest previous bounds-checking technique. On the compatibility front, our technique has been tested on over 7 million lines of code, which is much larger than that reported for previous bounds-checking techniques.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the {Tenth} {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {ACM},
	author = {Hasabnis, Niranjan and Misra, Ashish and Sekar, R.},
	year = {2012},
	pages = {135--144},
	file = {Hasabnis et al_2012_Light-weight Bounds Checking.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hasabnis et al_2012_Light-weight Bounds Checking.pdf:application/pdf}
}

@inproceedings{midi_memory_2017,
	address = {New York, NY, USA},
	series = {{ASIA} {CCS} '17},
	title = {Memory {Safety} for {Embedded} {Devices} with {nesCheck}},
	isbn = {978-1-4503-4944-4},
	url = {http://doi.acm.org/10.1145/3052973.3053014},
	doi = {10.1145/3052973.3053014},
	abstract = {Applications for TinyOS, a popular operating system for embedded systems and wireless sensor networks, are written in nesC, a C dialect prone to the same type and memory safety vulnerabilities as C. While availability and integrity are critical requirements, the distributed and concurrent nature of such applications, combined with the intrinsic unsafety of the language, makes those security goals hard to achieve. Traditional memory safety techniques cannot be applied, due to the strict platform constraints and hardware differences of embedded systems. We design nesCheck, an approach that combines static analysis and dynamic checking to automatically enforce memory safety on nesC programs without requiring source modifications. nesCheck analyzes the source code, identifies the minimal conservative set of vulnerable pointers, finds static memory bugs, and instruments the code with the required dynamic runtime checks. Our prototype extends the existing TinyOS compiler toolchain with LLVM-based passes. Our evaluation shows that nesCheck effectively and efficiently enforces memory protection, catching all memory errors with an overhead of 0.84\% on energy, 5.3\% on code size, up to 8.4\% on performance, and 16.7\% on RAM.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 2017 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Midi, Daniele and Payer, Mathias and Bertino, Elisa},
	year = {2017},
	keywords = {memory safety, static analysis, nesC, wireless sensor networks, instrumentation},
	pages = {127--139},
	file = {Midi et al_2017_Memory Safety for Embedded Devices with nesCheck.pdf:/home/michael/Dropbox/zotero-pdfs/M/Midi et al_2017_Memory Safety for Embedded Devices with nesCheck.pdf:application/pdf}
}

@inproceedings{perkins_automatically_2009,
	address = {New York, NY, USA},
	series = {{SOSP} '09},
	title = {Automatically {Patching} {Errors} in {Deployed} {Software}},
	isbn = {978-1-60558-752-3},
	url = {http://doi.acm.org/10.1145/1629575.1629585},
	doi = {10.1145/1629575.1629585},
	abstract = {We present ClearView, a system for automatically patching errors in deployed software. ClearView works on stripped Windows x86 binaries without any need for source code, debugging information, or other external information, and without human intervention. ClearView (1) observes normal executions to learn invariants thatcharacterize the application's normal behavior, (2) uses error detectors to distinguish normal executions from erroneous executions, (3) identifies violations of learned invariants that occur during erroneous executions, (4) generates candidate repair patches that enforce selected invariants by changing the state or flow of control to make the invariant true, and (5) observes the continued execution of patched applications to select the most successful patch. ClearView is designed to correct errors in software with high availability requirements. Aspects of ClearView that make it particularly appropriate for this context include its ability to generate patches without human intervention, apply and remove patchesto and from running applications without requiring restarts or otherwise perturbing the execution, and identify and discard ineffective or damaging patches by evaluating the continued behavior of patched applications. ClearView was evaluated in a Red Team exercise designed to test its ability to successfully survive attacks that exploit security vulnerabilities. A hostile external Red Team developed ten code injection exploits and used these exploits to repeatedly attack an application protected by ClearView. ClearView detected and blocked all of the attacks. For seven of the ten exploits, ClearView automatically generated patches that corrected the error, enabling the application to survive the attacks and continue on to successfully process subsequent inputs. Finally, the Red Team attempted to make Clear-View apply an undesirable patch, but ClearView's patch evaluation mechanism enabled ClearView to identify and discard both ineffective patches and damaging patches.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 22Nd {Symposium} on {Operating} {Systems} {Principles}},
	publisher = {ACM},
	author = {Perkins, Jeff H. and Kim, Sunghun and Larsen, Sam and Amarasinghe, Saman and Bachrach, Jonathan and Carbin, Michael and Pacheco, Carlos and Sherwood, Frank and Sidiroglou, Stelios and Sullivan, Greg and Wong, Weng-Fai and Zibin, Yoav and Ernst, Michael D. and Rinard, Martin},
	year = {2009},
	keywords = {healing, self},
	pages = {87--102},
	file = {Perkins et al_2009_Automatically Patching Errors in Deployed Software.pdf:/home/michael/Dropbox/zotero-pdfs/P/Perkins et al_2009_Automatically Patching Errors in Deployed Software.pdf:application/pdf}
}

@inproceedings{grossman_type-safe_2003,
	address = {New York, NY, USA},
	series = {{TLDI} '03},
	title = {Type-safe {Multithreading} in {Cyclone}},
	isbn = {978-1-58113-649-4},
	url = {http://doi.acm.org/10.1145/604174.604177},
	doi = {10.1145/604174.604177},
	abstract = {We extend Cyclone, a type-safe polymorphic language at the C level of abstraction, with threads and locks. Data races can violate type safety in Cyclone. An extended type system statically guarantees their absence by enforcing that thread-shared data is protected via locking and that thread-local data does not escape the thread that creates it. The extensions interact smoothly with parametric polymorphism and region-based memory management. We present a formal abstract machine that models the need to prevent races, a polymorphic type system for the machine that supports thread-local data, and a corresponding type-safety result.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 2003 {ACM} {SIGPLAN} {International} {Workshop} on {Types} in {Languages} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Grossman, Dan},
	year = {2003},
	keywords = {data races, types, cyclone},
	pages = {13--25},
	file = {Grossman_2003_Type-safe Multithreading in Cyclone.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grossman_2003_Type-safe Multithreading in Cyclone.pdf:application/pdf}
}

@inproceedings{rafkind_precise_2009,
	address = {New York, NY, USA},
	series = {{ISMM} '09},
	title = {Precise {Garbage} {Collection} for {C}},
	isbn = {978-1-60558-347-1},
	url = {http://doi.acm.org/10.1145/1542431.1542438},
	doi = {10.1145/1542431.1542438},
	abstract = {Magpie is a source-to-source transformation for C programs that enables precise garbage collection, where precise means that integers are not confused with pointers, and the liveness of a pointer is apparent at the source level. Precise GC is primarily useful for long-running programs and programs that interact with untrusted components. In particular, we have successfully deployed precise GC in the C implementation of a language run-time system that was originally designed to use conservative GC. We also report on our experience in transforming parts of the Linux kernel to use precise GC instead of manual memory management.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 2009 {International} {Symposium} on {Memory} {Management}},
	publisher = {ACM},
	author = {Rafkind, Jon and Wick, Adam and Regehr, John and Flatt, Matthew},
	year = {2009},
	keywords = {garbage collection, accurate, c programming language, conservative, precise},
	pages = {39--48},
	file = {Rafkind et al_2009_Precise Garbage Collection for C.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rafkind et al_2009_Precise Garbage Collection for C.pdf:application/pdf}
}

@inproceedings{memarian_into_2016,
	address = {New York, NY, USA},
	series = {{PLDI} '16},
	title = {Into the {Depths} of {C}: {Elaborating} the {De} {Facto} {Standards}},
	isbn = {978-1-4503-4261-2},
	shorttitle = {Into the {Depths} of {C}},
	url = {http://doi.acm.org/10.1145/2908080.2908081},
	doi = {10.1145/2908080.2908081},
	abstract = {C remains central to our computing infrastructure. It is notionally defined by ISO standards, but in reality the properties of C assumed by systems code and those implemented by compilers have diverged, both from the ISO standards and from each other, and none of these are clearly understood. We make two contributions to help improve this error-prone situation. First, we describe an in-depth analysis of the design space for the semantics of pointers and memory in C as it is used in practice. We articulate many specific questions, build a suite of semantic test cases, gather experimental data from multiple implementations, and survey what C experts believe about the de facto standards. We identify questions where there is a consensus (either following ISO or differing) and where there are conflicts. We apply all this to an experimental C implemented above capability hardware. Second, we describe a formal model, Cerberus, for large parts of C. Cerberus is parameterised on its memory model; it is linkable either with a candidate de facto memory object model, under construction, or with an operational C11 concurrency model; it is defined by elaboration to a much simpler Core language for accessibility, and it is executable as a test oracle on small examples. This should provide a solid basis for discussion of what mainstream C is now: what programmers and analysis tools can assume and what compilers aim to implement. Ultimately we hope it will be a step towards clear, consistent, and accepted semantics for the various use-cases of C.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Memarian, Kayvan and Matthiesen, Justus and Lingard, James and Nienhuis, Kyndylan and Chisnall, David and Watson, Robert N. M. and Sewell, Peter},
	year = {2016},
	keywords = {C},
	pages = {1--15},
	file = {Memarian et al_2016_Into the Depths of C - Elaborating the De Facto Standards.pdf:/home/michael/Dropbox/zotero-pdfs/M/Memarian et al_2016_Into the Depths of C - Elaborating the De Facto Standards.pdf:application/pdf}
}

@article{balasubramanian_system_2017,
	title = {System {Programming} in {Rust}: {Beyond} {Safety}},
	volume = {51},
	issn = {0163-5980},
	shorttitle = {System {Programming} in {Rust}},
	url = {http://doi.acm.org/10.1145/3139645.3139660},
	doi = {10.1145/3139645.3139660},
	abstract = {Rust is a new system programming language that offers a practical and safe alternative to C. Rust is unique in that it enforces safety without runtime overhead, most importantly, without the overhead of garbage collection. While zero-cost safety is remarkable on its own, we argue that the superpowers of Rust go beyond safety. In particular, Rust's linear type system enables capabilities that cannot be implemented efficiently in traditional languages, both safe and unsafe, and that dramatically improve security and reliability of system software. We show three examples of such capabilities: zero-copy software fault isolation, efficient static information flow analysis, and automatic checkpointing. While these capabilities have been in the spotlight of systems research for a long time, their practical use is hindered by high cost and complexity. We argue that with the adoption of Rust these mechanisms will become commoditized.},
	number = {1},
	urldate = {2018-02-28},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Balasubramanian, Abhiram and Baranowski, Marek S. and Burtsev, Anton and Panda, Aurojit and Rakamari, Zvonimir and Ryzhyk, Leonid},
	month = sep,
	year = {2017},
	pages = {94--99},
	file = {Balasubramanian et al_2017_System Programming in Rust - Beyond Safety.pdf:/home/michael/Dropbox/zotero-pdfs/B/Balasubramanian et al_2017_System Programming in Rust - Beyond Safety.pdf:application/pdf}
}

@article{dhurjati_memory_2005,
	title = {Memory {Safety} {Without} {Garbage} {Collection} for {Embedded} {Applications}},
	volume = {4},
	issn = {1539-9087},
	url = {http://doi.acm.org/10.1145/1053271.1053275},
	doi = {10.1145/1053271.1053275},
	abstract = {Traditional approaches to enforcing memory safety of programs rely heavily on run-time checks of memory accesses and on garbage collection, both of which are unattractive for embedded applications. The goal of our work is to develop advanced compiler techniques for enforcing memory safety with minimal run-time overheads. In this paper, we describe a set of compiler techniques that, together with minor semantic restrictions on C programs and no new syntax, ensure memory safety and provide most of the error-detection capabilities of type-safe languages, without using garbage collection, and with no run-time software checks, (on systems with standard hardware support for memory management). The language permits arbitrary pointer-based data structures, explicit deallocation of dynamically allocated memory, and restricted array operations. One of the key results of this paper is a compiler technique that ensures that dereferencing dangling pointers to freed memory does not violate memory safety, without annotations, run-time checks, or garbage collection, and works for arbitrary type-safe C programs. Furthermore, we present a new interprocedural analysis for static array bounds checking under certain assumptions. For a diverse set of embedded C programs, we show that we are able to ensure memory safety of pointer and dynamic memory usage in all these programs with no run-time software checks (on systems with standard hardware memory protection), requiring only minor restructuring to conform to simple type restrictions. Static array bounds checking fails for roughly half the programs we study due to complex array references, and these are the only cases where explicit run-time software checks would be needed under our language and system assumptions.},
	number = {1},
	urldate = {2018-02-28},
	journal = {ACM Trans. Embed. Comput. Syst.},
	author = {Dhurjati, Dinakar and Kowshik, Sumant and Adve, Vikram and Lattner, Chris},
	month = feb,
	year = {2005},
	keywords = {security, programming languages, static analysis, compilers, automatic pool allocation, Embedded systems, region management},
	pages = {73--111},
	file = {Dhurjati et al_2005_Memory Safety Without Garbage Collection for Embedded Applications.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dhurjati et al_2005_Memory Safety Without Garbage Collection for Embedded Applications.pdf:application/pdf}
}

@inproceedings{frampton_demystifying_2009,
	address = {New York, NY, USA},
	series = {{VEE} '09},
	title = {Demystifying {Magic}: {High}-level {Low}-level {Programming}},
	isbn = {978-1-60558-375-4},
	shorttitle = {Demystifying {Magic}},
	url = {http://doi.acm.org/10.1145/1508293.1508305},
	doi = {10.1145/1508293.1508305},
	abstract = {The power of high-level languages lies in their abstraction over hardware and software complexity, leading to greater security, better reliability, and lower development costs. However, opaque abstractions are often show-stoppers for systems programmers, forcing them to either break the abstraction, or more often, simply give up and use a different language. This paper addresses the challenge of opening up a high-level language to allow practical low-level programming without forsaking integrity or performance. The contribution of this paper is three-fold: 1) we draw together common threads in a diverse literature, 2) we identify a framework for extending high-level languages for low-level programming, and 3) we show the power of this approach through concrete case studies. Our framework leverages just three core ideas: extending semantics via intrinsic methods, extending types via unboxing and architectural-width primitives, and controlling semantics via scoped semantic regimes. We develop these ideas through the context of a rich literature and substantial practical experience. We show that they provide the power necessary to implement substantial artifacts such as a high-performance virtual machine, while preserving the software engineering benefits of the host language. The time has come for high-level low-level programming to be taken more seriously: 1) more projects now use high-level languages for systems programming, 2) increasing architectural heterogeneity and parallelism heighten the need for abstraction, and 3) a new generation of high-level languages are under development and ripe to be influenced.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 2009 {ACM} {SIGPLAN}/{SIGOPS} {International} {Conference} on {Virtual} {Execution} {Environments}},
	publisher = {ACM},
	author = {Frampton, Daniel and Blackburn, Stephen M. and Cheng, Perry and Garner, Robin J. and Grove, David and Moss, J. Eliot B. and Salishev, Sergey I.},
	year = {2009},
	keywords = {systems programming, debugging, intrinsics, jikes rvm, magic, mmtk, virtualization, vmmagic},
	pages = {81--90},
	file = {Frampton et al_2009_Demystifying Magic - High-level Low-level Programming.pdf:/home/michael/Dropbox/zotero-pdfs/F/Frampton et al_2009_Demystifying Magic - High-level Low-level Programming.pdf:application/pdf}
}

@inproceedings{mccorkle_modern_2006,
	address = {New York, NY, USA},
	series = {{ACM}-{SE} 44},
	title = {Modern {Features} for {Systems} {Programming} {Languages}},
	isbn = {978-1-59593-315-7},
	url = {http://doi.acm.org/10.1145/1185448.1185599},
	doi = {10.1145/1185448.1185599},
	abstract = {This paper presents a case for the design and implementation of a modern programming language for systems programming. It shows that traditional systems languages like C and Fortran possess features no longer relevant to the modern world. The paper also demonstrates how many of these features have a negative impact on the practice of systems programming. Finally, it proposes alternatives to these features that promote better practice.Additionally, the paper presents a number of features that should be included in a modern systems languages and argues in favor of their inclusion. It shows that these features have a beneficial impact on the expressive power of the language or the practices it promotes. The paper also demonstrates that these features do not compromise the objectives of simplicity, efficiency, and direct control that characterize a systems language.},
	urldate = {2018-02-28},
	booktitle = {Proceedings of the 44th {Annual} {Southeast} {Regional} {Conference}},
	publisher = {ACM},
	author = {McCorkle, Eric L.},
	year = {2006},
	pages = {691--697},
	file = {McCorkle_2006_Modern Features for Systems Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/M/McCorkle_2006_Modern Features for Systems Programming Languages.pdf:application/pdf}
}

@book{sridhar_sound_2008,
	title = {Sound and {Complete} {Type} {Inference} for a {Systems} {Programming} {Language}},
	abstract = {Abstract. This paper introduces a new type system designed for safe systems programming. The type system features a new mutability model that combines unboxed types with a consistent typing of mutability. The type system is provably sound, supports polymorphism, and eliminates the need for alias analysis to determine the immutability of a location. A sound and complete type inference algorithm for this system is presented. 1},
	author = {Sridhar, Swaroop and Shapiro, Jonathan S. and Smith, Scott F.},
	year = {2008},
	file = {Sridhar et al_Sound and Complete Type Inference for a Systems Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sridhar et al_Sound and Complete Type Inference for a Systems Programming Language.pdf:application/pdf}
}

@inproceedings{brewer_thirty_2005,
	title = {Thirty {Years} {Is} {Long} {Enough}: {Getting} {Beyond} {C}.},
	shorttitle = {Thirty {Years} {Is} {Long} {Enough}},
	booktitle = {{HotOS}},
	author = {Brewer, Eric A. and Condit, Jeremy and McCloskey, Bill and Zhou, Feng},
	year = {2005},
	file = {brewer.pdf:/home/michael/Zotero/storage/DGIBPEVY/brewer.pdf:application/pdf}
}

@inproceedings{kosakai_compiling_2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Compiling {C} {Programs} into a {Strongly} {Typed} {Assembly} {Language}},
	isbn = {978-3-540-76927-9 978-3-540-76929-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-76929-3_3},
	doi = {10.1007/978-3-540-76929-3_3},
	abstract = {C is one of the most popular languages in system programming, though its unsafe nature often causes security vulnerabilities. In the face of this situation, many tools are developed to ensure safety properties of C programs. However, most of them work at the source code level, and conventional compilers lose safety guarantee as they translate source code into assembly code. In this paper, we present CTAL0, a strongly typed assembly language that is aimed at certifying the memory safety of assembly code compiled from C programs. CTAL0 is expressive enough to implement potentially unsafe ANSI C features including pointer arithmetics and casts. We have also implemented a type-checker and an experimental C compiler that produces safe CTAL0 assembly code by performing several transformations on given programs to avoid dangerous operations.},
	language = {en},
	urldate = {2018-02-28},
	booktitle = {Advances in {Computer} {Science} – {ASIAN} 2007. {Computer} and {Network} {Security}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Kosakai, Takahiro and Maeda, Toshiyuki and Yonezawa, Akinori},
	month = dec,
	year = {2007},
	pages = {17--32},
	file = {Kosakai et al_2007_Compiling C Programs into a Strongly Typed Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kosakai et al_2007_Compiling C Programs into a Strongly Typed Assembly Language.pdf:application/pdf}
}

@article{tofte_retrospective_2004,
	title = {A {Retrospective} on {Region}-{Based} {Memory} {Management}},
	volume = {17},
	issn = {1388-3690, 1573-0557},
	url = {https://link.springer.com/article/10.1023/B:LISP.0000029446.78563.a4},
	doi = {10.1023/B:LISP.0000029446.78563.a4},
	abstract = {We report on our experience with designing, implementing, proving correct, and evaluating a region-based memory management system.},
	language = {en},
	number = {3},
	urldate = {2018-02-28},
	journal = {Higher-Order and Symbolic Computation},
	author = {Tofte, Mads and Birkedal, Lars and Elsman, Martin and Hallenberg, Niels},
	month = sep,
	year = {2004},
	pages = {245--265},
	file = {Tofte et al_2004_A Retrospective on Region-Based Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte et al_2004_A Retrospective on Region-Based Memory Management.pdf:application/pdf}
}

@article{jones_five_2006,
	title = {Five perspectives on modern memory management: {Systems}, hardware and theory},
	shorttitle = {Five perspectives on modern memory management},
	url = {https://core.ac.uk/display/82490175},
	language = {en-gb},
	urldate = {2018-02-28},
	author = {Jones, Richard},
	year = {2006},
	file = {Jones_2006_Five perspectives on modern memory management - Systems, hardware and theory.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_2006_Five perspectives on modern memory management - Systems, hardware and theory.pdf:application/pdf}
}

@article{wright_simple_1995,
	title = {Simple imperative polymorphism},
	volume = {8},
	issn = {0892-4635, 1573-0557},
	url = {https://link.springer.com/article/10.1007/BF01018828},
	doi = {10.1007/BF01018828},
	abstract = {This paper describes a simple extension of the Hindley-Milner polymorphic type discipline to call-by-value languages that incorporate imperative features like references, exceptions, and continuations. This extension sacrifices the ability to type every purely functional expression that is typable in the Hindley-Milner system. In return, it assigns the same type to functional and imperative implementations of the same abstraction. Hence with a module system that separates specifications from implementations, imperative features can be freely used to implement polymorphic specifications. A study of a number of ML programs shows that the inability to type all Hindley-Milner typable expressions seldom impacts realistic programs. Furthermore, most programs that are rendered untypable by the new system can be easily repaired.},
	language = {en},
	number = {4},
	urldate = {2018-03-02},
	journal = {LISP and Symbolic Computation},
	author = {Wright, Andrew K.},
	month = dec,
	year = {1995},
	pages = {343--355},
	file = {Wright_1995_Simple imperative polymorphism.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wright_1995_Simple imperative polymorphism.pdf:application/pdf}
}

@article{smith_sound_1998,
	series = {6th {European} {Symposium} on {Programming}},
	title = {A sound polymorphic type system for a dialect of {C}},
	volume = {32},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642397000300},
	doi = {10.1016/S0167-6423(97)00030-0},
	abstract = {Advanced polymorphic type systems have come to play an important role in the world of functional programming. But, so far, these type systems have had little impact upon widely used imperative programming languages like C and C++. We show that ML-style polymorphism can be integrated smoothly into a dialect of C, which we call Polymorphic C. It has the same pointer operations as C, including the address-of operator \&, the dereferencing operator ∗, and pointer arithmetic. We give a natural semantics for Polymorphic C, and prove a type soundness theorem that gives a rigorous and useful characterization of what can go wrong when a well-typed Polymorphic C program is executed. For example, a well-typed Polymorphic C program may fail to terminate, or it may abort due to a dangling pointer error. Proving such a type soundness theorem requires a notion of an attempted program execution; we show that a natural semantics gives rise quite naturally to a transition semantics, which we call a natural transition semantics, that models program execution in terms of transformations of partial derivation trees. This technique should be generally useful in proving type soundness theorems for languages defined using natural semantics.},
	number = {1},
	urldate = {2018-03-02},
	journal = {Science of Computer Programming},
	author = {Smith, Geoffrey and Volpano, Dennis},
	month = sep,
	year = {1998},
	keywords = {C, Natural semantics, Polymorphism, Transition semantics, Type soudness, Type systems, Variables},
	pages = {49--72},
	file = {Smith_Volpano_1998_A sound polymorphic type system for a dialect of C.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_Volpano_1998_A sound polymorphic type system for a dialect of C.pdf:application/pdf}
}

@article{grossman_quantified_2006,
	title = {Quantified {Types} in an {Imperative} {Language}},
	volume = {28},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1133651.1133653},
	doi = {10.1145/1133651.1133653},
	abstract = {We describe universal types, existential types, and type constructors in Cyclone, a strongly typed C-like language. We show how the language naturally supports first-class polymorphism and polymorphic recursion while requiring an acceptable amount of explicit type information. More importantly, we consider the soundness of type variables in the presence of C-style mutation and the address-of operator. For polymorphic references, we describe a solution more natural for the C level than the ML-style “value restriction.” For existential types, we discover and subsequently avoid a subtle unsoundness issue resulting from the address-of operator. We develop a formal abstract machine and type-safety proof that capture the essence of type variables at the C level.},
	number = {3},
	urldate = {2018-03-02},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Grossman, Dan},
	month = may,
	year = {2006},
	keywords = {polymorphism, Cyclone, existential types, type variables},
	pages = {429--475},
	file = {Grossman_2006_Quantified Types in an Imperative Language.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grossman_2006_Quantified Types in an Imperative Language.pdf:application/pdf}
}

@book{pierce_basic_1991,
	address = {Cambridge, MA, USA},
	title = {Basic {Category} {Theory} for {Computer} {Scientists}},
	isbn = {978-0-262-66071-6},
	publisher = {MIT Press},
	author = {Pierce, Benjamin C.},
	year = {1991}
}

@book{lane_categories_1978,
	address = {New York},
	edition = {2},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Categories for the {Working} {Mathematician}},
	isbn = {978-0-387-98403-2},
	url = {//www.springer.com/us/book/9780387984032},
	abstract = {Categories for the Working Mathematician provides an array of general ideas useful in a wide variety of fields. Starting from the foundations, this book illuminates the concepts of category, functor, natural transformation, and duality. The book then turns to adjoint functors, which provide a description of universal constructions, an analysis of the representations of functors by sets of morphisms, and a means of manipulating direct and inverse limits. These categorical concepts are extensively illustrated in the remaining chapters, which include many applications of the basic existence theorem for adjoint functors. The categories of algebraic systems are constructed from certain adjoint-like data and characterized by Beck's theorem. After considering a variety of applications, the book continues with the construction and exploitation of Kan extensions. This second edition includes a number of revisions and additions, including two new chapters on topics of active interest. One is on symmetric monoidal categories and braided monoidal categories and the coherence theorems for them. The second describes 2-categories and the higher dimensional categories which have recently come into prominence. The bibliography has also been expanded to cover some of the many other recent advances concerning categories.},
	language = {en},
	urldate = {2018-03-02},
	publisher = {Springer-Verlag},
	author = {Lane, Saunders Mac},
	year = {1978},
	file = {Lane_1978_Categories for the Working Mathematician.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lane_1978_Categories for the Working Mathematician.pdf:application/pdf}
}

@article{nieuwenhuis_solving_2006,
	title = {Solving {SAT} and {SAT} {Modulo} {Theories}: {From} an {Abstract} {Davis}–{Putnam}–{Logemann}–{Loveland} {Procedure} to {DPLL}({T})},
	volume = {53},
	issn = {0004-5411},
	shorttitle = {Solving {SAT} and {SAT} {Modulo} {Theories}},
	url = {http://doi.acm.org/10.1145/1217856.1217859},
	doi = {10.1145/1217856.1217859},
	abstract = {We first introduce Abstract DPLL, a rule-based formulation of the Davis--Putnam--Logemann--Loveland (DPLL) procedure for propositional satisfiability. This abstract framework allows one to cleanly express practical DPLL algorithms and to formally reason about them in a simple way. Its properties, such as soundness, completeness or termination, immediately carry over to the modern DPLL implementations with features such as backjumping or clause learning.We then extend the framework to Satisfiability Modulo background Theories (SMT) and use it to model several variants of the so-called lazy approach for SMT. In particular, we use it to introduce a few variants of a new, efficient and modular approach for SMT based on a general DPLL(X) engine, whose parameter X can be instantiated with a specialized solver SolverT for a given theory T, thus producing a DPLL(T) system. We describe the high-level design of DPLL(X) and its cooperation with SolverT, discuss the role of theory propagation, and describe different DPLL(T) strategies for some theories arising in industrial applications.Our extensive experimental evidence, summarized in this article, shows that DPLL(T) systems can significantly outperform the other state-of-the-art tools, frequently even in orders of magnitude, and have better scaling properties.},
	number = {6},
	urldate = {2018-03-06},
	journal = {J. ACM},
	author = {Nieuwenhuis, Robert and Oliveras, Albert and Tinelli, Cesare},
	month = nov,
	year = {2006},
	keywords = {SAT solvers, Satisfiability Modulo Theories},
	pages = {937--977},
	file = {Nieuwenhuis et al_2006_Solving SAT and SAT Modulo Theories - From an Abstract.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nieuwenhuis et al_2006_Solving SAT and SAT Modulo Theories - From an Abstract.pdf:application/pdf}
}

@article{gay_subtyping_2005,
	title = {Subtyping for session types in the pi calculus},
	volume = {42},
	issn = {0001-5903, 1432-0525},
	url = {https://link.springer.com/article/10.1007/s00236-005-0177-z},
	doi = {10.1007/s00236-005-0177-z},
	abstract = {Extending the pi calculus with the session types proposed by Honda et al. allows high-level specifications of structured patterns of communication, such as client-server protocols, to be expressed as types and verified by static typechecking. We define a notion of subtyping for session types, which allows protocol specifications to be extended in order to describe richer behaviour; for example, an implemented server can be refined without invalidating type-correctness of an overall system. We formalize the syntax, operational semantics and typing rules of an extended pi calculus, prove that typability guarantees absence of run-time communication errors, and show that the typing rules can be transformed into a practical typechecking algorithm.},
	language = {en},
	number = {2-3},
	urldate = {2018-03-07},
	journal = {Acta Informatica},
	author = {Gay, Simon and Hole, Malcolm},
	month = nov,
	year = {2005},
	pages = {191--225},
	file = {Gay_Hole_2005_Subtyping for session types in the pi calculus.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay_Hole_2005_Subtyping for session types in the pi calculus.pdf:application/pdf}
}

@inproceedings{anderson_engineering_2016,
	address = {New York, NY, USA},
	series = {{ICSE} '16},
	title = {Engineering the {Servo} {Web} {Browser} {Engine} {Using} {Rust}},
	isbn = {978-1-4503-4205-6},
	url = {http://doi.acm.org/10.1145/2889160.2889229},
	doi = {10.1145/2889160.2889229},
	abstract = {All modern web browsers --- Internet Explorer, Firefox, Chrome, Opera, and Safari --- have a core rendering engine written in C++. This language choice was made because it affords the systems programmer complete control of the underlying hardware features and memory in use, and it provides a transparent compilation model. Unfortunately, this language is complex (especially to new contributors!), challenging to write correct parallel code in, and highly susceptible to memory safety issues that potentially lead to security holes. Servo is a project started at Mozilla Research to build a new web browser engine that preserves the capabilities of these other browser engines but also both takes advantage of the recent trends in parallel hardware and is more memory-safe. We use a new language, Rust, that provides us a similar level of control of the underlying system to C++ but which statically prevents many memory safety issues and provides direct support for parallelism and concurrency. In this paper, we show how a language with an advanced type system can address many of the most common security issues and software engineering challenges in other browser engines, while still producing code that has the same performance and memory profile. This language is also quite accessible to new open source contributors and employees, even those without a background in C++ or systems programming. We also outline several pitfalls encountered along the way and describe some potential areas for future improvement.},
	urldate = {2018-03-07},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Software} {Engineering} {Companion}},
	publisher = {ACM},
	author = {Anderson, Brian and Bergstrom, Lars and Goregaokar, Manish and Matthews, Josh and McAllister, Keegan and Moffitt, Jack and Sapin, Simon},
	year = {2016},
	keywords = {concurrency, Rust, browser engine, parallelism, servo},
	pages = {81--89},
	file = {Anderson et al_2016_Engineering the Servo Web Browser Engine Using Rust.pdf:/home/michael/Dropbox/zotero-pdfs/A/Anderson et al_2016_Engineering the Servo Web Browser Engine Using Rust.pdf:application/pdf}
}

@article{gerakios_static_2014,
	title = {Static safety guarantees for a low-level multithreaded language with regions},
	volume = {80},
	issn = {01676423},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0167642313001433},
	doi = {10.1016/j.scico.2013.06.005},
	language = {en},
	urldate = {2018-03-07},
	journal = {Science of Computer Programming},
	author = {Gerakios, Prodromos and Papaspyrou, Nikolaos and Sagonas, Konstantinos},
	month = feb,
	year = {2014},
	pages = {223--263},
	file = {Gerakios et al_2014_Static safety guarantees for a low-level multithreaded language with regions.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gerakios et al_2014_Static safety guarantees for a low-level multithreaded language with regions.pdf:application/pdf}
}

@misc{noauthor_sel4_2013,
	title = {{seL}4 {Reference} {Manual} {API} version 1.2},
	publisher = {Trustworthy Systems Team, NICTA},
	month = mar,
	year = {2013},
	file = {2013_seL4 Reference Manual API version 1.2.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/2013_seL4 Reference Manual API version 1.2.pdf:application/pdf}
}

@inproceedings{litton_light-weight_2016,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'16},
	title = {Light-weight {Contexts}: {An} {OS} {Abstraction} for {Safety} and {Performance}},
	isbn = {978-1-931971-33-1},
	shorttitle = {Light-weight {Contexts}},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026882},
	abstract = {We introduce a new OS abstraction--light-weight contexts (lwCs)--that provides independent units of protection, privilege, and execution state within a process. A process may include several lwCs, each with possibly different views of memory, file descriptors, and access capabilities. lwCs can be used to efficiently implement roll-back (process can return to a prior recorded state), isolated address spaces (lwCs within the process may have different views of memory, e.g., isolating sensitive data from network-facing components or isolating different user sessions), and privilege separation (in-process reference monitors can arbitrate and control access). lwCs can be implemented efficiently: the overhead of a lwC is proportional to the amount of memory exclusive to the lwC; switching lwCs is quicker than switching kernel threads within the same process. We describe the lwC abstraction and API, and an implementation of lwCs within the FreeBSD 11.0 kernel. Finally, we present an evaluation of common usage patterns, including fast rollback, session isolation, sensitive data isolation, and inprocess reference monitoring, using Apache, nginx, PHP, and OpenSSL.},
	urldate = {2018-03-09},
	booktitle = {Proceedings of the 12th {USENIX} {Conference} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Litton, James and Vahldiek-Oberwagner, Anjo and Elnikety, Eslam and Garg, Deepak and Bhattacharjee, Bobby and Druschel, Peter},
	year = {2016},
	pages = {49--64},
	file = {Litton et al_2016_Light-weight Contexts - An OS Abstraction for Safety and Performance.pdf:/home/michael/Dropbox/zotero-pdfs/L/Litton et al_2016_Light-weight Contexts - An OS Abstraction for Safety and Performance.pdf:application/pdf}
}

@phdthesis{gottlieb_design_2011,
	title = {The design and implementation of a modern systems programming language},
	url = {https://code.google.com/archive/p/decac/},
	abstract = {Low-level systems programming has remained one of the most consistently difficult tasks in software engineering, since systems programmers must routinely deal with details that programming-language and systems researchers have referred to abstract away. At least partially, the difficulty arises from not applying the state of the art in programming-languages research to systems programming. I therefore describe the design and implementation of Deca, a systems language based on modern PL principles. Deca makes use of decades in programming-languages research, particularly drawing from the state of the art in functional programming, type systems, extensible data-types and subroutines, modularity, and systems programming-languages research. I describe Deca’s feature-set, examine the relevant literature, explain design decisions, and give some of the implementation details for Deca language features. I have been writing a compiler for Deca to translate it into machine code, and I describe the overall architecture of this compiler and some of its details in addition to stating where to find its source code as an open-source release. Deca’s
type system also could not have supported subtyping and type inference without a research advance, and I have documented that advance in the preprint conference paper added here as a technical report.},
	school = {University of Massachusetts at Amherst},
	author = {Gottlieb, Eli},
	year = {2011},
	file = {Gottlieb_2011_The design and implementation of a modern systems programming language.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gottlieb_2011_The design and implementation of a modern systems programming language.pdf:application/pdf}
}

@techreport{shapiro_origins_2008,
	title = {The {Origins} of the {BitC} {Progamming} {Language}},
	shorttitle = {Warning},
	url = {https://ipfs.io/ipfs/QmXoypizjW3WknFiJnKLwHCnL72vedxjQkDDP1mXWo6uco/wiki/BitC.html},
	abstract = {The process of programming language creation is a sub-ject of too little reflection and retrospection. Newcom-ers to the field (including, in some measure, us) regularly propose new languages without quite understanding what they are getting into or how big the task is. Those of us who have already crawled down the language design rat-hole rarely have time to describe either the depth of the hole or the true majesty of the rats involved. This paper describes the motivation and early design evolution of the BitC programming language, making our excuses in hindsight and providing a compilation of some of the things that we learned along the way. It describes the problems we were attempting to solve, and where the effort has taken us so far. It also discusses some of the balance points that we attempted to maintain in the lan-guage design process, and where (at least in our view) we think that we succeeded or failed. Some of the problems we were trying to address now have other solutions, but whether BitC per se succeeds or not, we still feel that a language like this remains motivated. 1},
	number = {2008-04},
	author = {Shapiro, Jonathan and Sridhar, Swaroop and Doerrie, Michael Scott},
	year = {2008},
	file = {Shapiro et al_2008_The Origins of the BitC Progamming Language.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shapiro et al_2008_The Origins of the BitC Progamming Language.pdf:application/pdf}
}

@book{d_programming_2006,
	title = {Programming {Language} {Challenges} in {Systems} {Codes} {Why} {Systems} {Programmers} {Still} {Use} {C}, and {What} to {Do} {About} {It}},
	abstract = {There have been major advances in programming languages over the last 20 years. Given this, it seems appropriate to ask why systems programmers continue to largely ignore these languages. What are the deficiencies in the eyes of the systems programmers? How have the efforts of the program-ming language community been misdirected (from their per-spective)? What can/should the PL community do address this? As someone whose research straddles these areas, I was asked to give a talk at this year’s PLOS workshop. What follows are my thoughts on this subject, which may or not represent those of other systems programmers. 1},
	author = {D, Jonathan Shapiro Ph},
	year = {2006},
	file = {D_2006_Programming Language Challenges in Systems Codes Why Systems Programmers Still.pdf:/home/michael/Dropbox/zotero-pdfs/D/D_2006_Programming Language Challenges in Systems Codes Why Systems Programmers Still.pdf:application/pdf}
}

@inproceedings{sewell_acute:_2005,
	title = {Acute: high-level programming language design for distributed computation},
	volume = {40},
	shorttitle = {Acute},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Sewell, Peter and Leifer, James J. and Wansbrough, Keith and Nardelli, Francesco Zappa and Allen-Williams, Mair and Habouzit, Pierre and Vafeiadis, Viktor},
	year = {2005},
	pages = {15--26},
	file = {paper3.pdf:/home/michael/Zotero/storage/89WYMGMT/paper3.pdf:application/pdf}
}

@article{munch-maccagnoni_resource_2018,
	title = {Resource {Polymorphism}},
	url = {http://arxiv.org/abs/1803.02796},
	abstract = {We present a resource-management model for ML-style programming languages, designed to be compatible with the OCaml philosophy and runtime model. This is a proposal to extend the OCaml language with destructors, move semantics, and resource polymorphism, to improve its safety, efficiency, interoperability, and expressiveness. It builds on the ownership-and-borrowing models of systems programming languages (Cyclone, C++11, Rust) and on linear types in functional programming (Linear Lisp, Clean, Alms). It continues a synthesis of resources from systems programming and resources in linear logic initiated by Baker. It is a combination of many known and some new ideas. On the novel side, it highlights the good mathematical structure of Stroustrup's "Resource acquisition is initialisation" (RAII) idiom for resource management based on destructors, a notion sometimes confused with finalizers, and builds on it a notion of resource polymorphism, inspired by polarisation in proof theory, that mixes C++'s RAII and a tracing garbage collector (GC). The proposal targets a new spot in the design space, with an automatic and predictable resource-management model, at the same time based on lightweight and expressive language abstractions. It is backwards-compatible: current code is expected to run with the same performance, the new abstractions fully combine with the current ones, and it supports a resource-polymorphic extension of libraries. It does so with only a few additions to the runtime, and it integrates with the current GC implementation. It is also compatible with the upcoming multicore extension, and suggests that the Rust model for eliminating data-races applies. Interesting questions arise for a safe and practical type system, many of which have already been thoroughly investigated in the languages and prototypes Cyclone, Rust, and Alms.},
	urldate = {2018-03-09},
	journal = {arXiv:1803.02796 [cs]},
	author = {Munch-Maccagnoni, Guillaume},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.02796},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, FROM-BEN},
	file = {Munch-Maccagnoni_2018_Resource Polymorphism.pdf:/home/michael/Dropbox/zotero-pdfs/M/Munch-Maccagnoni_2018_Resource Polymorphism.pdf:application/pdf}
}

@article{xi_applied_2017,
	title = {Applied {Type} {System}: {An} {Approach} to {Practical} {Programming} with {Theorem}-{Proving}},
	shorttitle = {Applied {Type} {System}},
	url = {http://arxiv.org/abs/1703.08683},
	abstract = {The framework Pure Type System (PTS) offers a simple and general approach to designing and formalizing type systems. However, in the presence of dependent types, there often exist certain acute problems that make it difficult for PTS to directly accommodate many common realistic programming features such as general recursion, recursive types, effects (e.g., exceptions, references, input/output), etc. In this paper, Applied Type System (ATS) is presented as a framework for designing and formalizing type systems in support of practical programming with advanced types (including dependent types). In particular, it is demonstrated that ATS can readily accommodate a paradigm referred to as programming with theorem-proving (PwTP) in which programs and proofs are constructed in a syntactically intertwined manner, yielding a practical approach to internalizing constraint-solving needed during type-checking. The key salient feature of ATS lies in a complete separation between statics, where types are formed and reasoned about, and dynamics, where programs are constructed and evaluated. With this separation, it is no longer possible for a program to occur in a type as is otherwise allowed in PTS. The paper contains not only a formal development of ATS but also some examples taken from ats-lang.org, a programming language with a type system rooted in ATS, in support of employing ATS as a framework to formulate advanced type systems for practical programming.},
	urldate = {2018-03-09},
	journal = {arXiv:1703.08683 [cs]},
	author = {Xi, Hongwei},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.08683},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	file = {Xi_2017_Applied Type System - An Approach to Practical Programming with Theorem-Proving.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xi_2017_Applied Type System - An Approach to Practical Programming with Theorem-Proving.pdf:application/pdf}
}

@inproceedings{chen_combining_2005,
	address = {New York, NY, USA},
	series = {{ICFP} '05},
	title = {Combining {Programming} with {Theorem} {Proving}},
	isbn = {978-1-59593-064-4},
	url = {http://doi.acm.org/10.1145/1086365.1086375},
	doi = {10.1145/1086365.1086375},
	abstract = {Applied Type System (ATS) is recently proposed as a framework for designing and formalizing (advanced) type systems in support of practical programming. In ATS, the definition of type equality involves a constraint relation, which may or may not be algorithmically decidable. To support practical programming, we adopted a design in the past that imposes certain restrictions on the syntactic form of constraints so that some effective means can be found for solving constraints automatically. Evidently, this is a rather em ad hoc design in its nature. In this design, which we claim to be both novel and practical. Instead of imposing syntactical restrictions on constraints, we provide a means for the programmer to construct proofs that attest to the validity of constraints. In particular, we are to accommodate a programming paradigm that enables the programmer to combine programming with theorem proving. Also we present some concrete examples in support of the practicality of this design.},
	urldate = {2018-03-09},
	booktitle = {Proceedings of the {Tenth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Chen, Chiyan and Xi, Hongwei},
	year = {2005},
	keywords = {dependent types, theorem proving, applied type system, ATS, proof erasure},
	pages = {66--77},
	file = {Chen_Xi_2005_Combining Programming with Theorem Proving.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chen_Xi_2005_Combining Programming with Theorem Proving.pdf:application/pdf}
}

@inproceedings{xi_dependent_1999,
	title = {Dependent types in practical programming},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages},
	publisher = {ACM},
	author = {Xi, Hongwei and Pfenning, Frank},
	year = {1999},
	pages = {214--227},
	file = {Xi_Pfenning_1999_Dependent types in practical programming.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xi_Pfenning_1999_Dependent types in practical programming.pdf:application/pdf}
}

@inproceedings{zhu_safe_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Safe {Programming} with {Pointers} {Through} {Stateful} {Views}},
	isbn = {978-3-540-24362-5 978-3-540-30557-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-30557-6_8},
	doi = {10.1007/978-3-540-30557-6_8},
	abstract = {The need for direct memory manipulation through pointers is essential in many applications. However, it is also commonly understood that the use (or probably misuse) of pointers is often a rich source of program errors. Therefore, approaches that can effectively enforce safe use of pointers in programming are highly sought after. ATS is a programming language with a type system rooted in a recently developed framework Applied Type System, and a novel and desirable feature in ATS lies in its support for safe programming with pointers through a novel notion of stateful views. In particular, even pointer arithmetic is allowed in ATS and guaranteed to be safe by the type system of ATS. In this paper, we give an overview of this feature in ATS, presenting some interesting examples based on a prototype implementation of ATS to demonstrate the practicality of safe programming with pointer through stateful views.},
	language = {en},
	urldate = {2018-03-09},
	booktitle = {Practical {Aspects} of {Declarative} {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Zhu, Dengping and Xi, Hongwei},
	month = jan,
	year = {2005},
	pages = {83--97},
	file = {Zhu_Xi_2005_Safe Programming with Pointers Through Stateful Views.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhu_Xi_2005_Safe Programming with Pointers Through Stateful Views.pdf:application/pdf}
}

@article{ren_programmer-centric_2012,
	title = {A {Programmer}-{Centric} {Approach} to {Program} {Verification} in {ATS}},
	url = {http://arxiv.org/abs/1203.6102},
	abstract = {Formal specification is widely employed in the construction of high-quality software. However, there is often a huge gap between formal specification and actual implementation. While there is already a vast body of work on software testing and verification, the task to ensure that an implementation indeed meets its specification is still undeniably of great difficulty. ATS is a programming language equipped with a highly expressive type system that allows the programmer to specify and implement and then verify within the language itself that an implementation meets its specification. In this paper, we present largely through examples a programmer-centric style of program verification that puts emphasis on requesting the programmer to explain in a literate fashion why his or her code works. This is a solid step in the pursuit of software construction that is verifiably correct according to specification.},
	urldate = {2018-03-09},
	journal = {arXiv:1203.6102 [cs]},
	author = {Ren, Zhiqiang and Xi, Hongwei},
	month = mar,
	year = {2012},
	note = {arXiv: 1203.6102},
	keywords = {Computer Science - Programming Languages, D.3.3, Computer Science - Software Engineering, D.2.4},
	file = {Ren_Xi_2012_A Programmer-Centric Approach to Program Verification in ATS.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ren_Xi_2012_A Programmer-Centric Approach to Program Verification in ATS.pdf:application/pdf}
}

@article{baker_lively_1992,
	title = {Lively linear {Lisp}: “look ma, no garbage!”},
	volume = {27},
	issn = {03621340},
	shorttitle = {Lively linear {Lisp}},
	url = {http://portal.acm.org/citation.cfm?doid=142137.142162},
	doi = {10.1145/142137.142162},
	abstract = {Linear logic has been proposed as one solution to the problem of garbage collection and providing efficient "updatein-place" capabilities within a more functional language. Linear logic conserves accessibility, and hence provides a mechanical metaphor which is more appropriate for a distributed-memory parallel processor in which copying is explicit. However, linear logic's lack of sharing may introduce significant inefficiencies of its own.},
	language = {en},
	number = {8},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Baker, Henry G.},
	month = aug,
	year = {1992},
	pages = {89--98},
	file = {Baker_1992_Lively linear Lisp - “look ma, no garbage!”.pdf:/home/michael/Dropbox/zotero-pdfs/B/Baker_1992_Lively linear Lisp - “look ma, no garbage!”.pdf:application/pdf}
}

@inproceedings{ennals_linear_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Linear {Types} for {Packet} {Processing}},
	isbn = {978-3-540-21313-0 978-3-540-24725-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-24725-8_15},
	doi = {10.1007/978-3-540-24725-8_15},
	abstract = {We present PacLang: an imperative, concurrent, linearly-typed language designed for expressing packet processing applications. PacLang’s linear type system ensures that no packet is referenced by more than one thread, but allows multiple references to a packet within a thread. We argue (i) that this property greatly simplifies compilation of high-level programs to the distributed memory architectures of modern Network Processors; and (ii) that PacLang’s type system captures that style in which imperative packet processing programs are already written. Claim (ii) is justified by means of a case-study: we describe a PacLang implementation of the IPv4 unicast packet forwarding algorithm. PacLang is formalised by means of an operational semantics and a Unique Ownership theorem formalises its correctness with respect to the type system.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Ennals, Robert and Sharp, Richard and Mycroft, Alan},
	month = mar,
	year = {2004},
	keywords = {FROM-BEN},
	pages = {204--218},
	file = {Ennals et al_2004_Linear Types for Packet Processing.pdf:/home/michael/Dropbox/zotero-pdfs/E/Ennals et al_2004_Linear Types for Packet Processing.pdf:application/pdf}
}

@inproceedings{fluet_linear_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Linear {Regions} {Are} {All} {You} {Need}},
	isbn = {978-3-540-33095-0 978-3-540-33096-7},
	url = {https://link.springer.com/chapter/10.1007/11693024_2},
	doi = {10.1007/11693024_2},
	abstract = {The type-and-effects system of the Tofte-Talpin region calculus makes it possible to safely reclaim objects without a garbage collector. However, it requires that regions have last-in-first-out (LIFO) lifetimes following the block structure of the language. We introduce λrgnUL, a core calculus that is powerful enough to encode Tofte-Talpin-like languages, and that eliminates the LIFO restriction. The target language has an extremely simple, substructural type system. To prove the power of the language, we sketch how Tofte-Talpin-style regions, as well as the first-class dynamic regions and unique pointers of the Cyclone programming language can be encoded in λrgnUL.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Fluet, Matthew and Morrisett, Greg and Ahmed, Amal},
	month = mar,
	year = {2006},
	keywords = {FROM-BEN},
	pages = {7--21},
	file = {Fluet et al_2006_Linear Regions Are All You Need.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fluet et al_2006_Linear Regions Are All You Need.pdf:application/pdf}
}

@inproceedings{grossman_existential_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Existential {Types} for {Imperative} {Languages}},
	isbn = {978-3-540-43363-7 978-3-540-45927-9},
	url = {https://link.springer.com/chapter/10.1007/3-540-45927-8_3},
	doi = {10.1007/3-540-45927-8_3},
	abstract = {We integrate existential types into a strongly typed C-like language. In particular, we show how a bad combination of existential types, mutation, and aliasing can cause a subtle violation of type safety. We explore two independent ways to strengthen the type system to restore safety. One restricts the mutation of existential packages. The other restricts the types of aliases of existential packages. We use our framework to explain why other languages with existential types are safe.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Grossman, Dan},
	month = apr,
	year = {2002},
	keywords = {FROM-BEN},
	pages = {21--35},
	file = {Grossman_2002_Existential Types for Imperative Languages.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grossman_2002_Existential Types for Imperative Languages.pdf:application/pdf}
}

@techreport{proust_asap:_2017,
	title = {{ASAP}: {As} {Static} {As} {Possible} memory management},
	url = {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-908.pdf},
	abstract = {Today, there are various ways to manage the memory of computer programs: garbage collectors of all kinds, reference counters, regions, linear types – each with benefits and drawbacks, each fit for specific settings, each appropriate to different problems, each with their own trade-offs.
Despite the plethora of techniques available, system programming (device drivers, networking libraries, cryptography applications, etc.) is still mostly done in C, even though memory management in C is notoriously unsafe. As a result, serious bugs are continuously discovered in system software.
In this dissertation, we study memory management strategies with an eye out for fitness to system programming.
First, we establish a framework to study memory management dtrategies. Often perceived as distinct categories, we argue that memory management approaches are actually part of a single
design space. To this end, we establish a precise and powerful lexicon to describe memory management strategies of any kind. Using our newly established vocabulary, we further argue that this design space has not been exhaustively explored. We argue that one of the unexplored portion of this space, the static-automatic gap, contributes to the persistence of C in system programming.
Second, we develop asap: a new memory management technique that fits in the static-automatic gap. Asap is fully automatic (not even annotations are required) and makes heavy use of static analysis. At compile time it inserts, in the original program, code that deallocates memory blocks as they becomes useless. We then show how asap interacts with various, advanced language features.
Specifically, we extend asap to support polymorphism and mutability.
Third, we compare asap with existing approaches. One of the points of comparison we use is the behavioural suitability to system programming. We also explore how the ideas from asap can be combined with other memory management strategies. We then show how asap handles
programs satisfying the linear or region constraints. Finally, we explore the insights gained whilst developing and studying ASAP.},
	number = {908},
	urldate = {2018-03-13},
	author = {Proust, Raphael L},
	month = jul,
	year = {2017},
	keywords = {FROM-BEN},
	file = {Proust_2017_ASAP - As Static As Possible memory management.pdf:/home/michael/Dropbox/zotero-pdfs/P/Proust_2017_ASAP - As Static As Possible memory management.pdf:application/pdf}
}

@inproceedings{pottier_information_2000,
	address = {New York, NY, USA},
	series = {{ICFP} '00},
	title = {Information {Flow} {Inference} for {Free}},
	isbn = {978-1-58113-202-1},
	url = {http://doi.acm.org/10.1145/351240.351245},
	doi = {10.1145/351240.351245},
	abstract = {This paper shows how to systematically extend an arbitrary type system with dependency information, and how soundness and non-interference proofs for the new system may rely upon, rather than duplicate, the soundness proof of the original system. This allows enriching virtually any of the type systems known today with information flow analysis, while requiring only a minimal proof effort.Our approach is based on an untyped operational semantics for a labelled calculus akin to core ML. Thus, it is simple, and should be applicable to other computing paradigms, such as object or process calculi.The paper also discusses access control, and shows it may be viewed as entirely independent of information flow control. Letting the two mechanisms coexist, without interacting, yields a simple and expressive type system, which allows, in particular, "selective" declassification.},
	urldate = {2018-03-13},
	booktitle = {Proceedings of the {Fifth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Pottier, François and Conchon, Sylvain},
	year = {2000},
	pages = {46--57},
	file = {Pottier_Conchon_2000_Information Flow Inference for Free.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pottier_Conchon_2000_Information Flow Inference for Free.pdf:application/pdf}
}

@article{hill_amdahls_nodate,
	title = {Amdahl’s {Law} in the {Multicore} {Era}},
	abstract = {We apply Amdahl’s Law to multicore chips using symmetric cores, asymmetric cores, and dynamic techniques that allows cores to work together on sequential execution. To Amdahl’s simple software model, we add a simple hardware model based on fixed chip resources.},
	author = {Hill, Mark D and Marty, Michael R},
	pages = {6},
	file = {Hill_Marty_Amdahl’s Law in the Multicore Era.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hill_Marty_Amdahl’s Law in the Multicore Era.pdf:application/pdf}
}

@book{agha_actors:_1986,
	address = {Cambridge, MA, USA},
	title = {Actors: {A} {Model} of {Concurrent} {Computation} in {Distributed} {Systems}},
	isbn = {978-0-262-01092-4},
	shorttitle = {Actors},
	publisher = {MIT Press},
	author = {Agha, Gul},
	year = {1986},
	file = {Agha_1986_Actors - A Model of Concurrent Computation in Distributed Systems.pdf:/home/michael/Dropbox/zotero-pdfs/A/Agha_1986_Actors - A Model of Concurrent Computation in Distributed Systems.pdf:application/pdf}
}

@article{de_moura_elaboration_2015,
	title = {Elaboration in {Dependent} {Type} {Theory}},
	url = {http://arxiv.org/abs/1505.04324},
	abstract = {To be usable in practice, interactive theorem provers need to provide convenient and efficient means of writing expressions, definitions, and proofs. This involves inferring information that is often left implicit in an ordinary mathematical text, and resolving ambiguities in mathematical expressions. We refer to the process of passing from a quasi-formal and partially-specified expression to a completely precise formal one as elaboration. We describe an elaboration algorithm for dependent type theory that has been implemented in the Lean theorem prover. Lean's elaborator supports higher-order unification, type class inference, ad hoc overloading, insertion of coercions, the use of tactics, and the computational reduction of terms. The interactions between these components are subtle and complex, and the elaboration algorithm has been carefully designed to balance efficiency and usability. We describe the central design goals, and the means by which they are achieved.},
	urldate = {2018-03-13},
	journal = {arXiv:1505.04324 [cs]},
	author = {de Moura, Leonardo and Avigad, Jeremy and Kong, Soonho and Roux, Cody},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04324},
	keywords = {Computer Science - Logic in Computer Science},
	file = {de Moura et al_2015_Elaboration in Dependent Type Theory.pdf:/home/michael/Dropbox/zotero-pdfs/D/de Moura et al_2015_Elaboration in Dependent Type Theory.pdf:application/pdf}
}

@article{wang_coroutine_1971,
	title = {Coroutine sequencing in a block structured environment},
	volume = {11},
	issn = {0006-3835, 1572-9125},
	url = {http://link.springer.com/10.1007/BF01939412},
	doi = {10.1007/BF01939412},
	abstract = {A certain primitive sequencing operation is defined, applicable as an extension to Algol-like languages. The operation serves the double purpose of "intermediate exit" from or "reentry" into procedure-like block instances. A second primitive, which corresponds to a fully symmetric coroutine linkage, is derived from the former. An abstract notation is introduced for the concepts of textual and dynamic enclosure of block instances. The effects of the sequencing primitives are explored in terms of this notation, and certain results are proved. Finally applications are given within the language framework of Simula 67.},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {BIT},
	author = {Wang, Arne and Dahl, Ole-Johan},
	month = dec,
	year = {1971},
	pages = {425--449},
	file = {Wang_Dahl_1971_Coroutine sequencing in a block structured environment.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang_Dahl_1971_Coroutine sequencing in a block structured environment.pdf:application/pdf}
}

@article{dennis_programming_1966,
	title = {Programming semantics for multiprogrammed computations},
	volume = {9},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=365230.365252},
	doi = {10.1145/365230.365252},
	number = {3},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Dennis, Jack B. and Van Horn, Earl C.},
	month = mar,
	year = {1966},
	pages = {143--155},
	file = {Dennis_Van Horn_1966_Programming semantics for multiprogrammed computations.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dennis_Van Horn_1966_Programming Semantics for Multiprogrammed Computations.pdf:application/pdf}
}

@article{jang_establishing_nodate,
	title = {Establishing {Browser} {Security} {Guarantees} through {Formal} {Shim} {Veriﬁcation}},
	abstract = {Web browsers mediate access to valuable private data in domains ranging from health care to banking. Despite this critical role, attackers routinely exploit browser vulnerabilities to exﬁltrate private data and take over the underlying system. We present QUARK, a browser whose kernel has been implemented and veriﬁed in Coq. We give a speciﬁcation of our kernel, show that the implementation satisﬁes the speciﬁcation, and ﬁnally show that the speciﬁcation implies several security properties, including tab non-interference, cookie integrity and conﬁdentiality, and address bar integrity.},
	author = {Jang, Dongseok and Tatlock, Zachary and Lerner, Sorin},
	pages = {19},
	file = {Jang et al_Establishing Browser Security Guarantees through Formal Shim Veriﬁcation.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jang et al_Establishing Browser Security Guarantees through Formal Shim Veriﬁcation.pdf:application/pdf}
}

@article{fisher_survey_1972,
	title = {A survey of control structures in programming languages},
	volume = {7},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=987361.987363},
	doi = {10.1145/987361.987363},
	language = {en},
	number = {11},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Fisher, David A.},
	month = nov,
	year = {1972},
	pages = {1},
	file = {Fisher_1972_A survey of control structures in programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fisher_1972_A survey of control structures in programming languages.pdf:application/pdf}
}

@article{abramsky_department_nodate,
	title = {Department of {Computing} {Imperial} {College} of {Science} and {Technology}},
	author = {Abramsky, Samson},
	pages = {48},
	file = {Abramsky_Department of Computing Imperial College of Science and Technology.pdf:/home/michael/Dropbox/zotero-pdfs/A/Abramsky_Department of Computing Imperial College of Science and Technology.pdf:application/pdf}
}

@inproceedings{kashyap_jsai:_2014,
	title = {{JSAI}: a static analysis platform for {JavaScript}},
	isbn = {978-1-4503-3056-5},
	shorttitle = {{JSAI}},
	url = {http://dl.acm.org/citation.cfm?doid=2635868.2635904},
	doi = {10.1145/2635868.2635904},
	abstract = {JavaScript is used everywhere from the browser to the server, including desktops and mobile devices. However, the current state of the art in JavaScript static analysis lags far behind that of other languages such as C and Java. Our goal is to help remedy this lack. We describe JSAI, a formally speciﬁed, robust abstract interpreter for JavaScript. JSAI uses novel abstract domains to compute a reduced product of type inference, pointer analysis, control-ﬂow analysis, string analysis, and integer and boolean constant propagation. Part of JSAI’s novelty is user-conﬁgurable analysis sensitivity, i.e., context-, path-, and heap-sensitivity. JSAI is designed to be provably sound with respect to a speciﬁc concrete semantics for JavaScript, which has been extensively tested against a commercial JavaScript implementation.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Kashyap, Vineeth and Dewey, Kyle and Kuefner, Ethan A. and Wagner, John and Gibbons, Kevin and Sarracino, John and Wiedermann, Ben and Hardekopf, Ben},
	year = {2014},
	pages = {121--132},
	file = {Kashyap et al_2014_JSAI - a static analysis platform for JavaScript.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kashyap et al_2014_JSAI - a static analysis platform for JavaScript.pdf:application/pdf}
}

@inproceedings{gibbons_just_2011,
	title = {Just do it: simple monadic equational reasoning},
	isbn = {978-1-4503-0865-6},
	shorttitle = {Just do it},
	url = {http://dl.acm.org/citation.cfm?doid=2034773.2034777},
	doi = {10.1145/2034773.2034777},
	abstract = {One of the appeals of pure functional programming is that it is so amenable to equational reasoning. One of the problems of pure functional programming is that it rules out computational effects. Moggi and Wadler showed how to get round this problem by using monads to encapsulate the effects, leading in essence to a phase distinction—a pure functional evaluation yielding an impure imperative computation. Still, it has not been clear how to reconcile that phase distinction with the continuing appeal of functional programming; does the impure imperative part become inaccessible to equational reasoning? We think not; and to back that up, we present a simple axiomatic approach to reasoning about programs with computational effects.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Gibbons, Jeremy and Hinze, Ralf},
	year = {2011},
	pages = {2},
	file = {Gibbons_Hinze_2011_Just do it - simple monadic equational reasoning.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gibbons_Hinze_2011_Just do it - simple monadic equational reasoning.pdf:application/pdf}
}

@incollection{okada_operational_2007,
	address = {Berlin, Heidelberg},
	title = {An {Operational} {Semantics} of {Program} {Dependence} {Graphs} for {Unstructured} {Programs}},
	volume = {4435},
	isbn = {978-3-540-77504-1 978-3-540-77505-8},
	url = {http://link.springer.com/10.1007/978-3-540-77505-8_22},
	abstract = {The program dependence graph (PDG) represents data and control dependences between statements in a program. The PDG is a useful intermediate representation for compiler code optimizations, because compiler code optimizations mostly rely on data and control dependence information. However, the validity of optimization methods based on PDGs has not been well studied. In order to justify optimization based on PDGs, it is necessary to introduce a formal semantics of PDGs. This paper presents an operational semantics of PDGs corresponding to programs which have an unstructured control ﬂow. Our PDG semantics is equivalent to sequential program semantics in the sense that a CFG and the corresponding PDG perform the same computation.},
	urldate = {2018-03-13},
	booktitle = {Advances in {Computer} {Science} - {ASIAN} 2006. {Secure} {Software} and {Related} {Issues}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ito, Souhei and Hagihara, Shigeki and Yonezaki, Naoki},
	editor = {Okada, Mitsu and Satoh, Ichiro},
	year = {2007},
	doi = {10.1007/978-3-540-77505-8_22},
	pages = {264--271},
	file = {Ito et al_2007_An Operational Semantics of Program Dependence Graphs for Unstructured Programs.pdf:/home/michael/Dropbox/zotero-pdfs/I/Ito et al_2007_An Operational Semantics of Program Dependence Graphs for Unstructured Programs.pdf:application/pdf}
}

@inproceedings{baillot_type_2010,
	title = {Type inference in intuitionistic linear logic},
	isbn = {978-1-4503-0132-9},
	url = {http://portal.acm.org/citation.cfm?doid=1836089.1836118},
	doi = {10.1145/1836089.1836118},
	abstract = {We study the type checking and type inference problems for intuitionistic linear logic: given a System F typed λ-term, (i) for an alleged linear logic type, determine whether there exists a corresponding typing derivation in linear logic (type checking) (ii) provide a concise description of all possible corresponding linear logic typings (type inference).},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Baillot, Patrick and Hofmann, Martin},
	year = {2010},
	pages = {219},
	file = {Baillot_Hofmann_2010_Type inference in intuitionistic linear logic.pdf:/home/michael/Dropbox/zotero-pdfs/B/Baillot_Hofmann_2010_Type inference in intuitionistic linear logic.pdf:application/pdf}
}

@incollection{goos_computer_1987,
	address = {Berlin, Heidelberg},
	title = {Computer architectures for artificial intelligence},
	volume = {272},
	isbn = {978-3-540-18203-0 978-3-540-47806-5},
	url = {http://link.springer.com/10.1007/3-540-18203-9_15},
	urldate = {2018-03-13},
	booktitle = {Future {Parallel} {Computers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Treleaven, Philip C. and Refenes, Apostolos N. and Lees, Kenneth J. and McCabe, Stephen C.},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Treleaven, P. and Vanneschi, M.},
	year = {1987},
	doi = {10.1007/3-540-18203-9_15},
	pages = {416--492},
	file = {Treleaven et al_1987_Computer architectures for artificial intelligence.pdf:/home/michael/Dropbox/zotero-pdfs/T/Treleaven et al_1987_Computer architectures for artificial intelligence.pdf:application/pdf}
}

@inproceedings{constantine_control_1968,
	title = {Control of sequence and parallelism in modular programs},
	url = {http://portal.acm.org/citation.cfm?doid=1468075.1468135},
	doi = {10.1145/1468075.1468135},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Constantine, Larry L.},
	year = {1968},
	pages = {409},
	file = {Constantine_1968_Control of sequence and parallelism in modular programs.pdf:/home/michael/Dropbox/zotero-pdfs/C/Constantine_1968_Control of sequence and parallelism in modular programs.pdf:application/pdf}
}

@article{bohm_flow_1966,
	title = {Flow diagrams, turing machines and languages with only two formation rules},
	volume = {9},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=355592.365646},
	doi = {10.1145/355592.365646},
	number = {5},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Böhm, Corrado and Jacopini, Giuseppe},
	month = may,
	year = {1966},
	pages = {366--371},
	file = {Bohm_Jacopini_1966_Flow diagrams, turing machines and languages with only two formation rules.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bohm_Jacopini_1966_Flow diagrams, turing machines and languages with only two formation rules.pdf:application/pdf}
}

@article{bird_formal_1987,
	title = {A formal development of an efficient supercombinator compiler},
	volume = {8},
	issn = {01676423},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0167642387900177},
	doi = {10.1016/0167-6423(87)90017-7},
	abstract = {This paper presents a formal development, employing techniques of transformational programming, of a non-trivial algorithm in the field of functional language implementation. The problem deals with the translation of lambda calculus expressions into combinator form, using Hughes-style supercombinators rather than the fixed repertoire of combinators proposed by Turner. The final algorithm is presented as a functional program and is efficient in the sense that its worst-case running time is proportional to n log n, where n is the size of the output. This efficiency is-obtained by means of a number of simple transformations on the initial specification of the problem, the most significant of which is a data structure refinement step for tabulating partial results.},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {Science of Computer Programming},
	author = {Bird, R.S.},
	month = apr,
	year = {1987},
	pages = {113--137},
	file = {Bird_1987_A formal development of an efficient supercombinator compiler.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bird_1987_A formal development of an efficient supercombinator compiler.pdf:application/pdf}
}

@incollection{goos_proving_1996,
	address = {Berlin, Heidelberg},
	title = {Proving safety properties for embedded control systems},
	volume = {1150},
	isbn = {978-3-540-61772-3 978-3-540-70677-9},
	url = {http://link.springer.com/10.1007/3-540-61772-8_46},
	urldate = {2018-03-13},
	booktitle = {Dependable {Computing} — {EDCC}-2},
	publisher = {Springer Berlin Heidelberg},
	author = {Bernardeschi, Cinzia and Fantechi, Alessandro and Gnesi, Stefania and Mongardi, Giorgio},
	editor = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan and Hlawiczka, Andrzej and Silva, João Gabriel and Simoncini, Luca},
	year = {1996},
	doi = {10.1007/3-540-61772-8_46},
	pages = {321--332},
	file = {Bernardeschi et al_1996_Proving safety properties for embedded control systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bernardeschi et al_1996_Proving safety properties for embedded control systems.pdf:application/pdf}
}

@article{barr_category_nodate,
	title = {Category {Theory} for {Computing} {Science}},
	author = {Barr, Michael and Wells, Charles},
	pages = {556},
	file = {Barr_Wells_Category Theory for Computing Science.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barr_Wells_Category Theory for Computing Science.pdf:application/pdf}
}

@inproceedings{barnett_weakest-precondition_2005,
	title = {Weakest-precondition of unstructured programs},
	isbn = {978-1-59593-239-6},
	url = {http://portal.acm.org/citation.cfm?doid=1108792.1108813},
	doi = {10.1145/1108792.1108813},
	abstract = {Program veriﬁcation systems typically transform a program into a logical expression which is then fed to a theorem prover. The logical expression represents the weakest precondition of the program relative to its speciﬁcation; when (and if!) the theorem prover is able to prove the expression, then the program is considered correct. Computing such a logical expression for an imperative, structured program is straightforward, although there are issues having to do with loops and the efﬁciency both of the computation and of the complexity of the formula with respect to the theorem prover. This paper presents a novel approach for computing the weakest precondition of an unstructured program that is sound even in the presence of loops. The computation is efﬁcient and the resulting logical expression provides more leeway for the theorem prover efﬁciently to attack the proof.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Barnett, Mike and Leino, K. Rustan M.},
	year = {2005},
	pages = {82},
	file = {Barnett_Leino_2005_Weakest-precondition of unstructured programs.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barnett_Leino_2005_Weakest-precondition of unstructured programs.pdf:application/pdf}
}

@article{barendregt_dutch_1987,
	title = {The dutch parallel reduction machine project},
	volume = {3},
	issn = {0167739X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0167739X87900306},
	doi = {10.1016/0167-739X(87)90030-6},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {Future Generation Computer Systems},
	author = {Barendregt, H.P. and Van Eekelen, M.C.J.D. and Plasmeijer, M.J. and Hartel, P.H. and Hertzberger, L.O. and Vree, W.G.},
	month = dec,
	year = {1987},
	pages = {261--270},
	file = {Barendregt et al_1987_The dutch parallel reduction machine project.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barendregt et al_1987_The dutch parallel reduction machine project.pdf:application/pdf}
}

@article{balasubramanian_isstac:_nodate,
	title = {{ISSTAC}: {Integrated} {Symbolic} {Execution} for {Space}-{Time} {Analysis} of {Code}},
	abstract = {Cybersecurity is one of the most critical challenges facing the computing discipline. Vulnerabilities that result from space-time usage of programs are especially hard to detect and defend against, since they are due to algorithmic behavior of programs rather than implementation errors. We present an integrated symbolic execution approach that provides both qualitative and quantitative reasoning for space-time analysis of Java programs. Our tool-set consists of a pre-processing component that uses static analysis and visualization to help developers identify potentially vulnerable parts of the code for further analysis. Symbolic execution components implement WorstCase Analysis to detect algorithmic complexity vulnerabilities, and Side-Channel Analysis to detect and quantify information leakage. Both analyses are parametrized with respect to cost models for space-time consumption. Our tool-set also contains a distributed framework to achieve scalable analysis, and uses a combination of satisﬁability checkers and model-counting tools to quantify the results. We demonstrate the effectiveness of our approach on a set of challenging use cases on which we identiﬁed classes of space-time vulnerabilities.},
	author = {Balasubramanian, Daniel and Luckow, Kasper and Pasareanu, Corina and Aydin, Abdulbaki and Bang, Lucas and Bultan, Tevﬁk and Gavrilov, Miroslav and Kahsai, Temesghen and Kersten, Rody and Kostyuchenko, Dmitriy and Phan, Quoc-Sang and Zhang, Zhenkai and Karsai, Gabor},
	pages = {12},
	file = {Balasubramanian et al_ISSTAC - Integrated Symbolic Execution for Space-Time Analysis of Code.pdf:/home/michael/Dropbox/zotero-pdfs/B/Balasubramanian et al_ISSTAC - Integrated Symbolic Execution for Space-Time Analysis of Code.pdf:application/pdf}
}

@article{bage_combinator_1990,
	title = {Combinator evaluation of functional programs with logical variables},
	volume = {3},
	issn = {0892-4635, 1573-0557},
	url = {http://link.springer.com/10.1007/BF01806101},
	doi = {10.1007/BF01806101},
	language = {en},
	number = {3},
	urldate = {2018-03-13},
	journal = {Lisp and Symbolic Computation},
	author = {Båge, Göran and Lindstrom, Gary},
	month = sep,
	year = {1990},
	pages = {289--320},
	file = {Bage_Lindstrom_1990_Combinator evaluation of functional programs with logical variables.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bage_Lindstrom_1990_Combinator evaluation of functional programs with logical variables.pdf:application/pdf}
}

@article{avigad_type_nodate,
	title = {Type inference in mathematics},
	abstract = {In the theory of programming languages, type inference is the process of inferring the type of an expression automatically, often making use of information from the context in which the expression appears. Such mechanisms turn out to be extremely useful in the practice of interactive theorem proving, whereby users interact with a computational proof assistant to construct formal axiomatic derivations of mathematical theorems. This article explains some of the mechanisms for type inference used by the Mathematical Components project, which is working towards a veriﬁcation of the Feit-Thompson theorem.},
	author = {Avigad, Jeremy},
	pages = {19},
	file = {Avigad_Type inference in mathematics.pdf:/home/michael/Dropbox/zotero-pdfs/A/Avigad_Type inference in mathematics.pdf:application/pdf}
}

@inproceedings{aydin_automated_2014,
	title = {Automated {Test} {Generation} from {Vulnerability} {Signatures}},
	isbn = {978-1-4799-2255-0},
	url = {http://ieeexplore.ieee.org/document/6823881/},
	doi = {10.1109/ICST.2014.32},
	abstract = {Web applications need to validate and sanitize user inputs in order to avoid attacks such as Cross Site Scripting (XSS) and SQL Injection. Writing string manipulation code for input validation and sanitization is an error-prone process leading to many vulnerabilities in real-world web applications. Automata-based static string analysis techniques can be used to automatically compute vulnerability signatures (represented as automata) that characterize all the inputs that can exploit a vulnerability. However, there are several factors that limit the applicability of static string analysis techniques in general: 1) undecidability of static string analysis requires the use of approximations leading to false positives, 2) static string analysis tools do not handle all string operations, 3) dynamic nature of the scripting languages makes static analysis difﬁcult. In this paper, we show that vulnerability signatures computed for deliberately insecure web applications (developed for demonstrating different types of vulnerabilities) can be used to generate test cases for other applications. Given a vulnerability signature represented as an automaton, we present algorithms for test case generation based on state, transition, and path coverage. These automatically generated test cases can be used to test applications that are not analyzable statically, and to discover attack strings that demonstrate how the vulnerabilities can be exploited.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Aydin, Abdulbaki and Alkhalaf, Muath and Bultan, Tevfik},
	month = mar,
	year = {2014},
	pages = {193--202},
	file = {Aydin et al_2014_Automated Test Generation from Vulnerability Signatures.pdf:/home/michael/Dropbox/zotero-pdfs/A/Aydin et al_2014_Automated Test Generation from Vulnerability Signatures.pdf:application/pdf}
}

@inproceedings{ariola_call-by-need_1995,
	title = {A call-by-need lambda calculus},
	isbn = {978-0-89791-692-9},
	url = {http://portal.acm.org/citation.cfm?doid=199448.199507},
	doi = {10.1145/199448.199507},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Ariola, Zena M. and Maraist, John and Odersky, Martin and Felleisen, Matthias and Wadler, Philip},
	year = {1995},
	pages = {233--246},
	file = {Ariola et al_1995_A call-by-need lambda calculus.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ariola et al_1995_A call-by-need lambda calculus.pdf:application/pdf}
}

@inproceedings{ariola_syntactic_1991,
	title = {A syntactic approach to program transformations},
	isbn = {978-0-89791-433-8},
	url = {http://portal.acm.org/citation.cfm?doid=115865.115878},
	doi = {10.1145/115865.115878},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Ariola, Zena M.},
	year = {1991},
	pages = {116--129},
	file = {Ariola_1991_A syntactic approach to program transformations.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ariola_1991_A syntactic approach to program transformations.pdf:application/pdf}
}

@inproceedings{appel_continuation-passing_1989,
	title = {Continuation-passing, closure-passing style},
	isbn = {978-0-89791-294-5},
	url = {http://portal.acm.org/citation.cfm?doid=75277.75303},
	doi = {10.1145/75277.75303},
	abstract = {We implemented a continuation-passing style (CPS) code generator for ML. Our CPS language is represented as an ML datatype in which all functions are named and most kinds of ill-formed expressions are impossible. We separate the code generation into phases that rewrite this representation into ever-simpler forms. Closures are represented explicitly as records, so that closure strategies can be communicated from one phase to another. No stack is used. Our benchmark data shows that the new method is an improvement over our previous, abstract-machinebasedcode generator.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Appel, A. W. and Jim, T.},
	year = {1989},
	pages = {293--302},
	file = {Appel_Jim_1989_Continuation-passing, closure-passing style.pdf:/home/michael/Dropbox/zotero-pdfs/A/Appel_Jim_1989_Continuation-passing, closure-passing style.pdf:application/pdf}
}

@incollection{page_typing_2011,
	address = {Berlin, Heidelberg},
	title = {Typing {Coroutines}},
	volume = {6546},
	isbn = {978-3-642-22940-4 978-3-642-22941-1},
	url = {http://link.springer.com/10.1007/978-3-642-22941-1_2},
	abstract = {A coroutine is a programming construct between function and thread. It behaves like a function that can suspend itself arbitrarily often to yield intermediate results and to get new inputs before returning a result. This facility makes coroutines suitable for implementing generator abstractions.},
	urldate = {2018-03-13},
	booktitle = {Trends in {Functional} {Programming}},
	publisher = {Springer Berlin Heidelberg},
	author = {Anton, Konrad and Thiemann, Peter},
	editor = {Page, Rex and Horváth, Zoltán and Zsók, Viktória},
	year = {2011},
	doi = {10.1007/978-3-642-22941-1_2},
	pages = {16--30},
	file = {Anton_Thiemann_2011_Typing Coroutines.pdf:/home/michael/Dropbox/zotero-pdfs/A/Anton_Thiemann_2011_Typing Coroutines.pdf:application/pdf}
}

@inproceedings{angiuli_homotopical_2014,
	title = {Homotopical patch theory},
	isbn = {978-1-4503-2873-9},
	url = {http://dl.acm.org/citation.cfm?doid=2628136.2628158},
	doi = {10.1145/2628136.2628158},
	abstract = {Homotopy type theory is an extension of Martin-Löf type theory, based on a correspondence with homotopy theory and higher category theory. In homotopy type theory, the propositional equality type becomes proof-relevant, and corresponds to paths in a space. This allows for a new class of datatypes, called higher inductive types, which are speciﬁed by constructors not only for points but also for paths. In this paper, we consider a programming application of higher inductive types. Version control systems such as Darcs are based on the notion of patches—syntactic representations of edits to a repository. We show how patch theory can be developed in homotopy type theory. Our formulation separates formal theories of patches from their interpretation as edits to repositories. A patch theory is presented as a higher inductive type. Models of a patch theory are given by maps out of that type, which, being functors, automatically preserve the structure of patches. Several standard tools of homotopy theory come into play, demonstrating the use of these methods in a practical programming context.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Angiuli, Carlo and Morehouse, Edward and Licata, Daniel R. and Harper, Robert},
	year = {2014},
	pages = {243--256},
	file = {Angiuli et al_2014_Homotopical patch theory.pdf:/home/michael/Dropbox/zotero-pdfs/A/Angiuli et al_2014_Homotopical patch theory.pdf:application/pdf}
}

@article{anderson_scheduler_1992,
	title = {Scheduler activations: effective kernel support for the user-level management of parallelism},
	volume = {10},
	issn = {07342071},
	shorttitle = {Scheduler activations},
	url = {http://portal.acm.org/citation.cfm?doid=146941.146944},
	doi = {10.1145/146941.146944},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM Transactions on Computer Systems},
	author = {Anderson, Thomas E. and Bershad, Brian N. and Lazowska, Edward D. and Levy, Henry M.},
	month = feb,
	year = {1992},
	pages = {53--79},
	file = {Anderson et al_1992_Scheduler activations - Effective kernel support for the user-level management.pdf:/home/michael/Dropbox/zotero-pdfs/A/Anderson et al_1992_Scheduler activations - Effective kernel support for the user-level management.pdf:application/pdf;Anderson et al_1992_Scheduler activations - effective kernel support for the user-level management.pdf:/home/michael/Dropbox/zotero-pdfs/A/Anderson et al_1992_Scheduler activations - effective kernel support for the user-level management.pdf:application/pdf}
}

@article{andersen_program_nodate,
	title = {Program {Analysis} and {Specialization} for the {C} {Programming} {Language}},
	author = {Andersen, Lars Ole},
	pages = {311},
	file = {Andersen_Program Analysis and Specialization for the C Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/A/Andersen_Program Analysis and Specialization for the C Programming Language.pdf:application/pdf}
}

@article{kaiser_widening_2014,
	title = {A {Widening} {Approach} to {Multithreaded} {Program} {Verification}},
	volume = {36},
	issn = {01640925},
	url = {http://dl.acm.org/citation.cfm?doid=2684821.2629608},
	doi = {10.1145/2629608},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Kaiser, Alexander and Kroening, Daniel and Wahl, Thomas},
	month = oct,
	year = {2014},
	pages = {1--29},
	file = {Kaiser et al_2014_A Widening Approach to Multithreaded Program Verification.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kaiser et al_2014_A Widening Approach to Multithreaded Program Verification.pdf:application/pdf}
}

@article{bevier_kit:_1989,
	title = {Kit: a study in operating system verification},
	volume = {15},
	issn = {00985589},
	shorttitle = {Kit},
	url = {http://ieeexplore.ieee.org/document/41331/},
	doi = {10.1109/32.41331},
	number = {11},
	urldate = {2018-03-13},
	journal = {IEEE Transactions on Software Engineering},
	author = {Bevier, W.R.},
	month = nov,
	year = {1989},
	pages = {1382--1396},
	file = {Bevier_1989_Kit - a study in operating system verification.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bevier_1989_Kit - a study in operating system verification.pdf:application/pdf}
}

@incollection{landin_-calculus_1966,
	title = {A λ-{CALCULUS} {APPROACH}},
	isbn = {978-0-08-011356-2},
	url = {http://linkinghub.elsevier.com/retrieve/pii/B9780080113562500082},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Advances in {Programming} and {Non}-{Numerical} {Computation}},
	publisher = {Elsevier},
	author = {Landin, P.J.},
	year = {1966},
	doi = {10.1016/B978-0-08-011356-2.50008-2},
	pages = {97--141},
	file = {Landin_1966_A λ-CALCULUS APPROACH.pdf:/home/michael/Dropbox/zotero-pdfs/L/Landin_1966_A λ-CALCULUS APPROACH.pdf:application/pdf}
}

@article{berson_ksos-development_1979,
	title = {{KSOS}-{Development} methodology for a secure operating system},
	author = {BERSON, T A and BARKSDALE, G L},
	year = {1979},
	pages = {8},
	file = {BERSON_BARKSDALE_1979_KSOS-Development methodology for a secure operating system.pdf:/home/michael/Dropbox/zotero-pdfs/B/BERSON_BARKSDALE_1979_KSOS-Development methodology for a secure operating system.pdf:application/pdf}
}

@article{bershad_extensibility_1995,
	title = {Extensibility safety and performance in the {SPIN} operating system},
	volume = {29},
	issn = {01635980},
	url = {http://portal.acm.org/citation.cfm?doid=224057.224077},
	doi = {10.1145/224057.224077},
	abstract = {This paper describes the motivation, architecture and performance of SPIN, an extensible operating system. SPIN provides an extension infrastructure, together with a core set of extensible services, that allow applications to safely change the operating system’s interface and implementation. Extensions allow an application to specialize the underlying operating system in order to achieve a particular level of performance and functionality. SPIN uses language and link-time mechanisms to inexpensively export ﬁne-grained interfaces to operating system services. Extensions are written in a type safe language, and are dynamically linked into the operating system kernel. This approach offers extensions rapid access to system services, while protecting the operating system code executing within the kernel address space. SPIN and its extensions are written in Modula-3 and run on DEC Alpha workstations.},
	language = {en},
	number = {5},
	urldate = {2018-03-13},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Bershad, B. N. and Savage, S. and Pardyak, P. and Sirer, E. G. and Fiuczynski, M. E. and Becker, D. and Chambers, C. and Eggers, S.},
	month = dec,
	year = {1995},
	pages = {267--283},
	file = {Bershad et al_1995_Extensibility safety and performance in the SPIN operating system.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bershad et al_1995_Extensibility Safety and Performance in the SPIN Operating System.pdf:application/pdf}
}

@techreport{bell_secure_1976,
	address = {Fort Belvoir, VA},
	title = {Secure {Computer} {System}: {Unified} {Exposition} and {Multics} {Interpretation}:},
	shorttitle = {Secure {Computer} {System}},
	url = {http://www.dtic.mil/docs/citations/ADA023588},
	urldate = {2018-03-13},
	institution = {Defense Technical Information Center},
	author = {Bell, D. Elliott and La Padula, Leonard J.},
	month = mar,
	year = {1976},
	doi = {10.21236/ADA023588},
	file = {Bell_La Padula_1976_Secure Computer System - Unified Exposition and Multics Interpretation.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bell_La Padula_1976_Secure Computer System - Unified Exposition and Multics Interpretation.pdf:application/pdf}
}

@article{foss_mils_2006,
	title = {The {MILS} architecture for high-assurance embedded systems},
	volume = {2},
	issn = {1741-1068, 1741-1076},
	url = {http://www.inderscience.com/link.php?id=14859},
	doi = {10.1504/IJES.2006.014859},
	abstract = {High-assurance systems require a level of rigor, in both design and analysis, not typical of conventional systems. This paper provides an overview of the Multiple Independent Levels of Security and Safety (MILS) approach to high-assurance system design for security and safety critical embedded systems. MILS enables the development of a system using manageable units, each of which can be analyzed separately, avoiding costly analysis required of more conventional designs. MILS is particularly well suited to embedded systems that must provide guaranteed safety or security properties.},
	language = {en},
	number = {3/4},
	urldate = {2018-03-13},
	journal = {International Journal of Embedded Systems},
	author = {Foss, Jim Alves and Oman, Paul W. and Taylor, Carol and Harrison, W. Scott},
	year = {2006},
	pages = {239},
	file = {Foss et al_2006_The MILS architecture for high-assurance embedded systems.pdf:/home/michael/Dropbox/zotero-pdfs/F/Foss et al_2006_The MILS architecture for high-assurance embedded systems.pdf:application/pdf}
}

@misc{volpano_sound_1996-1,
	title = {A sound type system for secure flow analysis},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/JCS-1996-42-304},
	urldate = {2018-03-13},
	author = {Volpano, Dennis and Irvine, Cynthia and Smith, Geoffrey},
	month = apr,
	year = {1996},
	file = {Volpano et al_1996_A sound type system for secure flow analysis.pdf:/home/michael/Dropbox/zotero-pdfs/V/Volpano et al_1996_A sound type system for secure flow analysis2.pdf:application/pdf}
}

@techreport{renninger_approaches_1974,
	address = {Gaithersburg, MD},
	title = {Approaches to privacy and security in computer systems},
	url = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nbsspecialpublication404.pdf},
	language = {en},
	number = {NBS SP 404},
	urldate = {2018-03-13},
	institution = {National Bureau of Standards},
	author = {Renninger, Clark R},
	year = {1974},
	doi = {10.6028/NBS.SP.404},
	file = {Renninger_1974_Approaches to privacy and security in computer systems.pdf:/home/michael/Dropbox/zotero-pdfs/R/Renninger_1974_Approaches to privacy and security in computer systems.pdf:application/pdf}
}

@article{shannon_symbolic_1938,
	title = {A symbolic analysis of relay and switching circuits},
	volume = {57},
	issn = {0095-9197},
	url = {http://ieeexplore.ieee.org/document/6431064/},
	doi = {10.1109/EE.1938.6431064},
	number = {12},
	urldate = {2018-03-13},
	journal = {Electrical Engineering},
	author = {Shannon, Claude E.},
	month = dec,
	year = {1938},
	pages = {713--723},
	file = {Shannon_1938_A symbolic analysis of relay and switching circuits.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shannon_1938_A symbolic analysis of relay and switching circuits.pdf:application/pdf}
}

@article{smith_implementing_1988,
	title = {Implementing precise interrupts in pipelined processors},
	volume = {37},
	issn = {00189340},
	url = {http://ieeexplore.ieee.org/document/4607/},
	doi = {10.1109/12.4607},
	abstract = {This paper describes and evaluates solutions to the precise interrupt problem in pipelined processors. An interrupt is precise if the saved process state corresponds with a sequential model of program execution where one instruction completes before the next begins. In a pipelined processor, precise interrupts are difficult to implement because an instruction may be initiated before its predecessors have completed.},
	number = {5},
	urldate = {2018-03-13},
	journal = {IEEE Transactions on Computers},
	author = {Smith, J.E. and Pleszkun, A.R.},
	month = may,
	year = {1988},
	pages = {562--573},
	file = {Smith_Pleszkun_1988_Implementing precise interrupts in pipelined processors.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_Pleszkun_1988_Implementing precise interrupts in pipelined processors.pdf:application/pdf}
}

@article{samuel_studies_2000,
	title = {Some studies in machine learning using the game of checkers},
	volume = {44},
	issn = {0018-8646, 0018-8646},
	url = {http://ieeexplore.ieee.org/document/5389202/},
	doi = {10.1147/rd.441.0206},
	abstract = {Two machine-learning procedures have been investigated in some detail usi!Jg the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to playa better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these 'experiments are, of course, applicable to many other situations.},
	number = {1.2},
	urldate = {2018-03-13},
	journal = {IBM Journal of Research and Development},
	author = {Samuel, A. L.},
	month = jan,
	year = {2000},
	pages = {206--226},
	file = {Samuel_2000_Some studies in machine learning using the game of checkers.pdf:/home/michael/Dropbox/zotero-pdfs/S/Samuel_2000_Some studies in machine learning using the game of checkers.pdf:application/pdf}
}

@article{saltzer_protection_1975,
	title = {The protection of information in computer systems},
	volume = {63},
	issn = {0018-9219},
	url = {http://ieeexplore.ieee.org/document/1451869/},
	doi = {10.1109/PROC.1975.9939},
	number = {9},
	urldate = {2018-03-13},
	journal = {Proceedings of the IEEE},
	author = {Saltzer, J.H. and Schroeder, M.D.},
	year = {1975},
	pages = {1278--1308},
	file = {Saltzer_Schroeder_1975_The protection of information in computer systems.pdf:/home/michael/Dropbox/zotero-pdfs/S/Saltzer_Schroeder_1975_The protection of information in computer systems.pdf:application/pdf}
}

@incollection{levy_studies_1988,
	address = {New York, NY},
	title = {Some {Studies} in {Machine} {Learning} {Using} the {Game} of {Checkers}. {II}—{Recent} {Progress}},
	isbn = {978-1-4613-8718-3 978-1-4613-8716-9},
	url = {http://link.springer.com/10.1007/978-1-4613-8716-9_15},
	abstract = {A new signature tabletechnique is described together with an improved book learning procedure which is thougthot be much superior to the linear polynomial method described earlier. Full useis made of the so called “alpha-beta” pruningand several forms of forward pruningto restrict the spreadof the move tree andto permit the programto look aheadto a much greater depth than it otherwise could do. While still unable to outplay checker masters,the program’s playing ability has been greatly improved.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Computer {Games} {I}},
	publisher = {Springer New York},
	author = {Samuel, Arthur L.},
	editor = {Levy, David N. L.},
	year = {1988},
	doi = {10.1007/978-1-4613-8716-9_15},
	pages = {366--400},
	file = {Samuel_1988_Some Studies in Machine Learning Using the Game of Checkers. II—Recent Progress.pdf:/home/michael/Dropbox/zotero-pdfs/S/Samuel_1988_Some Studies in Machine Learning Using the Game of Checkers. II—Recent Progress.pdf:application/pdf}
}

@article{walker_specification_1980,
	title = {Specification and verification of the {UCLA} {Unix} security kernel},
	volume = {23},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=358818.358825},
	doi = {10.1145/358818.358825},
	number = {2},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Walker, Bruce J. and Kemmerer, Richard A. and Popek, Gerald J.},
	month = feb,
	year = {1980},
	pages = {118--131},
	file = {Walker et al_1980_Specification and verification of the UCLA Unix security kernel.pdf:/home/michael/Dropbox/zotero-pdfs/W/Walker et al_1980_Specification and verification of the UCLA Unix security kernel.pdf:application/pdf}
}

@article{tuch_doctor_nodate,
	title = {Doctor of {Philosophy} {School} of {Computer} {Science} and {Engineering} {The} {University} of {New} {South} {Wales}},
	author = {Tuch, Harvey},
	pages = {269},
	file = {Tuch_Doctor of Philosophy School of Computer Science and Engineering The University.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tuch_Doctor of Philosophy School of Computer Science and Engineering The University.pdf:application/pdf}
}

@incollection{goos_software_2003,
	address = {Berlin, Heidelberg},
	title = {Software {Verification} with {BLAST}},
	volume = {2648},
	isbn = {978-3-540-40117-9 978-3-540-44829-7},
	url = {http://link.springer.com/10.1007/3-540-44829-2_17},
	urldate = {2018-03-13},
	booktitle = {Model {Checking} {Software}},
	publisher = {Springer Berlin Heidelberg},
	author = {Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak and Sutre, Grégoire},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Ball, Thomas and Rajamani, Sriram K.},
	year = {2003},
	doi = {10.1007/3-540-44829-2_17},
	pages = {235--239},
	file = {Henzinger et al_2003_Software Verification with BLAST.pdf:/home/michael/Dropbox/zotero-pdfs/H/Henzinger et al_2003_Software Verification with BLAST.pdf:application/pdf}
}

@article{moggi_notions_1991,
	title = {Notions of computation and monads},
	abstract = {The λ-calculus is considered an useful mathematical tool in the study of programming languages, since programs can be identiﬁed with λ-terms. However, if one goes further and uses βη-conversion to prove equivalence of programs, then a gross simpliﬁcation is introduced (programs are identiﬁed with total functions from values to values), that may jeopardise the applicability of theoretical results. In this paper we introduce calculi based on a categorical semantics for computations, that provide a correct basis for proving equivalence of programs, for a wide range of notions of computation.},
	author = {Moggi, Eugenio},
	year = {1991},
	pages = {29},
	file = {Moggi_Notions of computation and monads.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moggi_Notions of computation and monads.pdf:application/pdf}
}

@article{millen_security_1976,
	title = {Security {Kernel} validation in practice},
	volume = {19},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=360051.360059},
	doi = {10.1145/360051.360059},
	abstract = {Kernel Design The design began as a model [3], in the context of general systems theory, of a secure system, with states and transitions. The system state includes an access relation between subjects and objects, and an assignment of security levels to both subjects and objects. Each object is given a security level when it is created. Security levels are assumed to have a partial ordering, that is, an ordering in which some pairs of elements may not be comparable. The existence of maximum and minimum elements is assumed.},
	number = {5},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Millen, Jonathan K.},
	month = may,
	year = {1976},
	pages = {243--250},
	file = {Millen_1976_Security Kernel validation in practice.pdf:/home/michael/Dropbox/zotero-pdfs/M/Millen_1976_Security Kernel validation in practice.pdf:application/pdf}
}

@article{hoare_proof_1972,
	title = {Proof of correctness of data representations},
	volume = {1},
	issn = {0001-5903, 1432-0525},
	url = {http://link.springer.com/10.1007/BF00289507},
	doi = {10.1007/BF00289507},
	abstract = {A powerful method of simplifying the proofs of program correctness is suggested; and some new light is shed on the problem of functions with side-effects.},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {Acta Informatica},
	author = {Hoare, C. A. R.},
	year = {1972},
	pages = {271--281},
	file = {Hoare_1972_Proof of correctness of data representations.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1972_Proof of correctness of data representations.pdf:application/pdf}
}

@article{cock_bitelds_nodate,
	title = {Bitﬁelds and {Tagged} {Unions} in {C} – {Veriﬁcation} through {Automatic} {Generation}},
	abstract = {We present a tool for automatic generation of packed bitﬁelds and tagged unions for systems-level C, along with automatic, machine checked reﬁnement proofs in Isabelle/HOL. Our approach provides greater predictability than compiler-speciﬁc bitﬁeld implementations, and provides a basis for formal reasoning about these typically non-type-safe operations. The tool is used in the implementation of the seL4 microkernel, and hence also in the lowest-level reﬁnement step of the L4.veriﬁed project which aims to prove the functional correctness of seL4. Within seL4, it has eliminated the need for unions entirely.},
	author = {Cock, David},
	pages = {12},
	file = {Cock_Bitﬁelds and Tagged Unions in C – Veriﬁcation through Automatic Generation.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cock_Bitﬁelds and Tagged Unions in C – Veriﬁcation through Automatic Generation.pdf:application/pdf}
}

@article{pfenning_lecture_2012,
	title = {Lecture {Notes} on {Deductive} {Inference}},
	author = {Pfenning, Frank},
	year = {2012},
	pages = {17},
	file = {Pfenning_2012_Lecture Notes on Deductive Inference.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_2012_Lecture Notes on Deductive Inference.pdf:application/pdf}
}

@article{cardone_history_nodate,
	title = {History of {Lambda}-calculus and {Combinatory} {Logic}},
	author = {Cardone, Felice and Hindley, J Roger},
	pages = {95},
	file = {Cardone_Hindley_History of Lambda-calculus and Combinatory Logic.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardone_Hindley_History of Lambda-calculus and Combinatory Logic.pdf:application/pdf}
}

@incollection{goos_semantics_1984,
	address = {Berlin, Heidelberg},
	title = {A semantics of multiple inheritance},
	volume = {173},
	isbn = {978-3-540-13346-9 978-3-540-38891-3},
	url = {http://link.springer.com/10.1007/3-540-13346-1_2},
	urldate = {2018-03-13},
	booktitle = {Semantics of {Data} {Types}},
	publisher = {Springer Berlin Heidelberg},
	author = {Cardelli, Luca},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Kahn, Gilles and MacQueen, David B. and Plotkin, Gordon},
	year = {1984},
	doi = {10.1007/3-540-13346-1_2},
	pages = {51--67},
	file = {Cardelli_1984_A semantics of multiple inheritance.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli_1984_A semantics of multiple inheritance.pdf:application/pdf}
}

@article{caesar_bgp_2005,
	title = {{BGP} {Routing} {Policies} in {ISP} {Networks}},
	abstract = {The Internet has quickly evolved into a vast global network owned and operated by thousands of different administrative entities. During this time, it became apparent that vanilla shortest path routing would be insufficient to handle the myriad operational, economic, and political factors involved in routing. ISPs began to modify routing configurations to support routing policies — goals held by the router’s owner that controlled which routes were chosen and which routes were propagated to neighbors. BGP, originally a simple path vector protocol, was incrementally modified over time with a number of mechanisms to support policies, adding substantially to the complexity. Much of the mystery in BGP comes not only from the protocol complexity, but also from a lack of understanding of the underlying policies and the problems ISPs face that are addressed by these policies. In this article we shed light on goals operators have and their resulting routing policies, why BGP evolved the way it did, and how common policies are implemented using BGP. We also discuss recent and current work in the field that aims to address problems that arise in applying and supporting routing policies.},
	journal = {IEEE Network},
	author = {Caesar, Matthew and Rexford, Jennifer},
	year = {2005},
	pages = {7},
	file = {Caesar_Rexford_2005_BGP Routing Policies in ISP Networks.pdf:/home/michael/Dropbox/zotero-pdfs/C/Caesar_Rexford_2005_BGP Routing Policies in ISP Networks.pdf:application/pdf}
}

@incollection{goos_clean_1987,
	address = {Berlin, Heidelberg},
	title = {Clean — {A} language for functional graph rewriting},
	volume = {274},
	isbn = {978-3-540-18317-4 978-3-540-47879-9},
	url = {http://link.springer.com/10.1007/3-540-18317-5_20},
	abstract = {Clean is an experimental language for specifying functional computations in terms of graph rewriting. It is based on an extension of Term Rewriting Systems (TRS) in which the terms are replaced by graphs. Such a Graph Rewriting System (GRS) consists of a, possibly cyclic, directed graph, called the data graph and graph rewrite rules which specify how this data graph may be rewr{\textasciitilde}en. Clean is designed to provide a firm base for functional programming. In particular, Clean is suitable as an intermediate language between functional languages and (parallel) target machine architectures. A sequential implementation of Clean on a conventional machine is described and its performance is compared with other systems. The results show that Clean can be efficiently implemented.},
	urldate = {2018-03-13},
	booktitle = {Functional {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer Berlin Heidelberg},
	author = {Brus, T. H. and Eekelen, M. C. J. D. and Leer, M. O. and Plasmeijer, M. J.},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Kahn, Gilles},
	year = {1987},
	doi = {10.1007/3-540-18317-5_20},
	pages = {364--384},
	file = {Brus et al_1987_Clean — A language for functional graph rewriting.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brus et al_1987_Clean — A language for functional graph rewriting.pdf:application/pdf}
}

@inproceedings{bruggeman_representing_1996,
	title = {Representing control in the presence of one-shot continuations},
	isbn = {978-0-89791-795-7},
	url = {http://portal.acm.org/citation.cfm?doid=231379.231395},
	doi = {10.1145/231379.231395},
	abstract = {Traditional rst-class continuation mechanisms allow a captured continuation to be invoked multiple times. Many continuations, however, are invoked only once. This paper introduces one-shot continuations, shows how they interact with traditional multi-shot continuations, and describes a stack-based implementation of control that handles both one-shot and multi-shot continuations. The implementation eliminates the copying overhead for one-shot continuations that is inherent in multi-shot continuations.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Bruggeman, Carl and Waddell, Oscar and Dybvig, R. Kent},
	year = {1996},
	pages = {99--107},
	file = {Bruggeman et al_1996_Representing control in the presence of one-shot continuations.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bruggeman et al_1996_Representing control in the presence of one-shot continuations.pdf:application/pdf}
}

@incollection{goos_architecture_1987,
	address = {Berlin, Heidelberg},
	title = {The architecture of {DOOM}},
	volume = {272},
	isbn = {978-3-540-18203-0 978-3-540-47806-5},
	url = {http://link.springer.com/10.1007/3-540-18203-9_6},
	abstract = {This paper describes the architecture of DOOM, a Decentralized Object-Oriented Machine, which is being designed in the Computer Science department of Philips Research Laboratories. The paper starts by resuming the essential characteristics of POOL-T, the parallel objectoriented language designed in the framework of the project. An abstract architecture matching the computational model of the language is then described. In three successive steps this architecture is transformed to the DOOM architecture which is under design. Each of the steps reveals the requirements on the actual system that are introduced by the transformation. The DOOM architecture consists of a collection of self contained computers, consistingof a cpu, local memory and a communicationunit to connect these computers via a point-to-pointpacket switching network. The functional requirements and the architecture of the cpu, the memory and the communication networks are then treated in greater detail, covering one section each.},
	urldate = {2018-03-13},
	booktitle = {Future {Parallel} {Computers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bronnenberg, W. J. H. J. and Janssens, M. D. and Odijk, E. A. M. and Twist, R. A. H.},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Treleaven, P. and Vanneschi, M.},
	year = {1987},
	doi = {10.1007/3-540-18203-9_6},
	pages = {227--269},
	file = {Bronnenberg et al_1987_The architecture of DOOM.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bronnenberg et al_1987_The architecture of DOOM.pdf:application/pdf}
}

@incollection{hutchison_simple_2013,
	address = {Berlin, Heidelberg},
	title = {Simple and {Efficient} {Construction} of {Static} {Single} {Assignment} {Form}},
	volume = {7791},
	isbn = {978-3-642-37050-2 978-3-642-37051-9},
	url = {http://link.springer.com/10.1007/978-3-642-37051-9_6},
	abstract = {We present a simple SSA construction algorithm, which allows direct translation from an abstract syntax tree or bytecode into an SSA-based intermediate representation. The algorithm requires no prior analysis and ensures that even during construction the intermediate representation is in SSA form. This allows the application of SSA-based optimizations during construction. After completion, the intermediate representation is in minimal and pruned SSA form. In spite of its simplicity, the runtime of our algorithm is on par with Cytron et al.’s algorithm.},
	urldate = {2018-03-13},
	booktitle = {Compiler {Construction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Braun, Matthias and Buchwald, Sebastian and Hack, Sebastian and Leißa, Roland and Mallon, Christoph and Zwinkau, Andreas},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Jhala, Ranjit and De Bosschere, Koen},
	year = {2013},
	doi = {10.1007/978-3-642-37051-9_6},
	pages = {102--122},
	file = {Braun et al_2013_Simple and Efficient Construction of Static Single Assignment Form.pdf:/home/michael/Dropbox/zotero-pdfs/B/Braun et al_2013_Simple and Efficient Construction of Static Single Assignment Form.pdf:application/pdf}
}

@article{brady_idris_2013,
	title = {Idris, a general-purpose dependently typed programming language: {Design} and implementation},
	volume = {23},
	issn = {0956-7968, 1469-7653},
	shorttitle = {Idris, a general-purpose dependently typed programming language},
	url = {http://www.journals.cambridge.org/abstract_S095679681300018X},
	doi = {10.1017/S095679681300018X},
	abstract = {Many components of a dependently-typed programming language are by now well understood, for example the underlying type theory, type checking, uniﬁcation and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementators. In this paper, I describe the implementation of IDRIS, a new dependently-typed functional programming language. IDRIS is intended to be a general purpose programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for elaborating concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.},
	language = {en},
	number = {05},
	urldate = {2018-03-13},
	journal = {Journal of Functional Programming},
	author = {Brady, Edwin},
	month = sep,
	year = {2013},
	pages = {552--593},
	file = {Brady_2013_Idris, a general-purpose dependently typed programming language - Design and.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brady_2013_Idris, a general-purpose dependently typed programming language - Design and.pdf:application/pdf}
}

@article{boyd-wickizer_corey:_nodate,
	title = {Corey: {An} {Operating} {System} for {Many} {Cores}},
	abstract = {Multiprocessor application performance can be limited by the operating system when the application uses the operating system frequently and the operating system services use data structures shared and modiﬁed by multiple processing cores. If the application does not need the sharing, then the operating system will become an unnecessary bottleneck to the application’s performance. This paper argues that applications should control sharing: the kernel should arrange each data structure so that only a single processor need update it, unless directed otherwise by the application. Guided by this design principle, this paper proposes three operating system abstractions (address ranges, kernel cores, and shares) that allow applications to control inter-core sharing and to take advantage of the likely abundance of cores by dedicating cores to speciﬁc operating system functions.},
	author = {Boyd-Wickizer, Silas and Chen, Haibo and Chen, Rong and Mao, Yandong and Kaashoek, Frans and Morris, Robert and Pesterev, Aleksey and Stein, Lex and Wu, Ming and Dai, Yuehua and Zhang, Yang and Zhang, Zheng},
	pages = {15},
	file = {Boyd-Wickizer et al_Corey - An Operating System for Many Cores.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyd-Wickizer et al_Corey - An Operating System for Many Cores.pdf:application/pdf}
}

@article{cousot_fondements_nodate,
	title = {{FONDEMENTS} {DES} {VTÉTHODES} {DE} {PREUVE} {D}'{INVARIANCE} {ET} {DE} {FATATITÉ} {DE} {PROGRAMMES} {PARATLÈLES}},
	author = {COUSOT, Radhia and Verjus, J P},
	pages = {553},
	file = {COUSOT_Verjus_FONDEMENTS DES VTETHODES DE PREUVE D'INVARIANCE ET DE FATATITE DE PROGRAMMES.PDF:/home/michael/Dropbox/zotero-pdfs/C/COUSOT_Verjus_FONDEMENTS DES VTETHODES DE PREUVE D'INVARIANCE ET DE FATATITE DE PROGRAMMES.PDF:application/pdf}
}

@inproceedings{cousot_types_1997,
	title = {Types as abstract interpretations},
	isbn = {978-0-89791-853-4},
	url = {http://portal.acm.org/citation.cfm?doid=263699.263744},
	doi = {10.1145/263699.263744},
	abstract = {Starting from a denotational semantics of the eager untyped lambda-calculus with explicit runtime errors, the standard collecting semantics is deﬁned as specifying the strongest program properties. By a ﬁrst abstraction, a new sound type collecting semantics is derived in compositional ﬁxpoint form. Then by successive (semi-dual) Galois connection based abstractions, type systems and/or type inference algorithms are designed as abstract semantics or abstract interpreters approximating the type collecting semantics. This leads to a hierarchy of type systems, which is part of the lattice of abstract interpretations of the untyped lambda-calculus. This hierarchy includes two new `a la Church/Curry polytype systems. Abstractions of this polytype semantics lead to classical Milner/Mycroft and Damas/Milner polymorphic type schemes, Church/Curry monotypes and Hindley principal typing algorithm. This shows that types are abstract interpretations.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Cousot, Patrick},
	year = {1997},
	pages = {316--331},
	file = {Cousot_1997_Types as abstract interpretations.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cousot_1997_Types as abstract interpretations.pdf:application/pdf}
}

@incollection{bruynooghe_comparing_1992,
	address = {Berlin/Heidelberg},
	title = {Comparing the {Galois} connection and widening/narrowing approaches to abstract interpretation},
	volume = {631},
	isbn = {978-3-540-55844-6},
	url = {http://link.springer.com/10.1007/3-540-55844-6_142},
	abstract = {The use of inﬁnite abstract domains with widening and narrowing for accelerating the convergence of abstract interpretations is shown to be more powerful than the Galois connection approach re­ stricted to ﬁnite lattices (or lattices satisfying the chain condition).},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Language} {Implementation} and {Logic} {Programming}},
	publisher = {Springer-Verlag},
	author = {Cousot, Patrick and Cousot, Radhia},
	editor = {Bruynooghe, Maurice and Wirsing, Martin},
	year = {1992},
	doi = {10.1007/3-540-55844-6_142},
	pages = {269--295},
	file = {Cousot_Cousot_1992_Comparing the Galois connection and widening-narrowing approaches to abstract.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cousot_Cousot_1992_Comparing the Galois connection and widening-narrowing approaches to abstract.pdf:application/pdf}
}

@article{coquand_calculus_nodate,
	title = {The calculus of constructions},
	author = {Coquand, T},
	pages = {25},
	file = {Coquand_The calculus of constructions.pdf:/home/michael/Dropbox/zotero-pdfs/C/Coquand_The calculus of constructions.pdf:application/pdf}
}

@article{conway_design_1963,
	title = {Design of a separable transition-diagram compiler},
	volume = {6},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=366663.366704},
	doi = {10.1145/366663.366704},
	number = {7},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Conway, Melvin E.},
	month = jul,
	year = {1963},
	pages = {396--408},
	file = {Conway_1963_Design of a separable transition-diagram compiler.pdf:/home/michael/Dropbox/zotero-pdfs/C/Conway_1963_Design of a separable transition-diagram compiler.pdf:application/pdf}
}

@inproceedings{maurer_compiling_2017,
	title = {Compiling without continuations},
	isbn = {978-1-4503-4988-8},
	url = {http://dl.acm.org/citation.cfm?doid=3062341.3062380},
	doi = {10.1145/3062341.3062380},
	abstract = {Many ﬁelds of study in compilers give rise to the concept of a join point—a place where different execution paths come together. Join points are often treated as functions or continuations, but we believe it is time to study them in their own right. We show that adding join points to a direct-style functional intermediate language is a simple but powerful change that allows new optimizations to be performed, including a signiﬁcant improvement to list fusion. Finally, we report on recent work on adding join points to the intermediate language of the Glasgow Haskell Compiler.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Maurer, Luke and Downen, Paul and Ariola, Zena M. and Peyton Jones, Simon},
	year = {2017},
	pages = {482--494},
	file = {Maurer et al_2017_Compiling without continuations.pdf:/home/michael/Dropbox/zotero-pdfs/M/Maurer et al_2017_Compiling without continuations.pdf:application/pdf}
}

@article{clint_program_nodate,
	title = {Program {Proving}: {Coroutines}},
	abstract = {Proof methods adequate for a wide range of computer programs have been given in [t-6]. This paper develops a method suitable for programs which incorporate coroutines. The implementation of coroutines described follows closely that given in SIMULA [7, 81, a language in which such features may be used to great advantage. Proof rules for establishing the correctness of coroutines are given and the method is illustrated by the proof of a useful program for histogram compilation.},
	author = {Clint, M},
	pages = {14},
	file = {Clint_Program Proving - Coroutines.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clint_Program Proving - Coroutines.pdf:application/pdf}
}

@article{church_unsolvable_1936,
	title = {An {Unsolvable} {Problem} of {Elementary} {Number} {Theory}},
	volume = {58},
	issn = {00029327},
	url = {http://www.jstor.org/stable/2371045?origin=crossref},
	doi = {10.2307/2371045},
	number = {2},
	urldate = {2018-03-13},
	journal = {American Journal of Mathematics},
	author = {Church, Alonzo},
	month = apr,
	year = {1936},
	pages = {345},
	file = {Church_1936_An Unsolvable Problem of Elementary Number Theory.pdf:/home/michael/Dropbox/zotero-pdfs/C/Church_1936_An Unsolvable Problem of Elementary Number Theory.pdf:application/pdf}
}

@article{church_set_1932,
	title = {A {Set} of {Postulates} for the {Foundation} of {Logic}},
	volume = {33},
	issn = {0003486X},
	url = {http://www.jstor.org/stable/1968337?origin=crossref},
	doi = {10.2307/1968337},
	number = {2},
	urldate = {2018-03-13},
	journal = {The Annals of Mathematics},
	author = {Church, Alonzo},
	month = apr,
	year = {1932},
	pages = {346},
	file = {Church_1932_A Set of Postulates for the Foundation of Logic.pdf:/home/michael/Dropbox/zotero-pdfs/C/Church_1932_A Set of Postulates for the Foundation of Logic.pdf:application/pdf}
}

@article{church_formulation_1940,
	title = {A formulation of the simple theory of types},
	volume = {5},
	issn = {0022-4812, 1943-5886},
	url = {https://www.cambridge.org/core/product/identifier/S0022481200108187/type/journal_article},
	doi = {10.2307/2266170},
	language = {en},
	number = {02},
	urldate = {2018-03-13},
	journal = {The Journal of Symbolic Logic},
	author = {Church, Alonzo},
	month = jun,
	year = {1940},
	pages = {56--68},
	file = {Church_1940_A formulation of the simple theory of types.pdf:/home/michael/Dropbox/zotero-pdfs/C/Church_1940_A formulation of the simple theory of types.pdf:application/pdf}
}

@incollection{goos_compiling_2001,
	address = {Berlin, Heidelberg},
	title = {Compiling {Lazy} {Functional} {Programs} {Based} on the {Spineless} {Tagless} {G}-machine for the {Java} {Virtual} {Machine}},
	volume = {2024},
	isbn = {978-3-540-41739-2 978-3-540-44716-0},
	url = {http://link.springer.com/10.1007/3-540-44716-4_6},
	abstract = {A systematic method of compiling lazy functional programs based on the Spineless Tagless G-machine (STGM) is presented for the Java Virtual Machine (JVM). A new speciﬁcation of the STGM, which consists of a compiler and a reduction machine, is presented; the compiler translates a program in the STG language, which is the source language for the STGM, into a program in an intermediate language called L-code, and our reduction machine reduces the L-code program into an answer. With our representation for the reduction machine by the Java language, an L-code program is translated into a Java program simulating the reduction machine.},
	urldate = {2018-03-13},
	booktitle = {Functional and {Logic} {Programming}},
	publisher = {Springer Berlin Heidelberg},
	author = {Choi, Kwanghoon and Lim, Hyun-il and Han, Taisook},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kuchen, Herbert and Ueda, Kazunori},
	year = {2001},
	doi = {10.1007/3-540-44716-4_6},
	pages = {92--107},
	file = {Choi et al_2001_Compiling Lazy Functional Programs Based on the Spineless Tagless G-machine for.pdf:/home/michael/Dropbox/zotero-pdfs/C/Choi et al_2001_Compiling Lazy Functional Programs Based on the Spineless Tagless G-machine for2.pdf:application/pdf}
}

@inproceedings{chlipala_parametric_2008,
	title = {Parametric higher-order abstract syntax for mechanized semantics},
	isbn = {978-1-59593-919-7},
	url = {http://portal.acm.org/citation.cfm?doid=1411204.1411226},
	doi = {10.1145/1411204.1411226},
	abstract = {We present parametric higher-order abstract syntax (PHOAS), a new approach to formalizing the syntax of programming languages in computer proof assistants based on type theory. Like higherorder abstract syntax (HOAS), PHOAS uses the meta language’s binding constructs to represent the object language’s binding constructs. Unlike HOAS, PHOAS types are deﬁnable in generalpurpose type theories that support traditional functional programming, like Coq’s Calculus of Inductive Constructions. We walk through how Coq can be used to develop certiﬁed, executable program transformations over several statically-typed functional programming languages formalized with PHOAS; that is, each transformation has a machine-checked proof of type preservation and semantic preservation. Our examples include CPS translation and closure conversion for simply-typed lambda calculus, CPS translation for System F, and translation from a language with ML-style pattern matching to a simpler language with no variable-arity binding constructs. By avoiding the syntactic hassle associated with ﬁrst-order representation techniques, we achieve a very high degree of proof automation.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Chlipala, Adam},
	year = {2008},
	pages = {143},
	file = {Chlipala_2008_Parametric higher-order abstract syntax for mechanized semantics.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chlipala_2008_Parametric higher-order abstract syntax for mechanized semantics.pdf:application/pdf}
}

@inproceedings{chen_quantitative_2012,
	title = {Quantitative {Verification} of {Implantable} {Cardiac} {Pacemakers}},
	isbn = {978-1-4673-3098-5},
	url = {http://ieeexplore.ieee.org/document/6424809/},
	doi = {10.1109/RTSS.2012.77},
	abstract = {Implantable medical devices, such as cardiac pacemakers, must be designed and programmed to the highest levels of safety and reliability. Recently, errors in embedded software have led to a substantial increase in safety alerts, costly device recalls or even patient death. To address such issues, we propose a model-based framework for quantitative, automated veriﬁcation of pacemaker software. We adapt the electrocardiogram model of Clifford et al, which generates realistic normal and abnormal heart beat behaviours, with probabilistic transitions between them, to produce a timed sequence of action potential signals that serve as pacemaker input. Working with the timed automata model of the pacemaker by Jiang et al, we develop a methodology for deriving the composition of the heart and the pacemaker, based on discretisation. The main correctness properties we consider include checking that the pacemaker corrects Bradycardia (slow heart beat) and does not induce Tachycardia (fast heart beat), for a range of realistic heart behaviours. We also analyse undersensing, through considering noise on sensor readings, and energy usage. We implement the framework using the probabilistic model checker PRISM and MATLAB and demonstrate encouraging experimental results. Our approach can be adapted to individual patients and is applicable to other pacemaker models.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Chen, Taolue and Diciolla, Marco and Kwiatkowska, Marta and Mereacre, Alexandru},
	month = dec,
	year = {2012},
	pages = {263--272},
	file = {Chen et al_2012_Quantitative Verification of Implantable Cardiac Pacemakers.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chen et al_2012_Quantitative Verification of Implantable Cardiac Pacemakers.pdf:application/pdf}
}

@incollection{hutchison_call-by-need_2012,
	address = {Berlin, Heidelberg},
	title = {The {Call}-by-{Need} {Lambda} {Calculus}, {Revisited}},
	volume = {7211},
	isbn = {978-3-642-28868-5 978-3-642-28869-2},
	url = {http://link.springer.com/10.1007/978-3-642-28869-2_7},
	abstract = {The existing call-by-need λ calculi describe lazy evaluation via equational logics. A programmer can use these logics to safely ascertain whether one term is behaviorally equivalent to another or to determine the value of a lazy program. However, neither of the existing calculi models evaluation in a way that matches lazy implementations.},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Chang, Stephen and Felleisen, Matthias},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Seidl, Helmut},
	year = {2012},
	doi = {10.1007/978-3-642-28869-2_7},
	pages = {128--147},
	file = {Chang_Felleisen_2012_The Call-by-Need Lambda Calculus, Revisited.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chang_Felleisen_2012_The Call-by-Need Lambda Calculus, Revisited.pdf:application/pdf}
}

@article{emre_fuzzer_nodate,
	title = {Fuzzer {Evaluation}: {A} {Critique} and {Proposal}},
	abstract = {Fuzzing is a widely applicable bug-ﬁnding technique that has led to the discovery of thousands of bugs in a variety of real-world software projects. Fuzzing is an active research area, with dozens of papers evaluating the effectiveness of novel fuzzing techniques. During the development of our own novel fuzzing technique for SMT solvers, we found that many of the evaluation metrics used in existing work are unreliable and popular metrics are effectively meaningless. We argue that the fundamental reason is that accurately determining the total number of unique bugs a fuzzer has found is an exceedingly difﬁcult problem. However, we show this metric to be crucially important. Our solution to this problem is a novel evaluation methodology that can automatically derive this metric with a minimal amount of human effort. This enables evaluations which are more scientiﬁcally rigorous. A secondary effect of this work is the discovery of 24 new bugs across popular SMT solvers, speciﬁcally Z3, CVC4, MathSAT5, and Boolector. Correctness bugs were found in each solver tested, and the majority of these bugs have already been ﬁxed.},
	author = {Emre, Kyle Dewey Mehmet and Hardekopf, Ben},
	pages = {12},
	file = {Emre_Hardekopf_Fuzzer Evaluation - A Critique and Proposal.pdf:/home/michael/Dropbox/zotero-pdfs/E/Emre_Hardekopf_Fuzzer Evaluation - A Critique and Proposal.pdf:application/pdf}
}

@inproceedings{dewey_automated_2015,
	title = {Automated {Data} {Structure} {Generation}: {Refuting} {Common} {Wisdom}},
	isbn = {978-1-4799-1934-5},
	shorttitle = {Automated {Data} {Structure} {Generation}},
	url = {http://ieeexplore.ieee.org/document/7194559/},
	doi = {10.1109/ICSE.2015.26},
	abstract = {Common wisdom in the automated data structure generation community states that declarative techniques have better usability than imperative techniques, while imperative techniques have better performance. We show that this reasoning is fundamentally ﬂawed: if we go to the declarative limit and employ constraint logic programming (CLP), the CLP data structure generation has orders of magnitude better performance than comparable imperative techniques. Conversely, we observe and argue that when it comes to realistically complex data structures and properties, the CLP speciﬁcations become more obscure, indirect, and difﬁcult to implement and understand than their imperative counterparts. We empirically evaluate three competing generation techniques, CLP, Korat, and UDITA, to validate these observations on more complex and interesting data structures than any prior work in this area. We explain why these observations are true, and discuss possible techniques for attaining the best of both worlds.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Dewey, Kyle and Nichols, Lawton and Hardekopf, Ben},
	month = may,
	year = {2015},
	pages = {32--43},
	file = {Dewey et al_2015_Automated Data Structure Generation - Refuting Common Wisdom.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dewey et al_2015_Automated Data Structure Generation - Refuting Common Wisdom.pdf:application/pdf}
}

@inproceedings{dewey_parallel_2015,
	title = {A parallel abstract interpreter for {JavaScript}},
	isbn = {978-1-4799-8161-8},
	url = {http://ieeexplore.ieee.org/document/7054185/},
	doi = {10.1109/CGO.2015.7054185},
	abstract = {We investigate parallelizing ﬂow- and context-sensitive static analysis for JavaScript. Previous attempts to parallelize such analyses for other languages typically start with the traditional framework of sequential dataﬂow analysis, and then propose methods to parallelize the existing sequential algorithms within this framework. However, we show that this approach is non-optimal and propose a new perspective on program analysis based on abstract interpretation that separates the analysis into two components: (1) an embarrassingly parallel state exploration of a state transition system; and (2) a separate component that controls the size of the state space by selectively merging states, thus injecting sequential dependencies into the system. This perspective simpliﬁes the parallelization problem and exposes useful opportunities to exploit the natural parallelism of the analysis.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Dewey, Kyle and Kashyap, Vineeth and Hardekopf, Ben},
	month = feb,
	year = {2015},
	pages = {34--45},
	file = {Dewey et al_2015_A parallel abstract interpreter for JavaScript.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dewey et al_2015_A parallel abstract interpreter for JavaScript.pdf:application/pdf}
}

@inproceedings{dewey_language_2014,
	title = {Language fuzzing using constraint logic programming},
	isbn = {978-1-4503-3013-8},
	url = {http://dl.acm.org/citation.cfm?doid=2642937.2642963},
	doi = {10.1145/2642937.2642963},
	abstract = {Fuzz testing builds conﬁdence in compilers and interpreters. It is desirable for fuzzers to allow targeted generation of programs that showcase speciﬁc language features and behaviors. However, the predominant program generation technique used by most language fuzzers, stochastic context-free grammars, does not have this property. We propose the use of constraint logic programming (CLP) for program generation. Using CLP, testers can write declarative predicates specifying interesting programs, including syntactic features and semantic behaviors. CLP subsumes and generalizes the stochastic grammar approach.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Dewey, Kyle and Roesch, Jared and Hardekopf, Ben},
	year = {2014},
	pages = {725--730},
	file = {Dewey et al_2014_Language fuzzing using constraint logic programming.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dewey et al_2014_Language fuzzing using constraint logic programming.pdf:application/pdf}
}

@incollection{goos_first_1974,
	address = {Berlin, Heidelberg},
	title = {First version of a data flow procedure language},
	volume = {19},
	isbn = {978-3-540-06859-4 978-3-540-37819-8},
	url = {http://link.springer.com/10.1007/3-540-06859-7_145},
	abstract = {A language for representing computational procedures based on the concept of data flow is presented in terms of a semantic model that permits concurrent execution of noninterfering program parts.},
	urldate = {2018-03-13},
	booktitle = {Programming {Symposium}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dennis, Jack B.},
	editor = {Goos, G. and Hartmanis, J. and Brinch Hansen, P. and Gries, D. and Moler, C. and Seegmüller, G. and Wirth, N. and Robinet, B.},
	year = {1974},
	doi = {10.1007/3-540-06859-7_145},
	pages = {362--376},
	file = {Dennis_1974_First version of a data flow procedure language.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dennis_1974_First version of a data flow procedure language.pdf:application/pdf}
}

@inproceedings{dennis_parallel_1998,
	title = {A parallel program execution model supporting modular software construction},
	isbn = {978-0-8186-8427-2},
	url = {http://ieeexplore.ieee.org/document/715961/},
	doi = {10.1109/MPPM.1997.715961},
	abstract = {A watershed is near in the architecture of computer systems. There is overwhelming demand for systems that support a universal format for computer programs and software components so users may beneﬁt from their use on a wide variety of computing platforms. At present this demand is being met by commodity microprocessors together with standard operating system interfaces. However, current systems do not offer a standard API (application program interface) for parallel programming, and the popular interfaces for parallel computing violate essential principles of modular or component-based software construction. Moreover, microprocessor architecture is reaching the limit of what can be done usefully within the framework of superscalar and VLIW processor models. The next step is to put several processors (or the equivalent) on a single chip.},
	urldate = {2018-03-13},
	publisher = {IEEE Comput. Soc},
	author = {Dennis, J.B.},
	year = {1998},
	pages = {50--60},
	file = {Dennis_1998_A parallel program execution model supporting modular software construction.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dennis_1998_A parallel program execution model supporting modular software construction.pdf:application/pdf}
}

@incollection{felty_lean_2015,
	address = {Cham},
	title = {The {Lean} {Theorem} {Prover} ({System} {Description})},
	volume = {9195},
	isbn = {978-3-319-21400-9 978-3-319-21401-6},
	url = {http://link.springer.com/10.1007/978-3-319-21401-6_26},
	abstract = {Lean is a new open source theorem prover being developed at Microsoft Research and Carnegie Mellon University, with a small trusted kernel based on dependent type theory. It aims to bridge the gap between interactive and automated theorem proving, by situating automated tools and methods in a framework that supports user interaction and the construction of fully speciﬁed axiomatic proofs. Lean is an ongoing and long-term eﬀort, but it already provides many useful components, integrated development environments, and a rich API which can be used to embed it into other systems. It is currently being used to formalize category theory, homotopy type theory, and abstract algebra. We describe the project goals, system architecture, and main features, and we discuss applications and continuing work.},
	urldate = {2018-03-13},
	booktitle = {Automated {Deduction} - {CADE}-25},
	publisher = {Springer International Publishing},
	author = {de Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and van Doorn, Floris and von Raumer, Jakob},
	editor = {Felty, Amy P. and Middeldorp, Aart},
	year = {2015},
	doi = {10.1007/978-3-319-21401-6_26},
	pages = {378--388},
	file = {de Moura et al_2015_The Lean Theorem Prover (System Description).pdf:/home/michael/Dropbox/zotero-pdfs/D/de Moura et al_2015_The Lean Theorem Prover (System Description).pdf:application/pdf}
}

@article{moura_revisiting_2009,
	title = {Revisiting coroutines},
	volume = {31},
	issn = {01640925},
	url = {http://portal.acm.org/citation.cfm?doid=1462166.1462167},
	doi = {10.1145/1462166.1462167},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Moura, Ana Lúcia De and Ierusalimschy, Roberto},
	month = feb,
	year = {2009},
	pages = {1--31},
	file = {Moura_Ierusalimschy_2009_Revisiting coroutines.pdf:/home/michael/Dropbox/zotero-pdfs/M/Moura_Ierusalimschy_2009_Revisiting coroutines.pdf:application/pdf}
}

@inproceedings{danvy_abstracting_1990,
	title = {Abstracting control},
	isbn = {978-0-89791-368-3},
	url = {http://portal.acm.org/citation.cfm?doid=91556.91622},
	doi = {10.1145/91556.91622},
	abstract = {The last few years have seen a renewed interest in continuations for expressing advanced control structures in programming languages, and new models such as Abstract Continuations have been proposed to capture these dimensions. This article investigates an alternative formulation, exploiting the latent expressive power of the standard continuation-passing style (CPS) instead of introducing yet other new concepts. We build on a single foundation: abstracting control as a hierarchy of continuations, each one modeling a speci c language feature as acting on nested evaluation contexts.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Danvy, Olivier and Filinski, Andrzej},
	year = {1990},
	pages = {151--160},
	file = {Danvy_Filinski_1990_Abstracting control.pdf:/home/michael/Dropbox/zotero-pdfs/D/Danvy_Filinski_1990_Abstracting control.pdf:application/pdf}
}

@article{dahl_iii._nodate,
	title = {{III}. {Hierarchical} {Program} {Structures}},
	author = {DAHL, OLE-JOHAN and HOARE, C A R},
	pages = {46},
	file = {DAHL_HOARE_III. Hierarchical Program Structures.pdf:/home/michael/Dropbox/zotero-pdfs/D/DAHL_HOARE_III. Hierarchical Program Structures.pdf:application/pdf}
}

@article{curry_inconsistency_1942,
	title = {The inconsistency of certain formal logics},
	volume = {7},
	issn = {0022-4812, 1943-5886},
	url = {https://www.cambridge.org/core/product/identifier/S002248120006388X/type/journal_article},
	doi = {10.2307/2269292},
	language = {en},
	number = {03},
	urldate = {2018-03-13},
	journal = {The Journal of Symbolic Logic},
	author = {Curry, Haskell B.},
	month = sep,
	year = {1942},
	pages = {115--117},
	file = {Curry_1942_The inconsistency of certain formal logics.pdf:/home/michael/Dropbox/zotero-pdfs/C/Curry_1942_The inconsistency of certain formal logics.pdf:application/pdf}
}

@article{curry_functionality_1934,
	title = {Functionality in {Combinatory} {Logic}},
	volume = {20},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.20.11.584},
	doi = {10.1073/pnas.20.11.584},
	abstract = {F. Thus if we hold to the suggested interpretations F is a more restricted concept than F', and the assertion F- FX Yf says more about f than that fx belongs to Y for every x in X. For many purposes it is desirable to retain this more restricted F, and we obtain increased generality by so doing.},
	language = {en},
	number = {11},
	urldate = {2018-03-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Curry, H. B.},
	month = nov,
	year = {1934},
	pages = {584--590},
	file = {Curry_1934_Functionality in Combinatory Logic.pdf:/home/michael/Dropbox/zotero-pdfs/C/Curry_1934_Functionality in Combinatory Logic.pdf:application/pdf}
}

@article{grigore_java_nodate,
	title = {Java {Generics} are {Turing} {Complete}},
	abstract = {This note proves that nominal subtyping with contravariance is undecidable even in the absence of multiple instantiation inheritance, thus solving an open problem posed by Kennedy and Pierce in 2007.},
	author = {Grigore, Radu},
	pages = {6},
	file = {Grigore_Java Generics are Turing Complete.pdf:/home/michael/Dropbox/zotero-pdfs/G/Grigore_Java Generics are Turing Complete.pdf:application/pdf}
}

@article{gordon_functional_nodate,
	title = {Functional {Programming} and {Input}/{Output}},
	author = {Gordon, Andrew Donald},
	pages = {168},
	file = {Gordon_Functional Programming and Input-Output.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon_Functional Programming and Input-Output.pdf:application/pdf}
}

@article{gordon_semantics_nodate,
	title = {Semantics for 1/0 in a {Lazy} {Functional} {Language}},
	abstract = {.},
	author = {Gordon, Andrew D},
	pages = {10},
	file = {Gordon_Semantics for 1-0 in a Lazy Functional Language.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon_Semantics for 1-0 in a Lazy Functional Language.pdf:application/pdf}
}

@article{gordon_tutorial_nodate,
	title = {A {Tutorial} on {Co}-induction and {Functional} {Programming}},
	abstract = {Co-induction is an important tool for reasoning about unbounded structures. This tutorial explains the foundations of co-induction, and shows how it justi es intuitive arguments about lazy streams, of central importance to lazy functional programmers. We explain from rst principles a theory based on a new formulation of bisimilarity for functional programs, which coincides exactly with Morris-style contextual equivalence. We show how to prove properties of lazy streams by co-induction and derive Bird and Wadler's Take Lemma, a well-known proof technique for lazy streams.},
	author = {Gordon, Andrew D},
	pages = {18},
	file = {Gordon_A Tutorial on Co-induction and Functional Programming.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon_A Tutorial on Co-induction and Functional Programming.pdf:application/pdf}
}

@article{gonthier_formal_2008,
	title = {Formal {Proof}—{The} {Four}- {Color} {Theorem}},
	volume = {55},
	number = {11},
	author = {Gonthier, Georges},
	year = {2008},
	pages = {12},
	file = {Gonthier_2008_Formal Proof—The Four- Color Theorem.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gonthier_2008_Formal Proof—The Four- Color Theorem.pdf:application/pdf}
}

@article{godefroid_dart:_2005,
	title = {{DART}: directed automated random testing},
	volume = {40},
	issn = {03621340},
	shorttitle = {{DART}},
	url = {http://portal.acm.org/citation.cfm?doid=1064978.1065036},
	doi = {10.1145/1064978.1065036},
	abstract = {We present a new tool, named DART, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or DART for short. The main strength of DART is thus that testing can be performed completely automatically on any program that compiles – there is no need to write any test driver or harness code. During testing, DART detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
	language = {en},
	number = {6},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
	month = jun,
	year = {2005},
	pages = {213},
	file = {Godefroid et al_2005_DART - directed automated random testing.pdf:/home/michael/Dropbox/zotero-pdfs/G/Godefroid et al_2005_DART - directed automated random testing.pdf:application/pdf}
}

@book{girard_proofs_1989,
	address = {Cambridge [England] ; New York},
	series = {Cambridge tracts in theoretical computer science},
	title = {Proofs and types},
	isbn = {978-0-521-37181-0},
	number = {7},
	publisher = {Cambridge University Press},
	author = {Girard, Jean-Yves},
	year = {1989},
	keywords = {Lambda calculus},
	file = {Girard_1989_Proofs and types.pdf:/home/michael/Dropbox/zotero-pdfs/G/Girard_1989_Proofs and types.pdf:application/pdf}
}

@incollection{hutchison_proving_2014,
	address = {Cham},
	title = {Proving {Termination} of {Programs} {Automatically} with {AProVE}},
	volume = {8562},
	isbn = {978-3-319-08586-9 978-3-319-08587-6},
	url = {http://link.springer.com/10.1007/978-3-319-08587-6_13},
	abstract = {AProVE is a system for automatic termination and complexity proofs of Java, C, Haskell, Prolog, and term rewrite systems (TRSs). To analyze programs in high-level languages, AProVE automatically converts them to TRSs. Then, a wide range of techniques is employed to prove termination and to infer complexity bounds for the resulting TRSs. The generated proofs can be exported to check their correctness using automatic certiﬁers. For use in software construction, we present an AProVE plug-in for the popular Eclipse software development environment.},
	urldate = {2018-03-13},
	booktitle = {Automated {Reasoning}},
	publisher = {Springer International Publishing},
	author = {Giesl, Jürgen and Brockschmidt, Marc and Emmes, Fabian and Frohn, Florian and Fuhs, Carsten and Otto, Carsten and Plücker, Martin and Schneider-Kamp, Peter and Ströder, Thomas and Swiderski, Stephanie and Thiemann, René},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Demri, Stéphane and Kapur, Deepak and Weidenbach, Christoph},
	year = {2014},
	doi = {10.1007/978-3-319-08587-6_13},
	pages = {184--191},
	file = {Giesl et al_2014_Proving Termination of Programs Automatically with AProVE.pdf:/home/michael/Dropbox/zotero-pdfs/G/Giesl et al_2014_Proving Termination of Programs Automatically with AProVE.pdf:application/pdf}
}

@incollection{goos_using_1999,
	address = {Berlin, Heidelberg},
	title = {Using {Model} {Checking} to {Generate} {Tests} from {Requirements} {Specifications}},
	volume = {1687},
	isbn = {978-3-540-66538-0 978-3-540-48166-9},
	url = {http://link.springer.com/10.1007/3-540-48166-4_10},
	abstract = {Recently, many formal methods, such as the SCR (Software Cost Reduction) requirements method, have been proposed for improving the quality of software speciﬁcations. Although improved speciﬁcations are valuable, the ultimate objective of software development is to produce software that satisﬁes its requirements. To evaluate the correctness of a software implementation, one can apply black-box testing to determine whether the implementation, given a sequence of system inputs, produces the correct system outputs. This paper describes a speciﬁcation-based method for constructing a suite of test sequences, where a test sequence is a sequence of inputs and outputs for testing a software implementation. The test sequences are derived from a tabular SCR requirements speciﬁcation containing diverse data types, i.e., integer, boolean, and enumerated types. From the functions deﬁned in the SCR speciﬁcation, the method forms a collection of predicates called branches, which “cover” all possible software behaviors described by the speciﬁcation. Based on these predicates, the method then derives a suite of test sequences by using a model checker’s ability to construct counterexamples. The paper presents the results of applying our method to four speciﬁcations, including a sizable component of a contractor speciﬁcation of a real system.},
	urldate = {2018-03-13},
	booktitle = {Software {Engineering} — {ESEC}/{FSE} ’99},
	publisher = {Springer Berlin Heidelberg},
	author = {Gargantini, Angelo and Heitmeyer, Constance},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Nierstrasz, Oscar and Lemoine, Michel},
	year = {1999},
	doi = {10.1007/3-540-48166-4_10},
	pages = {146--162},
	file = {Gargantini_Heitmeyer_1999_Using Model Checking to Generate Tests from Requirements Specifications.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gargantini_Heitmeyer_1999_Using Model Checking to Generate Tests from Requirements Specifications.pdf:application/pdf}
}

@article{biagioni_information_nodate,
	title = {{INFORMATION} {AND} {COMPUTER} {SCIENCES} {AUGUST} 1999},
	author = {Biagioni, Edoardo S and Peterson, W Wesley and Chin, David N},
	pages = {54},
	file = {Biagioni et al_INFORMATION AND COMPUTER SCIENCES AUGUST 1999.pdf:/home/michael/Dropbox/zotero-pdfs/B/Biagioni et al_INFORMATION AND COMPUTER SCIENCES AUGUST 1999.pdf:application/pdf}
}

@article{ford_microkernels_1996-1,
	title = {Microkernels meet recursive virtual machines},
	volume = {30},
	issn = {01635980},
	url = {http://portal.acm.org/citation.cfm?doid=248155.238769},
	doi = {10.1145/248155.238769},
	abstract = {This paper describes a novel approach to providing modular and extensible operating system functionality and encapsulated environments based on a synthesis of microkernel and virtual machine concepts. We have developed a software-based virtualizable architecture called Fluke that allows recursive virtual machines (virtual machines running on other virtual machines) to be implemented efﬁciently by a microkernel running on generic hardware. A complete virtual machine interface is provided at each level; efﬁciency derives from needing to implement only new functionality at each level. This infrastructure allows common OS functionality, such as process management, demand paging, fault tolerance, and debugging support, to be provided by cleanly modularized, independent, stackable virtual machine monitors, implemented as user processes. It can also provide uncommon or unique OS features, including the above features specialized for particular applications’ needs, virtual machines transparently distributed cross-node, or security monitors that allow arbitrary untrusted binaries to be executed safely. Our prototype implementation of this model indicates that it is practical to modularize operating systems this way. Some types of virtual machine layers impose almost no overhead at all, while others impose some overhead (typically 0–35\%), but only on certain classes of applications.},
	language = {en},
	number = {SI},
	urldate = {2018-03-13},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Ford, Bryan and Hibler, Mike and Lepreau, Jay and Tullmann, Patrick and Back, Godmar and Clawson, Stephen},
	month = oct,
	year = {1996},
	pages = {137--151},
	file = {Ford et al_1996_Microkernels meet recursive virtual machines.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ford et al_1996_Microkernels meet recursive virtual machines.pdf:application/pdf}
}

@article{ford_interface_nodate,
	title = {Interface and {Execution} {Models} in the {Fluke} {Kernel}},
	abstract = {We have deﬁned and implemented a kernel API that makes every exported operation fully interruptible and restartable, thereby appearing atomic to the user. To achieve interruptibility, all possible kernel states in which a thread may become blocked for a “long” time are represented as kernel system calls, without requiring the kernel to retain any unexposable internal state.},
	author = {Ford, Bryan and Hibler, Mike and Lepreau, Jay and McGrath, Roland and Tullmann, Patrick},
	pages = {16},
	file = {Ford et al_Interface and Execution Models in the Fluke Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ford et al_Interface and Execution Models in the Fluke Kernel.pdf:application/pdf}
}

@article{fokker_abstract_2009,
	title = {Abstract {Interpretation} of {Functional} {Programs} using an {Attribute} {Grammar} {System}},
	volume = {238},
	issn = {15710661},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066109003983},
	doi = {10.1016/j.entcs.2009.09.044},
	abstract = {We describe an algorithm for abstract interpretation of an intermediate language in a Haskell compiler, itself also written in Haskell. It computes approximations of possible values for all variables in the program, which can be used for optimizing the object code. The analysis is done by collecting constraints on variables, which are then solved by ﬁxpoint iteration. The set of constraints grows while solving, as possible values of unknown functions become known. The constraints are collected by decorating the abstract syntax tree with an attribute grammar based preprocessor for Haskell. An introduction to this preprocessor is also given.},
	language = {en},
	number = {5},
	urldate = {2018-03-13},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Fokker, Jeroen and Swierstra, S. Doaitse},
	month = oct,
	year = {2009},
	pages = {117--133},
	file = {Fokker_Swierstra_2009_Abstract Interpretation of Functional Programs using an Attribute Grammar System.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fokker_Swierstra_2009_Abstract Interpretation of Functional Programs using an Attribute Grammar System.pdf:application/pdf}
}

@article{ferdinand_static_nodate,
	title = {Static {Memory} and {Timing} {Analysis} of {Embedded} {Systems} {Code}},
	abstract = {Failure of a safety-critical application on an embedded processor can lead to severe damage or even loss of life. Here we are concerned with two kinds of failure: stack overﬂow, which usually leads to runtime errors that are difﬁcult to diagnose, and failure to meet deadlines, which is catastrophic for systems with hard real-time characteristics. Classical validation methods like code review and testing with repeated measurements require a lot of effort, are expensive, and do not really help in proving the absence of such errors. AbsInt’s tools StackAnalyzer and aiT (timing analyzer) provide a solution to this problem. They use abstract interpretation as a formal method that allows to obtain statements valid for all program runs with all inputs.},
	author = {Ferdinand, Christian and Heckmann, Reinhold},
	pages = {11},
	file = {Ferdinand_Heckmann_Static Memory and Timing Analysis of Embedded Systems Code.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ferdinand_Heckmann_Static Memory and Timing Analysis of Embedded Systems Code.pdf:application/pdf}
}

@article{fenichel_lisp_1969,
	title = {A {LISP} garbage-collector for virtual-memory computer systems},
	volume = {12},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=363269.363280},
	doi = {10.1145/363269.363280},
	abstract = {In this paper a garbage-collection algorithm for list-processing systems which operate within very large virtual memo, ies is described. The object of the algorithm is more the compaction of active storage than the discovery of free storage. Because free storage is never really exhausted, the decision to garbage collect is not easily made; therefore, various criteria of this decision are discussed.},
	number = {11},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Fenichel, Robert R. and Yochelson, Jerome C.},
	month = nov,
	year = {1969},
	pages = {611--612},
	file = {Fenichel_Yochelson_1969_A LISP garbage-collector for virtual-memory computer systems.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fenichel_Yochelson_1969_A LISP garbage-collector for virtual-memory computer systems.pdf:application/pdf}
}

@article{felleisen_revised_1992,
	title = {The revised report on the syntactic theories of sequential control and state},
	volume = {103},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0304397592900147},
	doi = {10.1016/0304-3975(92)90014-7},
	abstract = {The syntactic theories of control and state are conservative extensions of the λv-calculus for equational reasoning about imperative programming facilities in higher-order languages. Unlike the simple λv-calculus, the extended theories are mixtures of equivalence relations and compatible congruence relations on the term language, which signiﬁcantly complicates the reasoning process. In this paper we develop fully compatible equational theories of the same imperative higher-order programming languages. The new theories subsume the original calculi of control and state and satisfy the usual Church-Rosser and Standardization Theorems. With the new calculi, equational reasoning about imperative programs becomes as simple as reasoning about functional programs.},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {Theoretical Computer Science},
	author = {Felleisen, Matthias and Hieb, Robert},
	month = sep,
	year = {1992},
	pages = {235--271},
	file = {Felleisen_Hieb_1992_The revised report on the syntactic theories of sequential control and state.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felleisen_Hieb_1992_The revised report on the syntactic theories of sequential control and state2.pdf:application/pdf}
}

@incollection{goos_expressive_1990,
	address = {Berlin, Heidelberg},
	title = {On the expressive power of programming languages},
	volume = {432},
	isbn = {978-3-540-52592-9 978-3-540-47045-8},
	url = {http://link.springer.com/10.1007/3-540-52592-0_60},
	abstract = {The literature on programming languages contains an abundance of informal claims on the relative expressive power of programming languages, but there is no framework for formalizing such statements nor for deriving interesting consequences. As a rst step in this direction, we develop a formal notion of expressiveness and investigate its properties. To validate the theory, we analyze some widely held beliefs about the expressive power of several extensions of functional languages. Based on these results, we believe that our system correctly captures many of the informal ideas on expressiveness, and that it constitutes a foundation for further research in this direction.},
	urldate = {2018-03-13},
	booktitle = {{ESOP} '90},
	publisher = {Springer Berlin Heidelberg},
	author = {Felleisen, Matthias},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Jones, Neil},
	year = {1990},
	doi = {10.1007/3-540-52592-0_60},
	pages = {134--151},
	file = {Felleisen_1990_On the expressive power of programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felleisen_1990_On the expressive power of programming languages.pdf:application/pdf}
}

@article{feiertag_foundations_nodate,
	title = {The foundations of a provably secure operating system ({PSOS})},
	author = {Feiertag, Richard J and Neumann, Peter G},
	pages = {9},
	file = {Feiertag_Neumann_The foundations of a provably secure operating system (PSOS).pdf:/home/michael/Dropbox/zotero-pdfs/F/Feiertag_Neumann_The foundations of a provably secure operating system (PSOS).pdf:application/pdf}
}

@incollection{goos_sharing_2001,
	address = {Berlin, Heidelberg},
	title = {Sharing in {Typed} {Module} {Assembly} {Language}},
	volume = {2071},
	isbn = {978-3-540-42196-2 978-3-540-45332-1},
	url = {http://link.springer.com/10.1007/3-540-45332-6_4},
	abstract = {There is a growing need to provide low-overhead software-based protection mechanisms to protect against malicious or untrusted code. Type-based approaches such as proof-carrying code and typed assembly language provide this protection by relying on untrusted compilers to certify the safety properties of machine language programs. Typed Module Assembly Language (TMAL) is an extension of typed assembly language with support for the type-safe manipulation of dynamically linked libraries. A particularly important aspect of TMAL is its support for shared libraries.},
	urldate = {2018-03-13},
	booktitle = {Types in {Compilation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Duggan, Dominic},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Harper, Robert},
	year = {2001},
	doi = {10.1007/3-540-45332-6_4},
	pages = {85--116},
	file = {Duggan_2001_Sharing in Typed Module Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/D/Duggan_2001_Sharing in Typed Module Assembly Language.pdf:application/pdf}
}

@article{duan_correctness_nodate,
	title = {Correctness {Proofs} for {Device} {Drivers} in {Embedded} {Systems}},
	abstract = {Computer systems do not exist in isolation: they must interact with the world through I/O devices. Our work, which focuses on constrained embedded systems, provides a framework for verifying device driver software at the machine code level. We created an abstract device model that can be plugged into an existing formal semantics for an instruction set architecture. We have instantiated the abstract model with a model for the serial port for a real embedded processor, and we have veriﬁed the full functional correctness of the transmit and receive functions from an open-source driver for this device.},
	author = {Duan, Jianjun and Regehr, John},
	pages = {9},
	file = {Duan_Regehr_Correctness Proofs for Device Drivers in Embedded Systems.pdf:/home/michael/Dropbox/zotero-pdfs/D/Duan_Regehr_Correctness Proofs for Device Drivers in Embedded Systems.pdf:application/pdf}
}

@incollection{goos_proving_2003,
	address = {Berlin, Heidelberg},
	title = {Proving {Make} {Correct}: {I}/{O} {Proofs} in {Haskell} and {Clean}},
	volume = {2670},
	isbn = {978-3-540-40190-2 978-3-540-44854-9},
	shorttitle = {Proving {Make} {Correct}},
	url = {http://link.springer.com/10.1007/3-540-44854-3_5},
	abstract = {This paper discusses reasoning about I/O operations in the languages Haskell and Clean and makes some observations about proving properties of programs which perform signiﬁcant I/O. We developed a model of the I/O system and produced some techniques to reason about the behaviour of programs run in the model. We then used those techniques to prove some properties of a program based on the standard make tool. We consider the I/O systems of both languages from a program proving perspective, and note some similarities in the overall structure of the proofs. A set of operators for assisting in the reasoning process are deﬁned, and we then draw some conclusions concerning reasoning about the eﬀect of functional programs on the outside world, give some suggestions for techniques and discuss future work.},
	urldate = {2018-03-13},
	booktitle = {Implementation of {Functional} {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dowse, Malcolm and Strong, Glenn and Butterfield, Andrew},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Peña, Ricardo and Arts, Thomas},
	year = {2003},
	doi = {10.1007/3-540-44854-3_5},
	pages = {68--83},
	file = {Dowse et al_2003_Proving Make Correct - I-O Proofs in Haskell and Clean.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dowse et al_2003_Proving Make Correct - I-O Proofs in Haskell and Clean.pdf:application/pdf}
}

@article{donahue_data_1985,
	title = {Data types are values},
	volume = {7},
	issn = {01640925},
	url = {http://portal.acm.org/citation.cfm?doid=3916.3987},
	doi = {10.1145/3916.3987},
	number = {3},
	urldate = {2018-03-13},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Donahue, James and Demers, Alan},
	month = jul,
	year = {1985},
	pages = {426--445},
	file = {Donahue_Demers_1985_Data types are values.pdf:/home/michael/Dropbox/zotero-pdfs/D/Donahue_Demers_1985_Data types are values.pdf:application/pdf}
}

@article{peyton_jones_how_1993,
	title = {How to give a good research talk},
	volume = {28},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=165564.903972},
	doi = {10.1145/165564.903972},
	language = {en},
	number = {11},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Peyton Jones, Simon L. and Hughes, John and Launchbury, John},
	month = nov,
	year = {1993},
	pages = {9--12},
	file = {Peyton Jones et al_1993_How to give a good research talk.pdf:/home/michael/Dropbox/zotero-pdfs/P/Peyton Jones et al_1993_How to give a good research talk.pdf:application/pdf}
}

@incollection{horowitz_hints_1983,
	address = {Berlin, Heidelberg},
	title = {Hints on {Programming} {Language} {Design}},
	isbn = {978-3-662-09509-6 978-3-662-09507-2},
	url = {http://link.springer.com/10.1007/978-3-662-09507-2_3},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hoare, C. A. R.},
	editor = {Horowitz, Ellis},
	year = {1983},
	doi = {10.1007/978-3-662-09507-2_3},
	pages = {31--40},
	file = {Hoare_1983_Hints on Programming Language Design.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1983_Hints on Programming Language Design.pdf:application/pdf}
}

@article{hieb_continuations_1990,
	title = {Continuations and concurrency},
	volume = {25},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=99164.99178},
	doi = {10.1145/99164.99178},
	language = {en},
	number = {3},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Hieb, R. and Dybvig, R. Kent},
	month = mar,
	year = {1990},
	pages = {128--136},
	file = {Hieb_Dybvig_1990_Continuations and concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hieb_Dybvig_1990_Continuations and concurrency.pdf:application/pdf}
}

@article{hicks_performance_nodate,
	title = {Performance {Studies} of {Id} on the {Monsoon} {Data} ow {System}},
	abstract = {In this paper, we examine the performance of Id, an implicitly parallel language, on Monsoon, an experimental data ow machine. One of the precepts of our work is that the Id run-time system and compiled Id programs should run on any number of Monsoon processors without change. Our experiments running Id programs on Monsoon show that speedups of more than seven are easily achieved on eight processors for most of the applications that we studied. We explain the sources of overhead that limit the speedup of each of our benchmark programs.},
	author = {Hicks, James and Chiou, Derek and Ang, Boon Seong},
	pages = {54},
	file = {Hicks et al_Performance Studies of Id on the Monsoon Data ow System.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hicks et al_Performance Studies of Id on the Monsoon Data ow System.pdf:application/pdf}
}

@incollection{goos_control-flow_1995,
	address = {Berlin, Heidelberg},
	title = {Control-flow analysis and type systems},
	volume = {983},
	isbn = {978-3-540-60360-3 978-3-540-45050-4},
	url = {http://link.springer.com/10.1007/3-540-60360-3_40},
	abstract = {We establish a series of equivalences between type systems and control- ow analyses. Speci cally, we take four type systems from the literature (involving simple types, subtypes and recursion) and conservatively extend them to reason about control- ow information. Similarly, we take four standard control- ow systems and conservatively extend them to reason about type consistency. Our main result is that we can match up the resulting type and control- ow systems such that we obtain pairs of equivalent systems, where the equivalence is with respect to both type and control- ow information. In essence, type systems and control- ow analysis can be viewed as complementary approaches for addressing questions of type consistency and control- ow.},
	urldate = {2018-03-13},
	booktitle = {Static {Analysis}},
	publisher = {Springer Berlin Heidelberg},
	author = {Heintze, Nevin},
	editor = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan and Mycroft, Alan},
	year = {1995},
	doi = {10.1007/3-540-60360-3_40},
	pages = {189--206},
	file = {Heintze_1995_Control-flow analysis and type systems.pdf:/home/michael/Dropbox/zotero-pdfs/H/Heintze_1995_Control-flow analysis and type systems.pdf:application/pdf}
}

@article{haynes_obtaining_1986,
	title = {Obtaining coroutines with continuations},
	volume = {11},
	issn = {00960551},
	url = {http://linkinghub.elsevier.com/retrieve/pii/009605518690007X},
	doi = {10.1016/0096-0551(86)90007-X},
	language = {en},
	number = {3-4},
	urldate = {2018-03-13},
	journal = {Computer Languages},
	author = {Haynes, Christopher T. and Friedman, Daniel P. and Wand, Mitchell},
	month = jan,
	year = {1986},
	pages = {143--153},
	file = {Haynes et al_1986_Obtaining coroutines with continuations.pdf:/home/michael/Dropbox/zotero-pdfs/H/Haynes et al_1986_Obtaining coroutines with continuations.pdf:application/pdf}
}

@incollection{goos_logic_1986,
	address = {Berlin, Heidelberg},
	title = {Logic continuations},
	volume = {225},
	isbn = {978-3-540-16492-0 978-3-540-39831-8},
	url = {http://link.springer.com/10.1007/3-540-16492-8_117},
	urldate = {2018-03-13},
	booktitle = {Third {International} {Conference} on {Logic} {Programming}},
	publisher = {Springer Berlin Heidelberg},
	author = {Haynes, Christopher T.},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Shapiro, Ehud},
	year = {1986},
	doi = {10.1007/3-540-16492-8_117},
	pages = {671--685},
	file = {Haynes_1986_Logic continuations.pdf:/home/michael/Dropbox/zotero-pdfs/H/Haynes_1986_Logic continuations.pdf:application/pdf}
}

@article{hawblitzel_automated_2009,
	title = {Automated verification of practical garbage collectors},
	volume = {44},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=1594834.1480935},
	doi = {10.1145/1594834.1480935},
	abstract = {Garbage collectors are notoriously hard to verify, due to their lowlevel interaction with the underlying system and the general difﬁculty in reasoning about reachability in graphs. Several papers have presented veriﬁed collectors, but either the proofs were handwritten or the collectors were too simplistic to use on practical applications. In this work, we present two mechanically veriﬁed garbage collectors, both practical enough to use for real-world C\# benchmarks. The collectors and their associated allocators consist of x86 assembly language instructions and macro instructions, annotated with preconditions, postconditions, invariants, and assertions. We used the Boogie veriﬁcation generator and the Z3 automated theorem prover to verify this assembly language code mechanically. We provide measurements comparing the performance of the veriﬁed collector with that of the standard Bartok collectors on off-the-shelf C\# benchmarks, demonstrating their competitiveness.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Hawblitzel, Chris and Petrank, Erez},
	month = jan,
	year = {2009},
	pages = {441},
	file = {Hawblitzel_Petrank_2009_Automated verification of practical garbage collectors.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hawblitzel_Petrank_2009_Automated verification of practical garbage collectors.pdf:application/pdf}
}

@incollection{hutchison_widening_2014,
	address = {Berlin, Heidelberg},
	title = {Widening for {Control}-{Flow}},
	volume = {8318},
	isbn = {978-3-642-54012-7 978-3-642-54013-4},
	url = {http://link.springer.com/10.1007/978-3-642-54013-4_26},
	abstract = {We present a parameterized widening operator that determines the control-ﬂow sensitivity of an analysis, i.e., its ﬂow-sensitivity, context-sensitivity, and path-sensitivity. By instantiating the operator’s parameter in diﬀerent ways, the analysis can be tuned to arbitrary sensitivities without changing the abstract semantics of the analysis itself. Similarly, the analysis can be implemented so that its sensitivity can be tuned without changing the analysis implementation. Thus, the sensitivity is an independent concern, allowing the analysis designer to design and implement the analysis without worrying about its sensitivity and then easily experiment with diﬀerent sensitivities after the fact. Additionally, we show that the space of control-ﬂow sensitivities induced by this widening operator forms a lattice. The lattice meet and join operators are the product and sum of sensitivities, respectively. They can be used to automatically create new sensitivities from existing ones without manual eﬀort. The sum operation in particular is a novel construction, which creates a new sensitivity less precise than either of its operands but containing elements of both.},
	urldate = {2018-03-13},
	booktitle = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hardekopf, Ben and Wiedermann, Ben and Churchill, Berkeley and Kashyap, Vineeth},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and McMillan, Kenneth L. and Rival, Xavier},
	year = {2014},
	doi = {10.1007/978-3-642-54013-4_26},
	pages = {472--491},
	file = {Hardekopf et al_2014_Widening for Control-Flow.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hardekopf et al_2014_Widening for Control-Flow.pdf:application/pdf}
}

@inproceedings{hardekopf_flow-sensitive_2011,
	title = {Flow-sensitive pointer analysis for millions of lines of code},
	isbn = {978-1-61284-356-8},
	url = {http://ieeexplore.ieee.org/document/5764696/},
	doi = {10.1109/CGO.2011.5764696},
	abstract = {Many program analyses beneﬁt, both in precision and performance, from precise pointer analysis. An important dimension of pointer analysis precision is ﬂow-sensitivity, which has been shown to be useful for applications such as program veriﬁcation and static analysis of binary code, among many others. However, ﬂow-sensitive pointer analysis has historically been unable to scale to programs with millions of lines of code. We present a new ﬂow-sensitive pointer analysis algorithm that is an order of magnitude faster than the existing state of the art, enabling for the ﬁrst time ﬂow-sensitive pointer analysis for programs with millions of lines of code. Our ﬂow-sensitive algorithm is based on a sparse representation of program code created by a staged, ﬂow-insensitive pointer analysis. We explain how this new algorithm is a member of a new family of pointer analysis algorithms that deserves further study.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Hardekopf, Ben and Lin, Calvin},
	month = apr,
	year = {2011},
	pages = {289--298},
	file = {Hardekopf_Lin_2011_Flow-sensitive pointer analysis for millions of lines of code.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hardekopf_Lin_2011_Flow-sensitive pointer analysis for millions of lines of code.pdf:application/pdf}
}

@article{hardekopf_semi-sparse_2009,
	title = {Semi-sparse flow-sensitive pointer analysis},
	volume = {44},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=1594834.1480911},
	doi = {10.1145/1594834.1480911},
	abstract = {Pointer analysis is a prerequisite for many program analyses, and the effectiveness of these analyses depends on the precision of the pointer information they receive. Two major axes of pointer analysis precision are ﬂow-sensitivity and context-sensitivity, and while there has been signiﬁcant recent progress regarding scalable context-sensitive pointer analysis, relatively little progress has been made in improving the scalability of ﬂow-sensitive pointer analysis. This paper presents a new interprocedural, ﬂow-sensitive pointer analysis algorithm that combines two ideas—semi-sparse analysis and a novel use of BDDs—that arise from a careful understanding of the unique challenges that face ﬂow-sensitive pointer analysis. We evaluate our algorithm on 12 C benchmarks ranging from 11K to 474K lines of code. Our fastest algorithm is on average 197× faster and uses 4.6× less memory than the state of the art, and it can analyze programs that are an order of magnitude larger than the previous state of the art.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Hardekopf, Ben and Lin, Calvin},
	month = jan,
	year = {2009},
	pages = {226},
	file = {Hardekopf_Lin_2009_Semi-sparse flow-sensitive pointer analysis.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hardekopf_Lin_2009_Semi-sparse flow-sensitive pointer analysis.pdf:application/pdf}
}

@incollection{murphy_actors_2007,
	address = {Berlin, Heidelberg},
	title = {Actors {That} {Unify} {Threads} and {Events}},
	volume = {4467},
	isbn = {978-3-540-72793-4},
	url = {http://link.springer.com/10.1007/978-3-540-72794-1_10},
	abstract = {There is an impedance mismatch between message-passing concurrency and virtual machines, such as the JVM. VMs usually map their threads to heavyweight OS processes. Without a lightweight process abstraction, users are often forced to write parts of concurrent applications in an event-driven style which obscures control ﬂow, and increases the burden on the programmer.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Coordination {Models} and {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Haller, Philipp and Odersky, Martin},
	editor = {Murphy, Amy L. and Vitek, Jan},
	year = {2007},
	doi = {10.1007/978-3-540-72794-1_10},
	pages = {171--190},
	file = {Haller_Odersky_2007_Actors That Unify Threads and Events.pdf:/home/michael/Dropbox/zotero-pdfs/H/Haller_Odersky_2007_Actors That Unify Threads and Events.pdf:application/pdf}
}

@inproceedings{bocic_inductive_2014,
	title = {Inductive verification of data model invariants for web applications},
	isbn = {978-1-4503-2756-5},
	url = {http://dl.acm.org/citation.cfm?doid=2568225.2568281},
	doi = {10.1145/2568225.2568281},
	abstract = {Modern software applications store their data in remote cloud servers. Users interact with these applications using web browsers or thin clients running on mobile devices. A key issue in dependability of these applications is the correctness of the actions that update the data store, which are triggered by user requests. In this paper, we present techniques for automatically checking if the actions of an application preserve the data model invariants. Our approach ﬁrst automatically extracts a data model speciﬁcation, which we call an abstract data store, from a given application using instrumented execution. The abstract data store identiﬁes the sets of objects and relations (associations) used by the application, and the actions that update the data store by deleting or creating objects or by changing the relations among the objects. We show that checking invariants of an abstract data store corresponds to inductive invariant veriﬁcation, and can be done using a mapping to First Order Logic (FOL) and using a FOL theorem prover. We implemented this approach for the Rails framework and applied it to three open source applications. We found four previously unknown bugs and reported them to the developers, who conﬁrmed and immediately ﬁxed two of them.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Bocić, Ivan and Bultan, Tevfik},
	year = {2014},
	pages = {620--631},
	file = {Bocic_Bultan_2014_Inductive verification of data model invariants for web applications.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bocic_Bultan_2014_Inductive verification of data model invariants for web applications.pdf:application/pdf}
}

@article{hutton_monadic_1998,
	title = {Monadic parsing in {Haskell}},
	volume = {8},
	issn = {09567968},
	url = {http://www.journals.cambridge.org/abstract_S0956796898003050},
	doi = {10.1017/S0956796898003050},
	number = {4},
	urldate = {2018-03-13},
	journal = {Journal of Functional Programming},
	author = {Hutton, Graham and Meijer, Erik},
	month = jul,
	year = {1998},
	pages = {437--444},
	file = {Hutton_Meijer_1998_Monadic parsing in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hutton_Meijer_1998_Monadic parsing in Haskell.pdf:application/pdf}
}

@article{hughes_why_1989,
	title = {Why {Functional} {Programming} {Matters}},
	volume = {32},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/32.2.98},
	doi = {10.1093/comjnl/32.2.98},
	abstract = {As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write and to debug, and provides a collection of modules that can be reused to reduce future programming costs. In this paper we show that two features of functional languages in particular, higher-order functions and lazy evaluation, can contribute signiﬁcantly to modularity. As examples, we manipulate lists and trees, program several numerical algorithms, and implement the alpha-beta heuristic (an algorithm from Artiﬁcial Intelligence used in game-playing programs). We conclude that since modularity is the key to successful programming, functional programming oﬀers important advantages for software development.},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {The Computer Journal},
	author = {Hughes, J.},
	month = feb,
	year = {1989},
	pages = {98--107},
	file = {Hughes_1989_Why Functional Programming Matters.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hughes_1989_Why Functional Programming Matters.pdf:application/pdf}
}

@article{dantzig_generalized_1955,
	title = {The generalized simplex method for minimizing a linear form under linear inequality restraints},
	volume = {5},
	issn = {0030-8730, 0030-8730},
	url = {http://msp.org/pjm/1955/5-2/p04.xhtml},
	doi = {10.2140/pjm.1955.5.183},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {Pacific Journal of Mathematics},
	author = {Dantzig, George and Orden, Alexander and Wolfe, Philip},
	month = jun,
	year = {1955},
	pages = {183--195},
	file = {Dantzig et al_1955_The generalized simplex method for minimizing a linear form under linear.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dantzig et al_1955_The generalized simplex method for minimizing a linear form under linear.pdf:application/pdf}
}

@article{lo_tutorial_nodate,
	title = {A tutorial implementation of a dependently typed lambda calculus},
	abstract = {We present the type rules for a dependently typed core calculus together with a straightforward implementation in Haskell. We explicitly highlight the changes necessary to shift from a simply-typed lambda calculus to the dependently typed lambda calculus. We also describe how to extend our core language with data types and write several small example programs. The article is accompanied by an executable interpreter and example code that allows immediate experimentation with the system we describe.},
	author = {Lo, Andres and McBride, Conor and Swierstra, Wouter},
	pages = {31},
	file = {Lo et al_A tutorial implementation of a dependently typed lambda calculus.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lo et al_A tutorial implementation of a dependently typed lambda calculus.pdf:application/pdf}
}

@article{lo_implementation_nodate,
	title = {An {Implementation} of a {Dependently} {Typed} {Lambda} {Calculus}},
	abstract = {We present an implementation in Haskell of a dependently-typed lambda calculus that can be used as the core of a programming language. We show that a dependently-typed lambda calculus is no more difﬁcult to implement than other typed lambda calculi. In fact, our implementation is almost as easy as an implementation of the simply typed lambda calculus, which we emphasize by discussing the modiﬁcations necessary to go from one to the other. We explain how to add data types and write simple programs in the core language, and discuss the steps necessary to build a full-ﬂedged programming language on top of our simple core.},
	author = {Lo, Andres and Swierstra, Conor McBride Wouter},
	pages = {12},
	file = {Lo_Swierstra_An Implementation of a Dependently Typed Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lo_Swierstra_An Implementation of a Dependently Typed Lambda Calculus.pdf:application/pdf}
}

@phdthesis{loh_exploring_2004,
	address = {S.l.},
	title = {Exploring generic {Haskell}},
	language = {English},
	school = {s.n.]},
	author = {Löh, Andres},
	year = {2004},
	note = {OCLC: 66608527},
	file = {Loh_2004_Exploring generic Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/L/Loh_2004_Exploring generic Haskell.pdf:application/pdf}
}

@incollection{horowitz_abstraction_1983,
	address = {Berlin, Heidelberg},
	title = {Abstraction {Mechanisms} in {CLU}},
	isbn = {978-3-662-09509-6 978-3-662-09507-2},
	url = {http://link.springer.com/10.1007/978-3-662-09507-2_14},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Liskov, B. and Snyder, A. and Atkinson, R. and Schaffert, C.},
	editor = {Horowitz, Ellis},
	year = {1983},
	doi = {10.1007/978-3-662-09507-2_14},
	pages = {226--238},
	file = {Liskov et al_1983_Abstraction Mechanisms in CLU.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liskov et al_1983_Abstraction Mechanisms in CLU.pdf:application/pdf}
}

@article{plotkin_structural_nodate,
	title = {A {Structural} {Approach} to {Operational} {Semantics}},
	author = {Plotkin, Gordon D},
	pages = {134},
	file = {Plotkin_A Structural Approach to Operational Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_A Structural Approach to Operational Semantics.pdf:application/pdf}
}

@article{leroy_develop_nodate,
	title = {Develop eﬃcient execution models.},
	author = {Leroy, X},
	pages = {23},
	file = {Leroy_Develop eﬃcient execution models.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leroy_Develop eﬃcient execution models.pdf:application/pdf}
}

@article{kong_emacs_nodate,
	title = {emacs mode for {Lean} {Theorem} {Prover}},
	author = {Kong, Soonho},
	pages = {22},
	file = {Kong_emacs mode for Lean Theorem Prover.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kong_emacs mode for Lean Theorem Prover.pdf:application/pdf}
}

@article{nichols_abstract_nodate,
	title = {Abstract {Interpretation} and {Information} {Flow} {On} the {Go}},
	author = {Nichols, Lawton and Hardekopf, Ben and Sherwood, Tevﬁk Bultan Tim},
	pages = {241},
	file = {Nichols et al_Abstract Interpretation and Information Flow On the Go.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nichols et al_Abstract Interpretation and Information Flow On the Go.pdf:application/pdf}
}

@article{landin_next_nodate,
	title = {The {Next} 700 {Programming} {Languages}},
	abstract = {ISWlM, and providing certain basic grammatical categories in terms of which all of Isw1{\textasciitilde}'s more numerous categories can be expressed.},
	journal = {Communications of the ACM},
	author = {Landin, P J},
	pages = {10},
	file = {Landin_The Next 700 Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/L/Landin_The Next 700 Programming Languages.pdf:application/pdf}
}

@article{lamport_interprocess_1985,
	title = {On {Interprocess} {Communication}},
	author = {Lamport, Leslie},
	year = {1985},
	pages = {56},
	file = {Lamport_On Interprocess Communication.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lamport_On Interprocess Communication.pdf:application/pdf}
}

@article{labun_combinator_nodate,
	title = {Combinator {Parsing} in {Scala}},
	author = {Labun, Eugen},
	pages = {91},
	file = {Labun_Combinator Parsing in Scala.pdf:/home/michael/Dropbox/zotero-pdfs/L/Labun_Combinator Parsing in Scala.pdf:application/pdf}
}

@article{kneuper_symbolic_1991,
	title = {Symbolic execution: a semantic approach},
	volume = {16},
	issn = {01676423},
	shorttitle = {Symbolic execution},
	url = {http://linkinghub.elsevier.com/retrieve/pii/016764239190008L},
	doi = {10.1016/0167-6423(91)90008-L},
	abstract = {Kneuper, R., Symbolic execution: a semantic approach, Science of Computer Programming 16 (1991) 207-249. This paper discusses symbolic execution from a semantic point of view, covering both programs and specifications. It defines the denotational semantics of symbolic execution of specifications and programs, and thus introduces a notion of correctness of symbolic execution which applies not just to an individual language but to a wide class of languages, namely those whose semantics can be described in terms of states and state transformations. Also described are the operational semantics of a language as used for symbolic execution. This work also provided the basis of the prototype symbolic execution system SYMBEXwhich was developed at the University of Manchester as part of the mural project. However, this paper only covers the theoretical foundations used by SYMBEX, but not the system itseif.},
	language = {en},
	number = {3},
	urldate = {2018-03-13},
	journal = {Science of Computer Programming},
	author = {Kneuper, Ralf},
	month = oct,
	year = {1991},
	pages = {207--249},
	file = {Kneuper_1991_Symbolic execution - a semantic approach.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kneuper_1991_Symbolic execution - a semantic approach.pdf:application/pdf}
}

@incollection{goos_reduction_1987,
	address = {Berlin, Heidelberg},
	title = {Reduction, data flow and control flow models of computation},
	volume = {255},
	isbn = {978-3-540-17906-1 978-3-540-47926-0},
	url = {http://link.springer.com/10.1007/3-540-17906-2_35},
	urldate = {2018-03-13},
	booktitle = {Petri {Nets}: {Applications} and {Relationships} to {Other} {Models} of {Concurrency}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kluge, Werner},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Brauer, W. and Reisig, W. and Rozenberg, G.},
	year = {1987},
	doi = {10.1007/3-540-17906-2_35},
	pages = {466--498},
	file = {Kluge_1987_Reduction, data flow and control flow models of computation.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kluge_1987_Reduction, data flow and control flow models of computation.pdf:application/pdf}
}

@article{klein_provable_nodate,
	title = {Provable {Security}: {How} feasible is it?},
	abstract = {Strong, machine-checked security proofs of operating systems have been in the too hard basket long enough. They will still be too hard for large mainstream operating systems, but even for systems designed from the ground up for security they have been counted as infeasible. There are high-level formal models, nice security properties, ways of architecting and engineering secure systems, but no implementation level proofs yet, not even with the recent veriﬁcation of the seL4 microkernel.},
	author = {Klein, Gerwin and Murray, Toby and Gammie, Peter and Sewell, Thomas and Winwood, Simon},
	pages = {5},
	file = {Klein et al_Provable Security - How feasible is it.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_Provable Security - How feasible is it.pdf:application/pdf}
}

@article{klein_run_2012-1,
	title = {Run your research: on the effectiveness of lightweight mechanization},
	volume = {47},
	issn = {03621340},
	shorttitle = {Run your research},
	url = {http://dl.acm.org/citation.cfm?doid=2103621.2103691},
	doi = {10.1145/2103621.2103691},
	abstract = {Formal models serve in many roles in the programming language community. In its primary role, a model communicates the idea of a language design; the architecture of a language tool; or the essence of a program analysis. No matter which role it plays, however, a faulty model doesn’t serve its purpose.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Klein, Casey and Findler, Robert Bruce and Clements, John and Dimoulas, Christos and Eastlund, Carl and Felleisen, Matthias and Flatt, Matthew and McCarthy, Jay A. and Rafkind, Jon and Tobin-Hochstadt, Sam},
	month = jan,
	year = {2012},
	pages = {285},
	file = {Klein et al_2012_Run your research - on the effectiveness of lightweight mechanization.pdf:/home/michael/Dropbox/zotero-pdfs/K/Klein et al_2012_Run your research - on the effectiveness of lightweight mechanization.pdf:application/pdf}
}

@article{kleene_inconsistency_1935,
	title = {The {Inconsistency} of {Certain} {Formal} {Logics}},
	volume = {36},
	issn = {0003486X},
	url = {http://www.jstor.org/stable/1968646?origin=crossref},
	doi = {10.2307/1968646},
	number = {3},
	urldate = {2018-03-13},
	journal = {The Annals of Mathematics},
	author = {Kleene, S. C. and Rosser, J. B.},
	month = jul,
	year = {1935},
	pages = {630},
	file = {Kleene_Rosser_1935_The Inconsistency of Certain Formal Logics.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kleene_Rosser_1935_The Inconsistency of Certain Formal Logics.pdf:application/pdf}
}

@article{king_symbolic_1976,
	title = {Symbolic execution and program testing},
	volume = {19},
	issn = {00010782},
	url = {http://portal.acm.org/citation.cfm?doid=360248.360252},
	doi = {10.1145/360248.360252},
	number = {7},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {King, James C.},
	month = jul,
	year = {1976},
	pages = {385--394},
	file = {King_1976_Symbolic execution and program testing.pdf:/home/michael/Dropbox/zotero-pdfs/K/King_1976_Symbolic execution and program testing.pdf:application/pdf}
}

@incollection{goos_towards_1987,
	address = {Berlin, Heidelberg},
	title = {Towards a parallel architecture for functional languages},
	volume = {272},
	isbn = {978-3-540-18203-0 978-3-540-47806-5},
	url = {http://link.springer.com/10.1007/3-540-18203-9_7},
	urldate = {2018-03-13},
	booktitle = {Future {Parallel} {Computers}},
	publisher = {Springer Berlin Heidelberg},
	author = {Karia, Rj},
	editor = {Goos, G. and Hartmanis, J. and Barstow, D. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Luckham, D. and Moler, C. and Pnueli, A. and Seegmüller, G. and Stoer, J. and Wirth, N. and Treleaven, P. and Vanneschi, M.},
	year = {1987},
	doi = {10.1007/3-540-18203-9_7},
	pages = {270--285},
	file = {Karia_1987_Towards a parallel architecture for functional languages.pdf:/home/michael/Dropbox/zotero-pdfs/K/Karia_1987_Towards a parallel architecture for functional languages.pdf:application/pdf}
}

@article{jones_range_nodate,
	title = {A {RANGE} {OF} {OPERATING} {SYSTEMS}  {WRITTEN} {IN} {A}  {PURELY} {FUNCTIONAL} {STYLE}},
	author = {Jones, Simon B},
	pages = {49},
	file = {Jones_A RANGE OF OPERATING SYSTEMS WRITTEN IN A PURELY FUNCTIONAL STYLE.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_A RANGE OF OPERATING SYSTEMS WRITTEN IN A PURELY FUNCTIONAL STYLE.pdf:application/pdf}
}

@inproceedings{jacobsen_lightweight_2015,
	title = {Lightweight capability domains: towards decomposing the {Linux} kernel},
	isbn = {978-1-4503-3942-1},
	shorttitle = {Lightweight capability domains},
	url = {http://dl.acm.org/citation.cfm?doid=2818302.2818307},
	doi = {10.1145/2818302.2818307},
	abstract = {Despite a number of radical changes in how computer systems are used, the design principles behind the very core of the systems stack—an operating system kernel—has remained unchanged for decades. We run monolithic kernels developed with a combination of an unsafe programming language, global sharing of data structures, opaque interfaces, and no explicit knowledge of kernel protocols. Today, the monolithic architecture of a kernel is the main factor undermining its security, and even worse, limiting its evolution towards a safer, more secure environment. Lack of isolation across kernel subsystems allows attackers to take control over the entire machine with a single kernel vulnerability. Furthermore, complex, semantically rich monolithic code with globally shared data structures and no explicit interfaces is not amenable to formal analysis and veriﬁcation tools. Even after decades of work to make monolithic kernels more secure, over a hundred serious kernel vulnerabilities are still reported every year.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Jacobsen, Charles and Khole, Muktesh and Spall, Sarah and Bauer, Scotty and Burtsev, Anton},
	year = {2015},
	pages = {8--14},
	file = {Jacobsen et al_2015_Lightweight capability domains - towards decomposing the Linux kernel.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jacobsen et al_2015_Lightweight capability domains - towards decomposing the Linux kernel.pdf:application/pdf}
}

@article{pan_real-time_1985,
	title = {A {Real}-{Time} {QRS} {Detection} {Algorithm}},
	volume = {BME-32},
	issn = {0018-9294},
	url = {http://ieeexplore.ieee.org/document/4122029/},
	doi = {10.1109/TBME.1985.325532},
	abstract = {We have developed a real-time algorithm for detection of a derivative, and a moving window integrator. The nonlinear the QRS complexes of ECG signals. It reliably recognizes QRS complexes based upon digital analyses of slope, amplitude, and width. A special digital bandpass filter reduces false detections caused by the various types of interference present in ECG signals. This filtering permits use of low thresholds, thereby increasing detection sensitivity. The algorithm automatically adjusts thresholds and parameters periodically to transformation that we use is signal amplitude squaring.},
	number = {3},
	urldate = {2018-03-13},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Pan, Jiapu and Tompkins, Willis J.},
	month = mar,
	year = {1985},
	pages = {230--236},
	file = {Pan_Tompkins_1985_A Real-Time QRS Detection Algorithm.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pan_Tompkins_1985_A Real-Time QRS Detection Algorithm.pdf:application/pdf}
}

@article{palsberg_type_1997,
	title = {Type inference with non-structural subtyping},
	volume = {9},
	issn = {0934-5043, 1433-299X},
	url = {http://link.springer.com/10.1007/BF01212524},
	doi = {10.1007/BF01212524},
	abstract = {We present an O(n3) time type inference algorithm for a type system with a largest type , a smallest type ⊥, and the usual ordering between function types. The algorithm infers type annotations of least shape, and it works equally well for recursive types. For the problem of typability, our algorithm is simpler than the one of Kozen, Palsberg, and Schwartzbach for type inference without ⊥. This may be surprising, especially because the system with ⊥ is strictly more powerful.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {Formal Aspects of Computing},
	author = {Palsberg, Jens and Wand, Mitchell and O'Keefe, Patrick},
	month = jan,
	year = {1997},
	pages = {49--67},
	file = {Palsberg et al_1997_Type inference with non-structural subtyping.pdf:/home/michael/Dropbox/zotero-pdfs/P/Palsberg et al_1997_Type inference with non-structural subtyping.pdf:application/pdf}
}

@article{palsberg_safety_1992,
	title = {Safety analysis versus type inference for partial types},
	volume = {43},
	issn = {00200190},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0020019092901963},
	doi = {10.1016/0020-0190(92)90196-3},
	abstract = {Safety analysis is an algorithm for determining if a term in an untyped lambda calculus with constants is safe, i.e., if it does not cause an error during evaluation. We prove that safety analysis accepts strictly more safe lambda terms than does type inference for Thatte’s partial types.},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {Information Processing Letters},
	author = {Palsberg, Jens and Schwartzbach, Michael I.},
	month = sep,
	year = {1992},
	pages = {175--180},
	file = {Palsberg_Schwartzbach_1992_Safety analysis versus type inference for partial types.pdf:/home/michael/Dropbox/zotero-pdfs/P/Palsberg_Schwartzbach_1992_Safety analysis versus type inference for partial types.pdf:application/pdf}
}

@incollection{thiemann_functional_2016,
	address = {Berlin, Heidelberg},
	title = {Functional {Big}-{Step} {Semantics}},
	volume = {9632},
	isbn = {978-3-662-49497-4 978-3-662-49498-1},
	url = {http://link.springer.com/10.1007/978-3-662-49498-1_23},
	abstract = {When doing an interactive proof about a piece of software, it is important that the underlying programming language’s semantics does not make the proof unnecessarily diﬃcult or unwieldy. Both smallstep and big-step semantics are commonly used, and the latter is typically given by an inductively deﬁned relation. In this paper, we consider an alternative: using a recursive function akin to an interpreter for the language. The advantages include a better induction theorem, less duplication, accessibility to ordinary functional programmers, and the ease of doing symbolic simulation in proofs via rewriting. We believe that this style of semantics is well suited for compiler veriﬁcation, including proofs of divergence preservation. We do not claim the invention of this style of semantics: our contribution here is to clarify its value, and to explain how it supports several language features that might appear to require a relational or small-step approach. We illustrate the technique on a simple imperative language with C-like for-loops and a break statement, and compare it to a variety of other approaches. We also provide ML and lambda-calculus based examples to illustrate its generality.},
	urldate = {2018-03-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Owens, Scott and Myreen, Magnus O. and Kumar, Ramana and Tan, Yong Kiam},
	editor = {Thiemann, Peter},
	year = {2016},
	doi = {10.1007/978-3-662-49498-1_23},
	pages = {589--615},
	file = {Owens et al_2016_Functional Big-Step Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/O/Owens et al_2016_Functional Big-Step Semantics.pdf:application/pdf}
}

@book{acm_workshop_on_wireless_traffic_measurement_and_modeling_papers_2005,
	address = {Berkeley, Calif.},
	title = {Papers presented at the 2005 workshop on wireless traffic measurements and modeling: {Seattle}, {Washington}, {June} 5, 2005},
	isbn = {978-1-931971-33-1},
	shorttitle = {Papers presented at the 2005 workshop on wireless traffic measurements and modeling},
	language = {English},
	publisher = {USENIX Association},
	editor = {{ACM Workshop on Wireless Traffic Measurement and Modeling} and Papadopoulis, Maria and Papagiannaki, Dina and Papagiannaki, Konstantina and {USENIX Association} and {ACM SIGMOBILE} and {ACM Special Interest Group in Operating Systems} and {ACM Digital Library}},
	year = {2005},
	note = {OCLC: 437626779},
	file = {ACM Workshop on Wireless Traffic Measurement and Modeling et al_2005_Papers presented at the 2005 workshop on wireless traffic measurements and.pdf:/home/michael/Dropbox/zotero-pdfs/A/ACM Workshop on Wireless Traffic Measurement and Modeling et al_2005_Papers presented at the 2005 workshop on wireless traffic measurements and.pdf:application/pdf}
}

@article{okasaki_purely_nodate,
	title = {Purely {Functional} {Data} {Structures}},
	author = {Okasaki, Chris},
	pages = {162},
	file = {Okasaki_Purely Functional Data Structures.pdf:/home/michael/Dropbox/zotero-pdfs/O/Okasaki_Purely Functional Data Structures.pdf:application/pdf}
}

@inproceedings{norell_dependently_2008,
	title = {Dependently typed programming in {Agda}},
	isbn = {978-1-60558-420-1},
	url = {http://portal.acm.org/citation.cfm?doid=1481861.1481862},
	doi = {10.1145/1481861.1481862},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Norell, Ulf},
	year = {2008},
	pages = {1--2},
	file = {Norell_2008_Dependently typed programming in Agda.pdf:/home/michael/Dropbox/zotero-pdfs/N/Norell_2008_Dependently typed programming in Agda.pdf:application/pdf}
}

@book{nipkow_concrete_2014-1,
	address = {Cham},
	title = {Concrete {Semantics}},
	isbn = {978-3-319-10541-3 978-3-319-10542-0},
	url = {http://link.springer.com/10.1007/978-3-319-10542-0},
	language = {en},
	urldate = {2018-03-13},
	publisher = {Springer International Publishing},
	author = {Nipkow, Tobias and Klein, Gerwin},
	year = {2014},
	doi = {10.1007/978-3-319-10542-0},
	file = {Nipkow_Klein_2014_Concrete Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nipkow_Klein_2014_Concrete Semantics.pdf:application/pdf}
}

@inproceedings{nethercote_how_2007,
	title = {How to shadow every byte of memory used by a program},
	isbn = {978-1-59593-630-1},
	url = {http://portal.acm.org/citation.cfm?doid=1254810.1254820},
	doi = {10.1145/1254810.1254820},
	abstract = {Several existing dynamic binary analysis tools use shadow memory—they shadow, in software, every byte of memory used by a program with another value that says something about it. Shadow memory is difﬁcult to implement both efﬁciently and robustly. Nonetheless, existing shadow memory implementations have not been studied in detail. This is unfortunate, because shadow memory is powerful—for example, some of the existing tools that use it detect critical errors such as bad memory accesses, data races, and uses of uninitialised or untrusted data.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Nethercote, Nicholas and Seward, Julian},
	year = {2007},
	pages = {65},
	file = {Nethercote_Seward_2007_How to shadow every byte of memory used by a program.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nethercote_Seward_2007_How to shadow every byte of memory used by a program.pdf:application/pdf}
}

@inproceedings{mountjoy_spineless_1998,
	title = {The spineless tagless {G}-machine, naturally},
	isbn = {978-1-58113-024-9},
	url = {http://portal.acm.org/citation.cfm?doid=289423.289439},
	doi = {10.1145/289423.289439},
	abstract = {The application of natural semantic speciﬁcations of lazy evaluation to areas such as usage analysis, formal proﬁling and abstract machine construction has shown it to be a useful formalism. This paper introduces several variants and extensions of this speciﬁcation.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Mountjoy, Jon},
	year = {1998},
	pages = {163--173},
	file = {Mountjoy_1998_The spineless tagless G-machine, naturally.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mountjoy_1998_The spineless tagless G-machine, naturally.pdf:application/pdf}
}

@article{morris_lambda_1963,
	title = {Lambda {Calculus} {Models} of {Programs}},
	author = {Morris, James Hiram},
	month = dec,
	year = {1963},
	pages = {130},
	file = {MORRIS_B.S., Carnegie Institute of Technology.pdf:/home/michael/Dropbox/zotero-pdfs/M/MORRIS_B.S., Carnegie Institute of Technology.pdf:application/pdf}
}

@article{mitchell_coercion_nodate,
	title = {Coercion and {Type} {Inference} ({Summary})},
	abstract = {A sinlple semantic model of automatic coercion is proposed. This modcl is used to explain four nlles for inferring polymorphic types and providing automatic coercions between types. With the addition ofa fifth rule. the rules become semantically c',mq{\textasciitilde}lete but the set of types associated with an expression may be undecidable. An cMcient type chcckio.g algorithm based on the Ih'st Ibur rules is presented. The algorithm is guaranteed to find a type whenever a type can be dedttccd ,sing the four inference rules. "1he type checking algorithm may be modi!icd so that calls to type conversion ftmctions are inserted at COmlfile time.},
	author = {Mitchell, John C and Laboratories, Bell and Hill, Murray},
	pages = {11},
	file = {Mitchell et al_Coercion and Type Inference (Summary).pdf:/home/michael/Dropbox/zotero-pdfs/M/Mitchell et al_Coercion and Type Inference (Summary).pdf:application/pdf}
}

@article{mine_docteur_nodate,
	title = {{DOCTEUR} {DE} {L}’{E}´{COLE} {POLYTECHNIQUE} {EN} {INFORMATIQUE}},
	abstract = {The goal of this thesis is to design techniques related to the automatic analysis of computer programs. One major application is the creation of tools to discover bugs before they actually happen, an important goal in a time when critical yet complex tasks are performed by computers. We will work in the Abstract Interpretation framework, a theory of sound approximation of program semantics. We will focus, in particular, on numerical abstract domains that specialise in the automatic discovery of properties of the numerical variables of programs.},
	author = {MINE, Antoine},
	pages = {308},
	file = {MINE_DOCTEUR DE L’E´COLE POLYTECHNIQUE EN INFORMATIQUE.pdf:/home/michael/Dropbox/zotero-pdfs/M/MINE_DOCTEUR DE L’E´COLE POLYTECHNIQUE EN INFORMATIQUE.pdf:application/pdf}
}

@article{milner_calculus_1992,
	title = {A calculus of mobile processes, {II}},
	volume = {100},
	issn = {08905401},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0890540192900095},
	doi = {10.1016/0890-5401(92)90009-5},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {Information and Computation},
	author = {Milner, Robin and Parrow, Joachim and Walker, David},
	month = sep,
	year = {1992},
	pages = {41--77},
	file = {Milner et al_1992_A calculus of mobile processes, II.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner et al_1992_A calculus of mobile processes, II.pdf:application/pdf}
}

@article{milner_calculus_1992-1,
	title = {A calculus of mobile processes, {I}},
	volume = {100},
	issn = {08905401},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0890540192900084},
	doi = {10.1016/0890-5401(92)90008-4},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {Information and Computation},
	author = {Milner, Robin and Parrow, Joachim and Walker, David},
	month = sep,
	year = {1992},
	pages = {1--40},
	file = {Milner et al_1992_A calculus of mobile processes, I.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner et al_1992_A calculus of mobile processes, I.pdf:application/pdf}
}

@article{milner_polyadic_nodate,
	title = {The {Polyadic}  -{Calculus}: a {Tutorial}},
	abstract = {The  -calculus is a model of concurrent computation based upon the notion of naming. It is rst presented in its simplest and original form, with the help of several illustrative applications. Then it is generalized from monadic to polyadic form. Semantics is done in terms of both a reduction system and a version of labelled transitions called commitment; the known algebraic axiomatization of strong bisimilarity is given in the new setting, and so also is a characterization in modal logic. Some theorems about the replication operator are proved.},
	author = {Milner, Robin},
	pages = {50},
	file = {Milner_The Polyadic -Calculus - a Tutorial.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_The Polyadic -Calculus - a Tutorial.pdf:application/pdf}
}

@book{milner_calculus_1980,
	address = {Berlin},
	series = {Lecture notes in computer science},
	title = {A calculus of communicating systems},
	isbn = {978-3-540-10235-9 978-0-387-10235-1},
	language = {eng},
	number = {92},
	publisher = {Springer},
	author = {Milner, Robin},
	year = {1980},
	note = {OCLC: 6649199},
	file = {Milner_1980_A calculus of communicating systems.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_1980_A calculus of communicating systems.pdf:application/pdf}
}

@inproceedings{miller_rios:_2013,
	title = {{RIOS}: a lightweight task scheduler for embedded systems},
	isbn = {978-1-4503-1765-8},
	shorttitle = {{RIOS}},
	url = {http://dl.acm.org/citation.cfm?doid=2530544.2530553},
	doi = {10.1145/2530544.2530553},
	abstract = {RIOS (Riverside-Irvine Operating System) is a lightweight portable task scheduler written entirely in C. The scheduler consists of just a few dozens lines of code, intended to be understandable by students learning embedded systems programming. Non-preemptive and preemptive scheduler versions exist. Compared to the existing open-source solutions FreeRTOS and AtomThreads, RIOS on average has 95\% fewer lines of total C code for a sample multitasking application, a 71\% smaller executable, and 70\% less scheduler time overhead. RIOS source code and examples are available for free at http://www.riosscheduler.org. RIOS is useful for education and as a stepping stone to understanding real-time operating system behavior. Additionally, RIOS is a sufficient real-time scheduling solution for various commercial applications.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Miller, Bailey and Vahid, Frank and Givargis, Tony},
	year = {2013},
	pages = {1--7},
	file = {Miller et al_2013_RIOS - a lightweight task scheduler for embedded systems.pdf:/home/michael/Dropbox/zotero-pdfs/M/Miller et al_2013_RIOS - a lightweight task scheduler for embedded systems.pdf:application/pdf}
}

@incollection{ehrhard_overview_2004,
	address = {Cambridge},
	title = {An {Overview} of {Linear} {Logic} {Programming}},
	isbn = {978-0-511-55085-0},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511550850A013},
	abstract = {Logic programming can be given a foundation in sequent calculus by viewing computation as the process of building a cut-free sequent proof bottom-up. The ﬁrst accounts of logic programming as proof search were given in classical and intuitionistic logic. Given that linear logic allows richer sequents and richer dynamics in the rewriting of sequents during proof search, it was inevitable that linear logic would be used to design new and more expressive logic programming languages. We overview how linear logic has been used to design such new languages and describe brieﬂy some applications and implementation issues for them.},
	urldate = {2018-03-13},
	booktitle = {Linear {Logic} in {Computer} {Science}},
	publisher = {Cambridge University Press},
	author = {Miller, Dale},
	editor = {Ehrhard, Thomas and Girard, Jean-Yves and Ruet, Paul and Scott, Philip},
	year = {2004},
	doi = {10.1017/CBO9780511550850.004},
	pages = {119--150},
	file = {Miller_2004_An Overview of Linear Logic Programming.pdf:/home/michael/Dropbox/zotero-pdfs/M/Miller_2004_An Overview of Linear Logic Programming.pdf:application/pdf}
}

@article{milea_program_nodate,
	title = {Program {Termination} {Proofs}},
	abstract = {Proving termination of programs is an undecidable problem. In this work we provide a sound method for proving the termination of a certain class of programs by using the power of linear programming tools. We handle while-loops with a simple loop condition where the assignment of the variables is nondeterministically-chosen out of a set of possible linear assignments. We implement a simple eﬃcient tool for proving termination and compare it with other existing tools.},
	author = {Milea, Tal},
	pages = {15},
	file = {Milea_Program Termination Proofs.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milea_Program Termination Proofs.pdf:application/pdf}
}

@article{metcalfe_ethernet:_1976,
	title = {Ethernet: distributed packet switching for local computer networks},
	volume = {19},
	issn = {00010782},
	shorttitle = {Ethernet},
	url = {http://portal.acm.org/citation.cfm?doid=360248.360253},
	doi = {10.1145/360248.360253},
	number = {7},
	urldate = {2018-03-13},
	journal = {Communications of the ACM},
	author = {Metcalfe, Robert M. and Boggs, David R.},
	month = jul,
	year = {1976},
	pages = {395--404},
	file = {Metcalfe_Boggs_1976_Ethernet - distributed packet switching for local computer networks.pdf:/home/michael/Dropbox/zotero-pdfs/M/Metcalfe_Boggs_1976_Ethernet - distributed packet switching for local computer networks.pdf:application/pdf}
}

@incollection{baeten_rewriting_1990,
	address = {Berlin/Heidelberg},
	title = {Rewriting as a unified model of concurrency},
	volume = {458},
	isbn = {978-3-540-53048-0},
	url = {http://www.springerlink.com/index/10.1007/BFb0039072},
	abstract = {The lecture given at the workshop was based on recent work published elsewhere [9, 10, 8, 7]. This abstract gives a brief description of the main results and ideas presented in that work, but does not provide any technical details; such details can be found in the papers mentioned above.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {{CONCUR} '90 {Theories} of {Concurrency}: {Unification} and {Extension}},
	publisher = {Springer-Verlag},
	author = {Meseguer, José},
	editor = {Baeten, J. C. M. and Klop, J. W.},
	year = {1990},
	doi = {10.1007/BFb0039072},
	pages = {384--400},
	file = {Meseguer_1990_Rewriting as a unified model of concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/M/Meseguer_1990_Rewriting as a unified model of concurrency.pdf:application/pdf}
}

@article{meseguer_conditional_1992,
	title = {Conditional rewriting logic as a unified model of concurrency},
	volume = {96},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/030439759290182F},
	doi = {10.1016/0304-3975(92)90182-F},
	abstract = {Meseguer, J., Conditional rewriting logic as a unified model of concurrency, Theoretical Computer Science 96 (1992) 73-155.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {Theoretical Computer Science},
	author = {Meseguer, José},
	month = apr,
	year = {1992},
	pages = {73--155},
	file = {Meseguer_1992_Conditional rewriting logic as a unified model of concurrency.pdf:/home/michael/Dropbox/zotero-pdfs/M/Meseguer_1992_Conditional rewriting logic as a unified model of concurrency.pdf:application/pdf}
}

@book{mendelson_introduction_1957,
	edition = {4},
	title = {Introduction to {Mathematical} {Logic}},
	isbn = {0-412-80830-7},
	url = {http://www.jstor.org/stable/2310410?origin=crossref},
	urldate = {2018-03-13},
	publisher = {Chapman \& Hall},
	author = {Mendelson, Elliott},
	month = feb,
	year = {1957},
	file = {Mendelson_1957_Introduction to Mathematical Logic.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mendelson_1957_Introduction to Mathematical Logic.pdf:application/pdf}
}

@incollection{mccarthy_basis_1963,
	title = {A {Basis} for a {Mathematical} {Theory} of {Computation})},
	volume = {35},
	isbn = {978-0-444-53400-2},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0049237X08720184},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Studies in {Logic} and the {Foundations} of {Mathematics}},
	publisher = {Elsevier},
	author = {McCarthy, John},
	year = {1963},
	doi = {10.1016/S0049-237X(08)72018-4},
	pages = {33--70},
	file = {McCarthy_1963_A Basis for a Mathematical Theory of Computation).pdf:/home/michael/Dropbox/zotero-pdfs/M/McCarthy_1963_A Basis for a Mathematical Theory of Computation).pdf:application/pdf}
}

@book{marlin_coroutines:_1980,
	address = {Berlin},
	series = {Lecture notes in computer science},
	title = {Coroutines: a programming methodology, a language design and an implementation},
	isbn = {978-3-540-10256-4 978-0-387-10256-6},
	shorttitle = {Coroutines},
	language = {eng},
	number = {95},
	publisher = {Springer},
	author = {Marlin, Christopher D.},
	year = {1980},
	note = {OCLC: 6863454},
	file = {Marlin_1980_Coroutines - a programming methodology, a language design and an implementation.pdf:/home/michael/Dropbox/zotero-pdfs/M/Marlin_1980_Coroutines - a programming methodology, a language design and an implementation.pdf:application/pdf}
}

@article{maraist_call-by-name_1999,
	title = {Call-by-name, call-by-value, call-by-need and the linear lambda calculus},
	volume = {228},
	issn = {03043975},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397598003582},
	doi = {10.1016/S0304-3975(98)00358-2},
	abstract = {Girard described two translations of intuitionistic logic into linear logic, one where A ! B maps to (!A) ? B, and another where it maps to !(A ? B). We detail the action of these translations on terms, and show that the rst corresponds to a callby-name calculus, while the second corresponds to call-by-value. We further show that if the target of the translation is taken to be an a ne calculus, where ! controls contraction but weakening is allowed everywhere, then the second translation corresponds to a call-by-need calculus, as recently de ned by Ariola, Felleisen, Maraist, Odersky and Wadler. Thus the di erent calling mechanisms can be explained in terms of logical translations, bringing them into the scope of the Curry-Howard isomorphism.},
	language = {en},
	number = {1-2},
	urldate = {2018-03-13},
	journal = {Theoretical Computer Science},
	author = {Maraist, J. and Odersky, M. and Turner, D.N. and Wadler, P.},
	month = oct,
	year = {1999},
	pages = {175--210},
	file = {Maraist et al_1999_Call-by-name, call-by-value, call-by-need and the linear lambda calculus.pdf:/home/michael/Dropbox/zotero-pdfs/M/Maraist et al_1999_Call-by-name, call-by-value, call-by-need and the linear lambda calculus.pdf:application/pdf}
}

@article{manson_java_2005,
	title = {The {Java} memory model},
	volume = {40},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=1047659.1040336},
	doi = {10.1145/1047659.1040336},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Manson, Jeremy and Pugh, William and Adve, Sarita V.},
	month = jan,
	year = {2005},
	pages = {378--391},
	file = {Manson et al_2005_The Java memory model.pdf:/home/michael/Dropbox/zotero-pdfs/M/Manson et al_2005_The Java memory model.pdf:application/pdf}
}

@book{awodey_category_2010,
	address = {Oxford ; New York},
	edition = {2nd ed},
	series = {Oxford logic guides},
	title = {Category theory},
	isbn = {978-0-19-958736-0 978-0-19-923718-0},
	number = {52},
	publisher = {Oxford University Press},
	author = {Awodey, Steve},
	year = {2010},
	keywords = {Categories (Mathematics)},
	file = {Awodey_2010_Category theory.pdf:/home/michael/Dropbox/zotero-pdfs/A/Awodey_2010_Category theory.pdf:application/pdf}
}

@article{rushby_subtypes_1998,
	title = {Subtypes for specifications: predicate subtyping in {PVS}},
	volume = {24},
	issn = {00985589},
	shorttitle = {Subtypes for specifications},
	url = {http://ieeexplore.ieee.org/document/713327/},
	doi = {10.1109/32.713327},
	abstract = {A specification language used in the context of an effective theorem prover can provide novel features that enhance precision and expressiveness. In particular, typechecking for the language can exploit the services of the theorem prover. We describe a feature called “predicate subtyping” that uses this capability and illustrate its utility as mechanized in PVS.},
	number = {9},
	urldate = {2018-03-13},
	journal = {IEEE Transactions on Software Engineering},
	author = {Rushby, J. and Owre, S. and Shankar, N.},
	month = sep,
	year = {1998},
	pages = {709--720},
	file = {Rushby et al_1998_Subtypes for specifications - predicate subtyping in PVS.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rushby et al_1998_Subtypes for specifications - predicate subtyping in PVS.pdf:application/pdf}
}

@article{rushby_design_1981,
	title = {Design and {Veri} cation of {Secure} {Systems}},
	abstract = {This paper reviews some of the di culties that arise in the veri cation of kernelized secure systems and suggests new techniques for their resolution. It is proposed that secure systems should be conceived as distributed systems in which security is achieved partly through the physical separation of their individual components and partly through the mediation of trusted functions performed within some of those components. The purpose of a security kernel is simply to allow such a `distributed' system to actually run within a single processor; policy enforcement is not the concern of a security kernel.},
	author = {Rushby, John},
	month = dec,
	year = {1981},
	pages = {21},
	file = {Rushby_1981_Design and Veri cation of Secure Systems.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rushby_1981_Design and Veri cation of Secure Systems.pdf:application/pdf}
}

@incollection{bensalem_runtime_2009,
	address = {Berlin, Heidelberg},
	title = {Runtime {Verification} of {C} {Memory} {Safety}},
	volume = {5779},
	isbn = {978-3-642-04693-3 978-3-642-04694-0},
	url = {http://link.springer.com/10.1007/978-3-642-04694-0_10},
	abstract = {C is the most widely used imperative system’s implementation language. While C provides types and high-level abstractions, its design goal has been to provide highest performance which often requires low-level access to memory. As a consequence C supports arbitrary pointer arithmetic, casting, and explicit allocation and deallocation. These operations are diﬃcult to use, resulting in programs that often have software bugs like buﬀer overﬂows and dangling pointers that cause security vulnerabilities. We say a C program is memory safe, if at runtime it never goes wrong with such a memory access error. Based on standards for writing “good” C code, this paper proposes strong memory safety as the least restrictive formal deﬁnition of memory safety amenable for runtime veriﬁcation. We show that although veriﬁcation of memory safety is in general undecidable, even when restricted to closed, terminating programs, runtime veriﬁcation of strong memory safety is a decision procedure for this class of programs. We verify strong memory safety of a program by executing the program using a symbolic, deterministic definition of the dynamic semantics. A prototype implementation of these ideas shows the feasibility of this approach.},
	urldate = {2018-03-13},
	booktitle = {Runtime {Verification}},
	publisher = {Springer Berlin Heidelberg},
	author = {Roşu, Grigore and Schulte, Wolfram and Şerbănuţă, Traian Florin},
	editor = {Bensalem, Saddek and Peled, Doron A.},
	year = {2009},
	doi = {10.1007/978-3-642-04694-0_10},
	pages = {132--151},
	file = {Rosu et al_2009_Runtime Verification of C Memory Safety.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rosu et al_2009_Runtime Verification of C Memory Safety2.pdf:application/pdf}
}

@article{waterman_this_nodate,
	title = {This document is also available as {Technical} {Report} {UCB}/{EECS}-2016-118.},
	author = {Waterman, Andrew and Lee, Yunsup and Patterson, David and Asanovi, Krste and Division, CS},
	pages = {131},
	file = {Waterman et al_This document is also available as Technical Report UCB-EECS-2016-118.pdf:/home/michael/Dropbox/zotero-pdfs/W/Waterman et al_This document is also available as Technical Report UCB-EECS-2016-118.pdf:application/pdf}
}

@incollection{audebaud_hoare_2008,
	address = {Berlin, Heidelberg},
	title = {A {Hoare} {Logic} for {Call}-by-{Value} {Functional} {Programs}},
	volume = {5133},
	isbn = {978-3-540-70593-2 978-3-540-70594-9},
	url = {http://link.springer.com/10.1007/978-3-540-70594-9_17},
	abstract = {We present a Hoare logic for a call-by-value programming language equipped with recursive, higher-order functions, algebraic data types, and a polymorphic type system in the style of Hindley and Milner. It is the theoretical basis for a tool that extracts proof obligations out of programs annotated with logical assertions. These proof obligations, expressed in a typed, higher-order logic, are discharged using oﬀ-theshelf automated or interactive theorem provers. Although the technical apparatus that we exploit is by now standard, its application to callby-value functional programming languages appears to be new, and (we claim) deserves attention. As a sample application, we check the partial correctness of a balanced binary search tree implementation.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Mathematics of {Program} {Construction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Régis-Gianas, Yann and Pottier, François},
	editor = {Audebaud, Philippe and Paulin-Mohring, Christine},
	year = {2008},
	doi = {10.1007/978-3-540-70594-9_17},
	pages = {305--335},
	file = {Regis-Gianas_Pottier_2008_A Hoare Logic for Call-by-Value Functional Programs.pdf:/home/michael/Dropbox/zotero-pdfs/R/Regis-Gianas_Pottier_2008_A Hoare Logic for Call-by-Value Functional Programs.pdf:application/pdf}
}

@article{rees_massachusetts_nodate,
	title = {{MASSACHUSETTS} {INSTITUTE} {OF} {TECHNOLOGY} {ARTIFICIAL} {INTELLIGENCE} {LABORATORY}},
	abstract = {Cooperation between independent agents depends upon establishing a degree of security. Each of the cooperating agents needs assurance that the cooperation will not endanger resources of value to that agent. In a computer system, a computational mechanism can assure safe cooperation among the system’s users by mediating resource access according to desired security policy. Such a mechanism, which is called a security kernel, lies at the heart of many operating systems and programming environments.},
	author = {Rees, Jonathan A},
	pages = {43},
	file = {Rees_MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rees_MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY.pdf:application/pdf}
}

@article{ramsay_type-checking_1984,
	title = {Type-checking in an untyped language},
	volume = {20},
	issn = {00207373},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020737384800152},
	doi = {10.1016/S0020-7373(84)80015-2},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {International Journal of Man-Machine Studies},
	author = {Ramsay, Allan},
	month = feb,
	year = {1984},
	pages = {157--167},
	file = {Ramsay_1984_Type-checking in an untyped language.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ramsay_1984_Type-checking in an untyped language.pdf:application/pdf}
}

@incollection{goos_adequate_1992,
	address = {Berlin, Heidelberg},
	title = {An adequate operational semantics of sharing in lazy evaluation},
	volume = {582},
	isbn = {978-3-540-55253-6 978-3-540-46803-5},
	url = {http://link.springer.com/10.1007/3-540-55253-7_26},
	abstract = {W e present LAZY-PCF-\{\vphantom{\}}-SHAR, an extension of P C F , that deals with lazy evaluation and explicitsubstitutionsto model the sharing engendered by the lazy evaluation strategy. We present a natural operational semantics for LAZY-PCFq-SHAR and show that it is equivaJent to the standard fixed-point semantics. Sharing is modeled by explicit substitutions, which require a great deal of careful attention in the proof.},
	urldate = {2018-03-13},
	booktitle = {{ESOP} '92},
	publisher = {Springer Berlin Heidelberg},
	author = {Purushothaman, S. and Seaman, Jill},
	editor = {Goos, Gerhard and Hartmanis, Juris and Krieg-Brückner, Bernd},
	year = {1992},
	doi = {10.1007/3-540-55253-7_26},
	pages = {435--450},
	file = {Purushothaman_Seaman_1992_An adequate operational semantics of sharing in lazy evaluation.pdf:/home/michael/Dropbox/zotero-pdfs/P/Purushothaman_Seaman_1992_An adequate operational semantics of sharing in lazy evaluation.pdf:application/pdf}
}

@article{hicks_programming_nodate,
	title = {The {Programming} {Languages} {Enthusiast}},
	author = {HICKS, MICHAEL},
	pages = {5},
	file = {HICKS_The Programming Languages Enthusiast.pdf:/home/michael/Dropbox/zotero-pdfs/H/HICKS_The Programming Languages Enthusiast.pdf:application/pdf}
}

@article{david_pict:_nodate,
	title = {Pict: {A} {Programming} {Language} {Based} on the {Pi}-{Calculus}},
	abstract = {The -calculus o ers an attractive basis for concurrent programming. It is small, elegant, and well studied, and supports (via simple encodings) a wide range of high-level constructs including data structures, higher-order functional programming, concurrent control structures, and objects. Moreover, familiar type systems for the -calculus have direct counterparts in the -calculus, yielding strong, static typing for a high-level language using the -calculus as its core. This paper describes Pict, a strongly-typed concurrent programming language constructed in terms of an explicitly-typed -calculus core language.},
	author = {David, Benjamin C Pierce and Turner, N},
	pages = {26},
	file = {David_Turner_Pict - A Programming Language Based on the Pi-Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/D/David_Turner_Pict - A Programming Language Based on the Pi-Calculus.pdf:application/pdf}
}

@book{pierce_advanced_2005,
	address = {Cambridge, Mass},
	title = {Advanced topics in types and programming languages},
	isbn = {978-0-262-16228-9},
	publisher = {MIT Press},
	editor = {Pierce, Benjamin C.},
	year = {2005},
	keywords = {Programming languages (Electronic computers)},
	file = {Pierce_2005_Advanced topics in types and programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pierce_2005_Advanced topics in types and programming languages.pdf:application/pdf}
}

@article{derrin_bachelor_nodate,
	title = {Bachelor of {Computer} {Science} ({Honours}) {Submitted}: {June} 7, 2005},
	author = {Derrin, Philip Geoffrey},
	pages = {102},
	file = {Derrin_Bachelor of Computer Science (Honours) Submitted - June 7, 2005.pdf:/home/michael/Dropbox/zotero-pdfs/D/Derrin_Bachelor of Computer Science (Honours) Submitted - June 7, 2005.pdf:application/pdf}
}

@inproceedings{pfenning_higher-order_1988,
	title = {Higher-order abstract syntax},
	isbn = {978-0-89791-269-3},
	url = {http://portal.acm.org/citation.cfm?doid=53990.54010},
	doi = {10.1145/53990.54010},
	abstract = {We describe motivation, design, use, and implementation of higher-order absrruct syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or unification are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higher-order abstract syntax, a supporting matching and unification algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Pfenning, F. and Elliot, C.},
	year = {1988},
	pages = {199--208},
	file = {Pfenning_Elliot_1988_Higher-order abstract syntax.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_Elliot_1988_Higher-order abstract syntax.pdf:application/pdf}
}

@article{pfenning_renement_nodate,
	title = {Reﬁnement {Types} for {Logical} {Frameworks}},
	abstract = {We propose a reﬁnement of the type theory underlying the LF logical framework by a form of subtypes and intersection types. This reﬁnement preserves desirable features of LF, such as decidability of type-checking, and at the same time considerably simpliﬁes the representations of many deductive systems. A subtheory can be applied directly to hereditary Harrop formulas which form the basis of λProlog and Isabelle.},
	author = {Pfenning, Frank},
	pages = {14},
	file = {Pfenning_Reﬁnement Types for Logical Frameworks.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfenning_Reﬁnement Types for Logical Frameworks.pdf:application/pdf}
}

@article{jones_imperative_nodate,
	title = {Imperative functional programming},
	abstract = {We present a new model, based on monads, for performing input/output in a non-strict, purely functional language. It is composable, extensible, e cient, requires no extensions to the type system, and extends smoothly to incorporate mixed-language working and in-place array updates.},
	author = {Jones, Simon L Peyton and Wadler, Philip},
	pages = {15},
	file = {Jones_Wadler_Imperative functional programming.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Wadler_Imperative functional programming2.pdf:application/pdf}
}

@article{jones_modular_1991,
	title = {A modular fully-lazy lambda lifter in {Haskell}},
	volume = {21},
	issn = {00380644, 1097024X},
	url = {http://doi.wiley.com/10.1002/spe.4380210505},
	doi = {10.1002/spe.4380210505},
	abstract = {An important step in many compilers for functional languages is lambda lifting. In his thesis, Hughes showed that by doing lambda lifting in a particular way, a useful property called full laziness can be preserved (Hughes 1983]). Full laziness has been seen as intertwined with lambda lifting ever since.},
	language = {en},
	number = {5},
	urldate = {2018-03-13},
	journal = {Software: Practice and Experience},
	author = {Jones, Simon L. Peyton and Lester, David},
	month = may,
	year = {1991},
	pages = {479--506},
	file = {Jones_Lester_1991_A modular fully-lazy lambda lifter in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Lester_1991_A modular fully-lazy lambda lifter in Haskell.pdf:application/pdf}
}

@article{peyton_jones_tackling_2010,
	title = {Tackling the {Awkward} {Squad}: monadic input/output, concurrency, exceptions, and foreign-language calls in {Haskell}},
	abstract = {Functional programming may be beautiful, but to write real applications we must grapple with awkward real-world issues: input/output, robustness, concurrency, and interfacing to programs written in other languages.},
	author = {Peyton Jones, Simon},
	month = apr,
	year = {2010},
	pages = {46},
	file = {JONES_Tackling the Awkward Squad - monadic input-output, concurrency, exceptions, and.pdf:/home/michael/Dropbox/zotero-pdfs/J/JONES_Tackling the Awkward Squad - monadic input-output, concurrency, exceptions, and2.pdf:application/pdf}
}

@article{jones_flic---functional_1988,
	title = {{FLIC}---a functional language intermediate code},
	volume = {23},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=47907.47910},
	doi = {10.1145/47907.47910},
	abstract = {PLIC is a Functional Language Intermediate Code, intended to provide a common intermediate language between diverse implementations of functional languages, including parallel ones. This paper gives a formal definition of FLIC's syntax and semantics, in the hope that its existence may encourage greater exchange of programs and benchmarks between research groups.},
	language = {en},
	number = {8},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Jones, S. L. Payton},
	month = aug,
	year = {1988},
	pages = {30--48},
	file = {Jones_1988_FLIC---a functional language intermediate code.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_1988_FLIC---a functional language intermediate code.pdf:application/pdf}
}

@article{sweeney_antitachycardia_2004,
	title = {Antitachycardia {Pacing} for {Ventricular} {Tachycardia} {Using} {Implantable} {Cardioverter} {Defibrillators}:. {Substrates}, {Methods}, and {Clinical} {Experience}},
	volume = {27},
	issn = {0147-8389, 1540-8159},
	shorttitle = {Antitachycardia {Pacing} for {Ventricular} {Tachycardia} {Using} {Implantable} {Cardioverter} {Defibrillators}},
	url = {http://doi.wiley.com/10.1111/j.1540-8159.2004.00622.x},
	doi = {10.1111/j.1540-8159.2004.00622.x},
	language = {en},
	number = {9},
	urldate = {2018-03-13},
	journal = {Pacing and Clinical Electrophysiology},
	author = {Sweeney, Michael O.},
	month = sep,
	year = {2004},
	pages = {1292--1305},
	file = {Sweeney_2004_Antitachycardia Pacing for Ventricular Tachycardia Using Implantable.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sweeney_2004_Antitachycardia Pacing for Ventricular Tachycardia Using Implantable.pdf:application/pdf}
}

@inproceedings{sutherland_sketchpad:_1963,
	title = {Sketchpad: a man-machine graphical communication system},
	shorttitle = {Sketchpad},
	url = {http://portal.acm.org/citation.cfm?doid=1461551.1461591},
	doi = {10.1145/1461551.1461591},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Sutherland, Ivan E.},
	year = {1963},
	pages = {329},
	file = {Sutherland_1963_Sketchpad - a man-machine graphical communication system.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sutherland_1963_Sketchpad - a man-machine graphical communication system.pdf:application/pdf}
}

@article{sussman_scheme:_nodate,
	title = {Scheme: {A} {Interpreter} for {Extended} {Lambda} {Calculus}},
	abstract = {Inspired by ACTORS [7, 17], we have implemented an interpreter for a LISP-like language, SCHEME, based on the lambda calculus [2], but extended for side effects, multiprocessing, and process synchronization. The purpose of this implementation is tutorial. We wish to: 1. alleviate the confusion caused by Micro-PLANNER, CONNIVER, etc., by clarifying the embedding of non-recursive control structures in a recursive host language like LISP. 2. explain how to use these control structures, independent of such issues as pattern matching and data base manipulation. 3. have a simple concrete experimental domain for certain issues of programming semantics and style. This paper is organized into sections. The ﬁrst section is a short “reference manual” containing speciﬁcations for all the unusual features of SCHEME. Next, we present a sequence of programming examples which illustrate various programming styles, and how to use them. This will raise certain issues of semantics which we will try to clarify with lambda calculus in the third section. In the fourth section we will give a general discussion of the issues facing an implementor of an interpreter for a language based on lambda calculus. Finally, we will present a completely annotated interpreter for SCHEME, written in MacLISP [13], to acquaint programmers with the tricks of the trade of implementing non-recursive control structures in a recursive language like LISP.},
	author = {SUSSMAN, GERALD JAY and JR, GUY L STEELE},
	pages = {35},
	file = {SUSSMAN_JR_Scheme - A Interpreter for Extended Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/S/SUSSMAN_JR_Scheme - A Interpreter for Extended Lambda Calculus.pdf:application/pdf}
}

@incollection{hutchison_stranger:_2010,
	address = {Berlin, Heidelberg},
	title = {Stranger: {An} {Automata}-{Based} {String} {Analysis} {Tool} for {PHP}},
	volume = {6015},
	isbn = {978-3-642-12001-5 978-3-642-12002-2},
	shorttitle = {Stranger},
	url = {http://link.springer.com/10.1007/978-3-642-12002-2_13},
	abstract = {STRANGER is an automata-based string analysis tool for ﬁnding and eliminating string-related security vulnerabilities in PHP applications. STRANGER uses symbolic forward and backward reachability analyses to compute the possible values that the string expressions can take during program execution. STRANGER can automatically (1) prove that an application is free from speciﬁed attacks or (2) generate vulnerability signatures that characterize all malicious inputs that can be used to generate attacks.},
	urldate = {2018-03-13},
	booktitle = {Tools and {Algorithms} for the {Construction} and {Analysis} of {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Yu, Fang and Alkhalaf, Muath and Bultan, Tevfik},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Esparza, Javier and Majumdar, Rupak},
	year = {2010},
	doi = {10.1007/978-3-642-12002-2_13},
	pages = {154--157},
	file = {Yu et al_2010_Stranger - An Automata-Based String Analysis Tool for PHP.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yu et al_2010_Stranger - An Automata-Based String Analysis Tool for PHP.pdf:application/pdf}
}

@inproceedings{stoica_chord:_2001,
	title = {Chord: {A} scalable peer-to-peer lookup service for internet applications},
	isbn = {978-1-58113-411-7},
	shorttitle = {Chord},
	url = {http://portal.acm.org/citation.cfm?doid=383059.383071},
	doi = {10.1145/383059.383071},
	abstract = {A fundamental problem that confronts peer-to-peer applications is to efﬁciently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efﬁciently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Stoica, Ion and Morris, Robert and Karger, David and Kaashoek, M. Frans and Balakrishnan, Hari},
	year = {2001},
	pages = {149--160},
	file = {Stoica et al_2001_Chord - A scalable peer-to-peer lookup service for internet applications.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stoica et al_2001_Chord - A scalable peer-to-peer lookup service for internet applications.pdf:application/pdf}
}

@book{symposium_on_operating_systems_principles_sosp_2013,
	title = {{SOSP} '13: proceedings of the twenty-fourth {ACM} {Symposium} on {Operating} {Systems} {Principles} : {November} 3-6, 2013, {Farmington}, {PA}, {USA}},
	isbn = {978-1-4503-2388-8},
	shorttitle = {{SOSP} '13},
	url = {http://dl.acm.org/citation.cfm?id=2517349},
	language = {English},
	urldate = {2018-03-13},
	author = {{Symposium on Operating Systems Principles} and {ACM Special Interest Group in Operating Systems} and {USENIX Association}},
	year = {2013},
	note = {OCLC: 870330680},
	file = {Symposium on Operating Systems Principles et al_2013_SOSP '13 - proceedings of the twenty-fourth ACM Symposium on Operating Systems.pdf:/home/michael/Dropbox/zotero-pdfs/S/Symposium on Operating Systems Principles et al_2013_SOSP '13 - proceedings of the twenty-fourth ACM Symposium on Operating Systems.pdf:application/pdf}
}

@misc{road_qnx_2014,
	title = {{QNX} {Neutrino} {RTOS} {System} {Architecture}},
	author = {Road, Farrar},
	month = feb,
	year = {2014},
	file = {Road_2014_QNX Neutrino RTOS System Architecture.pdf:/home/michael/Dropbox/zotero-pdfs/R/Road_2014_QNX Neutrino RTOS System Architecture.pdf:application/pdf}
}

@inproceedings{slowinska_dde:_2010-1,
	title = {{DDE}: dynamic data structure excavation},
	isbn = {978-1-4503-0195-4},
	shorttitle = {{DDE}},
	url = {http://portal.acm.org/citation.cfm?doid=1851276.1851280},
	doi = {10.1145/1851276.1851280},
	abstract = {Dynamic Datastructure Excavation (DDE) is a new approach to extract datastructures from C binaries without any need for debugging symbols. Unlike most existing tools, DDE uses dynamic analysis (on a QEMU-based emulator) and detects data structures by tracking how a program uses memory. Its results are much more accurate than those of previous methods.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Slowinska, Asia and Stancescu, Traian and Bos, Herbert},
	year = {2010},
	pages = {13},
	file = {Slowinska et al_2010_DDE - dynamic data structure excavation.pdf:/home/michael/Dropbox/zotero-pdfs/S/Slowinska et al_2010_DDE - dynamic data structure excavation.pdf:application/pdf}
}

@incollection{siff_coping_1999,
	address = {Berlin, Heidelberg},
	title = {Coping with {Type} {Casts} in {C}},
	volume = {1687},
	isbn = {978-3-540-66538-0 978-3-540-48166-9},
	url = {http://link.springer.com/10.1007/3-540-48166-4_12},
	abstract = {The use of type casts is pervasive in C. Although casts provide great ﬂexibility in writing programs, their use obscures the meaning of programs, and can present obstacles during maintenance. Casts involving pointers to structures (C structs) are particularly problematic, because by using them, a programmer can interpret any memory region to be of any desired type, thereby compromising C’s already weak type system.},
	urldate = {2018-03-13},
	booktitle = {Software {Engineering} — {ESEC}/{FSE} ’99},
	publisher = {Springer Berlin Heidelberg},
	author = {Siff, Michael and Chandra, Satish and Ball, Thomas and Kunchithapadam, Krishna and Reps, Thomas and Siff, Michael and Chandra, Satish and Ball, Thomas and Kunchithapadam, Krishna and Reps, Thomas},
	year = {1999},
	doi = {10.1007/3-540-48166-4_12},
	pages = {180--198},
	file = {Siff et al_1999_Coping with Type Casts in C.pdf:/home/michael/Dropbox/zotero-pdfs/S/Siff et al_1999_Coping with Type Casts in C.pdf:application/pdf}
}

@article{shulman_praise_nodate,
	title = {In {Praise} of {Dependent} {Types}},
	author = {Shulman, Mike},
	pages = {5},
	file = {Shulman_In Praise of Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shulman_In Praise of Dependent Types.pdf:application/pdf}
}

@article{shapiro_eros:_2000,
	title = {{EROS}: a fast capability system},
	volume = {34},
	issn = {01635980},
	shorttitle = {{EROS}},
	url = {http://portal.acm.org/citation.cfm?doid=346152.346191},
	doi = {10.1145/346152.346191},
	abstract = {EROS is a capability-based operating system for commodity processors which uses a single level storage model. The single level store’s persistence is transparent to applications. The performance consequences of support for transparent persistence and capability-based architectures are generally believed to be negative. Surprisingly, the basic operations of EROS (such as IPC) are generally comparable in cost to similar operations in conventional systems. This is demonstrated with a set of microbenchmark measurements of semantically similar operations in Linux.},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Shapiro, Jonathan S. and Smith, Jonathan M. and Farber, David J.},
	month = apr,
	year = {2000},
	pages = {21--22},
	file = {Shapiro et al_2000_EROS - a fast capability system.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shapiro et al_2000_EROS - a fast capability system.pdf:application/pdf}
}

@incollection{goos_effects_1997,
	address = {Berlin, Heidelberg},
	title = {The effects of the precision of pointer analysis},
	volume = {1302},
	isbn = {978-3-540-63468-3 978-3-540-69576-9},
	url = {http://link.springer.com/10.1007/BFb0032731},
	abstract = {In order to analyze programs that manipulate pointers, it is necessary to have safe information about what each pointer might point to. There are many algorithms that can be used to determine this information, with varying degrees of accuracy. However, there has been very little previous work that addresses how much the relative accuracies of diﬀerent pointer-analysis algorithms aﬀect “transitive” results: the results of a subsequent analysis.},
	urldate = {2018-03-13},
	booktitle = {Static {Analysis}},
	publisher = {Springer Berlin Heidelberg},
	author = {Shapiro, Marc and Horwitz, Susan},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Van Hentenryck, Pascal},
	year = {1997},
	doi = {10.1007/BFb0032731},
	pages = {16--34},
	file = {Shapiro_Horwitz_1997_The effects of the precision of pointer analysis.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shapiro_Horwitz_1997_The effects of the precision of pointer analysis.pdf:application/pdf}
}

@article{shannon_mathematical_1948,
	title = {A {Mathematical} {Theory} of {Communication}},
	volume = {27},
	issn = {00058580},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6773067},
	doi = {10.1002/j.1538-7305.1948.tb00917.x},
	language = {en},
	number = {4},
	urldate = {2018-03-13},
	journal = {Bell System Technical Journal},
	author = {Shannon, C. E.},
	month = oct,
	year = {1948},
	pages = {623--656},
	file = {Shannon_1948_A Mathematical Theory of Communication.pdf:/home/michael/Dropbox/zotero-pdfs/S/Shannon_1948_A Mathematical Theory of Communication.pdf:application/pdf}
}

@inproceedings{serrano_scheme_2004,
	title = {Scheme fair threads},
	isbn = {978-1-58113-819-1},
	url = {http://portal.acm.org/citation.cfm?doid=1013963.1013986},
	doi = {10.1145/1013963.1013986},
	abstract = {This paper presents Fair Threads, a new model for concurrent programming. This multi-threading model combines preemptive and cooperative scheduling. User threads execute according to a cooperative strategy. Service threads execute according to a preemptive strategy. User threads may ask services from service threads in order to improve performance by exploiting hardware parallelism and in order to execute non-blocking operations.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Serrano, Manuel and Boussinot, Frédéric and Serpette, Bernard},
	year = {2004},
	pages = {203--214},
	file = {Serrano et al_2004_Scheme fair threads.pdf:/home/michael/Dropbox/zotero-pdfs/S/Serrano et al_2004_Scheme fair threads.pdf:application/pdf}
}

@article{serbanuta_rewriting_2009,
	title = {A rewriting logic approach to operational semantics},
	volume = {207},
	issn = {08905401},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540108001302},
	doi = {10.1016/j.ic.2008.03.026},
	abstract = {We show how one can use rewriting logic to faithfully capture (not implement) various operational semantic frameworks as rewrite logic theories, namely big-step and small-step semantics, reduction semantics using evaluation contexts, and continuation-based semantics. There is a one-to-one correspondence between an original operational semantics and its associated rewrite logic theory, both notationally and computationally. Once an operational semantics is deﬁned as a rewrite logic theory, one can use standard, oﬀ-the-shelf context-insensitive rewrite engines to “execute” programs directly within their semantics; in other words, one gets interpreters for free for the deﬁned languages, directly from their semantic deﬁnitions. Experiments show that the resulting correct-by-deﬁnition interpreters are also reasonably eﬃcient.},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {Information and Computation},
	author = {Şerbănuţă, Traian Florin and Roşu, Grigore and Meseguer, José},
	month = feb,
	year = {2009},
	pages = {305--340},
	file = {Serbanuta et al_2009_A rewriting logic approach to operational semantics.pdf:/home/michael/Dropbox/zotero-pdfs/E/Serbanuta et al_2009_A rewriting logic approach to operational semantics.pdf:application/pdf}
}

@article{baker-finch_semantics_nodate,
	title = {The {Semantics} of {Programming} {Languages}},
	author = {Baker-Finch, Clem},
	pages = {62},
	file = {Baker-Finch_The Semantics of Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/B/Baker-Finch_The Semantics of Programming Languages.pdf:application/pdf}
}

@inproceedings{schwartz_native_2013,
	address = {Berkeley, Calif},
	title = {Native x86 {Decompilations} {Using} {Semantics}-{Preserving} {Structural} {Analysis} and {Iterative} {Control}-{Flow} {Structuring}},
	isbn = {978-1-931971-03-4},
	shorttitle = {Proceedings of the {Sixteenth} {Systems} {Administration} {Conference} ({LISA} {XVI})},
	abstract = {There are many security tools and techniques for analyzing software, but many of them require access to source code. We propose leveraging decompilation, the study of recovering abstractions from compiled code, to apply existing source-based tools and techniques to compiled programs. A decompiler should focus on two properties to be used for security. First, it should recover abstractions as much as possible to minimize the complexity that must be handled by the security analysis that follows. Second, it should aim to recover these abstractions correctly. Previous work in control-ﬂow structuring, an abstraction recovery problem used in decompilers, does not provide either of these properties. Speciﬁcally, existing structuring algorithms are not semantics-preserving, which means that they cannot safely be used for decompilation without modiﬁcation. Existing structural algorithms also miss opportunities for recovering control ﬂow structure. We propose a new structuring algorithm in this paper that addresses these problems. We evaluate our decompiler, Phoenix, and our new structuring algorithm, on a set of 107 real world programs from GNU coreutils. Our evaluation is an order of magnitude larger than previous systematic studies of endto-end decompilers. We show that our decompiler outperforms the de facto industry standard decompiler Hex-Rays in correctness by 114\%, and recovers 30× more controlﬂow structure than existing structuring algorithms in the literature.},
	language = {eng},
	booktitle = {Proceedings of the 22nd {USENIX} {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Schwartz, Edward J. and Lee, JongHyup and Woo, Maverick and Brumley, David},
	month = aug,
	year = {2013},
	note = {OCLC: 249435017},
	file = {Schwartz et al_2013_Native x86 Decompilations Using Semantics-Preserving Structural Analysis and.pdf:/home/michael/Dropbox/zotero-pdfs/S/Systems Administration Conference_USENIX Association_2002_Proceedings of the Sixteenth Systems Administration Conference (LISA XVI) -.pdf:application/pdf}
}

@article{schmidt_trace-based_nodate,
	title = {Trace-{Based} {Abstract} {Interpretation} of {Operational} {Semantics}},
	abstract = {We present trace-based abstract interpretation, a uni cation of several lines of research on applying Cousot-Cousot-style abstract interpretation (a.i. ) to operational semantics de nitions (such as owchart, big-step, and small-step semantics) that express a program's semantics as a concrete computation tree of trace paths. A program's traced-based a.i. is also a computation tree whose nodes contain abstractions of state and whose paths simulate the paths in the program's concrete computation tree. Using such computation trees, we provide a simple explanation of the central concept of collecting semantics, and we distinguish concrete from abstract collecting semantics and state-based from path-based collecting semantics. We also expose the relationship between collecting semantics extraction and results garnered from ow-analytic and model-checking-based analysis techniques. We adapt concepts from concurrency theory to formalize {\textbackslash}safe" and {\textbackslash}live" a.i. s for computation trees; in particular, coinduction techniques help extend fundamental results to in nite computation trees.},
	author = {Schmidt, David A},
	pages = {36},
	file = {Schmidt_Trace-Based Abstract Interpretation of Operational Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/S/Schmidt_Trace-Based Abstract Interpretation of Operational Semantics.pdf:application/pdf}
}

@article{ceze_requirements_nodate,
	title = {requirements for the degree of {Doctor} of {Philosophy}},
	author = {Ceze, Luis and Grossman, Daniel and Oskin, Mark},
	pages = {212},
	file = {Ceze et al_requirements for the degree of Doctor of Philosophy.pdf:/home/michael/Dropbox/zotero-pdfs/C/Ceze et al_requirements for the degree of Doctor of Philosophy.pdf:application/pdf}
}

@incollection{lindley_recursion_1982,
	address = {Cham},
	title = {Recursion {Equations} as a {Programming} {Language}},
	volume = {9600},
	isbn = {978-3-319-30935-4 978-3-319-30936-1},
	url = {http://link.springer.com/10.1007/978-3-319-30936-1_24},
	urldate = {2018-03-13},
	booktitle = {A {List} of {Successes} {That} {Can} {Change} the {World}},
	publisher = {Springer International Publishing},
	author = {Turner, D. A.},
	editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
	year = {1982},
	doi = {10.1007/978-3-319-30936-1_24},
	pages = {459--478},
	file = {Turner_1982_Recursion Equations as a Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turner_1982_Recursion Equations as a Programming Language.pdf:application/pdf}
}

@incollection{epstein_computing_2009,
	address = {Dordrecht},
	title = {Computing {Machinery} and {Intelligence}},
	isbn = {978-1-4020-9624-2 978-1-4020-6710-5},
	url = {http://link.springer.com/10.1007/978-1-4020-6710-5_3},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Parsing the {Turing} {Test}},
	publisher = {Springer Netherlands},
	author = {Turing, Alan M.},
	editor = {Epstein, Robert and Roberts, Gary and Beber, Grace},
	year = {2009},
	doi = {10.1007/978-1-4020-6710-5_3},
	pages = {23--65},
	file = {Turing_2009_Computing Machinery and Intelligence.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turing_2009_Computing Machinery and Intelligence.pdf:application/pdf}
}

@article{turing_i.computing_1950,
	title = {I.—{COMPUTING} {MACHINERY} {AND} {INTELLIGENCE}},
	volume = {LIX},
	issn = {0026-4423, 1460-2113},
	url = {https://academic.oup.com/mind/article-lookup/doi/10.1093/mind/LIX.236.433},
	doi = {10.1093/mind/LIX.236.433},
	language = {en},
	number = {236},
	urldate = {2018-03-13},
	journal = {Mind},
	author = {Turing, A. M.},
	year = {1950},
	pages = {433--460},
	file = {Turing_1950_I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turing_1950_I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf:application/pdf}
}

@article{tolmach_external_nodate,
	title = {An {External} {Representation} for the {GHC} {Core} {Language} ({For} {GHC} 6.10)},
	abstract = {This document provides a precise deﬁnition for the GHC Core language, so that it can be used to communicate between GHC and new stand-alone compilation tools such as back-ends or optimizers.1 The deﬁnition includes a formal grammar and an informal semantics. An executable typechecker and interpreter (in Haskell), which formally embody the static and dynamic semantics, are available separately.},
	author = {Tolmach, Andrew and Chevalier, Tim},
	pages = {14},
	file = {Tolmach_Chevalier_An External Representation for the GHC Core Language (For GHC 6.10).pdf:/home/michael/Dropbox/zotero-pdfs/T/Tolmach_Chevalier_An External Representation for the GHC Core Language (For GHC 6.10).pdf:application/pdf}
}

@article{thekkath_hardware_1994,
	title = {Hardware and software support for efficient exception handling},
	volume = {28},
	issn = {01635980},
	url = {http://portal.acm.org/citation.cfm?doid=381792.195515},
	doi = {10.1145/381792.195515},
	abstract = {Program-synchronous exceptions, for example, breakpoints, watchpoints, illegal opcodes, and memory access violations, provide information about exceptional conditions, interrupting the program and vectoring to an operating system handler. Over the last decade, however, programs and run-time systems have increasingly employed these mechanisms as a performance optimization to detect normal and expected conditions. Unfortunately, current architecture and operating system structures are designed for exceptional or erroneous conditions, where performance is of secondary importance, rather than normal conditions. Consequently, this has limited the practicality of such hardware-based detection mechanisms. We propose both hardware and software structures that permit efﬁcient handling of synchronous exceptions by user-level code. We demonstrate a software implementation that reduces exceptiondelivery cost by an order-of-magnitude on current RISC processors, and show the performance beneﬁts of that mechanism for several example applications.},
	language = {en},
	number = {5},
	urldate = {2018-03-13},
	journal = {ACM SIGOPS Operating Systems Review},
	author = {Thekkath, Chandramohan A. and Levy, Henry M.},
	month = dec,
	year = {1994},
	pages = {110--119},
	file = {Thekkath_Levy_1994_Hardware and software support for efficient exception handling.pdf:/home/michael/Dropbox/zotero-pdfs/T/Thekkath_Levy_1994_Hardware and software support for efficient exception handling.pdf:application/pdf}
}

@article{jones_glasgow_nodate,
	title = {The {Glasgow} {Haskell} compiler: a technical overview},
	author = {Jones, Simon L Peyton and Hammond, Cordy Hall Kevin and Partain, Will and Wadler, Phil},
	pages = {9},
	file = {Jones et al_The Glasgow Haskell compiler - a technical overview.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones et al_The Glasgow Haskell compiler - a technical overview.pdf:application/pdf}
}

@article{tarski_lattice-theoretical_1955,
	title = {A lattice-theoretical fixpoint theorem and its applications},
	volume = {5},
	issn = {0030-8730, 0030-8730},
	url = {http://msp.org/pjm/1955/5-2/p11.xhtml},
	doi = {10.2140/pjm.1955.5.285},
	language = {en},
	number = {2},
	urldate = {2018-03-13},
	journal = {Pacific Journal of Mathematics},
	author = {Tarski, Alfred},
	month = jun,
	year = {1955},
	pages = {285--309},
	file = {Tarski_1955_A lattice-theoretical fixpoint theorem and its applications.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tarski_1955_A lattice-theoretical fixpoint theorem and its applications2.pdf:application/pdf}
}

@article{weirich_generative_2011,
	title = {Generative type abstraction and type-level computation},
	volume = {46},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=1925844.1926411},
	doi = {10.1145/1925844.1926411},
	abstract = {Modular languages support generative type abstraction, ensuring that an abstract type is distinct from its representation, except inside the implementation where the two are synonymous. We show that this well-established feature is in tension with the non-parametric features of newer type systems, such as indexed type families and GADTs. In this paper we solve the problem by using kinds to distinguish between parametric and non-parametric contexts. The result is directly applicable to Haskell, which is rapidly developing support for type-level computation, but the same issues should arise whenever generativity and non-parametric features are combined.},
	language = {en},
	number = {1},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Weirich, Stephanie and Vytiniotis, Dimitrios and Peyton Jones, Simon and Zdancewic, Steve},
	month = jan,
	year = {2011},
	pages = {227},
	file = {Weirich et al_2011_Generative type abstraction and type-level computation.pdf:/home/michael/Dropbox/zotero-pdfs/W/Weirich et al_2011_Generative type abstraction and type-level computation.pdf:application/pdf}
}

@inproceedings{weihl_interprocedural_1980,
	title = {Interprocedural data flow analysis in the presence of pointers, procedure variables, and label variables},
	isbn = {978-0-89791-011-8},
	url = {http://portal.acm.org/citation.cfm?doid=567446.567455},
	doi = {10.1145/567446.567455},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Weihl, William E.},
	year = {1980},
	pages = {83--94},
	file = {Weihl_1980_Interprocedural data flow analysis in the presence of pointers, procedure.pdf:/home/michael/Dropbox/zotero-pdfs/W/Weihl_1980_Interprocedural data flow analysis in the presence of pointers, procedure.pdf:application/pdf}
}

@inproceedings{weber_balancing_2013,
	title = {Balancing {Adder} for error tolerant applications},
	isbn = {978-1-4673-5762-3 978-1-4673-5760-9 978-1-4673-5761-6},
	url = {http://ieeexplore.ieee.org/document/6572519/},
	doi = {10.1109/ISCAS.2013.6572519},
	abstract = {Recent imprecise hardware (IHW) design methodologies present opportunities for achieving gains in nonfunctional efficiency design metrics by allowing errors in computation within error tolerant application domains. This work presents a novel imprecise Error Tolerant Balancing Adder (ETBA) design – an augmentation of the ETAIIM IHW adder that reduces errors by introducing a balance block that detects and corrects carry chain inconsistencies in the ETAIIM but operates off the critical path. Furthermore, this work identifies a common class of killer inputs with high error rates for IHW adders, and demonstrates the ETBA’s resilience to these errors. A JPEG decompression case study reveals a 24\% reduction in ETBA addition energy-delay product compared to a Kogge-Stone adder with only a 0.2\% reduction in SSIM image quality.},
	urldate = {2018-03-13},
	publisher = {IEEE},
	author = {Weber, Matthew and Putic, Mateja and {Hang Zhang} and Lach, John and {Jiawei Huang}},
	month = may,
	year = {2013},
	pages = {3038--3041},
	file = {Weber et al_2013_Balancing Adder for error tolerant applications.pdf:/home/michael/Dropbox/zotero-pdfs/W/Weber et al_2013_Balancing Adder for error tolerant applications.pdf:application/pdf}
}

@article{velykis_formal_nodate,
	title = {Formal {Modelling} of {Separation} {Kernels}},
	author = {Velykis, Andrius},
	pages = {228},
	file = {Velykis_Formal Modelling of Separation Kernels.pdf:/home/michael/Dropbox/zotero-pdfs/V/Velykis_Formal Modelling of Separation Kernels.pdf:application/pdf}
}

@inproceedings{vardoulakis_pushdown_2011,
	title = {Pushdown flow analysis of first-class control},
	isbn = {978-1-4503-0865-6},
	url = {http://dl.acm.org/citation.cfm?doid=2034773.2034785},
	doi = {10.1145/2034773.2034785},
	abstract = {Pushdown models are better than control-ﬂow graphs for higherorder ﬂow analysis. They faithfully model the call/return structure of a program, which results in fewer spurious ﬂows and increased precision. However, pushdown models require that calls and returns in the analyzed program nest properly. As a result, they cannot be used to analyze language constructs that break call/return nesting such as generators, coroutines, call/cc, etc.},
	language = {en},
	urldate = {2018-03-13},
	publisher = {ACM Press},
	author = {Vardoulakis, Dimitrios and Shivers, Olin},
	year = {2011},
	pages = {69},
	file = {Vardoulakis_Shivers_2011_Pushdown flow analysis of first-class control.pdf:/home/michael/Dropbox/zotero-pdfs/V/Vardoulakis_Shivers_2011_Pushdown flow analysis of first-class control.pdf:application/pdf}
}

@article{van_horn_relating_2007,
	title = {Relating complexity and precision in control flow analysis},
	volume = {42},
	issn = {03621340},
	url = {http://portal.acm.org/citation.cfm?doid=1291220.1291166},
	doi = {10.1145/1291220.1291166},
	abstract = {We analyze the computational complexity of kCFA, a hierarchy of control ﬂow analyses that determine which functions may be applied at a given call-site. This hierarchy speciﬁes related decision problems, quite apart from any algorithms that may implement their solutions. We identify a simple decision problem answered by this analysis and prove that in the 0CFA case, the problem is complete for polynomial time. The proof is based on a nonstandard, symmetric implementation of Boolean logic within multiplicative linear logic (MLL). We also identify a simpler version of 0CFA related to η-expansion, and prove that it is complete for logarithmic space, using arguments based on computing paths and permutations.},
	language = {en},
	number = {9},
	urldate = {2018-03-13},
	journal = {ACM SIGPLAN Notices},
	author = {Van Horn, David and Mairson, Harry G.},
	month = oct,
	year = {2007},
	pages = {85},
	file = {Van Horn_Mairson_2007_Relating complexity and precision in control flow analysis.pdf:/home/michael/Dropbox/zotero-pdfs/V/Van Horn_Mairson_2007_Relating complexity and precision in control flow analysis.pdf:application/pdf}
}

@inproceedings{laird_calculus_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Calculus} of {Coroutines}},
	isbn = {978-3-540-22849-3 978-3-540-27836-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-27836-8_74},
	doi = {10.1007/978-3-540-27836-8_74},
	abstract = {We describe a simple but expressive calculus of sequential processes, which are represented as coroutines. This calculus can be used to express a variety of programming language features; we give simple macros for procedure calls, labelled jumps, integer references and stacks. We describe the operational properties of the calculus using reduction rules and equational axioms.We describe a notion of categorical model for our calculus, and give a simple example of such a model based on a category of games and strategies. We prove full abstraction results showing that equivalence in the categorical model corresponds to observational equivalence in the calculus, and also to equivalence of evaluation trees, which are infinitary normal forms for the calculus.We show that our categorical model can be used to interpret the untyped λ-calculus and use this fact to extract a sound translation of the λ-calculus into our calculus of coroutines.},
	language = {en},
	urldate = {2018-03-13},
	booktitle = {Automata, {Languages} and {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Laird, J.},
	month = jul,
	year = {2004},
	pages = {882--893},
	file = {Laird_2004_A Calculus of Coroutines.pdf:/home/michael/Dropbox/zotero-pdfs/L/Laird_2004_A Calculus of Coroutines.pdf:application/pdf}
}

@techreport{watson_capability_2014,
	title = {Capability {Hardware} {Enhanced} {RISC} {Instructions}: {CHERI} {Instruction}-set architecture},
	number = {850},
	institution = {University of Cambridge},
	author = {Watson, Robert N. M. and Neumann, Peter G. and Woodruff, Jonathan and Anderson, Jonathan and Chisnall, David and Davis, Brooks and Laurie, Ben and Moore, Simon W. and Murdoch, Steven J. and Roe, Michael},
	month = apr,
	year = {2014},
	file = {Watson et al_2014_Capability Hardware Enhanced RISC Instructions - CHERI Instruction-set.pdf:/home/michael/Dropbox/zotero-pdfs/W/Watson et al_2014_Capability Hardware Enhanced RISC Instructions - CHERI Instruction-set.pdf:application/pdf}
}

@article{ball_slic:_2002,
	title = {{SLIC}: {A} {Specification} {Language} for {Interface} {Checking} (of {C})},
	shorttitle = {{SLIC}},
	url = {https://www.microsoft.com/en-us/research/publication/slic-a-specification-language-for-interface-checking-of-c/},
	abstract = {Modern software systems are built by a multitude of programmers using application program interfaces (APIs). When a software system is built using APIs, there are several classes of problems that can hamper its dependability: a client P of an API may use it improperly; an implementation L may not properly implement the API. There are …},
	language = {en-US},
	urldate = {2018-03-14},
	journal = {Microsoft Research},
	author = {Ball, Tom and Rajamani, Sriram},
	month = jan,
	year = {2002},
	file = {Ball_Rajamani_2002_SLIC - A Specification Language for Interface Checking (of C).pdf:/home/michael/Dropbox/zotero-pdfs/B/Ball_Rajamani_2002_SLIC - A Specification Language for Interface Checking (of C).pdf:application/pdf}
}

@techreport{bevier_mathematical_2004,
	title = {A {Mathematical} {Model} of the {Mach} {Kernel}},
	institution = {Computational Logic, Inc.},
	author = {Bevier, William R. and Smith, Lawrence M.},
	year = {2004},
	file = {Bevier_Smith_2004_A Mathematical Model of the Mach Kernel.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bevier_Smith_2004_A Mathematical Model of the Mach Kernel.pdf:application/pdf}
}

@article{colmerauer_birth_1992,
	title = {The birth of {Prolog}},
	author = {Colmerauer, Alain and Roussel, Philippe},
	month = nov,
	year = {1992},
	file = {Colmerauer_Roussel_1992_The birth of Prolog.pdf:/home/michael/Dropbox/zotero-pdfs/C/Colmerauer_Roussel_1992_The birth of Prolog.pdf:application/pdf}
}

@article{garcia_lopez_edge-centric_2015,
	title = {Edge-centric {Computing}: {Vision} and {Challenges}},
	volume = {45},
	issn = {0146-4833},
	shorttitle = {Edge-centric {Computing}},
	url = {http://doi.acm.org/10.1145/2831347.2831354},
	doi = {10.1145/2831347.2831354},
	abstract = {In many aspects of human activity, there has been a continuous struggle between the forces of centralization and decentralization. Computing exhibits the same phenomenon; we have gone from mainframes to PCs and local networks in the past, and over the last decade we have seen a centralization and consolidation of services and applications in data centers and clouds. We position that a new shift is necessary. Technological advances such as powerful dedicated connection boxes deployed in most homes, high capacity mobile end-user devices and powerful wireless networks, along with growing user concerns about trust, privacy, and autonomy requires taking the control of computing applications, data, and services away from some central nodes (the "core") to the other logical extreme (the "edge") of the Internet. We also position that this development can help blurring the boundary between man and machine, and embrace social computing in which humans are part of the computation and decision making loop, resulting in a human-centered system design. We refer to this vision of human-centered edge-device based computing as Edge-centric Computing. We elaborate in this position paper on this vision and present the research challenges associated with its implementation.},
	number = {5},
	urldate = {2018-03-20},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Garcia Lopez, Pedro and Montresor, Alberto and Epema, Dick and Datta, Anwitaman and Higashino, Teruo and Iamnitchi, Adriana and Barcellos, Marinho and Felber, Pascal and Riviere, Etienne},
	month = sep,
	year = {2015},
	keywords = {cloud computing, decentralized systems, fog computing, peer-to-peer},
	pages = {37--42},
	file = {Garcia Lopez et al_2015_Edge-centric Computing.pdf:/home/michael/Dropbox/zotero-pdfs/G/Garcia Lopez et al_2015_Edge-centric Computing.pdf:application/pdf}
}

@inproceedings{dimopoulos_justice:_2017,
	title = {Justice: {A} {Deadline}-{Aware}, {Fair}-{Share} {Resource} {Allocator} for {Implementing} {Multi}-{Analytics}},
	isbn = {978-1-5386-2326-8},
	shorttitle = {Justice},
	url = {http://ieeexplore.ieee.org/document/8048935/},
	doi = {10.1109/CLUSTER.2017.52},
	abstract = {In this paper, we present Justice, a fair-share deadline-aware resource allocator for big data cluster managers. In resource constrained environments, where resource contention introduces signiﬁcant execution delays, Justice outperforms the popular existing fair-share allocator that is implemented as part of Mesos and YARN. Justice uses deadline information supplied with each job and historical job execution logs to implement admission control. It automatically adapts to changing workload conditions to assign enough resources for each job to meet its deadline “just in time.” We use trace-based simulation of production YARN workloads to evaluate Justice under different deadline formulations. We compare Justice to the existing fairshare allocation policy deployed on cluster managers like YARN and Mesos and ﬁnd that in resource-constrained settings, Justice improves fairness, satisﬁes signiﬁcantly more deadlines, and utilizes resources more efﬁciently.},
	urldate = {2018-03-20},
	publisher = {IEEE},
	author = {Dimopoulos, Stratos and Krintz, Chandra and Wolski, Rich},
	month = sep,
	year = {2017},
	pages = {233--244},
	file = {Dimopoulos et al_2017_Justice.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dimopoulos et al_2017_Justice.pdf:application/pdf}
}

@inproceedings{wolski_probabilistic_2017,
	title = {Probabilistic guarantees of execution duration for {Amazon} spot instances},
	isbn = {978-1-4503-5114-0},
	url = {http://dl.acm.org/citation.cfm?doid=3126908.3126953},
	doi = {10.1145/3126908.3126953},
	abstract = {In this paper we propose D AFTS – a methodology for implementing probabilistic guarantees of instance reliability in the Amazon Spot tier. Amazon o ers “unreliable” virtual machine instances (ones that may be terminated at any time) at a potentially large discount relative to “reliable” On-demand and Reserved instances. Our method predicts the “bid values” that users can specify to provision Spot instances which ensure at least a xed duration of execution with a given probability. We illustrate the method and test its validity using Spot pricing data post facto, both randomly and using real-world workload traces. We also test the e cacy of the method experimentally by using it to launch Spot instances and then observing the instance termination rate. Our results indicate that it is possible to obtain the same level of reliability from unreliable instances that the Amazon service level agreement guarantees for reliable instances with a greatly reduced cost.},
	language = {en},
	urldate = {2018-03-21},
	publisher = {ACM Press},
	author = {Wolski, Rich and Brevik, John and Chard, Ryan and Chard, Kyle},
	year = {2017},
	pages = {1--11},
	file = {Wolski et al_2017_Probabilistic guarantees of execution duration for Amazon spot instances.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wolski et al_2017_Probabilistic guarantees of execution duration for Amazon spot instances.pdf:application/pdf}
}

@inproceedings{dimopoulos_pythia:_2017,
	title = {{PYTHIA}: {Admission} {Control} for {Multi}-{Framework}, {Deadline}- {Driven}, {Big} {Data} {Workloads}},
	isbn = {978-1-5386-1993-3},
	shorttitle = {{PYTHIA}},
	url = {http://ieeexplore.ieee.org/document/8030625/},
	doi = {10.1109/CLOUD.2017.69},
	abstract = {In this paper, we present PYTHIA, deadline-aware admission control for systems that execute jobs from multiple big data (batch) frameworks using shared resources. PYTHIA adds support for deadline-driven workloads in resource-constrained cloud settings, for use by resource negotiators such as Apache Mesos or YARN. PYTHIA uses histories of job statistics to estimate the minimum number of CPUs to allocate to a job in order for it to meet its deadline. PYTHIA admits jobs when these resources are available. Any job not admitted “fails fast” and wastes no resources. We implement a PYTHIA prototype and empirically evaluate it using production YARN traces under different resource constraints and deadline assignments. Our results show that PYTHIA is able to meet signiﬁcantly more deadlines than fair share approaches and wastes fewer cloud resources in resource-limited scenarios, for the workloads, cluster sizes, and deadline assignments that we consider.},
	urldate = {2018-03-21},
	publisher = {IEEE},
	author = {Dimopoulos, Stratos and Krintz, Chandra and Wolski, Rich},
	month = jun,
	year = {2017},
	pages = {488--495},
	file = {Dimopoulos et al_2017_PYTHIA.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dimopoulos et al_2017_PYTHIA.pdf:application/pdf}
}

@inproceedings{jayathilaka_response_2015,
	address = {New York, NY, USA},
	series = {{SoCC} '15},
	title = {Response {Time} {Service} {Level} {Agreements} for {Cloud}-hosted {Web} {Applications}},
	isbn = {978-1-4503-3651-2},
	url = {http://doi.acm.org/10.1145/2806777.2806842},
	doi = {10.1145/2806777.2806842},
	abstract = {Cloud computing is a successful model for hosting web-facing applications that are accessed by their users as services. While clouds currently offer Service Level Agreements (SLAs) containing guarantees of availability, they do not make performance guarantees for deployed applications. In this work we present Cerebro -- a system for establishing statistical guarantees of application response time in cloud settings. Cerebro combines off-line static analysis of application control structure with on-line cloud performance monitoring and statistical forecasting to predict bounds on the response time of web-facing application programming interfaces (APIs). Because Cerebro does not require application instrumentation or per-application cloud benchmarking, it does not impose any runtime overhead, and is suitable for use at cloud scales. Also, because the bounds are statistical, they are appropriate for use as the basis for SLAs between cloud-hosted applications and their users. We investigate the correctness of Cerebro predictions, the tightness of their bounds, and the duration over which the bounds persist in both Google App Engine and AppScale (public and private cloud platforms respectively). We also detail the effectiveness of our SLA prediction methodology compared to other performance bound estimation methods based on simple statistical analysis.},
	urldate = {2018-03-21},
	booktitle = {Proceedings of the {Sixth} {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {ACM},
	author = {Jayathilaka, Hiranya and Krintz, Chandra and Wolski, Rich},
	year = {2015},
	keywords = {cloud computing, SLA, web APIs},
	pages = {315--328},
	file = {Jayathilaka et al_2015_Response Time Service Level Agreements for Cloud-hosted Web Applications.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jayathilaka et al_2015_Response Time Service Level Agreements for Cloud-hosted Web Applications.pdf:application/pdf}
}

@inproceedings{nurmi_eucalyptus_2009,
	address = {Washington, DC, USA},
	series = {{CCGRID} '09},
	title = {The {Eucalyptus} {Open}-{Source} {Cloud}-{Computing} {System}},
	isbn = {978-0-7695-3622-4},
	url = {http://dx.doi.org/10.1109/CCGRID.2009.93},
	doi = {10.1109/CCGRID.2009.93},
	abstract = {Cloud computing systems fundamentally provide access to large pools of data and computational resources through a variety of interfaces similar in spirit to existing grid and HPC resource management and programming systems. These types of systems offer a new programming target for scalable application developers and have gained popularity over the past few years. However, most cloud computing systems in operation today are proprietary, rely upon infrastructure that is invisible to the research community, or are not explicitly designed to be instrumented and modified by systems researchers. In this work, we present Eucalyptus -- an open-source software framework for cloud computing that implements what is commonly referred to as Infrastructure as a Service (IaaS); systems that give users the ability to run and control entire virtual machine instances deployed across a variety physical resources. We outline the basic principles of the Eucalyptus design, detail important operational aspects of the system, and discuss architectural trade-offs that we have made in order to allow Eucalyptus to be portable, modular and simple to use on infrastructure commonly found within academic settings. Finally, we provide evidence that Eucalyptus enables users familiar with existing Grid and HPC systems to explore new cloud computing functionality while maintaining access to existing, familiar application development software and Grid middle-ware.},
	urldate = {2018-03-21},
	booktitle = {Proceedings of the 2009 9th {IEEE}/{ACM} {International} {Symposium} on {Cluster} {Computing} and the {Grid}},
	publisher = {IEEE Computer Society},
	author = {Nurmi, Daniel and Wolski, Rich and Grzegorczyk, Chris and Obertelli, Graziano and Soman, Sunil and Youseff, Lamia and Zagorodnov, Dmitrii},
	year = {2009},
	keywords = {virtualization, cloud computing},
	pages = {124--131},
	file = {Nurmi et al_2009_The Eucalyptus Open-Source Cloud-Computing System.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nurmi et al_2009_The Eucalyptus Open-Source Cloud-Computing System.pdf:application/pdf}
}

@inproceedings{toka_online_2010,
	title = {Online {Data} {Backup}: {A} {Peer}-{Assisted} {Approach}},
	shorttitle = {Online {Data} {Backup}},
	doi = {10.1109/P2P.2010.5570003},
	abstract = {In this work we study the benefits of a peer- assisted approach to online backup applications, in which spare bandwidth and storage space of end- hosts complement that of an online storage service. Via simulations, we analyze the interplay between two key aspects of such applications: data placement and bandwidth allocation. Our analysis focuses on metrics such as the time required to complete a backup and a restore operation, as well as the storage costs. We show that, by using adequate bandwidth allocation policies in which storage space at a cloud provider can be used temporarily, hybrid systems can achieve performance comparable to traditional client-server architectures at a fraction of the costs. Moreover, we explore the impact of mechanisms to impose fairness and conclude that a peer-assisted approach does not discriminate peers in terms of performance, but associates a storage cost to peers contributing with little resources.},
	booktitle = {2010 {IEEE} {Tenth} {International} {Conference} on {Peer}-to-{Peer} {Computing} ({P}2P)},
	author = {Toka, L. and Dell'Amico, M. and Michiardi, P.},
	month = aug,
	year = {2010},
	keywords = {security of data, cache storage, Computer crashes, Internet, Availability, back-up procedures, Bandwidth, bandwidth allocation, bandwidth allocation policy, Channel allocation, client-server architectures, client-server systems, online backup applications, online storage service, Peer to peer computing, peer-assisted approach, peer-to-peer computing, Redundancy, Servers},
	pages = {1--10},
	file = {Toka et al_2010_Online Data Backup.pdf:/home/michael/Dropbox/zotero-pdfs/T/Toka et al_2010_Online Data Backup.pdf:application/pdf}
}

@article{lee_swarm_2014,
	title = {The {Swarm} at the {Edge} of the {Cloud}},
	volume = {31},
	issn = {2168-2356},
	doi = {10.1109/MDAT.2014.2314600},
	abstract = {The paper explains how to use sensors as the eyes, ears, hands, and feet for the cloud. This paper describes the opportunities and challenges when integrating sensors and cloud computing.},
	number = {3},
	journal = {IEEE Design Test},
	author = {Lee, E. A. and Hartmann, B. and Kubiatowicz, J. and Rosing, T. Simunic and Wawrzynek, J. and Wessel, D. and Rabaey, J. and Pister, K. and Sangiovanni-Vincentelli, A. and Seshia, S. A. and Blaauw, D. and Dutta, P. and Fu, K. and Guestrin, C. and Taskar, B. and Jafari, R. and Jones, D. and Kumar, V. and Mangharam, R. and Pappas, G. J. and Murray, R. M. and Rowe, A.},
	month = jun,
	year = {2014},
	keywords = {Computational modeling, wireless sensor networks, Embedded systems, cloud computing, Actuators, Cloud computing, embedded systems, Mobile communication, Monitoring, Paricle swarm optimization, TerraSwarm applications},
	pages = {8--20},
	file = {Lee et al_2014_The Swarm at the Edge of the Cloud.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee et al_2014_The Swarm at the Edge of the Cloud.pdf:application/pdf}
}

@inproceedings{ryden_nebula:_2014,
	title = {Nebula: {Distributed} {Edge} {Cloud} for {Data} {Intensive} {Computing}},
	shorttitle = {Nebula},
	doi = {10.1109/IC2E.2014.34},
	abstract = {Centralized cloud infrastructures have become the de-facto platform for data-intensive computing today. However, they suffer from inefficient data mobility due to the centralization of cloud resources, and hence, are highly unsuited for dispersed-data-intensive applications, where the data may be spread at multiple geographical locations. In this paper, we present Nebula: a dispersed cloud infrastructure that uses voluntary edge resources for both computation and data storage. We describe the lightweight Nebula architecture that enables distributed data-intensive computing through a number of optimizations including location-aware data and computation placement, replication, and recovery. We evaluate Nebula's performance on an emulated volunteer platform that spans over 50 PlanetLab nodes distributed across Europe, and show how a common data-intensive computing framework, MapReduce, can be easily deployed and run on Nebula. We show Nebula MapReduce is robust to a wide array of failures and substantially outperforms other wide-area versions based on a BOINC like model.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Cloud} {Engineering}},
	author = {Ryden, M. and Oh, K. and Chandra, A. and Weissman, J.},
	month = mar,
	year = {2014},
	keywords = {cloud computing, Bandwidth, Monitoring, BOINC like model, centralized cloud infrastructures, Cloud programming models and tools, cloud resource centralization, computation placement, Data Intensive, data mobility, data storage, de-facto platform, dispersed cloud infrastructure, distributed data-intensive computing, Distributed databases, distributed edge cloud, Edge, emulated volunteer platform, Europe, Fault tolerance, Fault tolerant systems, Geo-distributed, Load management, location-aware data, MapReduce, Nebula architecture, parallel processing, PlanetLab, Processor scheduling, recovery, replication, resource allocation, storage management, Voluntary, voluntary edge resources},
	pages = {57--66},
	file = {Ryden et al_2014_Nebula.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ryden et al_2014_Nebula.pdf:application/pdf}
}

@inproceedings{berger_diehard:_2006,
	address = {New York, NY, USA},
	series = {{PLDI} '06},
	title = {{DieHard}: {Probabilistic} {Memory} {Safety} for {Unsafe} {Languages}},
	isbn = {978-1-59593-320-1},
	shorttitle = {{DieHard}},
	url = {http://doi.acm.org/10.1145/1133981.1134000},
	doi = {10.1145/1133981.1134000},
	abstract = {Applications written in unsafe languages like C and C++ are vulnerable to memory errors such as buffer overflows, dangling pointers, and reads of uninitialized data. Such errors can lead to program crashes, security vulnerabilities, and unpredictable behavior. We present DieHard, a runtime system that tolerates these errors while probabilistically maintaining soundness. DieHard uses randomization and replication to achieve probabilistic memory safety by approximating an infinite-sized heap. DieHard's memory manager randomizes the location of objects in a heap that is at least twice as large as required. This algorithm prevents heap corruption and provides a probabilistic guarantee of avoiding memory errors. For additional safety, DieHard can operate in a replicated mode where multiple replicas of the same application are run simultaneously. By initializing each replica with a different random seed and requiring agreement on output, the replicated version of Die-Hard increases the likelihood of correct execution because errors are unlikely to have the same effect across all replicas. We present analytical and experimental results that show DieHard's resilience to a wide range of memory errors, including a heap-based buffer overflow in an actual application.},
	urldate = {2018-03-21},
	booktitle = {Proceedings of the 27th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Berger, Emery D. and Zorn, Benjamin G.},
	year = {2006},
	keywords = {replication, DieHard, dynamic memory allocation, probabilistic memory safety, randomization},
	pages = {158--168},
	file = {Berger_Zorn_2006_DieHard.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berger_Zorn_2006_DieHard.pdf:application/pdf}
}

@book{stoy_denotational_1977,
	address = {Cambridge, MA, USA},
	title = {Denotational {Semantics}: {The} {Scott}-{Strachey} {Approach} to {Programming} {Language} {Theory}},
	isbn = {978-0-262-19147-0},
	shorttitle = {Denotational {Semantics}},
	abstract = {From the Publisher:"First book-length exposition of the denotational (or `mathematical' or `functional') approach to the formal semantics of programming languages (in contrast to `operational' and `axiomatic' approaches). Treats various kinds of languages, beginning with the pure-lambda-calculus and progressing through languages with states, commands, jumps, and assignments. This somewhat discursive account is a valuable compilation of results not otherwise available in a single source." -- American Mathematical Monthly},
	publisher = {MIT Press},
	author = {Stoy, Joseph E.},
	year = {1977}
}

@article{rhiger_foundation_2003,
	title = {A foundation for embedded languages},
	volume = {25},
	issn = {01640925},
	url = {http://portal.acm.org/citation.cfm?doid=641909.641910},
	doi = {10.1145/641909.641910},
	abstract = {Recent work on embedding object languages into Haskell use “phantom types” (i.e., parameterized types whose parameter does not occur on the right-hand side of the type deﬁnition) to ensure that the embedded object-language terms are simply typed. But is it a safe assumption that only simply-typed terms can be represented in Haskell using phantom types? And conversely, can all simply-typed terms be represented in Haskell under the restrictions imposed by phantom types? In this article we investigate the conditions under which these assumptions are true: We show that these questions can be answered aﬃrmatively for an idealized Haskell-like language and discuss to which extent Haskell can be used as a meta-language.},
	language = {en},
	number = {3},
	urldate = {2018-03-21},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Rhiger, Morten},
	month = may,
	year = {2003},
	pages = {291--315},
	file = {Rhiger - 2003 - A foundation for embedded languages.pdf:/home/michael/Zotero/storage/VTQLLSCW/Rhiger - 2003 - A foundation for embedded languages.pdf:application/pdf}
}

@article{birkedal_bigraphical_nodate,
	title = {Bigraphical {Programming} {Languages} for {Pervasive} {Computing}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/similar?doi=10.1.1.68.7240&type=ab},
	abstract = {CiteSeerX - Document Details (Isaac Councill, Lee Giles): ... Grand Challenge by researching the use of bigraphical reactive systems as a general framework in which to combine theories for design and analysis with techniques, tools and methodologies for engineering and systems building. Initial work has been addressing Context-awareness, business processes and Reactive XML, axiomatisation and matching, and higherorder mobile embedded resources.},
	language = {en},
	urldate = {2018-03-21},
	author = {Birkedal, L. and Bundgaard, M. and Damgaard, T. C. and Debois, S. and Elsborg, E. and Glenstrup, A. J. and Hildebrandt, T. and Milner, R. and Niss, H.}
}

@article{milner_pervasive_2006,
	series = {Proceedings of the {Workshop} "{Essays} on {Algebraic} {Process} {Calculi}" ({APC} 25)},
	title = {Pervasive {Process} {Calculus}},
	volume = {162},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066106004439},
	doi = {10.1016/j.entcs.2005.12.112},
	abstract = {Process calculi with various signatures and reaction rules may provide a theoretical basis for pervasive computing.},
	urldate = {2018-03-21},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Milner, Robin},
	month = sep,
	year = {2006},
	keywords = {bigraph, graph-rewriting, mobile agent, pervasive computing, process calculus},
	pages = {255--259},
	file = {Milner_2006_Pervasive Process Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_2006_Pervasive Process Calculus.pdf:application/pdf}
}

@article{negash_dos-il:_2017,
	series = {8th {International} {Conference} on {Ambient} {Systems}, {Networks} and {Technologies}, {ANT}-2017 and the 7th {International} {Conference} on {Sustainable} {Energy} {Information} {Technology}, {SEIT} 2017, 16-19 {May} 2017, {Madeira}, {Portugal}},
	title = {{DoS}-{IL}: {A} {Domain} {Specific} {Internet} of {Things} {Language} for {Resource} {Constrained} {Devices}},
	volume = {109},
	issn = {1877-0509},
	shorttitle = {{DoS}-{IL}},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050917310876},
	doi = {10.1016/j.procs.2017.05.411},
	abstract = {The common approach enabling a resource constrained device to get connected to the Internet is through programming instructions and transferring it to an embedded device. This procedure involves various tools and cross-compiling of the code depending on the platform architecture. In practical IoT applications, where a huge number of nodes exist, this process becomes almost impossible due to the heterogeneous platforms and protocols involved and the deployment conditions. This paper introduces a flexible and scalable approach that enhances modifiability and programmability through client-server-server-client architecture. It allows changing the behavior of the system after deployment through a lightweight script written with a domain specific language, DoS-IL, and stored in a gateway at the fog layer. An embedded resource browser is used to request and execute the script. The results of analysis for this model and the tools developed along the way are discussed.},
	urldate = {2018-03-21},
	journal = {Procedia Computer Science},
	author = {Negash, Behailu and Westerlund, Tomi and Rahmani, Amir M. and Liljeberg, Pasi and Tenhunen, Hannu},
	month = jan,
	year = {2017},
	keywords = {Architecture, Domain Specific Language, Internet of Things (IoT), Interoperability, IoT-A, Programmability, Scalability},
	pages = {416--423},
	file = {Negash et al_2017_DoS-IL - A Domain Specific Internet of Things Language for Resource Constrained.pdf:/home/michael/Dropbox/zotero-pdfs/N/Negash et al_2017_DoS-IL - A Domain Specific Internet of Things Language for Resource Constrained.pdf:application/pdf}
}

@incollection{oiwa_fail-safe_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Fail-{Safe} {ANSI}-{C} {Compiler}: {An} {Approach} to {Making} {C} {Programs} {Secure} {Progress} {Report}},
	isbn = {978-3-540-00708-1 978-3-540-36532-7},
	shorttitle = {Fail-{Safe} {ANSI}-{C} {Compiler}},
	url = {https://link.springer.com/chapter/10.1007/3-540-36532-X_9},
	abstract = {It is well known that programs written in C are apt to suffer from nasty errors due to dangling pointers and/or buffer overflow. In particular, such errors in Internet servers are often exploited by malicious attackers to “crack” an entire system, which becomes even social problems nowadays. Nevertheless, it is yet unrealistic to throw away the C language at once because of legacy programs and legacy programmers. To alleviate this dilemma, many approaches to safe implementations of the C language-such as Safe C and CCured—have been proposed and implemented. To our knowledge, however, none of them support all the features of the ANSI C standard and prevent all unsafe operations. (By unsafe operations, we mean any operation that leads to “undefined behavior”, such as array boundary overrun and dereference of a pointer in a wrong type.) This paper describes a memory-safe implementation of the full ANSI C language. Our implementation detects and disallows all unsafe operations, yet conforming to the full ANSI C standard (including casts and unions) and even supporting many “dirty tricks” common in programs beyond ANSI C. This is achieved using sophisticated representations of pointers (and integers) that contain dynamic type and size information. We also devise several techniques—both compile-time and runtime—to reduce the overhead of runtime checks.},
	language = {en},
	urldate = {2018-03-26},
	booktitle = {Software {Security} — {Theories} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Oiwa, Yutaka and Sekiguchi, Tatsurou and Sumii, Eijiro and Yonezawa, Akinori},
	year = {2003},
	doi = {10.1007/3-540-36532-X_9},
	pages = {133--153},
	file = {Oiwa et al_2003_Fail-Safe ANSI-C Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/O/Oiwa et al_2003_Fail-Safe ANSI-C Compiler.pdf:application/pdf}
}

@misc{noauthor_saber-c_nodate,
	title = {Saber-{C} --- {An} {Interpreter}-based {Programming} {Environment} for the {C} {Language} {\textbar} {BibSonomy}},
	url = {https://www.bibsonomy.org/bibtex/21e785f8868649a455d3071bddf8e9fd5/liangzk},
	urldate = {2018-03-26}
}

@article{wright_practical_1997,
	title = {A {Practical} {Soft} {Type} {System} for {Scheme}},
	volume = {19},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/239912.239917},
	doi = {10.1145/239912.239917},
	abstract = {A soft type system infers types for the procedures and data structures of dynamically typed programs. Like conventional static types, soft types express program invariants and thereby provide valuable information for program optimization and debugging. A soft type checker uses the types inferred by a soft type system to eliminate run-time checks that are provably unnecessary; any remaining run-time checks are flagged as potential program errors. Soft Scheme is a practical soft type checker for R4RS Scheme. Its underlying type system generalizes conventional Hindley-Milner type inference by incorporating recursive types and a limited form of union type. Soft Scheme accommodates all of R4RS Scheme including uncurried procedures of fixed and variable arity, assignment, and continuations.},
	number = {1},
	urldate = {2018-03-26},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Wright, Andrew K. and Cartwright, Robert},
	month = jan,
	year = {1997},
	keywords = {run-time checks, soft typing},
	pages = {87--152},
	file = {Wright_Cartwright_1997_A Practical Soft Type System for Scheme.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wright_Cartwright_1997_A Practical Soft Type System for Scheme.pdf:application/pdf}
}

@inproceedings{cartwright_soft_1991,
	address = {New York, NY, USA},
	series = {{PLDI} '91},
	title = {Soft {Typing}},
	isbn = {978-0-89791-428-4},
	url = {http://doi.acm.org/10.1145/113445.113469},
	doi = {10.1145/113445.113469},
	urldate = {2018-03-26},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1991 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Cartwright, Robert and Fagan, Mike},
	year = {1991},
	pages = {278--292},
	file = {Cartwright_Fagan_1991_Soft Typing.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cartwright_Fagan_1991_Soft Typing.pdf:application/pdf}
}

@inproceedings{jagannathan_effective_1995,
	title = {Effective {Flow} {Analysis} for {Avoiding} {Run}-{Time} {Checks}},
	abstract = {. This paper describes a general purpose program analysis that computes global control-flow and data-flow information for higher-order, call-by-value programs. This information can be used to drive global program optimizations such as inlining and run-time check elimination, as well as optimizations like constant folding and loop invariant code motion that are typically based on special-purpose local analyses. The analysis employs a novel approximation technique called polymorphic splitting that uses let-expressions as syntactic clues to gain precision. Polymorphic splitting borrows ideas from Hindley-Milner polymorphic type inference systems to create an analog to polymorphism for flow analysis. Experimental results derived from an implementation of the analysis for Scheme indicate that the analysis is extremely precise and has reasonable cost. In particular, it eliminates significantly more run-time checks than simple flow analyses (i.e. 0CFA) or analyses based on type ...},
	booktitle = {In {Proceedings} of the 1995 {International} {Static} {Analysis} {Symposium}},
	publisher = {Springer-Verlag},
	author = {Jagannathan, Suresh and Wright, Andrew},
	year = {1995},
	pages = {207--224},
	file = {Jagannathan_Wright_1995_Effective Flow Analysis for Avoiding Run-Time Checks.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jagannathan_Wright_1995_Effective Flow Analysis for Avoiding Run-Time Checks.pdf:application/pdf}
}

@inproceedings{loginov_debugging_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Debugging via {Run}-{Time} {Type} {Checking}},
	isbn = {978-3-540-41863-4 978-3-540-45314-7},
	url = {https://link.springer.com/chapter/10.1007/3-540-45314-8_16},
	doi = {10.1007/3-540-45314-8_16},
	abstract = {This paper describes the design and implementation of a tool for C programs that provides run-time checks based on type information. The tool instruments a program to monitor the type stored in each memory location. Whenever a value is written into a location, the location’s run-time type tag is updated to match the type of the value. Also, the location’s static type is compared with the value’s type; if there is a mismatch, a warning message is issued. Whenever the value in a location is used, its run-time type tag is checked, and if the type is inappropriate in the context in which the value is being used, an error message is issued. The tool has been used to pinpoint the cause of bugs in several Solaris utilities and Olden benchmarks, usually providing information that is succinct and precise.},
	language = {en},
	urldate = {2018-03-26},
	booktitle = {Fundamental {Approaches} to {Software} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Loginov, Alexey and Yong, Suan Hsi and Horwitz, Susan and Reps, Thomas},
	month = apr,
	year = {2001},
	pages = {217--232},
	file = {Loginov et al_2001_Debugging via Run-Time Type Checking.pdf:/home/michael/Dropbox/zotero-pdfs/L/Loginov et al_2001_Debugging via Run-Time Type Checking.pdf:application/pdf}
}

@book{patil_efficient_1995,
	title = {Efficient {Run}-time {Monitoring} {Using} {Shadow} {Processing}},
	abstract = {General purpose multiprocessors are becoming increasingly common. We propose using  pairs of processors, one running an ordinary application program and the other monitoring  the application's execution. We call the processor doing the monitoring a "shadow processor,  " as it "shadows" the main processor's execution. We have developed a prototype  shadow processing system which supports full-size programs written in C. Our system  instruments an executable user program in C to obtain a "main process" and a "shadow  process." The main process performs computations from the original program, occasionally  communicating a few key values to the shadow process. The shadow process follows  the main process, checking pointer and array accesses and detecting memory leaks. The  overhead to the main process is very low --- almost always less than 10\%. Further, since  the shadow process avoids repeating some of the computations from the input program, it  runs much faster than a single process pe...},
	author = {Patil, Harish and Fischer, Charles},
	year = {1995},
	file = {Patil_Fischer_1995_Efficient Run-time Monitoring Using Shadow Processing.pdf:/home/michael/Dropbox/zotero-pdfs/P/Patil_Fischer_1995_Efficient Run-time Monitoring Using Shadow Processing.pdf:application/pdf}
}

@article{jones_backwards-compatible_1997,
	title = {Backwards-compatible bounds checking for arrays and pointers in {C} programs},
	abstract = {This paper presents a new approach to enforcing array bounds and pointer checking in the C language. Checking is rigorous in the sense that the result of pointer arithmetic must refer to the same object as the original pointer (this object is sometimes called the 'intended referent'). The novel aspect of this work is that checked code can inter-operate without restriction with unchecked code, without interface problems, with some e ective checking, and without false alarms. This {\textbackslash}backwards compatibility" property allows the overheads of checking to be con ned to suspect modules, and also facilitates the use of libraries for which source code is not available. The paper describes the scheme, its prototype implementation (as an extension to the GNU C compiler), presents experimental results to evaluate its e ectiveness, and discusses performance issues and the e ectiveness of some simple optimisations.},
	language = {en},
	author = {Jones, Richard W M and Kelly, Paul H J},
	year = {1997},
	pages = {14},
	file = {Jones_Kelly_1997_Backwards-compatible bounds checking for arrays and pointers in C programs.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Kelly_1997_Backwards-compatible bounds checking for arrays and pointers in C programs.pdf:application/pdf}
}

@inproceedings{ramalingam_aggregate_1999,
	address = {New York, NY, USA},
	series = {{POPL} '99},
	title = {Aggregate {Structure} {Identification} and {Its} {Application} to {Program} {Analysis}},
	isbn = {978-1-58113-095-9},
	url = {http://doi.acm.org/10.1145/292540.292553},
	doi = {10.1145/292540.292553},
	abstract = {In this paper, we describe an efficient algorithm for lazily decomposing aggregates such as records and arrays into simpler components based on the access patterns specific to a given program. This process allows us both to identify implicit aggregate structure not evident from declarative information in the program, and to simplify the representation of declared aggregates when references are made only to a subset of their components. We show that the structure identification process can be exploited to yield the following principal results: - A fast type analysis algorithm applicable to program maintenance applications such as date usage inference for the "Year 2000" problem. - An efficient algorithm for atomization of aggregates. Given a program, an aggregate atomization decomposes all of the data that can be manipulated by the program into a set of disjoint atoms such that each data reference can be modeled as one or more references to atoms without loss of semantic information. Aggregate atomization can be used to adapt program analyses and representations designed for scalar data to aggregate data. In particular, atomization can be used to build more precise versions of program representations such as SSA form or PDGs. Such representations can in turn yield more accurate results for problems such as program slicing.Our techniques are especially useful in weakly-typed languages such as Cobol (where a variable need not be declared as an aggregate to store an aggregate value) and in languages where references to statically-defined subranges of data such as arrays or strings are allowed.},
	urldate = {2018-03-26},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Ramalingam, G. and Field, John and Tip, Frank},
	year = {1999},
	pages = {119--132},
	file = {Ramalingam et al_1999_Aggregate Structure Identification and Its Application to Program Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ramalingam et al_1999_Aggregate Structure Identification and Its Application to Program Analysis.pdf:application/pdf}
}

@article{boehm_garbage_1988,
	title = {Garbage {Collection} in an {Uncooperative} {Environment}},
	volume = {18},
	issn = {0038-0644},
	url = {http://dx.doi.org/10.1002/spe.4380180902},
	doi = {10.1002/spe.4380180902},
	number = {9},
	urldate = {2018-03-26},
	journal = {Softw. Pract. Exper.},
	author = {Boehm, Hans-Juergen and Weiser, Mark},
	month = sep,
	year = {1988},
	pages = {807--820},
	file = {Boehm_Weiser_1988_Garbage Collection in an Uncooperative Environment.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boehm_Weiser_1988_Garbage Collection in an Uncooperative Environment.pdf:application/pdf}
}

@inproceedings{cardelli_modula-3_1989,
	title = {The {Modula}-3 type system},
	isbn = {978-0-89791-294-5},
	url = {http://portal.acm.org/citation.cfm?doid=75277.75295},
	doi = {10.1145/75277.75295},
	abstract = {This paper presents an overview of the programming language Modula-3, and a more detailed description of its type system.},
	language = {en},
	urldate = {2018-03-26},
	publisher = {ACM Press},
	author = {Cardelli, L. and Donahue, J. and Jordan, M. and Kalsow, B. and Nelson, G.},
	year = {1989},
	pages = {202--212},
	file = {Cardelli et al_1989_The Modula-3 type system.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli et al_1989_The Modula--3 type system.pdf:application/pdf}
}

@techreport{liskov_clu_1979,
	address = {Cambridge, MA, USA},
	title = {{CLU} {REFERENCE} {MANUAL}},
	abstract = {This document serves both as an introduction to CLU and as a language reference manual. Sections 1 through 4 present an overview of the language. These sections highlight the essential features of CLU, and discuss how CLU differs from other, more conventional, languages. Sections 5 though 13 form the reference manual proper. These sections describe each aspect of CLU in detail, and discuss the proper use of various features. Appendices 1 though III provide concise summaries of CLU''s syntax, data types, and I/O facilities. Appendix IV contains example programs.},
	institution = {Massachusetts Institute of Technology},
	author = {Liskov, B. and Atkinson, R. R. and Bloom, T. and Moss, E. B. and Schaffert, R. and Snyder, A.},
	year = {1979},
	file = {Liskov et al_1979_CLU REFERENCE MANUAL.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liskov et al_1979_CLU REFERENCE MANUAL.pdf:application/pdf}
}

@book{boehm_proposal_1992,
	title = {A {Proposal} for {Garbage}-{Collector}-{Safe} {C} {Compilation}},
	abstract = {Conservative garbage collectors are commonlyused in combination with conventional C programs. Empirically, this usually works well. However, there are no guarantees that this is safe in the presence of "improved" compiler optimization. We propose that C compilers provide a facility to suppress optimizations that are unsafe in the presence of conservative garbage collection. Such a facility can be added to an existing compiler at very minimal cost, provided the additional analysis is done in a machine-independent source-to-source prepass. Such a prepass may also check the source code for garbage-collector-safety. Garbage Collection and C  C programs normally allocate dynamic memory using malloc, and explicitly deallocate memory by calling  free when it is no longer needed. This approach is simple to describe and relatively simple to implement. Both malloc and free can be implemented reasonably efficiently with fairly predictable execution time. However, the need for explicit deallocatio...},
	author = {Boehm, Hans-J. and Chase, David},
	year = {1992},
	file = {Boehm_Chase_1992_A Proposal for Garbage-Collector-Safe C Compilation.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boehm_Chase_1992_A Proposal for Garbage-Collector-Safe C Compilation.pdf:application/pdf}
}

@article{tong_automatic_2016,
	title = {Automatic {Generation} of {Probabilistic} {Programming} from {Time} {Series} {Data}},
	url = {http://arxiv.org/abs/1607.00710},
	abstract = {Probabilistic programming languages represent complex data with intermingled models in a few lines of code. Efficient inference algorithms in probabilistic programming languages make possible to build unified frameworks to compute interesting probabilities of various large, real-world problems. When the structure of model is given, constructing a probabilistic program is rather straightforward. Thus, main focus have been to learn the best model parameters and compute marginal probabilities. In this paper, we provide a new perspective to build expressive probabilistic program from continue time series data when the structure of model is not given. The intuition behind of our method is to find a descriptive covariance structure of time series data in nonparametric Gaussian process regression. We report that such descriptive covariance structure efficiently derives a probabilistic programming description accurately.},
	urldate = {2018-03-22},
	journal = {arXiv:1607.00710 [stat]},
	author = {Tong, Anh and Choi, Jaesik},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.00710},
	keywords = {Statistics - Machine Learning},
	file = {Tong_Choi_2016_Automatic Generation of Probabilistic Programming from Time Series Data.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tong_Choi_2016_Automatic Generation of Probabilistic Programming from Time Series Data.pdf:application/pdf}
}

@article{bezanson_julia:_nodate,
	title = {Julia: {A} {Fast} {Dynamic} {Language} for {Technical} {Computing}},
	abstract = {Dynamic languages have become popular for scientiﬁc computing. They are generally considered highly productive, but lacking in performance. This paper presents Julia, a new dynamic language for technical computing, designed for performance from the beginning by adapting and extending modern programming language techniques. A design based on generic functions and a rich type system simultaneously enables an expressive programming model and successful type inference, leading to good performance for a wide range of programs. This makes it possible for much of Julia’s library to be written in Julia itself, while also incorporating best-of-breed C and Fortran libraries.},
	language = {en},
	author = {Bezanson, Jeﬀ and Karpinski, Stefan and Shah, Viral B and Edelman, Alan},
	pages = {27},
	file = {Bezanson et al. - Julia A Fast Dynamic Language for Technical Compu.pdf:/home/michael/Zotero/storage/F428RL2B/Bezanson et al. - Julia A Fast Dynamic Language for Technical Compu.pdf:application/pdf}
}

@inproceedings{ward_hardware_2002,
	title = {Hardware implementation of programming languages for real-time},
	doi = {10.1109/RTTAS.2002.1137403},
	abstract = {Real-Time Systems place large demands on the languages used to implement them. The current, processor based implementation methods do not allow accurate timing analysis due to the complexity of modern processors. FPGAs provide a means to implement a real-time system in a way that allows accurate timing analysis. Existing implementations of programming languages in hardware do not support the needs of a real time system. This paper presents a hardware implementation of SPARK Ada that allows accurate timing analysis.},
	booktitle = {Proceedings. {Eighth} {IEEE} {Real}-{Time} and {Embedded} {Technology} and {Applications} {Symposium}},
	author = {Ward, M. and Audsley, N. C.},
	year = {2002},
	keywords = {programming languages, FPGAs, Computer languages, Hardware, Books, Processor scheduling, Ada, computational complexity, Field programmable gate arrays, hardware implementation, Interference, Predictive models, processor based implementation methods, real time systems, Real time systems, real-time systems, SPARK Ada, Sparks, Timing, timing analysis},
	pages = {276--285},
	file = {Ward_Audsley_2002_Hardware implementation of programming languages for real-time.pdf:/home/michael/Dropbox/zotero-pdfs/W/Ward_Audsley_2002_Hardware implementation of programming languages for real-time.pdf:application/pdf}
}

@misc{lee_system_nodate,
	title = {System and {Language} {Support} for {Timing} {Constraints}},
	language = {en},
	author = {Lee, Insup},
	file = {Lee - System and Language Support for Timing Constraints.pdf:/home/michael/Zotero/storage/53PXXCQG/Lee - System and Language Support for Timing Constraints.pdf:application/pdf}
}

@inproceedings{ko_supporting_1996,
	title = {Supporting the specification and analysis of timing constraints},
	doi = {10.1109/RTTAS.1996.509534},
	abstract = {Real-time programmers have to deal with the problem of relating timing constraints associated with source code to sequences of machine instructions. This paper describes an environment to assist users in the specification and analysis of timing constraints. A user is allowed specify timing constraints within the source code of a C program. A user interface for a timing analyzer was developed to depict whether these constraints were violated or met. In addition, the interface allows portions of programs to be quickly selected with the corresponding bounded times, source code lines, and machine instructions automatically displayed The result is a user-friendly environment that supports the user specification and analysis of timing constraints at a high (source code) level and retains the accuracy of low (machine code) level analysis},
	booktitle = {Proceedings {Real}-{Time} {Technology} and {Applications}},
	author = {Ko, Lo and Healy, C. and Ratliff, E. and Arnold, R. and Whalley, D. and Harmon, M.},
	month = jun,
	year = {1996},
	keywords = {Computer science, High level languages, Performance analysis, C language, formal specification, Pipelines, Real time systems, real-time systems, Timing, C program, computer aided software engineering, Electronic mail, Optimizing compilers, Programming profession, project support environments, real-time programmers, synchronisation, timing, timing constraints, timing constraints analysis, user interface, User interfaces, user specification, user-friendly environment},
	pages = {170--178},
	file = {Ko et al_1996_Supporting the specification and analysis of timing constraints.pdf:/home/michael/Dropbox/zotero-pdfs/K/Ko et al_1996_Supporting the specification and analysis of timing constraints.pdf:application/pdf}
}

@article{wang_specification_2004,
	title = {Specification and {Timing} {Analysis} of {Real}-{Time} {Systems}},
	volume = {28},
	issn = {0922-6443, 1573-1383},
	url = {https://link.springer.com/article/10.1023/B:TIME.0000033379.78994.1a},
	doi = {10.1023/B:TIME.0000033379.78994.1a},
	abstract = {The correctness of hard real-time systems depends not only on the correct functional behavior but also on the correct temporal behavior. That is, the designed hard real-time system should meet all its functional and timing requirements even in the worst case. By performing timing analysis in early stages of the system life cycle, it is possible to reduce the overall development costs. This is due to the fact that the detection of the deadline violation in hard real-time systems will often lead to a complete redesign. Therefore the integration of system specification and timing analysis will be very helpful in the design of hard real-time systems. In this paper a method is proposed which supports both functional and timing verification of the specified system. The method integrates the extended specification and description language (SDL) and message sequence chart (MSC) specifications with the task allocation and schedulability analysis algorithms. The extensions of SDL and MSC are annotations in form of embedded comments in the original languages. They are used to describe the timing requirements of the specified system. The usability of the proposed method is illustrated through a case study.},
	language = {en},
	number = {1},
	urldate = {2018-03-22},
	journal = {Real-Time Systems},
	author = {Wang, Shuhua and Tsai, Grace},
	month = oct,
	year = {2004},
	pages = {69--90},
	file = {Wang_Tsai_2004_Specification and Timing Analysis of Real-Time Systems.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang_Tsai_2004_Specification and Timing Analysis of Real-Time Systems.pdf:application/pdf}
}

@article{verber_language_1996,
	title = {Language and compiler supported timing analysis in real-time control},
	volume = {4},
	issn = {0967-0661},
	url = {http://www.sciencedirect.com/science/article/pii/0967066196001530},
	doi = {10.1016/0967-0661(96)00153-0},
	abstract = {To ensure temporally predictable execution behaviour of an embedded hard real-time computer control system, layer-by-layer predictability of the system must be provided. Based on a simple structured programming language, a programming environment for hard real-time applications is under construction designed to function temporally predictably, and to support an experimental hardware platform as well as a corresponding operating system. A compiler with an integrated analyser for execution-time analysis of tasks is used to determine usable, realistic and not too pessimistic run-time estimates.},
	number = {10},
	urldate = {2018-03-22},
	journal = {Control Engineering Practice},
	author = {Verber, D. and Colnarič, M. and Halang, W. A.},
	month = oct,
	year = {1996},
	keywords = {compilers, Embedded hard real-time systems, execution time analysis, real-time programming languages, safety-critical systems, temporally predictable system behaviour},
	pages = {1427--1433},
	file = {Verber et al_1996_Language and compiler supported timing analysis in real-time control.pdf:/home/michael/Dropbox/zotero-pdfs/V/Verber et al_1996_Language and compiler supported timing analysis in real-time control.pdf:application/pdf}
}

@article{kadloor_mitigating_2016,
	title = {Mitigating {Timing} {Side} {Channel} in {Shared} {Schedulers}},
	volume = {24},
	issn = {1063-6692},
	url = {https://doi.org/10.1109/TNET.2015.2418194},
	doi = {10.1109/TNET.2015.2418194},
	abstract = {Loading...},
	number = {3},
	urldate = {2018-03-22},
	journal = {IEEE/ACM Trans. Netw.},
	author = {Kadloor, Sachin and Kiyavash, Negar and Venkitasubramaniam, Parv},
	month = jun,
	year = {2016},
	keywords = {security, privacy, forensics, scheduling algorithms, TIME},
	pages = {1562--1573},
	file = {Kadloor et al_2016_Mitigating Timing Side Channel in Shared Schedulers.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kadloor et al_2016_Mitigating Timing Side Channel in Shared Schedulers.pdf:application/pdf}
}

@article{yang_finding_2012,
	title = {Finding and understanding bugs in {C} compilers},
	volume = {47},
	issn = {03621340},
	url = {http://dl.acm.org/citation.cfm?doid=2345156.1993532},
	doi = {10.1145/2345156.1993532},
	abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to ﬁnd compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our ﬁrst contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undeﬁned and unspeciﬁed behaviors that would destroy its ability to automatically ﬁnd wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
	language = {en},
	number = {6},
	urldate = {2018-03-27},
	journal = {ACM SIGPLAN Notices},
	author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
	month = aug,
	year = {2012},
	pages = {283},
	file = {Yang et al. - 2012 - Finding and understanding bugs in C compilers.pdf:/home/michael/Zotero/storage/JHABIK53/Yang et al. - 2012 - Finding and understanding bugs in C compilers.pdf:application/pdf}
}

@inproceedings{rigger_lenient_2017,
	title = {Lenient {Execution} of {C} on a {Java} {Virtual} {Machine}: or: {How} {I} {Learned} to {Stop} {Worrying} and {Run} the {Code}},
	isbn = {978-1-4503-5340-3},
	shorttitle = {Lenient {Execution} of {C} on a {Java} {Virtual} {Machine}},
	url = {http://dl.acm.org/citation.cfm?doid=3132190.3132204},
	doi = {10.1145/3132190.3132204},
	abstract = {Most C programs do not conform strictly to the C standard, and often show undefined behaviors, for instance, in the case of signed integer overflow. When compiled by non-optimizing compilers, such programs often behave as the programmer intended. However, optimizing compilers may exploit undefined semantics to achieve more aggressive optimizations, possibly breaking the code in the process. Analysis tools can help to find and fix such issues. Alternatively, a C dialect could be defined in which clear semantics are specified for frequently occurring program patterns with otherwise undefined behaviors. In this paper, we present Lenient C, a C dialect that specifies semantics for behaviors left open for interpretation in the standard. Specifying additional semantics enables programmers to make safe use of otherwise undefined patterns. We demonstrate how we implemented the dialect in Safe Sulong, a C interpreter with a dynamic compiler that runs on the JVM.},
	language = {en},
	urldate = {2018-03-27},
	publisher = {ACM Press},
	author = {Rigger, Manuel and Schatz, Roland and Grimmer, Matthias and Mössenböck, Hanspeter},
	year = {2017},
	pages = {35--47},
	file = {Rigger et al. - 2017 - Lenient Execution of C on a Java Virtual Machine .pdf:/home/michael/Zotero/storage/XV9FWNZD/Rigger et al. - 2017 - Lenient Execution of C on a Java Virtual Machine .pdf:application/pdf}
}

@inproceedings{gay_safe_2007,
	address = {New York, NY, USA},
	series = {{ISMM} '07},
	title = {Safe {Manual} {Memory} {Management}},
	isbn = {978-1-59593-893-0},
	url = {http://doi.acm.org/10.1145/1296907.1296911},
	doi = {10.1145/1296907.1296911},
	abstract = {We present HeapSafe, a tool that uses reference counting to dynamically verify the soundness of manual memory management of C programs. HeapSafe relies on asimple extension to the usual malloc/free memory management API: delayed free scopes during which otherwise dangling references can exist. Porting programs for use with HeapSafe typically requires little effort (on average 0.6\% oflines change), adds an average 11\% time overhead (84\% in the worst case), and increases space usage by an average of 13\%. These results are based on portingover half a million lines of C code, including perl where we found sixpreviously unknown bugs.Many existing C programs continue to use unchecked manual memorymanagement. One reason is that programmers fear that moving to garbage collection is too big a risk. We believe that HeapSafe is a practical way toprovide safe memory management for such programs. Since HeapSafe checks existing memory management rather than changing it, programmers need not worrythat HeapSafe will introduce new bugs; and, since HeapSafe does not managememory itself, programmers can choose to deploy their programs without HeapSafe if performance is critical (a simple header file allows HeapSafe programs to compile and run with a regular C compiler). In contrast, we foundthat garbage collection, although faster, had much higher space overhead, and occasionally caused a space-usage explosion that made the program unusable.},
	urldate = {2018-03-27},
	booktitle = {Proceedings of the 6th {International} {Symposium} on {Memory} {Management}},
	publisher = {ACM},
	author = {Gay, David and Ennals, Rob and Brewer, Eric},
	year = {2007},
	keywords = {memory management, C, reference counting, safety},
	pages = {2--14},
	file = {Gay et al_2007_Safe Manual Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay et al_2007_Safe Manual Memory Management.pdf:application/pdf}
}

@inproceedings{simpson_segment_2005,
	address = {New York, NY, USA},
	series = {{CASES} '05},
	title = {Segment {Protection} for {Embedded} {Systems} {Using} {Run}-time {Checks}},
	isbn = {978-1-59593-149-8},
	url = {http://doi.acm.org/10.1145/1086297.1086307},
	doi = {10.1145/1086297.1086307},
	abstract = {The lack of virtual memory protection is a serious source of unreliability in many embedded systems. Without the segment-level protection it provides, these systems are subject to memory access violations, stemming from programmer error, whose results can be dangerous and catastrophic in safety-critical systems. The traditional method of testing embedded software before its deployment is an insufficient means of detecting and debugging all software errors, and the reliance on this practice is a severe gamble when the reliable performance of the embedded device is critical. Additionally, the use of safe languages and programming semantic restrictions as prevention mechanisms is often infeasible when considering the adoptability and compatibility of these languages since most embedded applications are written in C and C++.This work improves system reliability by providing a completely automatic software technique for guaranteeing segment protection for embedded systems lacking virtual memory. This is done by inserting optimized run-time checks before memory accesses that detect segmentation violations in cases in which there would otherwise be no error, enabling remedial action before system failure or corruption. This feature is invaluable for safety-critical embedded systems. Other advantages of our method include its low overhead, lack of any programming language or semantic restrictions, and ease of implementation. Our compile-time analysis, known as intended segment analysis, is a uniquely structured analysis that allows for the realization of optimizations used to reduce the number of required run-time checks and foster our technique into a truly viable solution for providing segment protection in embedded systems lacking virtual memory.Our experimental results show that these optimizations are effective at reducing the performance overheads associated with providing software segment protection to low, and in many cases, negligible levels. For the eight evaluated embedded benchmarks, the average increase in run-time is 0.72\%, the average increase in energy consumption is 0.44\%, and the average increase in code size is 3.60\%.},
	urldate = {2018-03-27},
	booktitle = {Proceedings of the 2005 {International} {Conference} on {Compilers}, {Architectures} and {Synthesis} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Simpson, Matthew and Middha, Bhuvan and Barua, Rajeev},
	year = {2005},
	keywords = {memory safety, compilers, reliability, virtual memory, run-time checks, ewmbedded systems, MMU, MPU, safe languages, segment protection, segmentation violations},
	pages = {66--77},
	file = {Simpson et al_2005_Segment Protection for Embedded Systems Using Run-time Checks.pdf:/home/michael/Dropbox/zotero-pdfs/S/Simpson et al_2005_Segment Protection for Embedded Systems Using Run-time Checks.pdf:application/pdf}
}

@inproceedings{condit_dependent_2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Dependent {Types} for {Low}-{Level} {Programming}},
	isbn = {978-3-540-71314-2 978-3-540-71316-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-71316-6_35},
	doi = {10.1007/978-3-540-71316-6_35},
	abstract = {In this paper, we describe the key principles of a dependent type system for low-level imperative languages. The major contributions of this work are (1) a sound type system that combines dependent types and mutation for variables and for heap-allocated structures in a more flexible way than before and (2) a technique for automatically inferring dependent types for local variables. We have applied these general principles to design Deputy, a dependent type system for C that allows the user to describe bounded pointers and tagged unions. Deputy has been used to annotate and check a number of real-world C programs.},
	language = {en},
	urldate = {2018-03-27},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Condit, Jeremy and Harren, Matthew and Anderson, Zachary and Gay, David and Necula, George C.},
	month = mar,
	year = {2007},
	pages = {520--535},
	file = {Condit et al_2007_Dependent Types for Low-Level Programming.pdf:/home/michael/Dropbox/zotero-pdfs/C/Condit et al_2007_Dependent Types for Low-Level Programming.pdf:application/pdf}
}

@inproceedings{harper_simplified_1994,
	title = {A {Simplified} {Account} of {Polymorphic} {References}},
	abstract = {A proof of the soundness of Tofte's imperative type discipline with respect to a structured operational semantics is given. The presentation is based on a semantic formalism that combines the benefits of the approaches considered by Wright and Felleisen, and by Tofte, leading to a particularly simple proof of soundness of Tofte's type discipline.},
	booktitle = {Information {Processing} {Letters}},
	author = {Harper, Robert},
	year = {1994},
	pages = {201--206},
	file = {Harper_1994_A Simplified Account of Polymorphic References.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harper_1994_A Simplified Account of Polymorphic References.pdf:application/pdf}
}

@article{ozgen_type_nodate,
	title = {A type inference algorithm and transition semantics for polymorphic {C}},
	language = {en},
	author = {Ozgen, Mustafa},
	pages = {131},
	file = {Ozgen_A type inference algorithm and transition semantics for polymorphic C.pdf:/home/michael/Dropbox/zotero-pdfs/O/Ozgen_A type inference algorithm and transition semantics for polymorphic C.pdf:application/pdf}
}

@inproceedings{fradet_static_1996,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Static detection of pointer errors: {An} axiomatisation and a checking algorithm},
	isbn = {978-3-540-61055-7 978-3-540-49942-8},
	shorttitle = {Static detection of pointer errors},
	url = {https://link.springer.com/chapter/10.1007/3-540-61055-3_33},
	doi = {10.1007/3-540-61055-3_33},
	abstract = {The incorrect use of pointers is one of the most common source of bugs. As a consequence, any kind of static code checking capable of detecting potential bugs at compile time is welcome. This paper presents a static analysis for the detection of incorrect accesses to memory (dereferences of invalid pointers). A pointer may be invalid because it has not been initialised or because it refers to a memory location which has been deallocated. The analyser is derived from an axiomatisation of alias and connectivity properties which is shown to be sound with respect to the natural semantics of the language. It deals with dynamically allocated data structures and it is accurate enough to handle circular structures.},
	language = {en},
	urldate = {2018-03-27},
	booktitle = {Programming {Languages} and {Systems} — {ESOP} '96},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Fradet, Pascal and Gaugne, Ronan and Métayer, Daniel Le},
	month = apr,
	year = {1996},
	pages = {125--140},
	file = {Fradet et al_1996_Static detection of pointer errors.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fradet et al_1996_Static detection of pointer errors.pdf:application/pdf}
}

@inproceedings{xi_imperative_2000,
	title = {Imperative programming with dependent types},
	isbn = {978-0-7695-0725-5},
	url = {http://ieeexplore.ieee.org/document/855785/},
	doi = {10.1109/LICS.2000.855785},
	abstract = {In this paper, we enrich imperative programming with a form of dependent types. We start with explaining some motivations for this enrichment and mentioning some major obstacles that need to be overcome. We then present the design of a source level dependently typed imperative programming language Xanadu, forming both static and dynamic semantics and then establishing the type soundness theorem. We also present realistic examples, which have all been veriﬁed in a prototype implementation, in support of the practicality of Xanadu. We claim that the language design of Xanadu is novel and it serves as an informative example that demonstrates a means to combine imperative programming with dependent types.},
	language = {en},
	urldate = {2018-03-30},
	publisher = {IEEE Comput. Soc},
	author = {Xi, Hongwei},
	year = {2000},
	pages = {375--387},
	file = {Xi_2000_Imperative programming with dependent types.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xi_2000_Imperative programming with dependent types.pdf:application/pdf}
}

@article{knowles_hybrid_2010,
	title = {Hybrid {Type} {Checking}},
	volume = {32},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1667048.1667051},
	doi = {10.1145/1667048.1667051},
	abstract = {Traditional static type systems are effective for verifying basic interface specifications. Dynamically checked contracts support more precise specifications, but these are not checked until runtime, resulting in incomplete detection of defects. Hybrid type checking is a synthesis of these two approaches that enforces precise interface specifications, via static analysis where possible, but also via dynamic checks where necessary. This article explores the key ideas and implications of hybrid type checking, in the context of the λ-calculus extended with contract types, that is, with dependent function types and with arbitrary refinements of base types.},
	number = {2},
	urldate = {2018-03-30},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Knowles, Kenneth and Flanagan, Cormac},
	month = feb,
	year = {2010},
	keywords = {static checking, Type systems, contracts, dynamic checking},
	pages = {6:1--6:34},
	file = {Knowles_Flanagan_2010_Hybrid Type Checking.pdf:/home/michael/Dropbox/zotero-pdfs/K/Knowles_Flanagan_2010_Hybrid Type Checking.pdf:application/pdf}
}

@inproceedings{dhurjati_backwards-compatible_2006,
	address = {New York, NY, USA},
	series = {{ICSE} '06},
	title = {Backwards-compatible {Array} {Bounds} {Checking} for {C} with {Very} {Low} {Overhead}},
	isbn = {978-1-59593-375-1},
	url = {http://doi.acm.org/10.1145/1134285.1134309},
	doi = {10.1145/1134285.1134309},
	abstract = {The problem of enforcing correct usage of array and pointer references in C and C++ programs remains unsolved. The approach proposed by Jones and Kelly (extended by Ruwase and Lam) is the only one we know of that does not require significant manual changes to programs, but it has extremely high overheads of 5x-6x and 11x-12x in the two versions. In this paper, we describe a collection of techniques that dramatically reduce the overhead of this approach, by exploiting a fine-grain partitioning of memory called Automatic Pool Allocation. Together, these techniques bring the average overhead checks down to only 12\% for a set of benchmarks (but 69\% for one case). We show that the memory partitioning is key to bringing down this overhead. We also show that our technique successfully detects all buffer overrun violations in a test suite modeling reported violations in some important real-world programs.},
	urldate = {2018-03-30},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Dhurjati, Dinakar and Adve, Vikram},
	year = {2006},
	keywords = {programming languages, compilers, automatic pool allocation, region management, array bounds checking},
	pages = {162--171},
	file = {Dhurjati_Adve_2006_Backwards-compatible Array Bounds Checking for C with Very Low Overhead.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dhurjati_Adve_2006_Backwards-compatible Array Bounds Checking for C with Very Low Overhead.pdf:application/pdf}
}

@inproceedings{siek_gradual_2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Gradual {Typing} for {Objects}},
	isbn = {978-3-540-73588-5 978-3-540-73589-2},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-73589-2_2},
	doi = {10.1007/978-3-540-73589-2_2},
	abstract = {Static and dynamic type systems have well-known strengths and weaknesses. In previous work we developed a gradual type system for a functional calculus named λ?→λ→?{\textbackslash}lambda{\textasciicircum}?\_{\textbackslash}to. Gradual typing provides the benefits of both static and dynamic checking in a single language by allowing the programmer to control whether a portion of the program is type checked at compile-time or run-time by adding or removing type annotations on variables. Several object-oriented scripting languages are preparing to add static checking. To support that work this paper develops Ob?{\textless}:Ob{\textless}:?{\textbackslash}mathbf\{Ob\}{\textasciicircum}\{?\}\_\{{\textless}:\}, a gradual type system for object-based languages, extending the Ob {\textless} : calculus of Abadi and Cardelli. Our primary contribution is to show that gradual typing and subtyping are orthogonal and can be combined in a principled fashion. We also develop a small-step semantics, provide a machine-checked proof of type safety, and improve the space efficiency of higher-order casts.},
	language = {en},
	urldate = {2018-03-30},
	booktitle = {{ECOOP} 2007 – {Object}-{Oriented} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Siek, Jeremy and Taha, Walid},
	month = jul,
	year = {2007},
	pages = {2--27},
	file = {Siek_Taha_2007_Gradual Typing for Objects.pdf:/home/michael/Dropbox/zotero-pdfs/S/Siek_Taha_2007_Gradual Typing for Objects.pdf:application/pdf}
}

@techreport{condit_dependent_2006,
	title = {Dependent {Types} for {Low}-{Level} {Programming}},
	url = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-129.html},
	abstract = {We describe the key principles of a flexible dependent type system for low-level imperative languages. Two major contributions are (1) a new typing rule for handling mutation that follows the model of Hoare's axiom for assignment and (2) a technique for automatically inferring dependent types for local variables. This type system is more expressive than previous dependent type systems because types can now depend on mutable variables; in addition, it improves ease of use by inferring dependent type annotations for local variables. Decidability is addressed by emitting run-time checks for those conditions that cannot be checked statically. Using these principles, we have designed Deputy, a dependent type system for C whose types allow the programmer to describe several common idioms for the safe use of pointers and tagged unions. We have used Deputy to enforce memory safety properties in a number of common benchmark suites as well as in Linux device drivers and TinyOS components. These experiments show that Deputy's dependent types are useful in a wide range of C programs and that they have a relatively low annotation burden and performance cost.},
	number = {UCB/EECS-2006-129},
	institution = {EECS Department, University of California, Berkeley},
	author = {Condit, Jeremy Paul and Harren, Matthew Thomas and Anderson, Zachary Ryan and Gay, David and Necula, George},
	month = oct,
	year = {2006},
	file = {Condit et al_2006_Dependent Types for Low-Level Programming.pdf:/home/michael/Dropbox/zotero-pdfs/C/Condit et al_2006_Dependent Types for Low-Level Programming.pdf:application/pdf}
}

@inproceedings{augustsson_cayennelanguage_1998,
	address = {New York, NY, USA},
	series = {{ICFP} '98},
	title = {Cayenne—a {Language} with {Dependent} {Types}},
	isbn = {978-1-58113-024-9},
	url = {http://doi.acm.org/10.1145/289423.289451},
	doi = {10.1145/289423.289451},
	abstract = {Cayenne is a Haskell-like language. The main difference between Haskell and Cayenne is that Cayenne has dependent types, i.e., the result type of a function may depend on the argument value, and types of record components (which can be types or values) may depend on other components. Cayenne also combines the syntactic categories for value expressions and type expressions; thus reducing the number of language concepts.Having dependent types and combined type and value expressions makes the language very powerful. It is powerful enough that a special module concept is unnecessary; ordinary records suffice. It is also powerful enough to encode predicate logic at the type level, allowing types to be used as specifications of programs. However, this power comes at a cost: type checking of Cayenne is undecidable. While this may appear to be a steep price to pay, it seems to work well in practice.},
	urldate = {2018-03-29},
	booktitle = {Proceedings of the {Third} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Augustsson, Lennart},
	year = {1998},
	keywords = {dependent types, type systems, language design, module systems},
	pages = {239--250},
	file = {Augustsson_1998_Cayenne—a Language with Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/A/Augustsson_1998_Cayenne—a Language with Dependent Types.pdf:application/pdf}
}

@article{anderson_static_2007,
	title = {Static {Analysis} of {C} for {Hybrid} {Type} {Checking}},
	abstract = {Hybrid type checking[5] is an approach to enforcing the welltypedness of programs that, where possible, uses static analysis to determine the types of expressions, and run-time checking when the precision of static analysis is insuﬃceint. This approach is useful for dependent type systems in which types are parameterized by run-time values of expressions. Deputy is a dependent type system for C that allows the user to describe bounded pointers, tagged unions, and null-terminated strings. Deputy runs in two phases. In the ﬁrst phase, simple typing rules are applied. The typing rules prescribe the insertion of run-time checks for certain operations. In the second phase, static analysis is used to identify checks that must either always succeed or always fail. The former may safely be removed, and the latter signify typing errors. This report describes the second phase of Deputy.},
	language = {en},
	author = {Anderson, Zachary R},
	month = jan,
	year = {2007},
	pages = {25},
	file = {Anderson_2007_Static Analysis of C for Hybrid Type Checking.pdf:/home/michael/Dropbox/zotero-pdfs/A/Anderson_2007_Static Analysis of C for Hybrid Type Checking.pdf:application/pdf}
}

@article{wolski_cspot:_2018,
	title = {{CSPOT}: {A} {Serveless} {Platform} of {Things}},
	language = {en},
	author = {Wolski, Rich and Krintz, Chandra},
	month = mar,
	year = {2018},
	pages = {15},
	file = {Wolski_Krintz_2018_CSPOT.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wolski_Krintz_2018_CSPOT.pdf:application/pdf}
}

@inproceedings{de_wael_just--time_2015,
	title = {Just-in-time data structures},
	isbn = {978-1-4503-3688-8},
	url = {http://dl.acm.org/citation.cfm?doid=2814228.2814231},
	doi = {10.1145/2814228.2814231},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {De Wael, Mattias and Marr, Stefan and De Koster, Joeri and Sartor, Jennifer B. and De Meuter, Wolfgang},
	year = {2015},
	pages = {61--75},
	file = {De Wael et al_2015_Just-in-time data structures.pdf:/home/michael/Dropbox/zotero-pdfs/D/De Wael et al_2015_Just-in-time data structures.pdf:application/pdf}
}

@inproceedings{polozov_flashmeta:_2015,
	title = {{FlashMeta}: a framework for inductive program synthesis},
	isbn = {978-1-4503-3689-5},
	shorttitle = {{FlashMeta}},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814310},
	doi = {10.1145/2814270.2814310},
	abstract = {Inductive synthesis, or programming-by-examples (PBE) is gaining prominence with disruptive applications for automating repetitive tasks in end-user programming. However, designing, developing, and maintaining an effective industrialquality inductive synthesizer is an intellectual and engineering challenge, requiring 1-2 man-years of effort.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Polozov, Oleksandr and Gulwani, Sumit},
	year = {2015},
	pages = {107--126},
	file = {Polozov_Gulwani_2015_FlashMeta.pdf:/home/michael/Dropbox/zotero-pdfs/P/Polozov_Gulwani_2015_FlashMeta.pdf:application/pdf}
}

@article{chu_scrap_nodate,
	title = {Scrap {Your} {Boilerplate} with {Object} {Algebras}},
	abstract = {Traversing complex Abstract Syntax Trees (ASTs) typically requires large amounts of tedious boilerplate code. For many operations most of the code simply walks the structure, and only a small portion of the code implements the functionality that motivated the traversal in the ﬁrst place. This paper presents a type-safe Java framework called Shy that removes much of this boilerplate code. In Shy Object Algebras are used to describe complex and extensible AST structures. Using Java annotations Shy generates generic boilerplate code for various types of traversals. For a concrete traversal, users of Shy can then inherit from the generated code and override only the interesting cases. Consequently, the amount of code that users need to write is signiﬁcantly smaller. Moreover, traversals using the Shy framework are also much more structure shy, becoming more adaptive to future changes or extensions to the AST structure. To prove the effectiveness of the approach, we applied Shy in the implementation of a domain-speciﬁc questionnaire language. Our results show that for a large number of traversals there was a signiﬁcant reduction in the amount of user-deﬁned code.},
	language = {en},
	author = {Chu, Haoyuan Zhang Zewei},
	pages = {20},
	file = {Chu_Scrap Your Boilerplate with Object Algebras.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chu_Scrap Your Boilerplate with Object Algebras.pdf:application/pdf}
}

@inproceedings{erdweg_sound_2015,
	title = {A sound and optimal incremental build system with dynamic dependencies},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814316},
	doi = {10.1145/2814270.2814316},
	abstract = {Build systems are used in all but the smallest software projects to invoke the right build tools on the right ﬁles in the right order. A build system must be sound (after a build, generated ﬁles consistently reﬂect the latest source ﬁles) and efﬁcient (recheck and rebuild as few build units as possible). Contemporary build systems provide limited efﬁciency because they lack support for expressing ﬁnegrained ﬁle dependencies. We present a build system called pluto that supports the deﬁnition of reusable, parameterized, interconnected builders. When run, a builder notiﬁes the build system about dynamically required and produced ﬁles as well as about other builders whose results are needed. To support ﬁne-grained ﬁle dependencies, we generalize the traditional notion of time stamps to allow builders to declare their actual requirements on a ﬁle’s content. pluto collects the requirements and products of a builder with their stamps in a build summary. This enables pluto to provides provably sound and optimal incremental rebuilding. To support dynamic dependencies, our rebuild algorithm interleaves dependency analysis and builder execution and enforces invariants on the dependency graph through a dynamic analysis. We have developed pluto as a Java API and used it to implement more than 25 builders. We describe our experience with migrating a larger Ant build script to pluto and compare the respective build times.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Erdweg, Sebastian and Lichter, Moritz and Weiel, Manuel},
	year = {2015},
	pages = {89--106},
	file = {Erdweg et al_2015_A sound and optimal incremental build system with dynamic dependencies.pdf:/home/michael/Dropbox/zotero-pdfs/E/Erdweg et al_2015_A sound and optimal incremental build system with dynamic dependencies.pdf:application/pdf}
}

@article{hottelier_synthesis_nodate,
	title = {Synthesis of {Layout} {Engines} from {Relational} {Constraints}},
	abstract = {We present an algorithm for synthesizing efﬁcient document layout engines from compact relational speciﬁcations. These speciﬁcations are compact in that a single speciﬁcation can produce multiple engines, each for a distinct layout situation, i.e., a different combination of known vs. unknown attributes. Technically, our speciﬁcations are relational attribute grammars, while our engines are functional attribute grammars. By synthesizing functions from relational constraints, we obviate the need for constraint solving at runtime, because functional attribute grammars can be easily evaluated according to a ﬁxed schedule, sidestepping the backtracking search performed by constraint solvers. Our experiments show that we can generate layout engines for non-trivial data visualizations, and that our synthesized engines are between 39- and 200-times faster than general-purpose constraint solvers. Relational speciﬁcations of layout give rise to synthesis problems that have previously proved intractable. Our algorithm exploits the hierarchical, grammar-based structure of the speciﬁcation, decomposing the speciﬁcation into smaller subproblems, which can be tackled with off-the-shelf synthesis procedures. The new synthesis problem then becomes the composition of the functions thus generated into a correct attribute grammar, which might be recursive. We show how to solve this problem by efﬁcient reduction to an SMT problem.},
	language = {en},
	author = {Hottelier, Thibaud and Bodik, Ras},
	pages = {15},
	file = {Hottelier_Bodik_Synthesis of Layout Engines from Relational Constraints.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hottelier_Bodik_Synthesis of Layout Engines from Relational Constraints.pdf:application/pdf}
}

@article{madhavan_automating_nodate,
	title = {Automating {Grammar} {Comparison}},
	abstract = {We consider from a practical perspective the problem of checking equivalence of context-free grammars. We present techniques for proving equivalence, as well as techniques for ﬁnding counter-examples that establish non-equivalence. Among the key building blocks of our approach is a novel algorithm for efﬁciently enumerating and sampling words and parse trees from arbitrary context-free grammars; the algorithm supports polynomial time random access to words belonging to the grammar. Furthermore, we propose an algorithm for proving equivalence of context-free grammars that is complete for LL grammars, yet can be invoked on any context-free grammar, including ambiguous grammars.},
	language = {en},
	author = {Madhavan, Ravichandhran and Mayer, Mikaël and Gulwani, Sumit and Kuncak, Viktor},
	pages = {18},
	file = {Madhavan et al_Automating Grammar Comparison.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madhavan et al_Automating Grammar Comparison.pdf:application/pdf}
}

@article{gardner_reasoning_nodate,
	title = {Reasoning about the {POSIX} {File} {System}},
	abstract = {We introduce a program logic for specifying a core sequential subset of the POSIX ﬁle system and for reasoning abstractly about client programs working with the ﬁle system. The challenge is to reason about the combination of local directory update and global pathname traversal (including ’..’ and symbolic links) which may overlap the directories being updated. Existing reasoning techniques are either based on ﬁrst-order logic and do not scale, or on separation logic and can only handle linear pathnames (no ’..’ or symbolic links). We introduce fusion logic for reasoning about local update and global pathname traversal, introducing a novel effect frame rule to propagate the effect of a local update on overlapping pathnames. We apply our reasoning to the standard recursive remove utility (rm -r), discovering bugs in well-known implementations.},
	language = {en},
	author = {Gardner, Gian Ntzik Philippa},
	pages = {20},
	file = {Gardner_Reasoning about the POSIX File System.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gardner_Reasoning about the POSIX File System.pdf:application/pdf}
}

@article{sharma_conditionally_nodate,
	title = {Conditionally {Correct} {Superoptimization}},
	abstract = {The aggressive optimization of heavily used kernels is an important problem in high-performance computing. However, both general purpose compilers and highly specialized tools such as superoptimizers often do not have sufﬁcient static knowledge of restrictions on program inputs that could be exploited to produce the very best code. For many applications, the best possible code is conditionally correct: the optimized kernel is equal to the code that it replaces only under certain preconditions on the kernel’s inputs. The main technical challenge in producing conditionally correct optimizations is in obtaining non-trivial and useful conditions and proving conditional equivalence formally in the presence of loops. We combine abstract interpretation, decision procedures, and testing to yield a veriﬁcation strategy that can address both of these problems. This approach yields a superoptimizer for x86 that in our experiments produces binaries that are often multiple times faster than those produced by production compilers.},
	language = {en},
	author = {Sharma, Rahul and Schkufza, Eric and Aiken, Alex},
	pages = {16},
	file = {Sharma et al_Conditionally Correct Superoptimization.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sharma et al_Conditionally Correct Superoptimization.pdf:application/pdf}
}

@inproceedings{blackshear_selective_2015,
	title = {Selective control-flow abstraction via jumping},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814293},
	doi = {10.1145/2814270.2814293},
	abstract = {We present jumping, a form of selective control-ﬂow abstraction useful for improving the scalability of goal-directed static analyses. Jumping is useful for analyzing programs with complex control-ﬂow such as event-driven systems. In such systems, accounting for orderings between certain events is important for precision, yet analyzing the product graph of all possible event orderings is intractable. Jumping solves this problem by allowing the analysis to selectively abstract away control-ﬂow between events irrelevant to a goal query while preserving information about the ordering of relevant events. We present a framework for designing sound jumping analyses and create an instantiation of the framework for performing precise inter-event analysis of Android applications. Our experimental evaluation showed that using jumping to augment a precise goal-directed analysis with inter-event reasoning enabled our analysis to prove 90–97\% of dereferences safe across our benchmarks.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Blackshear, Sam and Chang, Bor-Yuh Evan and Sridharan, Manu},
	year = {2015},
	pages = {163--182},
	file = {Blackshear et al_2015_Selective control-flow abstraction via jumping.pdf:/home/michael/Dropbox/zotero-pdfs/B/Blackshear et al_2015_Selective control-flow abstraction via jumping.pdf:application/pdf}
}

@article{zhang_valor:_nodate,
	title = {Valor: {Efﬁcient}, {Software}-{Only} {Region} {Conﬂict} {Exceptions} ∗},
	abstract = {Data races complicate programming language semantics, and a data race is often a bug. Existing techniques detect data races and deﬁne their semantics by detecting conﬂicts between synchronization-free regions (SFRs). However, such techniques either modify hardware or slow programs dramatically, preventing always-on use today. This paper describes Valor, a sound, precise, softwareonly region conﬂict detection analysis that achieves high performance by eliminating the costly analysis on each read operation that prior approaches require. Valor instead logs a region’s reads and lazily detects conﬂicts for logged reads when the region ends. As a comparison, we have also developed FastRCD, a conﬂict detector that leverages the epoch optimization strategy of the FastTrack data race detector.},
	language = {en},
	author = {Zhang, Swarnendu Biswas Minjia and Bond, Michael D and Lucia, Brandon},
	pages = {19},
	file = {Zhang et al_Valor.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhang et al_Valor.pdf:application/pdf}
}

@article{ou_automo:_nodate,
	title = {{AutoMO}: {Automatic} {Inference} of {Memory} {Order} {Parameters} for {C}/{C}++1},
	abstract = {Many concurrent data structures are initially designed for the sequential consistency (SC) memory model. Developers often then implement these algorithms on real-world systems with weaker memory models by adding sufﬁcient fences to ensure that their implementation on the weak memory model exhibits the same executions as the SC memory model.},
	language = {en},
	author = {Ou, Peizhao and Demsky, Brian},
	pages = {20},
	file = {Ou_Demsky_AutoMO.pdf:/home/michael/Dropbox/zotero-pdfs/O/Ou_Demsky_AutoMO.pdf:application/pdf}
}

@inproceedings{zheng_accurate_2015,
	title = {Accurate profiling in the presence of dynamic compilation},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814281},
	doi = {10.1145/2814270.2814281},
	abstract = {Many proﬁlers based on bytecode instrumentation yield wrong results in the presence of an optimizing dynamic compiler, either due to not being aware of optimizations such as stack allocation and method inlining, or due to the inserted code disrupting such optimizations. To avoid such perturbations, we present a novel technique to make any proﬁler implemented at the bytecode level aware of optimizations performed by the dynamic compiler. We implement our approach in a state-of-the-art Java virtual machine and demonstrate its signiﬁcance with concrete proﬁlers. We quantify the impact of escape analysis on allocation proﬁling, object lifetime analysis, and the impact of method inlining on callsite proﬁling. We illustrate how our approach enables new kinds of proﬁlers, such as a proﬁler for non-inlined callsites, and a testing framework for locating performance bugs in dynamic compiler implementations.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Zheng, Yudi and Bulej, Lubomír and Binder, Walter},
	year = {2015},
	pages = {433--450},
	file = {Zheng et al_2015_Accurate profiling in the presence of dynamic compilation.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zheng et al_2015_Accurate profiling in the presence of dynamic compilation.pdf:application/pdf}
}

@article{aigner_fast_nodate,
	title = {Fast, {Multicore}-{Scalable}, {Low}-{Fragmentation} {Memory} {Allocation} through {Large} {Virtual} {Memory} and {Global} {Data} {Structures}},
	abstract = {We demonstrate that general-purpose memory allocation involving many threads on many cores can be done with high performance, multicore scalability, and low memory consumption. For this purpose, we have designed and implemented scalloc, a concurrent allocator that generally performs and scales in our experiments better than other allocators while using less memory, and is still competitive otherwise. The main ideas behind the design of scalloc are: uniform treatment of small and big objects through so-called virtual spans, efﬁciently and effectively reclaiming free memory through fast and scalable global data structures, and constant-time (modulo synchronization) allocation and deallocation operations that trade off memory reuse and spatial locality without being subject to false sharing.},
	language = {en},
	author = {Aigner, Martin and Kirsch, Christoph M and Lippautz, Michael and Sokolova, Ana},
	pages = {19},
	file = {Aigner et al_Fast, Multicore-Scalable, Low-Fragmentation Memory Allocation through Large.pdf:/home/michael/Dropbox/zotero-pdfs/A/Aigner et al_Fast, Multicore-Scalable, Low-Fragmentation Memory Allocation through Large.pdf:application/pdf}
}

@book{bhagat_bloomsbury_2016,
	title = {The {Bloomsbury} {Encyclopedia} of {Design}},
	isbn = {978-1-4725-9616-1 978-1-4725-2155-2},
	url = {http://www.bloomsburydesignlibrary.com/encyclopedia?docid=b-9781472596161},
	abstract = {Previous work has shown how to insert fences that enforce sequential consistency. However, for many concurrent algorithms, sequential consistency is unnecessarily strong and can lead to high execution overhead. The reason is that, often, correctness relies on the execution order of a few speciﬁc pairs of instructions. Algorithm designers can declare those execution orders and thereby enable memory-modelindependent reasoning about correctness and also ease implementation of algorithms on multiple platforms. The literature has examples of such reasoning, while tool support for enforcing the orders has been lacking until now. In this paper we present a declarative approach to specify and enforce execution orders. Our fence insertion algorithm ﬁrst identiﬁes the execution orders that a given memory model enforces automatically, and then inserts fences that enforce the rest. Our benchmarks include three off-the-shelf transactional memory algorithms written in C/C++ for which we specify suitable execution orders. For those benchmarks, our experiments with the x86 and ARMv7 memory models show that our tool inserts fences that are competitive with those inserted by the original authors. Our tool is the ﬁrst to insert fences into transactional memory algorithms and it solves the long-standing problem of how to easily port such algorithms to a novel memory model.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {Bloomsbury Publishing},
	editor = {Bhagat, Dipti and Kettley, Sarah and O’Brien, Sorcha and Raizman, David and Willis, Anne-Marie},
	year = {2016},
	doi = {10.5040/9781472596161},
	file = {Bhagat et al_2016_The Bloomsbury Encyclopedia of Design.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bhagat et al_2016_The Bloomsbury Encyclopedia of Design.pdf:application/pdf}
}

@article{kuncak_synthesizing_nodate,
	title = {Synthesizing {Java} {Expressions} from {Free}-{Form} {Queries}},
	abstract = {We present a new code assistance tool for integrated development environments. Our system accepts as input free-form queries containing a mixture of English and Java, and produces Java code expressions that take the query into account and respect syntax, types, and scoping rules of Java, as well as statistical usage patterns. In contrast to solutions based on code search, the results returned by our tool need not directly correspond to any previously seen code fragment. As part of our system we have constructed a probabilistic context free grammar for Java constructs and library invocations, as well as an algorithm that uses a customized natural language processing tool chain to extract information from free-form text queries. We present the results on a number of examples showing that our technique (1) often produces the expected code fragments, (2) tolerates much of the ﬂexibility of natural language, and (3) can repair incorrect Java expressions that use, for example, the wrong syntax or missing arguments.},
	language = {en},
	author = {Kuncak, Tihomir Gvero Viktor},
	pages = {17},
	file = {Kuncak_Synthesizing Java Expressions from Free-Form Queries.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kuncak_Synthesizing Java Expressions from Free-Form Queries.pdf:application/pdf}
}

@article{upadhyaya_effectively_nodate,
	title = {Effectively {Mapping} {Linguistic} {Abstractions} for {Message}-passing {Concurrency} to {Threads} on the {Java} {Virtual} {Machine}},
	abstract = {Efﬁcient mapping of message passing concurrency (MPC) abstractions to Java Virtual Machine (JVM) threads is critical for performance, scalability, and CPU utilization; but tedious and time consuming to perform manually. In general, this mapping cannot be found in polynomial time, but we show that by exploiting the local characteristics of MPC abstractions and their communication patterns this mapping can be determined effectively. We describe our MPC abstraction to thread mapping technique, its realization in two frameworks (Panini and Akka), and its rigorous evaluation using several benchmarks from representative MPC frameworks. We also compare our technique against four default mapping techniques: thread-all, round-robin-task-all, random-task-all and work-stealing. Our evaluation shows that our mapping technique can improve the performance by 30\%-60\% over default mapping techniques. These improvements are due to a number of challenges addressed by our technique namely: i) balancing the computations across JVM threads, ii) reducing the communication overheads, iii) utilizing information about cache locality, and iv) mapping MPC abstractions to threads in a way that reduces the contention between JVM threads.},
	language = {en},
	author = {Upadhyaya, Ganesha and Rajan, Hridesh},
	pages = {21},
	file = {Upadhyaya_Rajan_Effectively Mapping Linguistic Abstractions for Message-passing Concurrency to.pdf:/home/michael/Dropbox/zotero-pdfs/U/Upadhyaya_Rajan_Effectively Mapping Linguistic Abstractions for Message-passing Concurrency to.pdf:application/pdf}
}

@inproceedings{ureche_automating_2015,
	title = {Automating ad hoc data representation transformations},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814271},
	doi = {10.1145/2814270.2814271},
	abstract = {To maximize run-time performance, programmers often specialize their code by hand, replacing library collections and containers by custom objects in which data is restructured for efﬁcient access. However, changing the data representation is a tedious and error-prone process that makes it hard to test, maintain and evolve the source code.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Ureche, Vlad and Biboudis, Aggelos and Smaragdakis, Yannis and Odersky, Martin},
	year = {2015},
	pages = {801--820},
	file = {Ureche et al_2015_Automating ad hoc data representation transformations.pdf:/home/michael/Dropbox/zotero-pdfs/U/Ureche et al_2015_Automating ad hoc data representation transformations.pdf:application/pdf}
}

@inproceedings{marr_tracing_2015,
	title = {Tracing vs. partial evaluation: comparing meta-compilation approaches for self-optimizing interpreters},
	isbn = {978-1-4503-3689-5},
	shorttitle = {Tracing vs. partial evaluation},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814275},
	doi = {10.1145/2814270.2814275},
	abstract = {Tracing and partial evaluation have been proposed as metacompilation techniques for interpreters to make just-in-time compilation language-independent. They promise that programs executing on simple interpreters can reach performance of the same order of magnitude as if they would be executed on state-of-the-art virtual machines with highly optimizing just-in-time compilers built for a speciﬁc language. Tracing and partial evaluation approach this metacompilation from two ends of a spectrum, resulting in different sets of tradeoffs.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Marr, Stefan and Ducasse, Stéphane},
	year = {2015},
	pages = {821--839},
	file = {Marr_Ducasse_2015_Tracing vs.pdf:/home/michael/Dropbox/zotero-pdfs/M/Marr_Ducasse_2015_Tracing vs.pdf:application/pdf}
}

@article{srinivasan_partial_nodate,
	title = {Partial {Evaluation} of {Machine} {Code} ∗},
	abstract = {This paper presents an algorithm for off-line partial evaluation of machine code. The algorithm follows the classical two-phase approach of binding-time analysis (BTA) followed by specialization. However, machine-code partial evaluation presents a number of new challenges, and it was necessary to devise new techniques for use in each phase.},
	language = {en},
	author = {Srinivasan, Venkatesh and Reps, Thomas},
	pages = {20},
	file = {Srinivasan_Reps_Partial Evaluation of Machine Code ∗.pdf:/home/michael/Dropbox/zotero-pdfs/S/Srinivasan_Reps_Partial Evaluation of Machine Code ∗.pdf:application/pdf}
}

@article{hammer_incremental_nodate,
	title = {Incremental {Computation} with {Names}},
	abstract = {Over the past thirty years, there has been signiﬁcant progress in developing general-purpose, language-based approaches to incremental computation, which aims to efﬁciently update the result of a computation when an input is changed. A key design challenge in such approaches is how to provide efﬁcient incremental support for a broad range of programs. In this paper, we argue that ﬁrst-class names are a critical linguistic feature for efﬁcient incremental computation. Names identify computations to be reused across differing runs of a program, and making them ﬁrst class gives programmers a high level of control over reuse. We demonstrate the beneﬁts of names by presenting NOMINAL ADAPTON, an ML-like language for incremental computation with names. We describe how to use NOMINAL ADAPTON to efﬁciently incrementalize several standard programming patterns—including maps, folds, and unfolds—and show how to build efﬁcient, incremental probabilistic trees and tries. Since NOMINAL ADAPTON’s implementation is subtle, we formalize it as a core calculus and prove it is from-scratch consistent, meaning it always produces the same answer as simply re-running the computation. Finally, we demonstrate that NOMINAL ADAPTON can provide large speedups over both from-scratch computation and ADAPTON, a previous state-of-the-art incremental system.},
	language = {en},
	author = {Hammer, Matthew A and Dunﬁeld, Joshua and Headley, Kyle and Labich, Nicholas and Foster, Jeffrey S and Hicks, Michael and Horn, David Van},
	pages = {29},
	file = {Hammer et al_Incremental Computation with Names.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hammer et al_Incremental Computation with Names.pdf:application/pdf}
}

@inproceedings{steindorfer_optimizing_2015,
	title = {Optimizing hash-array mapped tries for fast and lean immutable {JVM} collections},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814312},
	doi = {10.1145/2814270.2814312},
	abstract = {The data structures under-pinning collection API (e.g. lists, sets, maps) in the standard libraries of programming languages are used intensively in many applications.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Steindorfer, Michael J. and Vinju, Jurgen J.},
	year = {2015},
	pages = {783--800},
	file = {Steindorfer_Vinju_2015_Optimizing hash-array mapped tries for fast and lean immutable JVM collections.pdf:/home/michael/Dropbox/zotero-pdfs/S/Steindorfer_Vinju_2015_Optimizing hash-array mapped tries for fast and lean immutable JVM collections.pdf:application/pdf}
}

@article{wickerson_remote-scope_nodate,
	title = {Remote-{Scope} {Promotion}: {Clariﬁed}, {Rectiﬁed}, and {Veriﬁed}},
	abstract = {Modern accelerator programming frameworks, such as OpenCLTM, organise threads into work-groups. Remotescope promotion (RSP) is a language extension recently proposed by AMD researchers that is designed to enable applications, for the ﬁrst time, both to optimise for the common case of intra-work-group communication (using memory scopes to provide consistency only within a work-group) and to allow occasional inter-work-group communication (as required, for instance, to support the popular load-balancing idiom of work stealing).},
	language = {en},
	author = {Wickerson, John and Beckmann, Bradford M and Batty, Mark and Donaldson, Alastair F},
	pages = {17},
	file = {Wickerson et al_Remote-Scope Promotion.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wickerson et al_Remote-Scope Promotion.pdf:application/pdf}
}

@inproceedings{felgentreff_checks_2015,
	title = {Checks and balances: constraint solving without surprises in object-constraint programming languages},
	isbn = {978-1-4503-3689-5},
	shorttitle = {Checks and balances},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814311},
	doi = {10.1145/2814270.2814311},
	abstract = {Object-constraint programming systems integrate declarative constraint solving with imperative, object-oriented languages, seamlessly providing the power of both paradigms. However, experience with object-constraint systems has shown that giving too much power to the constraint solver opens up the potential for solutions that are surprising and unintended as well as for complex interactions between constraints and imperative code. On the other hand, systems that overly limit the power of the solver, for example by disallowing constraints involving mutable objects, object identity, or polymorphic message sends, run the risk of excluding the core object-oriented features of the language from the constraint part, and consequently not being able to express declaratively a large set of interesting problem solutions.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Felgentreff, Tim and Millstein, Todd and Borning, Alan and Hirschfeld, Robert},
	year = {2015},
	pages = {767--782},
	file = {Felgentreff et al_2015_Checks and balances.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felgentreff et al_2015_Checks and balances.pdf:application/pdf}
}

@article{toffola_performance_nodate,
	title = {Performance {Problems} {You} {Can} {Fix}: {A} {Dynamic} {Analysis} of {Memoization} {Opportunities}},
	abstract = {Performance bugs are a prevalent problem and recent research proposes various techniques to identify such bugs. This paper addresses a kind of performance problem that often is easy to address but difﬁcult to identify: redundant computations that may be avoided by reusing already computed results for particular inputs, a technique called memoization. To help developers ﬁnd and use memoization opportunities, we present MemoizeIt, a dynamic analysis that identiﬁes methods that repeatedly perform the same computation. The key idea is to compare inputs and outputs of method calls in a scalable yet precise way. To avoid the overhead of comparing objects at all method invocations in detail, MemoizeIt ﬁrst compares objects without following any references and iteratively increases the depth of exploration while shrinking the set of considered methods. After each iteration, the approach ignores methods that cannot beneﬁt from memoization, allowing it to analyze calls to the remaining methods in more detail. For every memoization opportunity that MemoizeIt detects, it provides hints on how to implement memoization, making it easy for the developer to ﬁx the performance issue. Applying MemoizeIt to eleven real-world Java programs reveals nine proﬁtable memoization opportunities, most of which are missed by traditional CPU time proﬁlers, conservative compiler optimizations, and other existing approaches for ﬁnding performance bugs. Adding memoization as proposed by MemoizeIt leads to statistically signiﬁcant speedups by factors between 1.04x and 12.93x.},
	language = {en},
	author = {Toffola, Luca Della and Pradel, Michael and Gross, Thomas R},
	pages = {16},
	file = {Toffola et al_Performance Problems You Can Fix.pdf:/home/michael/Dropbox/zotero-pdfs/T/Toffola et al_Performance Problems You Can Fix.pdf:application/pdf}
}

@article{alves_runtime_nodate,
	title = {Runtime {Pointer} {Disambiguation}},
	abstract = {To optimize code effectively, compilers must deal with memory dependencies. However, the state-of-the-art heuristics available in the literature to track memory dependencies are inherently imprecise and computationally expensive. Consequently, the most advanced code transformations that compilers have today are ineffective when applied on real-world programs. The goal of this paper is to solve this conundrum through dynamic disambiguation of pointers. We provide different ways to determine at runtime when two memory locations can overlap. We then produce two versions of a code region: one that is aliasing-free - hence, easy to optimize - and another that is not. Our checks let us safely branch to the optimizable region. We have applied these ideas on Polly-LLVM, a loop optimizer built on top of the LLVM compilation infrastructure. Our experiments indicate that our method is precise, effective and useful: we can disambiguate every pair of pointer in the loop intensive PolyBench benchmark suite. The result of this precision is code quality: the binaries we generate are 10\% faster than those that Polly-LLVM produces without our optimization, at the -O3 optimization level of LLVM.},
	language = {en},
	author = {Alves, Péricles and Gruber, Fabian and Doerfert, Johannes and Lamprineas, Alexandros and Grosser, Tobias and Rastello, Fabrice and Pereira, Fernando Magno Quintão},
	pages = {18},
	file = {Alves et al_Runtime Pointer Disambiguation.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alves et al_Runtime Pointer Disambiguation.pdf:application/pdf}
}

@inproceedings{madsen_static_2015,
	title = {Static analysis of event-driven {Node}.js {JavaScript} applications},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814272},
	doi = {10.1145/2814270.2814272},
	abstract = {Many JavaScript programs are written in an event-driven style. In particular, in server-side Node.js applications, operations involving sockets, streams, and ﬁles are typically performed in an asynchronous manner, where the execution of listeners is triggered by events. Several types of programming errors are speciﬁc to such event-based programs (e.g., unhandled events, and listeners that are registered too late). We present the event-based call graph, a program representation that can be used to detect bugs related to event handling. We have designed and implemented three analyses for constructing event-based call graphs. Our results show that these analyses are capable of detecting problems reported on StackOverﬂow. Moreover, we show that the number of false positives reported by the analysis on a suite of small Node.js applications is manageable.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Madsen, Magnus and Tip, Frank and Lhoták, Ondřej},
	year = {2015},
	pages = {505--519},
	file = {Madsen et al_2015_Static analysis of event-driven Node.pdf:/home/michael/Dropbox/zotero-pdfs/M/Madsen et al_2015_Static analysis of event-driven Node.pdf:application/pdf}
}

@inproceedings{oh_learning_2015,
	title = {Learning a strategy for adapting a program analysis via bayesian optimisation},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814309},
	doi = {10.1145/2814270.2814309},
	abstract = {Building a cost-effective static analyser for real-world programs is still regarded an art. One key contributor to this grim reputation is the difﬁculty in balancing the cost and the precision of an analyser. An ideal analyser should be adaptive to a given analysis task, and avoid using techniques that unnecessarily improve precision and increase analysis cost. However, achieving this ideal is highly nontrivial, and it requires a large amount of engineering efforts.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Oh, Hakjoo and Yang, Hongseok and Yi, Kwangkeun},
	year = {2015},
	pages = {572--588},
	file = {Oh et al_2015_Learning a strategy for adapting a program analysis via bayesian optimisation.pdf:/home/michael/Dropbox/zotero-pdfs/O/Oh et al_2015_Learning a strategy for adapting a program analysis via bayesian optimisation.pdf:application/pdf}
}

@article{wang_explorer_nodate,
	title = {{EXPLORER} : {Query}- and {Demand}-{Driven} {Exploration} of {Interprocedural} {Control} {Flow} {Properties}},
	abstract = {This paper describes a general framework—and its implementation in a tool called EXPLORER–for statically answering a class of interprocedural control ﬂow queries about Java programs. EXPLORER allows users to formulate queries about feasible callstack conﬁgurations using regular expressions, and it employs a precise, demand-driven algorithm for answering such queries. Speciﬁcally, EXPLORER constructs an automaton A that is iteratively reﬁned until either the language accepted by A is empty (meaning that the query has been refuted) or until no further reﬁnement is possible based on a precise, context-sensitive abstraction of the program. We evaluate EXPLORER by applying it to three different program analysis tasks, namely, (1) analysis of the observer design pattern in Java, (2) identiﬁcation of a class of performance bugs, and (3) analysis of inter-component communication in Android applications. Our evaluation shows that EXPLORER is both efﬁcient and precise.},
	language = {en},
	author = {Wang, Yu Feng Xinyu and Lin, Isil Dillig Calvin},
	pages = {15},
	file = {Wang_Lin_EXPLORER.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang_Lin_EXPLORER.pdf:application/pdf}
}

@article{crafa_chemical_nodate,
	title = {The chemical approach to typestate-oriented programming},
	abstract = {We study a novel approach to typestate-oriented programming based on the chemical metaphor: state and operations on objects are molecules of messages and state transformations are chemical reactions. This approach allows us to investigate typestate in an inherently concurrent setting, whereby objects can be accessed and modiﬁed concurrently by several processes, each potentially changing only part of their state. We introduce a simple behavioral type theory to express in a uniform way both the private and the public interfaces of objects, to describe and enforce structured object protocols consisting of possibilities, prohibitions, and obligations, and to control object sharing.},
	language = {en},
	author = {Crafa, Silvia and Padovani, Luca},
	pages = {22},
	file = {Crafa_Padovani_The chemical approach to typestate-oriented programming.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crafa_Padovani_The chemical approach to typestate-oriented programming.pdf:application/pdf}
}

@inproceedings{erdweg_co-contextual_2015,
	title = {A co-contextual formulation of type rules and its application to incremental type checking},
	isbn = {978-1-4503-3689-5},
	url = {http://dl.acm.org/citation.cfm?doid=2814270.2814277},
	doi = {10.1145/2814270.2814277},
	abstract = {Type rules associate types to expressions given a typing context. As the type checker traverses the expression tree topdown, it extends the typing context with additional context information that becomes available. This way, the typing context coordinates type checking in otherwise independent subexpressions, which inhibits parallelization and incrementalization of type checking. We propose a co-contextual formulation of type rules that only take an expression as input and produce a type and a set of context requirements. Co-contextual type checkers traverse an expression tree bottom-up and merge context requirements of independently checked subexpressions. We describe a method for systematically constructing a co-contextual formulation of type rules from a regular context-based formulation and we show how co-contextual type rules give rise to incremental type checking. Using our method, we derive incremental type checkers for PCF and for extensions that introduce records, parametric polymorphism, and subtyping. Our performance evaluation shows that co-contextual type checking has performance comparable to standard contextbased type checking, and incrementalization can improve performance signiﬁcantly.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Erdweg, Sebastian and Bračevac, Oliver and Kuci, Edlira and Krebs, Matthias and Mezini, Mira},
	year = {2015},
	pages = {880--897},
	file = {Erdweg et al_2015_A co-contextual formulation of type rules and its application to incremental.pdf:/home/michael/Dropbox/zotero-pdfs/E/Erdweg et al_2015_A co-contextual formulation of type rules and its application to incremental.pdf:application/pdf}
}

@article{clarke_disjointness_nodate,
	title = {Disjointness {Domains} for {Fine}-{Grained} {Aliasing} ∗},
	abstract = {Aliasing is crucial for supporting useful implementation patterns, but it makes reasoning about programs difﬁcult. To deal with this problem, numerous type-based aliasing control mechanisms have been proposed, expressing properties such as uniqueness. Uniqueness, however, is black-and-white: either a reference is unique or it can be arbitrarily aliased; and too global: excluding aliases throughout the entire system, making code brittle to changing requirements. Disjointness domains, a new approach to alias control, address this problem by enabling more graduations between uniqueness and arbitrary reference sharing. They allow expressing aliasing constraints local to a certain set of variables (either stack variables or ﬁelds) for instance that no aliasing occurs between variables within some set of variables but between such sets or the opposite, that aliasing occurs within that set but not between different sets. A hierarchy of disjointness domains controls the ﬂow of references through a program, helping the programmer reason about disjointness and enforce local alias invariants. The resulting system supports ﬁne-grained control of aliasing between both variables and objects, making aliasing explicit to programmers, compilers, and tooling. This paper presents a formal account of disjointness domains along with examples. Disjointness domains provide novel means of expressing may-alias kinds of constraints, which may prove useful in compiler optimisation and veriﬁcation.},
	language = {en},
	author = {Clarke, Stephan Brandauer Dave and Wrigstad, Tobias},
	pages = {19},
	file = {Clarke_Wrigstad_Disjointness Domains for Fine-Grained Aliasing ∗.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke_Wrigstad_Disjointness Domains for Fine-Grained Aliasing ∗.pdf:application/pdf}
}

@incollection{chaudhuri_psi:_2016,
	address = {Cham},
	title = {{PSI}: {Exact} {Symbolic} {Inference} for {Probabilistic} {Programs}},
	volume = {9779},
	isbn = {978-3-319-41527-7 978-3-319-41528-4},
	shorttitle = {{PSI}},
	url = {http://link.springer.com/10.1007/978-3-319-41528-4_4},
	abstract = {Probabilistic inference is a key mechanism for reasoning about probabilistic programs. Since exact inference is theoretically expensive, most probabilistic inference systems today have adopted approximate inference techniques, which trade precision for better performance (but often without guarantees). As a result, while desirable for its ultimate precision, the practical eﬀectiveness of exact inference for probabilistic programs is mostly unknown.},
	language = {en},
	urldate = {2018-04-03},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer International Publishing},
	author = {Gehr, Timon and Misailovic, Sasa and Vechev, Martin},
	editor = {Chaudhuri, Swarat and Farzan, Azadeh},
	year = {2016},
	doi = {10.1007/978-3-319-41528-4_4},
	pages = {62--83},
	file = {Gehr et al. - 2016 - PSI Exact Symbolic Inference for Probabilistic Pr.pdf:/home/michael/Zotero/storage/8R6T4ECL/Gehr et al. - 2016 - PSI Exact Symbolic Inference for Probabilistic Pr.pdf:application/pdf}
}

@inproceedings{mckinley_programming_2016,
	address = {New York, NY, USA},
	series = {{POPL} '16},
	title = {Programming the {World} of {Uncertain} {Things} ({Keynote})},
	isbn = {978-1-4503-3549-2},
	url = {http://doi.acm.org/10.1145/2837614.2843895},
	doi = {10.1145/2837614.2843895},
	abstract = {Computing has entered the era of uncertain data, in which hardware and software generate and reason about estimates. Applications use estimates from sensors, machine learning, big data, humans, and approximate hardware and software. Unfortunately, developers face pervasive correctness, programmability, and optimization problems due to estimates. Most programming languages unfortunately make these problems worse. We propose a new programming abstraction called Uncertain{\textless}T{\textgreater} embedded into languages, such as C\#, C++, Java, Python, and JavaScript. Applications that consume estimates use familiar discrete operations for their estimates; overloaded conditional operators specify hypothesis tests and applications use them control false positives and negatives; and new compositional operators express domain knowledge. By carefully restricting the expressiveness, the runtime automatically implements correct statistical reasoning at conditionals, relieving developers of the need to implement or deeply understand statistics. We demonstrate substantial programmability, correctness, and efficiency benefits of this programming model for GPS sensor navigation, approximate computing, machine learning, and xBox.},
	urldate = {2018-04-03},
	booktitle = {Proceedings of the 43rd {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {McKinley, Kathryn S.},
	year = {2016},
	keywords = {Lazy evaluation, Bayesian logic, Probabilistic programming, Programming with estimates},
	pages = {1--2},
	file = {McKinley_2016_Programming the World of Uncertain Things (Keynote).pdf:/home/michael/Dropbox/zotero-pdfs/M/McKinley_2016_Programming the World of Uncertain Things (Keynote).pdf:application/pdf}
}

@article{wang_combining_nodate,
	title = {{COMBINING} {ANALYSIS} {AND} {SYNTHESIS} {IN} {THE} {CHUCK} {PROGRAMMING} {LANGUAGE}},
	abstract = {In this paper, we present a new programming model for performing audio analysis, spectral processing, and feature extraction in the ChucK programming language. The solution unifies analysis and synthesis in the same high-level, strongly-timed, and concurrent environment, extending and fully integrating with the existing language framework. In particular, we introduce the notion of a Unit Analyzer (UAna) and new constructs for dataflow, data types and semantics for operations in analysis domains, and mechanisms for seamlessly combining analysis and synthesis tasks in a precise, sample-synchronous manner. We present the motivation of our system, and describe new language-level syntaxes, semantics, and the underlying implementation. We provide code examples and discuss potential uses and benefits of the system for audio researchers, performers, and teachers.},
	language = {en},
	author = {Wang, Ge and Fiebrink, Rebecca and Cook, Perry R},
	pages = {8},
	file = {Wang et al. - COMBINING ANALYSIS AND SYNTHESIS IN THE CHUCK PROG.pdf:/home/michael/Zotero/storage/L36RR6ZP/Wang et al. - COMBINING ANALYSIS AND SYNTHESIS IN THE CHUCK PROG.pdf:application/pdf}
}

@incollection{jensenius_2004:_2017,
	address = {Cham},
	title = {2004: {On}-the-{Fly} {Programming}: {Using} {Code} as an {Expressive} {Musical} {Instrument}},
	volume = {3},
	isbn = {978-3-319-47213-3 978-3-319-47214-0},
	shorttitle = {2004},
	url = {http://link.springer.com/10.1007/978-3-319-47214-0_13},
	abstract = {On-the-fly programming is a style of programming in which the programmer/performer/composer augments and modifies the program while it is running, without stopping or restarting, in order to assert expressive, programmable control at runtime. Because of the fundamental powers of programming languages, we believe the technical and aesthetic aspects of on-the-fly programming are worth exploring.},
	language = {en},
	urldate = {2018-04-03},
	booktitle = {A {NIME} {Reader}},
	publisher = {Springer International Publishing},
	author = {Wang, Ge and Cook, Perry R.},
	editor = {Jensenius, Alexander Refsum and Lyons, Michael J.},
	year = {2017},
	doi = {10.1007/978-3-319-47214-0_13},
	pages = {193--210},
	file = {Wang and Cook - 2017 - 2004 On-the-Fly Programming Using Code as an Exp.pdf:/home/michael/Zotero/storage/5J55NUD5/Wang and Cook - 2017 - 2004 On-the-Fly Programming Using Code as an Exp.pdf:application/pdf}
}

@misc{noauthor_session_nodate,
	title = {Session types in programming languages---a collection of implementations. {\textbar} {Simon} {Fowler}},
	url = {http://simonjf.com/2016/05/28/session-type-implementations.html},
	urldate = {2018-04-03}
}

@article{barber_dual_nodate,
	title = {Dual {Intuitionistic} {Linear} {Logic}},
	abstract = {We present a new intuitionistic linear logic, Dual Intuitionistic Linear Logic, designed to reﬂect the motivation of exponentials as translations of intuitionistic types, and provide it with a term calculus, proving associated standard type-theoretic results. We give a sound and complete categorical semantics for the type-system, and consider the relationship of the new type-theory to the more familiar presentation found for example in [4].},
	language = {en},
	author = {Barber, Andrew},
	pages = {54},
	file = {Barber - Dual Intuitionistic Linear Logic.pdf:/home/michael/Zotero/storage/KCV7X585/Barber - Dual Intuitionistic Linear Logic.pdf:application/pdf}
}

@inproceedings{mazurak_lightweight_2010,
	title = {Lightweight linear types in system f°},
	isbn = {978-1-60558-891-9},
	url = {http://portal.acm.org/citation.cfm?doid=1708016.1708027},
	doi = {10.1145/1708016.1708027},
	abstract = {We present System F◦, an extension of System F that uses kinds to distinguish between linear and unrestricted types, simplifying the use of linearity for general-purpose programming. We demonstrate through examples how System F◦ can elegantly express many useful protocols, and we prove that any protocol representable as a DFA can be encoded as an F◦ type. We supply mechanized proofs of System F◦’s soundness and parametricity properties, along with a nonstandard operational semantics that formalizes common intuitions about linearity and aids in reasoning about protocols.},
	language = {en},
	urldate = {2018-04-03},
	publisher = {ACM Press},
	author = {Mazurak, Karl and Zhao, Jianzhou and Zdancewic, Steve},
	year = {2010},
	pages = {77},
	file = {Mazurak et al_2010_Lightweight linear types in system f°.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mazurak et al_2010_Lightweight linear types in system f°.pdf:application/pdf}
}

@article{plasmeijer_version_nodate,
	title = {Version 2.2 {Language} {Report}},
	language = {en},
	author = {Plasmeijer, Rinus},
	pages = {148},
	file = {Plasmeijer_Version 2.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plasmeijer_Version 2.pdf:application/pdf}
}

@article{crary_intensional_nodate,
	title = {Intensional {Polymorphism} in {Type}-{Erasure} {Semantics}},
	abstract = {Intensional polymorphism, the ability to dispatch to different routines based on types at run time, enables a variety of advanced implementation techniques for polymorphic languages, including tag-free garbage collection, unboxed function arguments, polymorphic marshalling, and ﬂattened data structures. To date, languages that support intensional polymorphism have required a type-passing (as opposed to type-erasure) interpretation where types are constructed and passed to polymorphic functions at run time. Unfortunately, type-passing suﬀers from a number of drawbacks; it requires duplication of constructs at the term and type levels, it prevents abstraction, and it severely complicates polymorphic closure conversion.},
	language = {en},
	author = {Crary, Karl and Morrisett, Stephanie Weirich Greg},
	pages = {14},
	file = {Crary_Morrisett_Intensional Polymorphism in Type-Erasure Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary_Morrisett_Intensional Polymorphism in Type-Erasure Semantics.pdf:application/pdf}
}

@inproceedings{fahndrich_adoption_2002,
	address = {New York, NY, USA},
	series = {{PLDI} '02},
	title = {Adoption and {Focus}: {Practical} {Linear} {Types} for {Imperative} {Programming}},
	isbn = {978-1-58113-463-6},
	shorttitle = {Adoption and {Focus}},
	url = {http://doi.acm.org/10.1145/512529.512532},
	doi = {10.1145/512529.512532},
	abstract = {A type system with linearity is useful for checking software protocols andresource management at compile time. Linearity provides powerful reasoning about state changes, but at the price of restrictions on aliasing. The hard division between linear and nonlinear types forces the programmer to make a trade-off between checking a protocol on an object and aliasing the object. Most onerous is the restriction that any type with a linear component must itself be linear. Because of this, checking a protocol on an object imposes aliasing restrictions on any data structure that directly or indirectly points to the object. We propose a new type system that reduces these restrictions with the adoption and focus constructs. Adoption safely allows a programmer to alias objects on which she is checking protocols, and focus allows the reverse. A programmer can alias data structures that point to linear objects and use focus for safe access to those objects. We discuss how we implemented these ideas in the Vault programming language.},
	urldate = {2018-04-03},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2002 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Fahndrich, Manuel and DeLine, Robert},
	year = {2002},
	keywords = {linear types, region-based memory management, heap aliasing},
	pages = {13--24},
	file = {Fahndrich_DeLine_2002_Adoption and Focus.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fahndrich_DeLine_2002_Adoption and Focus.pdf:application/pdf}
}

@inproceedings{lopez_protocol-based_2015,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2015},
	title = {Protocol-based {Verification} of {Message}-passing {Parallel} {Programs}},
	isbn = {978-1-4503-3689-5},
	url = {http://doi.acm.org/10.1145/2814270.2814302},
	doi = {10.1145/2814270.2814302},
	abstract = {We present ParTypes, a type-based methodology for the verification of Message Passing Interface (MPI) programs written in the C programming language. The aim is to statically verify programs against protocol specifications, enforcing properties such as fidelity and absence of deadlocks. We develop a protocol language based on a dependent type system for message-passing parallel programs, which includes various communication operators, such as point-to-point messages, broadcast, reduce, array scatter and gather. For the verification of a program against a given protocol, the protocol is first translated into a representation read by VCC, a software verifier for C. We successfully verified several MPI programs in a running time that is independent of the number of processes or other input parameters. This contrasts with alternative techniques, notably model checking and runtime verification, that suffer from the state-explosion problem or that otherwise depend on parameters to the program itself. We experimentally evaluated our approach against state-of-the-art tools for MPI to conclude that our approach offers a scalable solution.},
	urldate = {2018-04-03},
	booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {López, Hugo A. and Marques, Eduardo R. B. and Martins, Francisco and Ng, Nicholas and Santos, César and Vasconcelos, Vasco Thudichum and Yoshida, Nobuko},
	year = {2015},
	keywords = {Session types, Dependent types, MPI, Parallel programming, Program verification},
	pages = {280--298},
	file = {Lopez et al_2015_Protocol-based Verification of Message-passing Parallel Programs.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lopez et al_2015_Protocol-based Verification of Message-passing Parallel Programs.pdf:application/pdf}
}

@book{restall_introduction_2000,
	address = {London ; New York},
	title = {An introduction to substructural logics},
	isbn = {978-0-415-21533-6 978-0-415-21534-3},
	language = {en},
	publisher = {Routledge},
	author = {Restall, Greg},
	year = {2000},
	keywords = {Logic, Symbolic and mathematical},
	file = {Restall - 2000 - An introduction to substructural logics.pdf:/home/michael/Zotero/storage/K6NEQYBX/Restall - 2000 - An introduction to substructural logics.pdf:application/pdf}
}

@techreport{noauthor_secure_1978,
	title = {Secure {Minicomputer} {Operating} {System} ({KSOS}) {Secure} {UNIX} {Verification} {Plan}},
	institution = {Ford Aerospace and Communications Corporation},
	year = {1978},
	file = {[10]_FORD_ksos-verification-plan_1978_tech-report.pdf:/home/michael/Zotero/storage/66BCLVCX/[10]_FORD_ksos-verification-plan_1978_tech-report.pdf:application/pdf}
}

@article{robinson_machine-oriented_1965,
	title = {A {Machine}-{Oriented} {Logic} {Based} on the {Resolution} {Principle}},
	volume = {12},
	number = {1},
	journal = {Journal of the Association for Computing Machinery},
	author = {Robinson, J},
	month = jan,
	year = {1965},
	pages = {23--41},
	file = {ROBINSON_a-machine-oriented-logic-based-on-the-resolution-principle_1965_journal-of-the-acm.pdf:/home/michael/Zotero/storage/2X3CBJKT/ROBINSON_a-machine-oriented-logic-based-on-the-resolution-principle_1965_journal-of-the-acm.pdf:application/pdf}
}

@article{sagiv_parametric_2002,
	title = {Parametric {Shape} {Analysis} via 3-{Valued} {Logic}},
	author = {Sagiv, Mooly and Reps, Thomas and Wilhelm, Reinhard},
	year = {2002},
	file = {[9]_SAGIV-REPS-WILHELM_parametric-shape-analysis-via-3-valued-logic_2002.pdf:/home/michael/Zotero/storage/ZF5H3PZE/[9]_SAGIV-REPS-WILHELM_parametric-shape-analysis-via-3-valued-logic_2002.pdf:application/pdf}
}

@inproceedings{pierce_object-oriented_1993,
	address = {New York, NY, USA},
	series = {{POPL} '93},
	title = {Object-oriented {Programming} {Without} {Recursive} {Types}},
	isbn = {978-0-89791-560-1},
	url = {http://doi.acm.org/10.1145/158511.158653},
	doi = {10.1145/158511.158653},
	abstract = {It is widely agreed that recursive types are inherent in the static typing of the essential mechanisms of object-oriented programming: encapsulation, message passing, subtyping, and inheritance. We demonstrate here that modeling object encapsulation in terms of existential types yields a substantially more straightforward explanation of these features in a simpler calculus without recursive types.},
	urldate = {2018-04-04},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Pierce, Benjamin C. and Turner, David N.},
	year = {1993},
	pages = {299--312},
	file = {Pierce_Turner_1993_Object-oriented Programming Without Recursive Types.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pierce_Turner_1993_Object-oriented Programming Without Recursive Types.pdf:application/pdf}
}

@inproceedings{crary_toward_2003,
	address = {New York, NY, USA},
	series = {{POPL} '03},
	title = {Toward a {Foundational} {Typed} {Assembly} {Language}},
	isbn = {978-1-58113-628-9},
	url = {http://doi.acm.org/10.1145/604131.604149},
	doi = {10.1145/604131.604149},
	abstract = {We present the design of a typed assembly language called TALT that supports heterogeneous tuples, disjoint sums, and a general account of addressing modes. TALT also implements the von Neumann model in which programs are stored in memory, and supports relative addressing. Type safety for execution and for garbage collection are shown by machine-checkable proofs. TALT is the first formalized typed assembly language to provide any of these features.},
	urldate = {2018-04-04},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Crary, Karl},
	year = {2003},
	keywords = {typed assembly language, proof-carrying code},
	pages = {198--212},
	file = {Crary_2003_Toward a Foundational Typed Assembly Language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary_2003_Toward a Foundational Typed Assembly Language.pdf:application/pdf}
}

@inproceedings{hathhorn_defining_2015,
	address = {New York, NY, USA},
	series = {{PLDI} '15},
	title = {Defining the {Undefinedness} of {C}},
	isbn = {978-1-4503-3468-6},
	url = {http://doi.acm.org/10.1145/2737924.2737979},
	doi = {10.1145/2737924.2737979},
	abstract = {We present a ``negative'' semantics of the C11 language---a semantics that does not just give meaning to correct programs, but also rejects undefined programs. We investigate undefined behavior in C and discuss the techniques and special considerations needed for formally specifying it. We have used these techniques to modify and extend a semantics of C into one that captures undefined behavior. The amount of semantic infrastructure and effort required to achieve this was unexpectedly high, in the end nearly doubling the size of the original semantics. From our semantics, we have automatically extracted an undefinedness checker, which we evaluate against other popular analysis tools, using our own test suite in addition to a third-party test suite. Our checker is capable of detecting examples of all 77 categories of core language undefinedness appearing in the C11 standard, more than any other tool we considered. Based on this evaluation, we argue that our work is the most comprehensive and complete semantic treatment of undefined behavior in C, and thus of the C language itself.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Hathhorn, Chris and Ellison, Chucky and Roşu, Grigore},
	year = {2015},
	keywords = {C11, K Framework, Programming language semantics, Undefined behavior},
	pages = {336--345},
	file = {Hathhorn et al_2015_Defining the Undefinedness of C.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hathhorn et al_2015_Defining the Undefinedness of C.pdf:application/pdf}
}

@inproceedings{ball_slam_2002,
	address = {New York, NY, USA},
	series = {{POPL} '02},
	title = {The {SLAM} {Project}: {Debugging} {System} {Software} via {Static} {Analysis}},
	isbn = {978-1-58113-450-6},
	shorttitle = {The {SLAM} {Project}},
	url = {http://doi.acm.org/10.1145/503272.503274},
	doi = {10.1145/503272.503274},
	abstract = {The goal of the SLAM project is to check whether or not a program obeys "API usage rules" that specify what it means to be a good client of an API. The SLAM toolkit statically analyzes a C program to determine whether or not it violates given usage rules. The toolkit has two unique aspects: it does not require the programmer to annotate the source program (invariants are inferred); it minimizes noise (false error messages) through a process known as "counterexample-driven refinement". SLAM exploits and extends results from program analysis, model checking and automated deduction. We have successfully applied the SLAM toolkit to Windows XP device drivers, to both validate behavior and find defects in their usage of kernel APIs.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 29th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Ball, Thomas and Rajamani, Sriram K.},
	year = {2002},
	pages = {1--3},
	file = {Ball_Rajamani_2002_The SLAM Project.pdf:/home/michael/Dropbox/zotero-pdfs/B/Ball_Rajamani_2002_The SLAM Project.pdf:application/pdf}
}

@inproceedings{ball_thorough_2006,
	address = {New York, NY, USA},
	series = {{EuroSys} '06},
	title = {Thorough {Static} {Analysis} of {Device} {Drivers}},
	isbn = {978-1-59593-322-5},
	url = {http://doi.acm.org/10.1145/1217935.1217943},
	doi = {10.1145/1217935.1217943},
	abstract = {Bugs in kernel-level device drivers cause 85\% of the system crashes in the Windows XP operating system [44]. One of the sources of these errors is the complexity of the Windows driver API itself: programmers must master a complex set of rules about how to use the driver API in order to create drivers that are good clients of the kernel. We have built a static analysis engine that finds API usage errors in C programs. The Static Driver Verifier tool (SDV) uses this engine to find kernel API usage errors in a driver. SDV includes models of the OS and the environment of the device driver, and over sixty API usage rules. SDV is intended to be used by driver developers "out of the box." Thus, it has stringent requirements: (1) complete automation with no input from the user; (2) a low rate of false errors. We discuss the techniques used in SDV to meet these requirements, and empirical results from running SDV on over one hundred Windows device drivers.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 1st {ACM} {SIGOPS}/{EuroSys} {European} {Conference} on {Computer} {Systems} 2006},
	publisher = {ACM},
	author = {Ball, Thomas and Bounimova, Ella and Cook, Byron and Levin, Vladimir and Lichtenberg, Jakob and McGarvey, Con and Ondrusek, Bohus and Rajamani, Sriram K. and Ustuner, Abdullah},
	year = {2006},
	keywords = {software model checking, formal verification},
	pages = {73--85},
	file = {Ball et al_2006_Thorough Static Analysis of Device Drivers.pdf:/home/michael/Dropbox/zotero-pdfs/B/Ball et al_2006_Thorough Static Analysis of Device Drivers.pdf:application/pdf}
}

@inproceedings{beyer_checking_2005,
	title = {Checking memory safety with {Blast}},
	booktitle = {International {Conference} on {Fundamental} {Approaches} to {Software} {Engineering}},
	publisher = {Springer},
	author = {Beyer, Dirk and Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak},
	year = {2005},
	pages = {2--18},
	file = {Beyer et al_2005_Checking memory safety with Blast.pdf:/home/michael/Dropbox/zotero-pdfs/B/Beyer et al_2005_Checking memory safety with Blast.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/4ZQT7IQZ/10.html:text/html}
}

@inproceedings{dhurjati_memory_2003,
	title = {Memory safety without runtime checks or garbage collection},
	volume = {38},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Dhurjati, Dinakar and Kowshik, Sumant and Adve, Vikram and Lattner, Chris},
	year = {2003},
	pages = {69--80},
	file = {Dhurjati et al_2003_Memory safety without runtime checks or garbage collection.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dhurjati et al_2003_Memory safety without runtime checks or garbage collection.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/H9N3P2CS/citation.html:text/html}
}

@inproceedings{caballero_undangle:_2012,
	title = {Undangle: early detection of dangling pointers in use-after-free and double-free vulnerabilities},
	shorttitle = {Undangle},
	booktitle = {Proceedings of the 2012 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Caballero, Juan and Grieco, Gustavo and Marron, Mark and Nappa, Antonio},
	year = {2012},
	pages = {133--143},
	file = {Caballero et al_2012_Undangle.pdf:/home/michael/Dropbox/zotero-pdfs/C/Caballero et al_2012_Undangle.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/XD7RN7MD/citation.html:text/html}
}

@inproceedings{condit_ccured_2003,
	title = {{CCured} in the real world},
	volume = {38},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Condit, Jeremy and Harren, Matthew and McPeak, Scott and Necula, George C. and Weimer, Westley},
	year = {2003},
	pages = {232--244},
	file = {Snapshot:/home/michael/Zotero/storage/NUCNJYDS/citation.html:text/html}
}

@inproceedings{lee_jinn:_2010,
	title = {Jinn: synthesizing dynamic bug detectors for foreign language interfaces},
	volume = {45},
	shorttitle = {Jinn},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Lee, Byeongcheol and Wiedermann, Ben and Hirzel, Martin and Grimm, Robert and McKinley, Kathryn S.},
	year = {2010},
	pages = {36--49},
	file = {Snapshot:/home/michael/Zotero/storage/2EATAJF7/citation.html:text/html}
}

@inproceedings{furr_checking_2005,
	title = {Checking type safety of foreign function calls},
	volume = {40},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Furr, Michael and Foster, Jeffrey S.},
	year = {2005},
	pages = {62--72},
	file = {Furr_Foster_2005_Checking type safety of foreign function calls.pdf:/home/michael/Dropbox/zotero-pdfs/F/Furr_Foster_2005_Checking type safety of foreign function calls.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/Z54NZI9N/citation.html:text/html}
}

@incollection{erlingsson_low-level_2007,
	title = {Low-level software security: {Attacks} and defenses},
	shorttitle = {Low-level software security},
	booktitle = {Foundations of security analysis and design {IV}},
	publisher = {Springer},
	author = {Erlingsson, Úlfar},
	year = {2007},
	pages = {92--134},
	file = {Erlingsson_2007_Low-level software security.pdf:/home/michael/Dropbox/zotero-pdfs/E/Erlingsson_2007_Low-level software security.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/5FFZRMXM/978-3-540-74810-6_4.html:text/html}
}

@article{nagarakatte_softbound:_2009,
	title = {{SoftBound}: {Highly} compatible and complete spatial memory safety for {C}},
	volume = {44},
	shorttitle = {{SoftBound}},
	number = {6},
	journal = {ACM Sigplan Notices},
	author = {Nagarakatte, Santosh and Zhao, Jianzhou and Martin, Milo MK and Zdancewic, Steve},
	year = {2009},
	pages = {245--258},
	file = {Nagarakatte et al_2009_SoftBound.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nagarakatte et al_2009_SoftBound.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/JHDRYDBZ/citation.html:text/html}
}

@article{patel_enabling_2015,
	title = {Enabling high-level application development for the {Internet} of {Things}},
	volume = {103},
	journal = {Journal of Systems and Software},
	author = {Patel, Pankesh and Cassou, Damien},
	year = {2015},
	pages = {62--84},
	file = {Patel_Cassou_2015_Enabling high-level application development for the Internet of Things.pdf:/home/michael/Dropbox/zotero-pdfs/P/Patel_Cassou_2015_Enabling high-level application development for the Internet of Things.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/7W8B5TEC/S0164121215000187.html:text/html}
}

@inproceedings{mainland_nikola:_2010,
	title = {Nikola: embedding compiled {GPU} functions in {Haskell}},
	volume = {45},
	shorttitle = {Nikola},
	booktitle = {{ACM} {Sigplan} {Notices}},
	publisher = {ACM},
	author = {Mainland, Geoffrey and Morrisett, Greg},
	year = {2010},
	pages = {67--78},
	file = {Mainland_Morrisett_2010_Nikola.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mainland_Morrisett_2010_Nikola.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/BFIKGBUR/citation.html:text/html}
}

@inproceedings{tlili_hybrid_2008,
	title = {A hybrid approach for safe memory management in {C}},
	booktitle = {International {Conference} on {Algebraic} {Methodology} and {Software} {Technology}},
	publisher = {Springer},
	author = {Tlili, Syrine and Yang, Zhenrong and Ling, Hai Zhou and Debbabi, Mourad},
	year = {2008},
	pages = {377--391},
	file = {Snapshot:/home/michael/Zotero/storage/LR5V55W5/978-3-540-79980-1_28.html:text/html;Tlili et al_2008_A hybrid approach for safe memory management in C.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tlili et al_2008_A hybrid approach for safe memory management in C.pdf:application/pdf}
}

@inproceedings{mammar_overview_2011,
	title = {An overview of a proof-based approach to detecting {C} vulnerabilities},
	booktitle = {Proceedings of the 2011 {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Mammar, Amel},
	year = {2011},
	pages = {1343--1344},
	file = {Snapshot:/home/michael/Zotero/storage/RIV962UN/citation.html:text/html}
}

@inproceedings{cervesato_efficient_1996,
	title = {Efficient resource management for linear logic proof search},
	booktitle = {International {Workshop} on {Extensions} of {Logic} {Programming}},
	publisher = {Springer},
	author = {Cervesato, Iliano and Hodas, Joshua S. and Pfenning, Frank},
	year = {1996},
	pages = {67--81},
	file = {Snapshot:/home/michael/Zotero/storage/WBDKTTL3/3-540-60983-0_5.html:text/html}
}

@inproceedings{mcheick_detecting_2010,
	title = {Detecting type errors and secure coding in {C}/{C}++ applications},
	booktitle = {Computer {Systems} and {Applications} ({AICCSA}), 2010 {IEEE}/{ACS} {International} {Conference} on},
	publisher = {IEEE},
	author = {Mcheick, Hamid and Dhiab, Heni and Dbouk, Mohamad and Mcheik, Rakan},
	year = {2010},
	pages = {1--9},
	file = {Mcheick et al_2010_Detecting type errors and secure coding in C-C++ applications.pdf:/home/michael/Dropbox/zotero-pdfs/M/Mcheick et al_2010_Detecting type errors and secure coding in C-C++ applications.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/SJRIJ5KD/5587027.html:text/html}
}

@article{gay_software_2007,
	title = {Software design patterns for {TinyOS}},
	volume = {6},
	number = {4},
	journal = {ACM Transactions on Embedded Computing Systems (TECS)},
	author = {Gay, David and Levis, Philip and Culler, David},
	year = {2007},
	pages = {22},
	file = {Gay et al_2007_Software design patterns for TinyOS.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gay et al_2007_Software design patterns for TinyOS.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/RSIR85SW/citation.html:text/html}
}

@book{grossman_safe_2003,
	title = {Safe programming at the {C} level of abstraction},
	publisher = {Citeseer},
	author = {Grossman, Dan and Morrisett, Greg},
	year = {2003}
}

@inproceedings{west_cuckoo:_2005,
	title = {Cuckoo: a language for implementing memory-and thread-safe system services},
	shorttitle = {Cuckoo},
	booktitle = {Proceedings of the {International} {Conference} on {Programming} {Languages} and {Compilers}},
	author = {West, Richard and Wong, Gary},
	month = jun,
	year = {2005},
	pages = {94--100},
	file = {Snapshot:/home/michael/Zotero/storage/TFBZIGM2/1833.html:text/html;West_Wong_2005_Cuckoo.pdf:/home/michael/Dropbox/zotero-pdfs/W/West_Wong_2005_Cuckoo.pdf:application/pdf}
}

@incollection{levis_tinyos:_2005,
	title = {{TinyOS}: {An} operating system for sensor networks},
	shorttitle = {{TinyOS}},
	booktitle = {Ambient intelligence},
	publisher = {Springer},
	author = {Levis, Philip and Madden, Sam and Polastre, Joseph and Szewczyk, Robert and Whitehouse, Kamin and Woo, Alec and Gay, David and Hill, Jason and Welsh, Matt and Brewer, Eric},
	year = {2005},
	pages = {115--148},
	file = {Levis et al_2005_TinyOS.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levis et al_2005_TinyOS.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/XHYEWLZM/3-540-27139-2_7.html:text/html}
}

@book{shapiro_bitc_2008,
	title = {{BitC} language specification},
	publisher = {Technical report, The EROS Group and Johns Hopkins University},
	author = {Shapiro, J. S. and Sridhar, Swaroop and Doerrie, M. S.},
	year = {2008}
}

@article{devietti_hardbound:_2008,
	title = {Hardbound: architectural support for spatial safety of the {C} programming language},
	volume = {36},
	shorttitle = {Hardbound},
	number = {1},
	journal = {ACM SIGARCH Computer Architecture News},
	author = {Devietti, Joe and Blundell, Colin and Martin, Milo MK and Zdancewic, Steve},
	year = {2008},
	pages = {103--114},
	file = {Devietti et al_2008_Hardbound.pdf:/home/michael/Dropbox/zotero-pdfs/D/Devietti et al_2008_Hardbound.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/SHWVBPU8/citation.html:text/html}
}

@inproceedings{pattabiraman_samurai:_2008,
	title = {Samurai: protecting critical data in unsafe languages},
	volume = {42},
	shorttitle = {Samurai},
	booktitle = {{ACM} {SIGOPS} {Operating} {Systems} {Review}},
	publisher = {ACM},
	author = {Pattabiraman, Karthik and Grover, Vinod and Zorn, Benjamin G.},
	year = {2008},
	pages = {219--232},
	file = {Pattabiraman et al_2008_Samurai.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pattabiraman et al_2008_Samurai.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/W7FPAQYF/citation.html:text/html}
}

@inproceedings{hallgren_principled_2005-1,
	title = {A principled approach to operating system construction in {Haskell}},
	volume = {40},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Hallgren, Thomas and Jones, Mark P. and Leslie, Rebekah and Tolmach, Andrew},
	year = {2005},
	pages = {116--128},
	file = {Hallgren et al_2005_A principled approach to operating system construction in Haskell.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hallgren et al_2005_A principled approach to operating system construction in Haskell.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/M56K42VC/citation.html:text/html}
}

@inproceedings{hicks_experience_2004,
	title = {Experience with safe manual memory-management in cyclone},
	booktitle = {Proceedings of the 4th international symposium on {Memory} management},
	publisher = {ACM},
	author = {Hicks, Michael and Morrisett, Greg and Grossman, Dan and Jim, Trevor},
	year = {2004},
	pages = {73--84},
	file = {Hicks et al_2004_Experience with safe manual memory-management in cyclone.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hicks et al_2004_Experience with safe manual memory-management in cyclone.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/M9BL28BP/citation.html:text/html}
}

@inproceedings{younan_paricheck:_2010,
	title = {{PAriCheck}: an efficient pointer arithmetic checker for {C} programs},
	shorttitle = {{PAriCheck}},
	booktitle = {Proceedings of the 5th {ACM} {Symposium} on {Information}, {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Younan, Yves and Philippaerts, Pieter and Cavallaro, Lorenzo and Sekar, R. and Piessens, Frank and Joosen, Wouter},
	year = {2010},
	pages = {145--156},
	file = {Snapshot:/home/michael/Zotero/storage/SY2NFFNX/citation.html:text/html;Younan et al_2010_PAriCheck.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Younan et al_2010_PAriCheck.pdf:application/pdf}
}

@article{aspinall_heap-bounded_2003,
	title = {Heap-bounded assembly language},
	volume = {31},
	number = {3-4},
	journal = {Journal of automated reasoning},
	author = {Aspinall, David and Compagnoni, Adriana},
	year = {2003},
	pages = {261--302},
	file = {Aspinall_Compagnoni_2003_Heap-bounded assembly language.pdf:/home/michael/Dropbox/zotero-pdfs/A/Aspinall_Compagnoni_2003_Heap-bounded assembly language.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/B7CHV96V/BJARS.0000021014.79255.html:text/html}
}

@book{deline_vault:_2001,
	title = {{VAULT}: a programming language for reliable systems},
	shorttitle = {{VAULT}},
	author = {Deline, R. and Fähndrich, M.},
	year = {2001}
}

@inproceedings{xu_safety_2000,
	title = {Safety checking of machine code},
	volume = {35},
	booktitle = {{ACM} {SIGPLAN} {Notices}},
	publisher = {ACM},
	author = {Xu, Zhichen and Miller, Barton P. and Reps, Thomas},
	year = {2000},
	pages = {70--82},
	file = {Snapshot:/home/michael/Zotero/storage/S7XXDMG5/citation.html:text/html;Xu et al_2000_Safety checking of machine code.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xu et al_2000_Safety checking of machine code.pdf:application/pdf}
}

@book{crary_toward_2003-1,
	title = {Toward a foundational typed assembly language},
	volume = {38},
	number = {1},
	publisher = {ACM},
	author = {Crary, Karl},
	year = {2003},
	file = {Crary_2003_Toward a foundational typed assembly language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary_2003_Toward a foundational typed assembly language.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/77GU6RSI/citation.html:text/html}
}

@inproceedings{crary_type_1999,
	title = {Type structure for low-level programming languages},
	booktitle = {International {Colloquium} on {Automata}, {Languages}, and {Programming}},
	publisher = {Springer},
	author = {Crary, Karl and Morrisett, Greg},
	year = {1999},
	pages = {40--54},
	file = {Crary_Morrisett_1999_Type structure for low-level programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/C/Crary_Morrisett_1999_Type structure for low-level programming languages.pdf:application/pdf;Snapshot:/home/michael/Zotero/storage/4F6CKIVT/3-540-48523-6_4.html:text/html}
}

@inproceedings{harren_using_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Using {Dependent} {Types} to {Certify} the {Safety} of {Assembly} {Code}},
	isbn = {978-3-540-28584-7 978-3-540-31971-9},
	url = {https://link.springer.com/chapter/10.1007/11547662_12},
	doi = {10.1007/11547662_12},
	abstract = {There are many source-level analyses or instrumentation tools that enforce various safety properties. In this paper we present an infrastructure that can be used to check independently that the assembly output of such tools has the desired safety properties. By working at assembly level we avoid the complications with unavailability of source code, with source-level parsing, and we certify the code that is actually deployed.The novel feature of the framework is an extensible dependently-typed framework that supports type inference and mutation of dependent values in memory. The type system can be extended with new types as needed for the source-level tool that is certified. Using these dependent types, we are able to express the invariants enforced by CCured, a source-level instrumentation tool that guarantees type safety in legacy C programs. We can therefore check that the x86 assembly code resulting from compilation with CCured is in fact type-safe.},
	language = {en},
	urldate = {2018-04-05},
	booktitle = {Static {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Harren, Matthew and Necula, George C.},
	month = sep,
	year = {2005},
	pages = {155--170},
	file = {Harren_Necula_2005_Using Dependent Types to Certify the Safety of Assembly Code.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harren_Necula_2005_Using Dependent Types to Certify the Safety of Assembly Code.pdf:application/pdf}
}

@inproceedings{regehr_efficient_2006,
	address = {New York, NY, USA},
	series = {{PLOS} '06},
	title = {Efficient {Type} and {Memory} {Safety} for {Tiny} {Embedded} {Systems}},
	isbn = {978-1-59593-577-9},
	url = {http://doi.acm.org/10.1145/1215995.1216001},
	doi = {10.1145/1215995.1216001},
	abstract = {We report our experience in implementing type and memory safety in an efficient manner for sensor network nodes running TinyOS: tiny embedded systems running legacy, C-like code. A compiler for a safe language must often insert dynamic checks into the programs it produces; these generally make programs both larger and slower. In this paper, we describe our novel compiler toolchain, which uses a family of techniques to minimize or avoid these run-time costs. Our results show that safety can in fact be implemented cheaply on low-end 8-bit microcontrollers.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 3rd {Workshop} on {Programming} {Languages} and {Operating} {Systems}: {Linguistic} {Support} for {Modern} {Operating} {Systems}},
	publisher = {ACM},
	author = {Regehr, John and Cooprider, Nathan and Archer, Will and Eide, Eric},
	year = {2006},
	file = {Regehr et al_2006_Efficient Type and Memory Safety for Tiny Embedded Systems.pdf:/home/michael/Dropbox/zotero-pdfs/R/Regehr et al_2006_Efficient Type and Memory Safety for Tiny Embedded Systems.pdf:application/pdf}
}

@inproceedings{greenaway_bridging_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Bridging the {Gap}: {Automatic} {Verified} {Abstraction} of {C}},
	isbn = {978-3-642-32346-1 978-3-642-32347-8},
	shorttitle = {Bridging the {Gap}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-32347-8_8},
	doi = {10.1007/978-3-642-32347-8_8},
	abstract = {Before low-level imperative code can be reasoned about in an interactive theorem prover, it must first be converted into a logical representation in that theorem prover. Accurate translations of such code should be conservative, choosing safe representations over representations convenient to reason about. This paper bridges the gap between conservative representation and convenient reasoning. We present a tool that automatically abstracts low-level C semantics into higher level specifications, while generating proofs of refinement in Isabelle/HOL for each translation step. The aim is to generate a verified, human-readable specification, convenient for further reasoning.},
	language = {en},
	urldate = {2018-04-05},
	booktitle = {Interactive {Theorem} {Proving}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Greenaway, David and Andronick, June and Klein, Gerwin},
	month = aug,
	year = {2012},
	pages = {99--115},
	file = {Greenaway et al_2012_Bridging the Gap.pdf:/home/michael/Dropbox/zotero-pdfs/G/Greenaway et al_2012_Bridging the Gap.pdf:application/pdf}
}

@inproceedings{simpson_segment_2005-1,
	address = {New York, NY, USA},
	series = {{CASES} '05},
	title = {Segment {Protection} for {Embedded} {Systems} {Using} {Run}-time {Checks}},
	isbn = {978-1-59593-149-8},
	url = {http://doi.acm.org/10.1145/1086297.1086307},
	doi = {10.1145/1086297.1086307},
	abstract = {The lack of virtual memory protection is a serious source of unreliability in many embedded systems. Without the segment-level protection it provides, these systems are subject to memory access violations, stemming from programmer error, whose results can be dangerous and catastrophic in safety-critical systems. The traditional method of testing embedded software before its deployment is an insufficient means of detecting and debugging all software errors, and the reliance on this practice is a severe gamble when the reliable performance of the embedded device is critical. Additionally, the use of safe languages and programming semantic restrictions as prevention mechanisms is often infeasible when considering the adoptability and compatibility of these languages since most embedded applications are written in C and C++.This work improves system reliability by providing a completely automatic software technique for guaranteeing segment protection for embedded systems lacking virtual memory. This is done by inserting optimized run-time checks before memory accesses that detect segmentation violations in cases in which there would otherwise be no error, enabling remedial action before system failure or corruption. This feature is invaluable for safety-critical embedded systems. Other advantages of our method include its low overhead, lack of any programming language or semantic restrictions, and ease of implementation. Our compile-time analysis, known as intended segment analysis, is a uniquely structured analysis that allows for the realization of optimizations used to reduce the number of required run-time checks and foster our technique into a truly viable solution for providing segment protection in embedded systems lacking virtual memory.Our experimental results show that these optimizations are effective at reducing the performance overheads associated with providing software segment protection to low, and in many cases, negligible levels. For the eight evaluated embedded benchmarks, the average increase in run-time is 0.72\%, the average increase in energy consumption is 0.44\%, and the average increase in code size is 3.60\%.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 2005 {International} {Conference} on {Compilers}, {Architectures} and {Synthesis} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Simpson, Matthew and Middha, Bhuvan and Barua, Rajeev},
	year = {2005},
	keywords = {memory safety, compilers, reliability, virtual memory, run-time checks, ewmbedded systems, MMU, MPU, safe languages, segment protection, segmentation violations},
	pages = {66--77},
	file = {Simpson et al_2005_Segment Protection for Embedded Systems Using Run-time Checks.pdf:/home/michael/Dropbox/zotero-pdfs/S/Simpson et al_2005_Segment Protection for Embedded Systems Using Run-time Checks.pdf:application/pdf}
}

@inproceedings{henglein_direct_2001-1,
	address = {New York, NY, USA},
	series = {{PPDP} '01},
	title = {A {Direct} {Approach} to {Control}-flow {Sensitive} {Region}-based {Memory} {Management}},
	isbn = {978-1-58113-388-2},
	url = {http://doi.acm.org/10.1145/773184.773203},
	doi = {10.1145/773184.773203},
	abstract = {Region-based memory management can be used to control dynamic memory allocations and deallocations safely and efficiently. Existing (direct-style) region systems that statically guarantee region safety---no dereferencing of dangling pointers---are based on refinements of Tofte and Talpin's seminal work on region inference for managing heap memory in stacks of regions.We present a unified Floyd-Hoare Logic inspired region type system for reasoning about and inferring region-based memory management, using a sublanguage of imperative region commands. Our system expresses and performs control-sensitive region management without requiring a stack discipline for allocating and deallocating regions. Furthermore, it captures storage mode analysis and late allocation/early deallocation analysis in a single, expressive, unified logical framework. Explicit region aliasing in combination with reference-counted regions provides flexible, context-sensitive early memory deallocation and simultaneously dispenses with the need for an integrated region alias analysis.In this paper we present the design of our region type system, illustrate its practical expressiveness, compare it to existing region analyses, demonstrate how this eliminates the need for previously required source code rewritings for good memory performance, and describe automatic inference of region commands that give consistently better (or at least equally good) memory performance as existing inference techniques.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 3rd {ACM} {SIGPLAN} {International} {Conference} on {Principles} and {Practice} of {Declarative} {Programming}},
	publisher = {ACM},
	author = {Henglein, Fritz and Makholm, Henning and Niss, Henning},
	year = {2001},
	pages = {175--186},
	file = {Henglein et al_2001_A Direct Approach to Control-flow Sensitive Region-based Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/H/Henglein et al_2001_A Direct Approach to Control-flow Sensitive Region-based Memory Management.pdf:application/pdf}
}

@inproceedings{lattner_automatic_2002,
	address = {New York, NY, USA},
	series = {{MSP} '02},
	title = {Automatic {Pool} {Allocation} for {Disjoint} {Data} {Structures}},
	url = {http://doi.acm.org/10.1145/773146.773041},
	doi = {10.1145/773146.773041},
	abstract = {This paper presents an analysis technique and a novel program transformation that can enable powerful optimizations for entire linked data structures. The fully automatic transformation converts ordinary programs to use pool (aka region) allocation for heap-based data structures. The transformation relies on an efficient link-time interprocedural analysis to identify disjoint data structures in the program, to check whether these data structures are accessed in a type-safe manner, and to construct a Disjoint Data Structure Graph that describes the connectivity pattern within such structures. We present preliminary experimental results showing that the data structure analysis and pool allocation are effective for a set of pointer intensive programs in the Olden benchmark suite. To illustrate the optimizations that can be enabled by these techniques, we describe a novel pointer compression transformation and briefly discuss several other optimization possibilities for linked data structures.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 2002 {Workshop} on {Memory} {System} {Performance}},
	publisher = {ACM},
	author = {Lattner, Chris and Adve, Vikram},
	year = {2002},
	pages = {13--24},
	file = {Lattner_Adve_2002_Automatic Pool Allocation for Disjoint Data Structures.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lattner_Adve_2002_Automatic Pool Allocation for Disjoint Data Structures.pdf:application/pdf}
}

@inproceedings{hawblitzel_low-level_2004,
	address = {Venice},
	title = {Low-{Level} {Linear} {Memory} {Management}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.1146},
	abstract = {Eﬃcient low-level systems need more control over memory than safe high-level languages usually provide. As a result, run-time systems are typically written in unsafe languages such as C. This paper extends previous work on linear types, alias types, regions, and typed garbage collection to give type-safe code more control over memory. The approach is truly low-level: memory consists of a single linear array of words, with load and store operations but no built-in notion of an object. The paper constructs lists and arrays out of the basic linear memory primitives, and then introduces type sequences for building regions of nonlinear data. It then describes a Cheney queue typed garbage collector, implemented safely over regions.},
	language = {en},
	booktitle = {Second {Workshop} on {Semantics}, {Program} {Analysis}, and {Computing} {Environments} for {Memory} {Management}},
	author = {Hawblitzel, Chris and Wei, Edward and Huang, Heng and Krupski, Eric and Wittie, Lea},
	month = jan,
	year = {2004},
	file = {Hawblitzel et al_2004_Low-Level Linear Memory Management.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hawblitzel et al_2004_Low-Level Linear Memory Management.pdf:application/pdf}
}

@phdthesis{heine_static_2005,
	address = {Stanford, CA, USA},
	type = {{PhD} {Thesis}},
	title = {Static {Memory} {Leak} {Detection}},
	abstract = {Memory management problems are common in programs written in languages requiring manual memory deallocation. They are important because they can cause program failure, potentially allowing remote denial of service or unauthorized execution. This dissertation presents a novel static analysis and its implementation Clouseau, a tool that can semi-automatically identify memory leaks and double deletes in large C and C++ applications. We have formalized a practical ownership model of memory management and developed type systems to enforce it. In the model, every object is pointed to by one and only one owning pointer, which holds the exclusive right and obligation to either delete the object or to transfer the right to another owning pointer. Programs hold references to many objects in container data structures like lists and maps. Some containers have polymorphic element ownership and can be used to hold either owning or non-owning pointers to objects. Clouseau helps identify containers in large programs. Small user-generated specifications on the procedures that manipulate containers are then used to enforce the ownership model. Clouseau uses flow-sensitive and context-sensitive algorithms to infer likely ownership interfaces of procedures, methods, and object fields. Statements inconsistent with the model are identified as sources of potential errors. The algorithms are sound with respect to a large subset of the C and C++ languages, reporting warnings for all possible errors. They are practical and useful; identifying those warnings likely corresponding to errors and aiding user understanding by identifying inferred ownership interfaces. Applying Clouseau to ten applications demonstrates its applicability to large real programs and its effectiveness at finding memory management problems. We show that enforcing ownership models is efficient and effective at identifying leaks and multiple deletions in important programs and libraries. We compare identifying leaks statically using Clouseau to identifying them dunamically; in many cases, our system finds program errors that account for a large majority of the dynamic memory leak volume. Moreover, where no leaks were identified dynamically, Clouseau found potential leaks. Clouseau is effective at identifying container implementations in large programs. Modeling ownership in containers can substantially increase the effectiveness of static leak detection.},
	school = {Stanford University},
	author = {Heine, David L.},
	year = {2005}
}

@article{fluet_monadic_2004,
	title = {Monadic {Regions}: {Formal} {Type} {Soundness} and {Correctness}},
	shorttitle = {Monadic {Regions}},
	url = {http://ecommons.cornell.edu/handle/1813/5647},
	abstract = {Drawing together two lines of research (that done in type-safe 
region-based memory management and that done in monadic encapsuation of effects), we give a type-preserving translation from a variation of the region calculus of Tofte and Talpin into an extension of System F augmented with monadic types and operations.  Our source language is a novel region calculus, dubbed the Single Effect Calculus, in which sets of effects are specified by a single region representing an upper bound on the set.  Our target language is F{\textasciicircum}RGN, which provides an encapsulation operator whose parametric type ensures that regions (and values allocated therein) are neither accessible nor visible outside the appropriate scope.},
	language = {en\_US},
	urldate = {2018-04-05},
	author = {Fluet, Matthew},
	month = apr,
	year = {2004},
	file = {Fluet_2004_Monadic Regions.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fluet_2004_Monadic Regions.pdf:application/pdf}
}

@inproceedings{cameron_multiple_2007,
	address = {New York, NY, USA},
	series = {{OOPSLA} '07},
	title = {Multiple {Ownership}},
	isbn = {978-1-59593-786-5},
	url = {http://doi.acm.org/10.1145/1297027.1297060},
	doi = {10.1145/1297027.1297060},
	abstract = {Existing ownership type systems require objects to have precisely one primary owner, organizing the heap into an ownership tree. Unfortunately, a tree structure is too restrictive for many programs, and prevents many common design patterns where multiple objects interact. Multiple Ownership is an ownership type system where objects can have more than one owner, and the resulting ownership structure forms a DAG. We give a straightforward model for multiple ownership, focusing in particular on how multiple ownership can support a powerful effects system that determines when two computations interfere-in spite of the DAG structure. We present a core programming language MOJO, Multiple ownership for Java-like Objects, including a type and effects system, and soundness proof. In comparison to other systems, MOJO imposes absolutely no restrictions on pointers, modifications or programs' structure, but in spite of this, MOJO's effects can be used to reason about or describe programs' behaviour.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 22Nd {Annual} {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming} {Systems} and {Applications}},
	publisher = {ACM},
	author = {Cameron, Nicholas R. and Drossopoulou, Sophia and Noble, James and Smith, Matthew J.},
	year = {2007},
	keywords = {ownership types, effects, type and effect systems},
	pages = {441--460},
	file = {Cameron et al_2007_Multiple Ownership.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cameron et al_2007_Multiple Ownership.pdf:application/pdf}
}

@incollection{maeda_writing_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Writing an {OS} {Kernel} in a {Strictly} and {Statically} {Typed} {Language}},
	isbn = {978-3-642-02001-8 978-3-642-02002-5},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-02002-5_10},
	abstract = {OS kernels have been written in weakly typed or non typed programming languages, for example, C. Therefore, it is extremely hard to verify even simple memory safety of the kernels. The difficulty could be resolved by writing OS kernels in strictly typed programming languages, but existing strictly typed languages are not flexible enough to implement important OS facilities (e.g., memory management and multi-thread management facilities). To address the problem, we designed and implemented TALK, a new strictly and statically typed assembly language which is flexible enough to implement OS facilities, and wrote an OS kernel with TALK. In our approach, the safety of the kernel can be verified automatically through static type checking at the level of binary executables without source code.},
	language = {en},
	urldate = {2018-04-05},
	booktitle = {Formal to {Practical} {Security}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Maeda, Toshiyuki and Yonezawa, Akinori},
	year = {2009},
	doi = {10.1007/978-3-642-02002-5_10},
	pages = {181--197},
	file = {Maeda_Yonezawa_2009_Writing an OS Kernel in a Strictly and Statically Typed Language.pdf:/home/michael/Dropbox/zotero-pdfs/M/Maeda_Yonezawa_2009_Writing an OS Kernel in a Strictly and Statically Typed Language.pdf:application/pdf}
}

@article{fluet_monadic_2006,
	title = {Monadic regions},
	volume = {16},
	issn = {0956-7968, 1469-7653},
	url = {http://www.journals.cambridge.org/abstract_S095679680600596X},
	doi = {10.1017/S095679680600596X},
	abstract = {Region-based type systems provide programmer control over memory management without sacriﬁcing type-safety. However, the type systems for region-based languages, such as the ML-Kit or Cyclone, are relatively complicated, and proving their soundness is non-trivial. This paper shows that the complication is in principle unnecessary. In particular, we show that plain old parametric polymorphism, as found in Haskell, is all that is needed. We substantiate this claim by giving a type- and meaning-preserving translation from a variation of the region calculus of Tofte and Talpin to a monadic variant of System F with region primitives whose types and operations are inspired by (and generalize) the ST monad of Launchbury and Peyton Jones.},
	language = {en},
	number = {4\&5},
	urldate = {2018-04-05},
	journal = {Journal of Functional Programming},
	author = {Fluet, Matthew and Morrisett, Greg},
	month = jul,
	year = {2006},
	pages = {485},
	file = {Fluet and Morrisett - 2006 - Monadic regions.pdf:/home/michael/Zotero/storage/W6F7HQT9/Fluet and Morrisett - 2006 - Monadic regions.pdf:application/pdf}
}

@article{akritidis_practical_2010,
	title = {Practical memory safety for {C}},
	language = {en},
	author = {Akritidis, Periklis},
	month = may,
	year = {2010},
	pages = {136},
	file = {Akritidis_2010_Practical memory safety for C.pdf:/home/michael/Dropbox/zotero-pdfs/A/Akritidis_2010_Practical memory safety for C.pdf:application/pdf}
}

@inproceedings{condit_unifying_2009,
	address = {New York, NY, USA},
	series = {{POPL} '09},
	title = {Unifying {Type} {Checking} and {Property} {Checking} for {Low}-level {Code}},
	isbn = {978-1-60558-379-2},
	url = {http://doi.acm.org/10.1145/1480881.1480921},
	doi = {10.1145/1480881.1480921},
	abstract = {We present a unified approach to type checking and property checking for low-level code. Type checking for low-level code is challenging because type safety often depends on complex, program-specific invariants that are difficult for traditional type checkers to express. Conversely, property checking for low-level code is challenging because it is difficult to write concise specifications that distinguish between locations in an untyped program's heap. We address both problems simultaneously by implementing a type checker for low-level code as part of our property checker. We present a low-level formalization of a C program's heap and its types that can be checked with an SMT solver, and we provide a decision procedure for checking type safety. Our type system is flexible enough to support a combination of nominal and structural subtyping for C, on a per-structure basis. We discuss several case studies that demonstrate the ability of this tool to express and check complex type invariants in low-level C code, including several small Windows device drivers.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Condit, Jeremy and Hackett, Brian and Lahiri, Shuvendu K. and Qadeer, Shaz},
	year = {2009},
	keywords = {type checking, assertion checking, decision procedure, low-level code, property checking, smt solver},
	pages = {302--314},
	file = {Condit et al_2009_Unifying Type Checking and Property Checking for Low-level Code.pdf:/home/michael/Dropbox/zotero-pdfs/C/Condit et al_2009_Unifying Type Checking and Property Checking for Low-level Code.pdf:application/pdf}
}

@inproceedings{rondon_low-level_2010,
	address = {New York, NY, USA},
	series = {{POPL} '10},
	title = {Low-level {Liquid} {Types}},
	isbn = {978-1-60558-479-9},
	url = {http://doi.acm.org/10.1145/1706299.1706316},
	doi = {10.1145/1706299.1706316},
	abstract = {We present Low-Level Liquid Types , a refinement type system for C based on Liquid Types . Low-Level Liquid Types combine refinement types with three key elements to automate verification of critical safety properties of low-level programs: First, by associating refinement types with individual heap locations and precisely tracking the locations referenced by pointers, our system is able to reason about complex invariants of in-memory data structures and sophisticated uses of pointer arithmetic. Second, by adding constructs which allow strong updates to the types of heap locations, even in the presence of aliasing, our system is able to verify properties of in-memory data structures in spite of temporary invariant violations. By using this strong update mechanism, our system is able to verify the correct initialization of newly-allocated regions of memory. Third, by using the abstract interpretation framework of Liquid Types, we are able to use refinement type inference to automatically verify important safety properties without imposing an onerous annotation burden. We have implemented our approach in CSOLVE, a tool for Low-Level Liquid Type inference for C programs. We demonstrate through several examples that CSOLVE is able to precisely infer complex invariants required to verify important safety properties, like the absence of array bounds violations and null-dereferences, with a minimal annotation overhead.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 37th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Rondon, Patrick Maxim and Kawaguchi, Ming and Jhala, Ranjit},
	year = {2010},
	keywords = {type inference, dependent types, c, liquid types},
	pages = {131--144},
	file = {Rondon et al_2010_Low-level Liquid Types.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rondon et al_2010_Low-level Liquid Types.pdf:application/pdf}
}

@techreport{clarke_object_2001,
	title = {Object {Ownership} and {Containment}},
	abstract = {Object-oriented programming relies on inter-object aliases to implement data structures  and other abstractions. Objects have mutable state, but it is when mutable state interacts with aliasing that problems arise. Through aliasing an object's state can be changed without the object being aware of the changes, potentially violating the object's invariants. This problem is fundamentally unresolvable. Many idioms such as the Observer design pattern rely on it. Hence aliasing cannot be eliminated from object-oriented programming, it can only be managed.  Various proposals have appeared in the literature addressing the issue of alias management. The most promising are based on alias encapsulation, which limits access to objects to within certain well-defined boundaries. Our approach called ownership types falls into this category. An object can specify the objects it owns, called its representation, and which objects can access its representation. A type system protects the representation by enforcing a well-defined containment invariant.  Our approach is a formal one. Ownership types are cast as a type system using an minor extension to Abadi and Cardelli's object calculus with subtyping. With this formalisation we prove the soundness of our ownership types system and demonstrate that well-typed programs satisfy the containment invariant. In addition, we also provide a firm grounding to enable ownership types to be safely added to an objectoriented programming language with inheritance, subtyping, and nested classes, as well as offering a sound basis for future work. Our type system can model aggregate objects with multiple interface objects sharing representation and friendly functions which access multiple objects' private representations, among other examples, thus over...},
	author = {Clarke, David},
	year = {2001},
	file = {Clarke_2001_Object Ownership and Containment.pdf:/home/michael/Dropbox/zotero-pdfs/C/Clarke_2001_Object Ownership and Containment.pdf:application/pdf}
}

@inproceedings{gifford_integrating_1986,
	title = {Integrating functional and imperative programming},
	isbn = {978-0-89791-200-6},
	url = {http://portal.acm.org/citation.cfm?doid=319838.319848},
	doi = {10.1145/319838.319848},
	abstract = {We present a class of programming languages that enables the advantages of functional and imperative computation to be combined within a single program. These languages, which we call fluent languages, have distinct sublanguages for functional and imperative programming. Sublanguage invariants are verified by a static checking system that simultaneously determines the type and the effect cla{\textasciitilde}8 of every expression. Effect checking is similar to type checking, but it is used to guarantee side-effect invariants instead of value invariants. Effect checking also makes it po{\textasciitilde}ible to implement polymorphism in a general, type-safe and efficient manner despite the presence of side-effects. Preliminary simulation results suggest that fluent programs are well suited for parallel processing.},
	language = {en},
	urldate = {2018-04-05},
	publisher = {ACM Press},
	author = {Gifford, David K. and Lucassen, John M.},
	year = {1986},
	pages = {28--38},
	file = {Gifford_Lucassen_1986_Integrating functional and imperative programming.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gifford_Lucassen_1986_Integrating functional and imperative programming.pdf:application/pdf}
}

@inproceedings{tofte_implementation_1994,
	address = {New York, NY, USA},
	series = {{POPL} '94},
	title = {Implementation of the {Typed} {Call}-by-value \${\textbackslash}lambda\$-calculus {Using} a {Stack} of {Regions}},
	isbn = {978-0-89791-636-3},
	url = {http://doi.acm.org/10.1145/174675.177855},
	doi = {10.1145/174675.177855},
	abstract = {We present a translation scheme for the polymorphically typed call-by-value \&lgr;-calculus. All runtime values, including function closures, are put into regions. The store consists of a stack of regions. Region inference and effect inference are used to infer where regions can be allocated and de-allocated. Recursive functions are handled using a limited form of polymorphic recursion. The translation is proved correct with respect to a store semantics, which models as a region-based run-time system. Experimental results suggest that regions tend to be small, that region allocation is frequent and that overall memory demands are usually modest, even without garbage collection.},
	urldate = {2018-04-05},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Tofte, Mads and Talpin, Jean-Pierre},
	year = {1994},
	pages = {188--201},
	file = {Tofte_Talpin_1994_Implementation of the Typed Call-by-value \$-lambda\$-calculus Using a Stack of.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte_Talpin_1994_Implementation of the Typed Call-by-value \$-lambda\$-calculus Using a Stack of.pdf:application/pdf}
}

@article{li_safe_2004,
	title = {Safe {Systems} {Programming} {Languages}},
	abstract = {The C programming language provides explicit memory management, precise control over low-level data representations and high code eﬃciency. These features are indispensable for systems programming. However, C achieved these goals at the cost of sacriﬁcing type safety. Safety violations like array out-of-bound accesses and dangling pointer accesses lead to a huge amount of well-known software bugs and malicious attacks.},
	language = {en},
	author = {Li, Peng},
	month = oct,
	year = {2004},
	pages = {34},
	file = {Li - Safe Systems Programming Languages.pdf:/home/michael/Zotero/storage/EEKLMQ78/Li - Safe Systems Programming Languages.pdf:application/pdf}
}

@phdthesis{wang_managing_2001,
	title = {Managing {Memory} with {Types}},
	url = {https://www.cs.princeton.edu/research/techreps/TR-640-01},
	language = {208},
	urldate = {2018-04-05},
	school = {Princeton},
	author = {Wang, Daniel},
	month = nov,
	year = {2001},
	file = {Wang_2001_Managing Memory with Types.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wang_2001_Managing Memory with Types.pdf:application/pdf}
}

@article{yong_protecting_2001,
	title = {Protecting {C} {Programs} from {Attacks} via {Invalid} {Pointer} {Dereferences}},
	abstract = {Writes via unchecked pointer dereferences rank high among vulnerabilities most often exploited by malicious code. The most common attacks use an unchecked string copy to cause a buﬀer overrun, thereby overwriting the return address in the function’s activation record. Then, when the function “returns”, control is actually transferred to the attacker’s code. Other attacks may overwrite function pointers, setjmp buﬀers, system-call arguments, or simply corrupt data to cause a denial of service.},
	language = {en},
	author = {Yong, Suan Hsi and Horwitz, Susan},
	month = sep,
	year = {2001},
	pages = {10},
	file = {Yong_Horwitz_2001_Protecting C Programs from Attacks via Invalid Pointer Dereferences.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Yong_Horwitz_2001_Protecting C Programs from Attacks via Invalid Pointer Dereferences.pdf:application/pdf}
}

@article{cardelli_modula-3_1992,
	title = {Modula-3 {Language} {Definition}},
	volume = {27},
	doi = {10.1145/142137.142141},
	language = {en},
	number = {8},
	author = {Cardelli, Luca and Donahue, James and Glassman, Lucille and Jordan, Mick and Kalsow, Bill and Nelson, Greg},
	month = aug,
	year = {1992},
	pages = {28},
	file = {Cardelli et al_1992_Modula-3 Language Definition.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli et al_1992_Modula-3 Language Definition.pdf:application/pdf}
}

@techreport{berry_foundations_nodate,
	title = {The {Foundations} of {Esterel}},
	author = {Berry, Gerard}
}

@inproceedings{kumar_harbor:_2007,
	address = {New York, NY, USA},
	series = {{IPSN} '07},
	title = {Harbor: {Software}-based {Memory} {Protection} for {Sensor} {Nodes}},
	isbn = {978-1-59593-638-7},
	shorttitle = {Harbor},
	url = {http://doi.acm.org/10.1145/1236360.1236404},
	doi = {10.1145/1236360.1236404},
	abstract = {Many sensor nodes contain resource constrained microcontrollers where user level applications, operating system components, and device drivers share a single address space with no form of hardware memory protection. Programming errors in one application can easily corrupt the state of the operating system or other applications. In this paper, we propose Harbor, a memory protection system that prevents many forms of memory corruption. We use software based fault isolation ("sandboxing") to restrict application memory accesses and control flow to protection domains within the address space. A flexible and efficient memory map data structure records ownership and layout information for memory regions; writes are validated using the memory map. Control flow integrity is preserved by maintaining a safe stack that stores return addresses in a protected memory region. Run-time checks validate computed control flow instructions. Cross domain calls perform low-overhead control transfers between domains. Checks are introduced by rewriting an application's compiled binary. The sand-boxed result is verified on the sensor node before it is admitted for execution. Harbor's fault isolation properties depend only on the correctness of this verifier and the Harbor runtime. We have implemented and tested Harbor on the SOS operating system. Harbor detected and prevented memory corruption caused by programming errors in application modules that had been in use for several months. Harbor's overhead, though high, is less than that of application-specific virtual machines, and reasonable for typical sensor workloads.},
	urldate = {2018-04-06},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Information} {Processing} in {Sensor} {Networks}},
	publisher = {ACM},
	author = {Kumar, Ram and Kohler, Eddie and Srivastava, Mani},
	year = {2007},
	keywords = {memory protection, software fault isolation},
	pages = {340--349},
	file = {Kumar et al_2007_Harbor.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kumar et al_2007_Harbor.pdf:application/pdf}
}

@inproceedings{titzer_virgil:_2006,
	title = {Virgil: {Objects} on the {Head} of a {Pin}},
	abstract = {Embedded microcontrollers are becoming increasingly prolific, serving as the primary or auxiliary processor in products and research systems from microwaves to sensor networks. Microcontrollers represent perhaps the most severely resource-constrained embedded processors, often with as little as a few bytes of memory and a few kilobytes of code space. Language and compiler technology has so far been unable to bring the benefits of modern object-oriented languages to such processors. In this paper, I will present the design and implementation of Virgil, a lightweight objectoriented language designed with careful consideration for resource-limited domains. Virgil explicitly separates initialization time from runtime, allowing an application t o build complex data structures during compilation and then run directly on the bare hardware without a virtual machine or any language runtime. This separation allows the entire program heap to be available at compile time and enables three new data-sensitive optimizations: reachable members analysis, reference compression, and ROM-ization. Experimental results demonstrate that Virgil is well suited for writing microcontroller programs, with five demonstrative applications fitting in less than 256 bytes of RAM with fewer than 50 bytes of metadata. Further results show that the optimizations presented in this paper reduced code size between 20\% and 80\% and RAM size by as much as 75\%.},
	language = {en},
	author = {Titzer, Ben L T},
	month = oct,
	year = {2006},
	pages = {17},
	file = {Titzer_2006_Virgil.pdf:/home/michael/Dropbox/zotero-pdfs/T/Titzer_2006_Virgil.pdf:application/pdf}
}

@inproceedings{smith_towards_1996,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards an {ML}-style polymorphic type system for {C}},
	isbn = {978-3-540-61055-7 978-3-540-49942-8},
	url = {https://link.springer.com/chapter/10.1007/3-540-61055-3_47},
	doi = {10.1007/3-540-61055-3_47},
	abstract = {Advanced polymorphic type systems have come to play an important role in the world of functional programming. But, curiously, these type systems have so far had little impact upon widely-used imperative programming languages like C and C++. We show that ML-style polymorphism can be integrated smoothly into a dialect of C, which we call Polymorphic C. It has the same pointer operations as C, including the address-of operator \&, the dereferencing operator*, and pointer arithmetic. Our type system allows these operations in their full generality, so that programmers need not give up the flexibility of C to gain the benefits of ML-style polymorphism. We prove a type soundness theorem that gives a rigorous and useful characterization of well-typed Polymorphic C programs in terms of what can go wrong when they are evaluated.},
	language = {en},
	urldate = {2018-04-06},
	booktitle = {Programming {Languages} and {Systems} — {ESOP} '96},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Smith, Geoffrey and Volpano, Dennis},
	month = apr,
	year = {1996},
	pages = {341--355},
	file = {Smith_Volpano_1996_Towards an ML-style polymorphic type system for C.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith_Volpano_1996_Towards an ML-style polymorphic type system for C.pdf:application/pdf}
}

@article{talpin_type_1994,
	title = {The {Type} and {Effect} {Discipline}},
	volume = {111},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/S0890540184710467},
	doi = {10.1006/inco.1994.1046},
	abstract = {The type and effect discipline is a new framework for reconstructing the principal type and the minimal effect of expressions in implicitly typed polymorphic functional languages that support imperative constructs. The type and effect discipline outperforms other polymorphic type systems. Just as types abstract collections of concrete values, effects denote imperative operations on regions. Regions abstract sets of possibly aliased memory locations. Effects are used to control type generalization in the presence of imperative constructs while regions delimit observable side-effects. The observable effects of an expression range over the regions that are free in its type environment and its type; effects related to local data structures can be discarded during type reconstruction. The type of an expression can be generalized with respect to the type variables that are not free in the type environment or in the observable effect. Introducing the type and effect discipline, we define both a dynamic and a static semantics for an ML-like language and prove that they are consistently related. We present a reconstruction algorithm that computes the principal type and the minimal observable effect of expressions. We prove its correctness with respect to the static semantics.},
	number = {2},
	urldate = {2018-04-07},
	journal = {Information and Computation},
	author = {Talpin, J. P. and Jouvelot, P.},
	month = jun,
	year = {1994},
	pages = {245--296},
	file = {Talpin_Jouvelot_1994_The Type and Effect Discipline.pdf:/home/michael/Dropbox/zotero-pdfs/T/Talpin_Jouvelot_1994_The Type and Effect Discipline.pdf:application/pdf}
}

@inproceedings{jouvelot_algebraic_1991,
	address = {New York, NY, USA},
	series = {{POPL} '91},
	title = {Algebraic {Reconstruction} of {Types} and {Effects}},
	isbn = {978-0-89791-419-2},
	url = {http://doi.acm.org/10.1145/99583.99623},
	doi = {10.1145/99583.99623},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Jouvelot, Pierre and Gifford, David},
	year = {1991},
	pages = {303--310},
	file = {Jouvelot_Gifford_1991_Algebraic Reconstruction of Types and Effects.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jouvelot_Gifford_1991_Algebraic Reconstruction of Types and Effects.pdf:application/pdf}
}

@inproceedings{ruggieri_lifetime_1988,
	address = {New York, NY, USA},
	series = {{POPL} '88},
	title = {Lifetime {Analysis} of {Dynamically} {Allocated} {Objects}},
	isbn = {978-0-89791-252-5},
	url = {http://doi.acm.org/10.1145/73560.73585},
	doi = {10.1145/73560.73585},
	abstract = {The choice of binding time disciplines has major consequences for both the run-time efficiency of programs and the convenience of the language expressing algorithms. Late storage binding time, dynamic allocation, provides the flexibility necessary to implement the complex data structures common in today's object oriented style of programming. In this paper we show that compile-time lifetime analysis can be applied to programs written in languages with static type systems and dynamically allocated objects, to provide earlier storage binding time for objects, while maintaining all the advantages of dynamic allocation.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Ruggieri, C. and Murtagh, T. P.},
	year = {1988},
	pages = {285--293},
	file = {Ruggieri_Murtagh_1988_Lifetime Analysis of Dynamically Allocated Objects.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ruggieri_Murtagh_1988_Lifetime Analysis of Dynamically Allocated Objects.pdf:application/pdf}
}

@inproceedings{turner_once_1995,
	address = {New York, NY, USA},
	series = {{FPCA} '95},
	title = {Once {Upon} a {Type}},
	isbn = {978-0-89791-719-3},
	url = {http://doi.acm.org/10.1145/224164.224168},
	doi = {10.1145/224164.224168},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the {Seventh} {International} {Conference} on {Functional} {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {ACM},
	author = {Turner, David N. and Wadler, Philip and Mossin, Christian},
	year = {1995},
	pages = {1--11},
	file = {Turner et al_1995_Once Upon a Type.pdf:/home/michael/Dropbox/zotero-pdfs/T/Turner et al_1995_Once Upon a Type.pdf:application/pdf}
}

@inproceedings{ahmed_logical_2003,
	address = {New York, NY, USA},
	series = {{TLDI} '03},
	title = {The {Logical} {Approach} to {Stack} {Typing}},
	isbn = {978-1-58113-649-4},
	url = {http://doi.acm.org/10.1145/604174.604185},
	doi = {10.1145/604174.604185},
	abstract = {We develop a logic for reasoning about adjacency and separation of memory blocks, as well as aliasing of pointers. We provide a memory model for our logic and present a sound set of natural deduction-style inference rules. We deploy the logic in a simple type system for a stack-based assembly language. The connectives for the logic provide a flexible yet concise mechanism for controlling allocation, deallocation and access to both heap-allocated and stack-allocated data.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 2003 {ACM} {SIGPLAN} {International} {Workshop} on {Types} in {Languages} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Ahmed, Amal and Walker, David},
	year = {2003},
	keywords = {memory management, ordered logic, typed assembly language, linear logic, type systems, bunched logic, stack},
	pages = {74--85},
	file = {Ahmed_Walker_2003_The Logical Approach to Stack Typing.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ahmed_Walker_2003_The Logical Approach to Stack Typing.pdf:application/pdf}
}

@inproceedings{ahmed_reasoning_2003,
	title = {Reasoning about hierarchical storage},
	doi = {10.1109/LICS.2003.1210043},
	abstract = {In this paper, we develop a new substructural logic that can encode invariants necessary for reasoning about hierarchical storage. We show how the logic can be used to describe the layout of bits in a memory word, the layout of memory words in a region, the layout of regions in an address space, or even the layout of address spaces in a multiprocessing environment. We provide a semantics for our formulas and then apply the semantics and logic to the task of developing a type system for Mini-KAM, a simplified version of the abstract machine used in the ML Kit with regions.},
	booktitle = {18th {Annual} {IEEE} {Symposium} of {Logic} in {Computer} {Science}, 2003. {Proceedings}.},
	author = {Ahmed, A. and Jia, L. and Walker, D.},
	month = jun,
	year = {2003},
	keywords = {Memory management, Computer science, programming language semantics, Assembly, Computer languages, Virtual machining, inference mechanisms, abstract machine, Bismuth, Data structures, hierarchical storage, Logic programming, memory bit, memory word, Mini-KAM, ML Kit, multiprocessing environment, storage allocation, storage reasoning, substructural logic, type system},
	pages = {33--44},
	file = {Ahmed et al_2003_Reasoning about hierarchical storage.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ahmed et al_2003_Reasoning about hierarchical storage.pdf:application/pdf}
}

@article{balabonski_design_2016,
	title = {The {Design} and {Formalization} of {Mezzo}, a {Permission}-{Based} {Programming} {Language}},
	volume = {38},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/2837022},
	doi = {10.1145/2837022},
	abstract = {The programming language Mezzo is equipped with a rich type system that controls aliasing and access to mutable memory. We give a comprehensive tutorial overview of the language. Then we present a modular formalization of Mezzo’s core type system, in the form of a concurrent λ-calculus, which we successively extend with references, locks, and adoption and abandon, a novel mechanism that marries Mezzo’s static ownership discipline with dynamic ownership tests. We prove that well-typed programs do not go wrong and are data-race free. Our definitions and proofs are machine checked.},
	number = {4},
	urldate = {2018-04-07},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Balabonski, Thibaut and Pottier, François and Protzenko, Jonathan},
	month = aug,
	year = {2016},
	keywords = {ownership, concurrency, Aliasing, side effects, static type systems},
	pages = {14:1--14:94},
	file = {Balabonski et al_2016_The Design and Formalization of Mezzo, a Permission-Based Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/B/Balabonski et al_2016_The Design and Formalization of Mezzo, a Permission-Based Programming Language.pdf:application/pdf}
}

@inproceedings{smith_alias_2000,
	address = {London, UK, UK},
	series = {{ESOP} '00},
	title = {Alias {Types}},
	isbn = {978-3-540-67262-3},
	url = {http://dl.acm.org/citation.cfm?id=645394.651903},
	abstract = {Linear type systems allow destructive operations such as object deallocation and imperative updates of functional data structures. These operations and others, such as the ability to reuse memory at different types, are essential in low-level typed languages. However, traditional linear type systems are too restrictive for use in low-level code where it is necessary to exploit pointer aliasing. We present a new typed language that allows functions to specify the shape of the store that they expect and to track the flow of pointers through a computation. Our type system is expressive enough to represent pointer aliasing and yet safely permit destructive operations.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 9th {European} {Symposium} on {Programming} {Languages} and {Systems}},
	publisher = {Springer-Verlag},
	author = {Smith, Frederick and Walker, David and Morrisett, J. Gregory},
	year = {2000},
	pages = {366--381},
	file = {Smith et al_2000_Alias Types.pdf:/home/michael/Dropbox/zotero-pdfs/S/Smith et al_2000_Alias Types.pdf:application/pdf}
}

@inproceedings{kowshik_ensuring_2002,
	address = {New York, NY, USA},
	series = {{CASES} '02},
	title = {Ensuring {Code} {Safety} {Without} {Runtime} {Checks} for {Real}-time {Control} {Systems}},
	isbn = {978-1-58113-575-6},
	url = {http://doi.acm.org/10.1145/581630.581678},
	doi = {10.1145/581630.581678},
	abstract = {This paper considers the problem of providing safe programming support and enabling secure online software upgrades for control software in real-time control systems. In such systems, offline techniques for ensuring code safety are greatly preferable to online techniques. We propose a language called Control-C that is essentially a subset of C, but with key restrictions designed to ensure that memory safety of code can be verified entirely by static checking, under certain system assumptions. The language permits pointer-based data structures, restricted dynamic memory allocation, and restricted array operations, without requiring any runtime checks on memory operations and without garbage collection. The language restrictions have been chosen based on an understanding of both compiler technology and the needs of real-time control systems. The paper describes the language design and a compiler implementation for Control-C. We use control codes from three different experimental control systems to evaluate the suitability of the language for these codes, the effort required to port them to Control-C, and the effectiveness of the compiler in detecting a wide range of potential security violations for one of the systems.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 2002 {International} {Conference} on {Compilers}, {Architecture}, and {Synthesis} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Kowshik, Sumant and Dhurjati, Dinakar and Adve, Vikram},
	year = {2002},
	keywords = {security, static analysis, programming language, compiler, control, real-time},
	pages = {288--297},
	file = {Kowshik et al_2002_Ensuring Code Safety Without Runtime Checks for Real-time Control Systems.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kowshik et al_2002_Ensuring Code Safety Without Runtime Checks for Real-time Control Systems.pdf:application/pdf}
}

@inproceedings{xu_efficient_2004,
	address = {New York, NY, USA},
	series = {{SIGSOFT} '04/{FSE}-12},
	title = {An {Efficient} and {Backwards}-compatible {Transformation} to {Ensure} {Memory} {Safety} of {C} {Programs}},
	isbn = {978-1-58113-855-9},
	url = {http://doi.acm.org/10.1145/1029894.1029913},
	doi = {10.1145/1029894.1029913},
	abstract = {Memory-related errors, such as buffer overflows and dangling pointers, remain one of the principal reasons for failures of C programs. As a result, a number of recent research efforts have focused on the problem of dynamic detection of memory errors in C programs. However, existing approaches suffer from one or more of the following problems: inability to detect all memory errors (e.g., Purify), requiring non-trivial modifications to existing C programs (e.g., Cyclone), changing the memory management model of C to use garbage collection (e.g., CCured), and excessive performance overheads. In this paper, we present a new approach that addresses these problems. Our approach operates via source code transformation and combines efficient data-structures with simple, localized optimizations to obtain good performance.},
	urldate = {2018-04-07},
	booktitle = {Proceedings of the 12th {ACM} {SIGSOFT} {Twelfth} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Xu, Wei and DuVarney, Daniel C. and Sekar, R.},
	year = {2004},
	keywords = {memory safety, C, program transformation},
	pages = {117--126},
	file = {Xu et al_2004_An Efficient and Backwards-compatible Transformation to Ensure Memory Safety of.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xu et al_2004_An Efficient and Backwards-compatible Transformation to Ensure Memory Safety of.pdf:application/pdf}
}

@inproceedings{reynolds_separation_2002,
	title = {Separation logic: a logic for shared mutable data structures},
	isbn = {978-0-7695-1483-3},
	shorttitle = {Separation logic},
	url = {http://ieeexplore.ieee.org/document/1029817/},
	doi = {10.1109/LICS.2002.1029817},
	abstract = {In joint work with Peter O’Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure.},
	language = {en},
	urldate = {2018-04-08},
	publisher = {IEEE Comput. Soc},
	author = {Reynolds, J.C.},
	year = {2002},
	pages = {55--74},
	file = {Reynolds - 2002 - Separation logic a logic for shared mutable data .pdf:/home/michael/Zotero/storage/K2ZXCI7A/Reynolds - 2002 - Separation logic a logic for shared mutable data .pdf:application/pdf}
}

@inproceedings{pottier_programming_2013,
	address = {New York, NY, USA},
	series = {{ICFP} '13},
	title = {Programming with {Permissions} in {Mezzo}},
	isbn = {978-1-4503-2326-0},
	url = {http://doi.acm.org/10.1145/2500365.2500598},
	doi = {10.1145/2500365.2500598},
	abstract = {We present Mezzo, a typed programming language of ML lineage. Mezzo is equipped with a novel static discipline of duplicable and affine permissions, which controls aliasing and ownership. This rules out certain mistakes, including representation exposure and data races, and enables new idioms, such as gradual initialization, memory re-use, and (type)state changes. Although the core static discipline disallows sharing a mutable data structure, Mezzo offers several ways of working around this restriction, including a novel dynamic ownership control mechanism which we dub "adoption and abandon".},
	urldate = {2018-04-08},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Pottier, François and Protzenko, Jonathan},
	year = {2013},
	keywords = {aliasing, ownership, side effects, static type systems},
	pages = {173--184},
	file = {Pottier_Protzenko_2013_Programming with Permissions in Mezzo.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pottier_Protzenko_2013_Programming with Permissions in Mezzo.pdf:application/pdf}
}

@book{berry_foundations_1998,
	title = {The {Foundations} of {Esterel}},
	author = {Berry, Gérard},
	year = {1998},
	file = {Berry_1998_The Foundations of Esterel.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berry_1998_The Foundations of Esterel.pdf:application/pdf}
}

@article{alur_reactive_1999,
	title = {Reactive {Modules}},
	volume = {15},
	issn = {0925-9856, 1572-8102},
	url = {https://link.springer.com/article/10.1023/A:1008739929481},
	doi = {10.1023/A:1008739929481},
	abstract = {We present a formal model for concurrent systems. The model represents synchronous and asynchronous components in a uniform framework that supports compositional (assume-guarantee) and hierarchical (stepwise-refinement) design and verification. While synchronous models are based on a notion of atomic computation step, and asynchronous models remove that notion by introducing stuttering, our model is based on a flexible notion of what constitutes a computation step: by applying an abstraction operator to a system, arbitrarily many consecutive steps can be collapsed into a single step. The abstraction operator, which may turn an asynchronous system into a synchronous one, allows us to describe systems at various levels of temporal detail. For describing systems at various levels of spatial detail, we use a hiding operator that may turn a synchronous system into an asynchronous one. We illustrate the model with diverse examples from synchronous circuits, asynchronous shared-memory programs, and synchronous message-passing protocols.},
	language = {en},
	number = {1},
	urldate = {2018-04-10},
	journal = {Formal Methods in System Design},
	author = {Alur, Rajeev and Henzinger, Thomas A.},
	month = jul,
	year = {1999},
	pages = {7--48},
	file = {Alur_Henzinger_1999_Reactive Modules.pdf:/home/michael/Dropbox/zotero-pdfs/A/Alur_Henzinger_1999_Reactive Modules.pdf:application/pdf}
}

@article{benveniste_synchronous_2003,
	title = {The synchronous languages 12 years later},
	volume = {91},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2002.805826},
	abstract = {Twelve years ago, Proceedings of the IEEE devoted a special section to the synchronous languages. This paper discusses the improvements, difficulties, and successes that have occured with the synchronous languages since then. Today, synchronous languages have been established as a technology of choice for modeling, specifying, validating, and implementing real-time embedded applications. The paradigm of synchrony has emerged as an engineer-friendly design method based on mathematically sound tools.},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Benveniste, A. and Caspi, P. and Edwards, S. A. and Halbwachs, N. and Guernic, P. Le and Simone, R. de},
	month = jan,
	year = {2003},
	keywords = {concurrency, Control systems, formal methods, Costs, Natural languages, embedded systems, real-time systems, Acoustical engineering, Centralized control, Commercialization, Concurrent computing, Design engineering, Design methodology, distributed programming, embedded applications, Esterel, high level languages, Lustre, modeling, Signal, specifying, Synchronization, synchronous languages},
	pages = {64--83},
	file = {Benveniste et al_2003_The synchronous languages 12 years later.pdf:/home/michael/Dropbox/zotero-pdfs/B/Benveniste et al_2003_The synchronous languages 12 years later.pdf:application/pdf}
}

@inproceedings{thies_streamit:_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{StreamIt}: {A} {Language} for {Streaming} {Applications}},
	isbn = {978-3-540-43369-9 978-3-540-45937-8},
	shorttitle = {{StreamIt}},
	url = {https://link.springer.com/chapter/10.1007/3-540-45937-5_14},
	doi = {10.1007/3-540-45937-5_14},
	abstract = {We characterize high-performance streaming applications as a new and distinct domain of programs that is becoming increasingly important. The StreamIt language provides novel high-level representations to improve programmer productivity and program robustness within the streaming domain. At the same time, the StreamIt compiler aims to improve the performance of streaming applications via stream-specific analyses and optimizations. In this paper, we motivate, describe and justify the language features of StreamIt, which include: a structured model of streams, a messaging system for control, a re-initialization mechanism, and a natural textual syntax.},
	language = {en},
	urldate = {2018-04-10},
	booktitle = {Compiler {Construction}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Thies, William and Karczmarek, Michal and Amarasinghe, Saman},
	month = apr,
	year = {2002},
	pages = {179--196},
	file = {Thies et al_2002_StreamIt.pdf:/home/michael/Dropbox/zotero-pdfs/T/Thies et al_2002_StreamIt.pdf:application/pdf}
}

@book{zhao_wireless_2004,
	title = {Wireless {Sensor} {Networks}: {An} {Information} {Processing} {Approach}},
	isbn = {978-1-55860-914-3},
	shorttitle = {Wireless {Sensor} {Networks}},
	abstract = {Designing, implementing, and operating a wireless sensor network involves a wide range of disciplines and many application-specific constraints. To make sense of and take advantage of these systems, a holistic approach is needed--and this is precisely what Wireless Sensor Networks delivers.Inside, two eminent researchers review the diverse technologies and techniques that interact in today's wireless sensor networks. At every step, they are guided by the high-level information-processing tasks that determine how these networks are architected and administered. Zhao and Guibas begin with the canonical problem of localizing and tracking moving objects, then systematically examine the many fundamental sensor network issues that spring from it, including network discovery, service establishment, data routing and aggregation, query processing, programming models, and system organization. The understanding gained as a result--how different layers support the needs of different applications, and how a wireless sensor network should be built to optimize performance and economy--is sure to endure as individual component technologies come and go. ·Written for practitioners, researchers, and students and relevant to all application areas, including environmental monitoring, industrial sensing and diagnostics, automotive and transportation, security and surveillance, military and battlefield uses, and large-scale infrastructural maintenance.·Skillfully integrates the many disciplines at work in wireless sensor network design: signal processing and estimation, communication theory and protocols, distributed algorithms and databases, probabilistic reasoning, energy-aware computing, design methodologies, evaluation metrics, and more.·Demonstrates how querying, data routing, and network self-organization can support high-level information-processing tasks.},
	language = {en},
	publisher = {Morgan Kaufmann},
	author = {Zhao, Feng and Guibas, Leonidas J.},
	year = {2004},
	note = {Google-Books-ID: BkaQkhkWGfoC},
	keywords = {Computers / Networking / General, Technology \& Engineering / Mobile \& Wireless Communications, Technology \& Engineering / Technical \& Manufacturing Industries \& Trades}
}

@article{harel_statecharts:_1987,
	title = {Statecharts: a visual formalism for complex systems},
	volume = {8},
	issn = {0167-6423},
	shorttitle = {Statecharts},
	url = {http://www.sciencedirect.com/science/article/pii/0167642387900359},
	doi = {10.1016/0167-6423(87)90035-9},
	abstract = {We present a broad extension of the conventional formalism of state machines and state diagrams, that is relevant to the specification and design of complex discrete-event systems, such as multi-computer real-time systems, communication protocols and digital control units. Our diagrams, which we call statecharts, extend conventional state-transition diagrams with essentially three elements, dealing, respectively, with the notions of hierarchy, concurrency and communication. These transform the language of state diagrams into a highly structured and economical description language. Statecharts are thus compact and expressive—small diagrams can express complex behavior—as well as compositional and modular. When coupled with the capabilities of computerized graphics, statecharts enable viewing the description at different levels of detail, and make even very large specifications manageable and comprehensible. In fact, we intend to demonstrate here that statecharts counter many of the objections raised against conventional state diagrams, and thus appear to render specification by diagrams an attractive and plausible approach. Statecharts can be used either as a stand-alone behavioral description or as part of a more general design methodology that deals also with the system's other aspects, such as functional decomposition and data-flow specification. We also discuss some practical experience that was gained over the last three years in applying the statechart formalism to the specification of a particularly complex system.},
	number = {3},
	urldate = {2018-04-10},
	journal = {Science of Computer Programming},
	author = {Harel, David},
	month = jun,
	year = {1987},
	pages = {231--274},
	file = {Harel_1987_Statecharts.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harel_1987_Statecharts.pdf:application/pdf}
}

@inproceedings{foster_frenetic:_2011,
	address = {New York, NY, USA},
	series = {{ICFP} '11},
	title = {Frenetic: {A} {Network} {Programming} {Language}},
	isbn = {978-1-4503-0865-6},
	shorttitle = {Frenetic},
	url = {http://doi.acm.org/10.1145/2034773.2034812},
	doi = {10.1145/2034773.2034812},
	abstract = {Modern networks provide a variety of interrelated services including routing, traffic monitoring, load balancing, and access control. Unfortunately, the languages used to program today's networks lack modern features - they are usually defined at the low level of abstraction supplied by the underlying hardware and they fail to provide even rudimentary support for modular programming. As a result, network programs tend to be complicated, error-prone, and difficult to maintain. This paper presents Frenetic, a high-level language for programming distributed collections of network switches. Frenetic provides a declarative query language for classifying and aggregating network traffic as well as a functional reactive combinator library for describing high-level packet-forwarding policies. Unlike prior work in this domain, these constructs are - by design - fully compositional, which facilitates modular reasoning and enables code reuse. This important property is enabled by Frenetic's novel run-time system which manages all of the details related to installing, uninstalling, and querying low-level packet-processing rules on physical switches. Overall, this paper makes three main contributions: (1) We analyze the state-of-the art in languages for programming networks and identify the key limitations; (2) We present a language design that addresses these limitations, using a series of examples to motivate and validate our choices; (3) We describe an implementation of the language and evaluate its performance on several benchmarks.},
	urldate = {2018-04-10},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Foster, Nate and Harrison, Rob and Freedman, Michael J. and Monsanto, Christopher and Rexford, Jennifer and Story, Alec and Walker, David},
	year = {2011},
	keywords = {functional reactive programming, domain-specific languages, network programming languages, openflow},
	pages = {279--291},
	file = {Foster et al_2011_Frenetic.pdf:/home/michael/Dropbox/zotero-pdfs/F/Foster et al_2011_Frenetic.pdf:application/pdf}
}

@article{boussinot_esterel_1991-1,
	title = {The {ESTEREL} language},
	volume = {79},
	issn = {0018-9219},
	doi = {10.1109/5.97299},
	abstract = {The authors present the basics of the ESTEREL reactive model of synchronous parallel systems. The ESTEREL programming style, based on instantaneous communications and decisions, is illustrated through the example of a mouse handler. The ESTEREL formal semantics is described, and it is shown how programs can be compiled into finite state sequential machines for efficient execution. The implementation is described with the ESTEREL environment, including simulation, and verification and validation tools. Some ESTEREL uses in various contexts are reported},
	number = {9},
	journal = {Proceedings of the IEEE},
	author = {Boussinot, F. and Simone, R. de},
	month = sep,
	year = {1991},
	keywords = {verification, parallel programming, Automata, Equations, program compilers, program verification, Broadcasting, ESTEREL environment, ESTEREL formal semantics, ESTEREL reactive model, finite state sequential machines, History, instantaneous communications, Logic, Mice, mouse handler, Production, programming environments, simulation, synchronous parallel systems, Transducers, validation tools},
	pages = {1293--1304},
	file = {Boussinot_Simone_1991_The ESTEREL language.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boussinot_Simone_1991_The ESTEREL language2.pdf:application/pdf}
}

@inproceedings{voelter_mbeddr:_2012,
	address = {New York, NY, USA},
	series = {{SPLASH} '12},
	title = {Mbeddr: {An} {Extensible} {C}-based {Programming} {Language} and {IDE} for {Embedded} {Systems}},
	isbn = {978-1-4503-1563-0},
	shorttitle = {Mbeddr},
	url = {http://doi.acm.org/10.1145/2384716.2384767},
	doi = {10.1145/2384716.2384767},
	abstract = {While the C programming language provides good support for writing efficient, low-level code, it is not adequate for defining higher-level abstractions relevant to embedded software. In this paper we present the mbeddr technology stack that supports extension of C with constructs adequate for embedded systems. In mbeddr, efficient low-level programs can be written using the well-known concepts from C. Higher-level domain-specific abstractions can be seamlessly integrated into C by means of modular language extension regarding syntax, type system, semantics and IDE. In the paper we show how language extension can address the challenges of embedded software development and report on our experience in building these extensions. We show that language workbenches deliver on the promise of significantly reducing the effort of language engineering and the construction of corresponding IDEs. mbeddr is built on top of the JetBrains MPS language workbench. Both MPS and mbeddr are open source software.},
	urldate = {2018-04-10},
	booktitle = {Proceedings of the 3rd {Annual} {Conference} on {Systems}, {Programming}, and {Applications}: {Software} for {Humanity}},
	publisher = {ACM},
	author = {Voelter, Markus and Ratiu, Daniel and Schaetz, Bernhard and Kolb, Bernd},
	year = {2012},
	keywords = {formal methods, development environments, dsls, embedded software, language extension},
	pages = {121--140},
	file = {Voelter et al_2012_Mbeddr.pdf:/home/michael/Dropbox/zotero-pdfs/V/Voelter et al_2012_Mbeddr.pdf:application/pdf}
}

@article{berry_real_nodate,
	title = {Real time programming: special purpose or general purpose languages},
	author = {Berry, Gérard},
	pages = {16},
	file = {Berry - Real time programming special purpose or general .pdf:/home/michael/Zotero/storage/MUF5MCEN/Berry - Real time programming special purpose or general .pdf:application/pdf}
}

@inproceedings{burchett_lowering:_2007,
	title = {Lowering: a static optimization technique for transparent functional reactivity},
	isbn = {978-1-59593-620-2},
	shorttitle = {Lowering},
	url = {http://portal.acm.org/citation.cfm?doid=1244381.1244393},
	doi = {10.1145/1244381.1244393},
	abstract = {Functional Reactive Programming (frp) extends traditional functional programming with dataﬂow evaluation, making it possible to write interactive programs in a declarative style. An frp language creates a dynamic graph of data dependencies and reacts to changes by propagating updates through the graph. In a transparent frp language, the primitive operators are implicitly lifted, so they construct graph nodes when they are applied to time-varying values. This model has some attractive properties, but it tends to produce a large graph that is costly to maintain. In this paper, we develop a transformation we call lowering, which improves performance by reducing the size of the graph. We present a static analysis that guides the sound application of this optimization, and we present benchmark results that demonstrate dramatic improvements in both speed and memory usage for real programs.},
	language = {en},
	urldate = {2018-04-10},
	publisher = {ACM Press},
	author = {Burchett, Kimberley and Cooper, Gregory H. and Krishnamurthi, Shriram},
	year = {2007},
	pages = {71},
	file = {Burchett et al. - 2007 - Lowering a static optimization technique for tran.pdf:/home/michael/Zotero/storage/W2G5RS8U/Burchett et al. - 2007 - Lowering a static optimization technique for tran.pdf:application/pdf}
}

@article{rompf_deprecating_nodate,
	title = {Deprecating the {Observer} {Pattern}},
	abstract = {Programming interactive systems by means of the observer pattern is hard and error-prone yet is still the implementation standard in many production environments. We present an approach to gradually deprecate observers in favor of reactive programming abstractions. Several library layers help programmers to smoothly migrate existing code from callbacks to a more declarative programming model. Our central high-level API layer embeds an extensible higher-order data-ﬂow DSL into our host language. This embedding is enabled by a continuation passing style transformation.},
	language = {en},
	author = {Rompf, Ingo Maier Tiark and Odersky, Martin},
	pages = {18},
	file = {Rompf and Odersky - Deprecating the Observer Pattern.pdf:/home/michael/Zotero/storage/MR6R2SBY/Rompf and Odersky - Deprecating the Observer Pattern.pdf:application/pdf}
}

@book{halbwachs_synchronous_2010,
	address = {Berlin, Heidelberg},
	title = {Synchronous {Programming} of {Reactive} {Systems}},
	isbn = {978-1-4419-5133-5},
	abstract = {This book presents a synthesis of recent works concerning reactive system design. The term `reactive system' has been introduced in order to avoid ambiguities often involved with the term `real-time system' which, while being best-known and suggestive, has been assigned so many different meanings that it is almost inevitably misunderstood. Industrial Process control system, transportation control and supervision systems, signal processing systems, etc. are examples of the systems we have in mind. Four programming languages are presented, which share the same underlying synchronous model: based on Robin Milner's pioneering works about synchronous process algebras, this model consists in considering that a program instantaneously reacts to events, or that the machine execution time is negligible with respect to the response delays of its environment. Using this abstract point of view, the time behavior of a system can be formalized in a very simple and elegant way. The languages presented are ESTEREL, a textual imperative language; ARGOS, a graphical language inspired by STATECHARTS; and LUSTRE and SIGNAL, two declarative languages. After a tutorial description of the languages, illustrated by various examples, a set of related tools is presented: compilers to sequential and distributed code, silicon compilers, verification tools.},
	publisher = {Springer-Verlag},
	author = {Halbwachs, Nicolas},
	year = {2010}
}

@inproceedings{coste-mainere_task-level_1992,
	title = {A task-level robot programming language and its reactive execution},
	doi = {10.1109/ROBOT.1992.219990},
	abstract = {A robotic application is defined by a set of scheduled actions, each action being modeled as a robot-task with functional and behavioral aspects. The authors propose a programming approach located at an intermediary level between objective and object levels, called the task-level. The basic feature consists of using a synchronous language (Esterel) as the target language of an application programming language that is able to express in a natural way the logical and temporal dependencies of the actions. The synchrony assumption induces the need for the design of a synchronous/asynchronous interface to be associated with the computer system. This aspect is considered. The proposed language is presented, and an example of a robotic application is given},
	booktitle = {Proceedings 1992 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Coste-Mainere, E. and Espiau, B. and Rutten, E.},
	month = may,
	year = {1992},
	keywords = {Application software, Computer languages, Availability, Sensor systems, Esterel, high level languages, behavioral aspects, Computer interfaces, Discrete event systems, Force control, Force sensors, intermediary level, logical dependencies, object levels, object-oriented programming, reactive execution, robot programming, Robot programming, Robot sensing systems, scheduled actions, synchronous language, synchronous/asynchronous interface, task-level robot programming language, temporal dependencies},
	pages = {2751--2756 vol.3},
	file = {Coste-Mainere et al_1992_A task-level robot programming language and its reactive execution.pdf:/home/michael/Dropbox/zotero-pdfs/C/Coste-Mainere et al_1992_A task-level robot programming language and its reactive execution.pdf:application/pdf}
}

@article{stoyenko_evolution_1992,
	title = {The evolution and state-of-the-art of real-time languages},
	volume = {18},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/016412129290046M},
	doi = {10.1016/0164-1212(92)90046-M},
	abstract = {Real-time computing applications are among the very earliest of all computing applications, and their use continues to grow at a rapid pace after 40 years. Many programming languages have been used to develop today's real-time software. We attempt to define appropriate requirements for a real-time language and undertake a chronological survey and assessment of languages representative of the many real-time languages designed and used. Following the survey, we draw conclusions and speculate on what future real-time language work may or should bring.},
	number = {1},
	urldate = {2018-04-10},
	journal = {Journal of Systems and Software},
	author = {Stoyenko, Alexander D.},
	month = apr,
	year = {1992},
	pages = {61--83},
	file = {Stoyenko_1992_The evolution and state-of-the-art of real-time languages.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stoyenko_1992_The evolution and state-of-the-art of real-time languages.pdf:application/pdf}
}

@inproceedings{benveniste_data-flow_1993,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Data-flow synchronous languages},
	isbn = {978-3-540-58043-0 978-3-540-48423-3},
	url = {https://link.springer.com/chapter/10.1007/3-540-58043-3_16},
	doi = {10.1007/3-540-58043-3_16},
	abstract = {In this paper, we present a theory of synchronous data-flow languages. Our theory is supported by both some heuristic analysis of applications and some theoretical investigation of the data-flow paradigm. Our model covers both behavioural and operational aspects, and allows both synchronous and asynchronous styles of implementation for synchronous programs. This model served as a basis to establish the GC common format for synchronous data-flow languages.},
	language = {en},
	urldate = {2018-04-10},
	booktitle = {A {Decade} of {Concurrency} {Reflections} and {Perspectives}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Benveniste, Albert and Caspi, Paul and Guernic, Paul Le and Halbwachs, Nicolas},
	month = jun,
	year = {1993},
	pages = {1--45},
	file = {Benveniste et al_1993_Data-flow synchronous languages.pdf:/home/michael/Dropbox/zotero-pdfs/B/Benveniste et al_1993_Data-flow synchronous languages.pdf:application/pdf}
}

@article{halang_comparative_1990,
	title = {Comparative evaluation of high-level real-time programming languages},
	volume = {2},
	issn = {0922-6443, 1573-1383},
	url = {https://link.springer.com/article/10.1007/BF01995678},
	doi = {10.1007/BF01995678},
	abstract = {Owing to the fast growing need for better means of building real-time systems, a number of representative languages used in real-time programming is surveyed. The evaluation focuses on seven languages which possess explicit real-time features. Based on a categorization of the latter, the seven languages are then compared with respect to their real-time capabilities. The strong points and the limitations of Ada and PEARL, the only high-level real-time languages readily applicable in industrial control environments, are covered in more detail. The evaluation reveals that none of the languages actually used in industry is genuinely real-time. Therefore, a number of new features is suggested for incorporation into existing or future languages and their run-time environments. These proposals are meant to advance the inadequate state of affairs, and also to reignite the discussion of this topic in the real-time community.},
	language = {en},
	number = {4},
	urldate = {2018-04-10},
	journal = {Real-Time Systems},
	author = {Halang, Wolfgang A. and Stoyenko, Alexander D.},
	month = nov,
	year = {1990},
	pages = {365--382},
	file = {Halang_Stoyenko_1990_Comparative evaluation of high-level real-time programming languages.pdf:/home/michael/Dropbox/zotero-pdfs/H/Halang_Stoyenko_1990_Comparative evaluation of high-level real-time programming languages.pdf:application/pdf}
}

@inproceedings{liao_towards_2000,
	address = {New York, NY, USA},
	series = {{CODES} '00},
	title = {Towards a {New} {Standard} for {System}-level {Design}},
	isbn = {978-1-58113-268-7},
	url = {http://doi.acm.org/10.1145/334012.334013},
	doi = {10.1145/334012.334013},
	abstract = {Huge new design challenges for system-on-chip (SoC) are the result of decreasing time-to-market coupled with rapidly increasing gate counts and embedded software representing 50-90 percent of the functionality. The exchange of system-level intellectual property (IP) models for creating executable specifications has become a key strategic element for efficient system-to-silicon design flows. Because C and C++ are the dominant languages used by chip architects, systems engineers and software engineers today, we believe that a C-based approach to hardware modeling is necessary. This will enable co-design, providing a more natural solution to partitioning functionality between hardware and software. In this paper we present the design of SystemC, a C++ class library that provides the necessary features for modeling design hierarchy, concurrency, and reactivity in hardware. We will also describe experiences of using SystemC 1) for the co-verification of 8051 processor with a bus-functional model and 2) for the modeling and simulation of an MPEG-2 video decoder.},
	urldate = {2018-04-10},
	booktitle = {Proceedings of the {Eighth} {International} {Workshop} on {Hardware}/{Software} {Codesign}},
	publisher = {ACM},
	author = {Liao, Stan Y.},
	year = {2000},
	pages = {2--6},
	file = {Liao_2000_Towards a New Standard for System-level Design.pdf:/home/michael/Dropbox/zotero-pdfs/L/Liao_2000_Towards a New Standard for System-level Design.pdf:application/pdf}
}

@article{gupta_computing_1998,
	series = {Concurrent {Constraint} {Programming}},
	title = {Computing with continuous change},
	volume = {30},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642397000063},
	doi = {10.1016/S0167-6423(97)00006-3},
	abstract = {A central challenge in computer science and knowledge representation is the integration of conceptual frameworks for continuous and discrete change, as exemplified by the theory of differential equations and real analysis on the one hand, and the theory of programming languages on the other. We take the first steps towards such an integrated theory by presenting a recipe for the construction of continuous programming languages — languages in which state dynamics can be described by differential equations. The basic idea is to start with an untimed language and extend it uniformly over dense (real) time. We present a concrete mathematical model and language (the Hybrid concurrent constraint programming model, Hybrid cc) instantiating these ideas. The language is intended to be used for modeling and programming hybrid systems. The language is declarative — programs can be understood as formulas that place constraints on the (temporal) evolution of the system, with parallel composition regarded as conjunction. It is expressive — it allows the definition of continuous versions of the preemption control constructs. The language is obtained by extending the general-purpose computational formalism of (default) concurrent constraint programming (Default cc) with a single temporal construct, called hence — hence A is read as asserting that A holds continuously beyond the current instant. Various patterns of temporal activity can be generated from this single construct by use of the other combinators in Default cc. We provide a precise operational semantics according to which execution alternates between (i) points at which discontinuous change can occur, and (ii) open intervals in which the state of the system changes continuously. Transitions from a state of continuous evolution are triggered when some condition starts or stops holding. We show that the denotational semantics is correct for reasoning about the operational semantics, through an adequacy theorem.},
	number = {1},
	urldate = {2018-04-10},
	journal = {Science of Computer Programming},
	author = {Gupta, V. and Jagadeesan, R. and Saraswat, V. A.},
	month = jan,
	year = {1998},
	pages = {3--49},
	file = {Gupta et al_1998_Computing with continuous change.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gupta et al_1998_Computing with continuous change.pdf:application/pdf}
}

@article{halbwachs_synchronous_nodate,
	title = {Synchronous programming of reactive systems},
	language = {en},
	author = {Halbwachs, Nicolas},
	pages = {16},
	file = {Halbwachs - Synchronous programming of reactive systems.pdf:/home/michael/Zotero/storage/2EI84BRE/Halbwachs - Synchronous programming of reactive systems.pdf:application/pdf}
}

@article{boussinot_frederic_reactive_2006,
	title = {Reactive {C}: {An} extension of {C} to program reactive systems},
	volume = {21},
	issn = {0038-0644},
	shorttitle = {Reactive {C}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380210406},
	doi = {10.1002/spe.4380210406},
	abstract = {Abstract Reactive systems are interactive programs that react continuously to sequences of activations coming from the external world. Reactive programming leads to a new programming style where one programs in terms of reactions to activations and reasons in a logic of instants. This paper describes an extension of the C programming language called RC (for ?Reactive C?) to program reactive systems. The language RC is described, then some programming examples are given to illustrate the reactive approach. The main RC notions come directly from the Esterel synchronous programming language. Finally, the Esterel and RC languages are compared.},
	number = {4},
	urldate = {2018-04-10},
	journal = {Software: Practice and Experience},
	author = {{Boussinot Frédéric}},
	month = oct,
	year = {2006},
	keywords = {C programming language, Parallelism, Reactive system},
	pages = {401--428},
	file = {Boussinot Frederic_2006_Reactive C.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boussinot Frederic_2006_Reactive C.pdf:application/pdf}
}

@inproceedings{chakrabarti_resource_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Resource {Interfaces}},
	isbn = {978-3-540-20223-3 978-3-540-45212-6},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-45212-6_9},
	doi = {10.1007/978-3-540-45212-6_9},
	abstract = {We present a formalism for specifying component interfaces that expose component requirements on limited resources. The formalism permits an algorithmic check if two or more components, when put together, exceed the available resources. Moreover, the formalism can be used to compute the quantity of resources necessary for satisfying the requirements of a collection of components. The formalism can be instantiated in several ways. For example, several components may draw power from the same source. Then, the formalism supports compatibility checks such as: can two components, when put together, achieve their tasks without ever exceeding the available amount of peak power? or, can they achieve their tasks by using no more than the initially available amount of energy (i.e., power accumulated over time)? The corresponding quantitative questions that our algorithms answer are the following: what is the amount of peak power needed for two components to be put together? what is the corresponding amount of initial energy? To solve these questions, we model interfaces with resource requirements as games with quantitative objectives. The games are played on state spaces where each state is labeled by a number (representing, e.g., power consumption), and a play produces an infinite path of labels. The objective may be, for example, to minimize the largest label that occurs during a play. We illustrate our approach by modeling compatibility questions for the components of robot control software, and of wireless sensor networks.},
	language = {en},
	urldate = {2018-04-10},
	booktitle = {Embedded {Software}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Chakrabarti, Arindam and Alfaro, Luca de and Henzinger, Thomas A. and Stoelinga, Mariëlle},
	month = oct,
	year = {2003},
	pages = {117--133},
	file = {Chakrabarti et al_2003_Resource Interfaces.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chakrabarti et al_2003_Resource Interfaces.pdf:application/pdf}
}

@inproceedings{lee_embedded_2002,
	title = {Embedded {Software}},
	abstract = {The science of computation has systematically abstracted away the physical world. Embedded software systems, however, engage the physical world. Time, concurrency, liveness, robustness, continuums, reactivity, and resource management must be remarried to computation. Prevailing abstractions of computational systems leave out these "non-functional" aspects. This chapter explains why embedded software is not just software on small computers, and why it therefore needs fundamentally new views of computation. It suggests component architectures based on a principle called "actor-oriented design," where actors interact according to a model of computation, and describes some models of computation that are suitable for embedded software. It then suggests that actors can define interfaces that declare dynamic aspects that are essential to embedded software, such as temporal properties. These interfaces can be structured in a "system-level type system" that supports the sort of design-time and run-time type checking that conventional software benefits from.},
	booktitle = {Advances in {Computers}},
	publisher = {Academic Press},
	author = {Lee, Edward A.},
	year = {2002},
	keywords = {TO-READ},
	pages = {2002},
	file = {Lee_2002_Embedded Software.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee_2002_Embedded Software.pdf:application/pdf}
}

@article{edwards_design_1997,
	title = {Design of embedded systems: formal models, validation, and synthesis},
	volume = {85},
	issn = {0018-9219},
	shorttitle = {Design of embedded systems},
	doi = {10.1109/5.558710},
	abstract = {This paper addresses the design of reactive real-time embedded systems. Such systems are often heterogeneous in implementation technologies and design styles, for example by combining hardware application-specific integrated circuits (ASICs) with embedded software. The concurrent design process for such embedded systems involves solving the specification, validation, and synthesis problems. We review the variety of approaches to these problems that have been taken},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {Edwards, S. and Lavagno, L. and Lee, E. A. and Sangiovanni-Vincentelli, A.},
	month = mar,
	year = {1997},
	keywords = {formal verification, Application software, Computer architecture, formal specification, systems analysis, Hardware, computer architecture, logic design, Safety, Microcontrollers, Real time systems, real-time systems, embedded software, application specific integrated circuits, Application specific integrated circuits, application-specific integrated circuits, ASIC, concurrent design process, Consumer electronics, Embedded computing, Embedded system, embedded systems design, formal models, formal validation, heterogeneous systems, reactive real-time system design, specification},
	pages = {366--390},
	file = {Edwards et al_1997_Design of embedded systems.pdf:/home/michael/Dropbox/zotero-pdfs/E/Edwards et al_1997_Design of embedded systems.pdf:application/pdf}
}

@article{benveniste_synchronous_1991-1,
	title = {The synchronous approach to reactive and real-time systems},
	volume = {79},
	issn = {0018-9219},
	doi = {10.1109/5.97297},
	abstract = {The state of the art in real-time programming is briefly reviewed. The synchronous approach is then introduced informally and its possible impact on the design of real-time and reactive systems is discussed. The authors present and discuss the application fields and the principles of synchronous programming. The major concern of the synchronous approach is to base synchronous programming languages on mathematical models. This makes it possible to handle compilation, logical correctness proofs, and verification of real-time programs in a formal way, leading to a clean and precise methodology for design and programming},
	number = {9},
	journal = {Proceedings of the IEEE},
	author = {Benveniste, A. and Berry, G.},
	month = sep,
	year = {1991},
	keywords = {verification, Application software, parallel programming, Computer languages, program verification, Hardware, Safety, Sensor systems, Real time systems, real-time systems, Timing, Logic programming, Design methodology, logical correctness proofs, mathematical models, real-time programming, synchronous approach, synchronous programming, Vocabulary},
	pages = {1270--1282},
	file = {Benveniste_Berry_1991_The synchronous approach to reactive and real-time systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Benveniste_Berry_1991_The synchronous approach to reactive and real-time systems.pdf:application/pdf}
}

@article{halbwachs_synchronous_1991,
	title = {The synchronous data flow programming language {LUSTRE}},
	volume = {79},
	issn = {0018-9219},
	doi = {10.1109/5.97300},
	abstract = {The authors describe LUSTRE, a data flow synchronous language designed for programming reactive systems-such as automatic control and monitoring systems-as well as for describing hardware. The data flow aspect of LUSTRE makes it very close to usual description tools in these domains (block-diagrams, networks of operators, dynamical sample-systems, etc.), and its synchronous interpretation makes it well suited for handling time in programs. Moreover, this synchronous interpretation allows it to be compiled into an efficient sequential program. The LUSTRE formalism is very similar to temporal logics. This allows the language to be used for both writing programs and expressing program properties, which results in an original program verification methodology},
	number = {9},
	journal = {Proceedings of the IEEE},
	author = {Halbwachs, N. and Caspi, P. and Raymond, P. and Pilaud, D.},
	month = sep,
	year = {1991},
	keywords = {Computer languages, reactive systems, program verification, Real time systems, Design methodology, Aerospace control, Automatic programming, Computerized monitoring, Delay, description tools, Frequency synchronization, Hardware design languages, LUSTRE, parallel languages, program verification methodology, Protocols, sequential program, synchronous data flow programming language, temporal logic, temporal logics},
	pages = {1305--1320},
	file = {Halbwachs et al_1991_The synchronous data flow programming language LUSTRE.pdf:/home/michael/Dropbox/zotero-pdfs/H/Halbwachs et al_1991_The synchronous data flow programming language LUSTRE.pdf:application/pdf}
}

@article{berry_esterel_1992,
	title = {The {Esterel} synchronous programming language: design, semantics, implementation},
	volume = {19},
	issn = {0167-6423},
	shorttitle = {The {Esterel} synchronous programming language},
	url = {http://www.sciencedirect.com/science/article/pii/016764239290005V},
	doi = {10.1016/0167-6423(92)90005-V},
	abstract = {We present the Esterel programming language which is especially designed to program reactive systems, that is systems which maintain a permanent interaction with their environment: real-time process controllers, communication protocols, man-machine interface drivers, etc. Esterel is a deterministic concurrent programming language. It differs from classical asynchronous languages by its synchrony hypothesis: the outputs of a system are conceptually synchronous with its inputs. The synchrony hypothesis permits a high-level modular programming style simpler and more rigorous than its asynchronous counterpart. We present the imperative primitives of Eesterel and the temporal manipulations they permit. We give a small programming example. We present two mathematical semantics of Eesterel, which are given by conditional rewrite rules and related by a correctness theorem. The behavioral semantics defines the behavior of programs in an uneffective way as the solution of fixpoint equations. The effective execution semantics computes actions to be performed by a conceptually infinitely fast execution machine. To relate the two semantics, we solve the causality problems that are inherent in synchronous formalisms. We show how the Eesterel v2 and Eesterel v3 compilers efficiently translate concurrent Eesterel programs into efficient equivalent sequential automata that can be implemented in conventional sequential languages. We discuss the quality of this object code and the practical adequacy of the synchrony hypothesis.
Résumé
Nous présentons le langage Eesterel, qui est spécifiquement adapté à la programmation des systèmes réatifs, c'est à dire des systèmes dont le rôle est de maintenir une interaction constante avec leur environment: contrôleurs de processus en temps-réel, protocoles de communications, interfaces homme-machine etc. Eesterel est un langage de programmation parallèle déterministe, qui diffère des langages classiques par son hypothèses de synchronisme: les sorties du système réactif sont supposées conceptuellement synchrones avec ses entrées. Cette hypothèse permet une programmation plus modulaire et plus simple que les techniques asynchrones classiques. Nous présentons les primitives impératives du langage et les manipulations temporelles qu'elles permettent. Nous donnons un exemple de programme typique. Nous présentons deux sémantiques mathématiques du langage: une sémantique comportementale qui définit de fao̧n non effective le comportement d'un programme, et une sémantique d'exécution qui permet de calculer effectivement ces comportements et de résoudre les problèmes de causalité inhérents aux systèmes synchrones. Ces deux sémantiques sont données par des règles de réécriture conditionnelles. Elles sont reliées par un théorème de correction. Nous montrons comment les compilateurs ESTEREL v2 et Eesterel v3 traduisent les programmes parallèles Eesterel en automates séquentiels équivalents et très efficaces. Nous discutons la qualité du code produit et la validité pratique de l'hypothèse de synchronisme.},
	number = {2},
	urldate = {2018-04-10},
	journal = {Science of Computer Programming},
	author = {Berry, Gérard and Gonthier, Georges},
	month = nov,
	year = {1992},
	pages = {87--152},
	file = {Berry_Gonthier_1992_The Esterel synchronous programming language.pdf:/home/michael/Dropbox/zotero-pdfs/B/Berry_Gonthier_1992_The Esterel synchronous programming language.pdf:application/pdf}
}

@inproceedings{bornholt_uncertaint:_2014,
	address = {New York, NY, USA},
	series = {{ASPLOS} '14},
	title = {{UncertainT}: {A} {First}-order {Type} for {Uncertain} {Data}},
	isbn = {978-1-4503-2305-5},
	shorttitle = {{UncertainT}},
	url = {http://doi.acm.org/10.1145/2541940.2541958},
	doi = {10.1145/2541940.2541958},
	abstract = {Emerging applications increasingly use estimates such as sensor data (GPS), probabilistic models, machine learning, big data, and human data. Unfortunately, representing this uncertain data with discrete types (floats, integers, and booleans) encourages developers to pretend it is not probabilistic, which causes three types of uncertainty bugs. (1) Using estimates as facts ignores random error in estimates. (2) Computation compounds that error. (3) Boolean questions on probabilistic data induce false positives and negatives.  This paper introduces Uncertain{\textless}T{\textgreater}, a new programming language abstraction for uncertain data. We implement a Bayesian network semantics for computation and conditionals that improves program correctness. The runtime uses sampling and hypothesis tests to evaluate computation and conditionals lazily and efficiently. We illustrate with sensor and machine learning applications that Uncertain{\textless}T{\textgreater} improves expressiveness and accuracy. Whereas previous probabilistic programming languages focus on experts, Uncertain{\textless}T{\textgreater} serves a wide range of developers. Experts still identify error distributions. However, both experts and application writers compute with distributions, improve estimates with domain knowledge, and ask questions with conditionals. The Uncertain{\textless}T{\textgreater} type system and operators encourage developers to expose and reason about uncertainty explicitly, controlling false positives and false negatives. These benefits make Uncertain{\textless}T{\textgreater} a compelling programming model for modern applications facing the challenge of uncertainty.},
	urldate = {2018-04-10},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Bornholt, James and Mytkowicz, Todd and McKinley, Kathryn S.},
	year = {2014},
	keywords = {estimates, probabilistic programming, uncertain data},
	pages = {51--66},
	file = {Bornholt et al_2014_UncertainT - A First-order Type for Uncertain Data.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bornholt et al_2014_UncertainT - A First-order Type for Uncertain Data.pdf:application/pdf}
}

@article{strom_typestate:_1986,
	title = {Typestate: {A} programming language concept for enhancing software reliability},
	volume = {SE-12},
	issn = {0098-5589},
	shorttitle = {Typestate},
	doi = {10.1109/TSE.1986.6312929},
	abstract = {The authors introduce a new programming language concept, called typestate, which is a refinement of the concept of type. Whereas the type of a data object determines the set of operations over permitted on the object, typestate determines the subset of these operations which is permitted in a particular context. Typestate tracking is a program analysis technique which enhances program reliability by detecting at compile-time syntactically legal but semantically undefined execution sequences. These include reading a variable before it has been initialized and dereferencing a pointer after the dynamic object has been deallocated. The authors define typestate, give examples of its application, and show how typestate checking may be embedded into a compiler. They discuss the consequences of typestate checking for software reliability and software structure, and summarize their experience in using a high-level language incorporating typestate checking.},
	number = {1},
	journal = {IEEE Transactions on Software Engineering},
	author = {Strom, R. E. and Yemini, S.},
	month = jan,
	year = {1986},
	keywords = {security, type checking, Computer languages, program compilers, Program processors, program verification, Context, programming language, compiler, compile-time, data object, data structures, dynamic object, high-level language, Law, Program analysis, program analysis technique, software reliability, Software reliability, typestate, undefined execution sequences},
	pages = {157--171},
	file = {Strom_Yemini_1986_Typestate - A programming language concept for enhancing software reliability.pdf:/home/michael/Dropbox/zotero-pdfs/S/Strom_Yemini_1986_Typestate - A programming language concept for enhancing software reliability.pdf:application/pdf}
}

@book{nielson_principles_1999,
	address = {Secaucus, NJ, USA},
	title = {Principles of {Program} {Analysis}},
	isbn = {978-3-540-65410-0},
	publisher = {Springer-Verlag New York, Inc.},
	author = {Nielson, Flemming and Nielson, Hanne R. and Hankin, Chris},
	year = {1999}
}

@article{gurd_manchester_1985,
	title = {The {Manchester} {Prototype} {Dataflow} {Computer}},
	volume = {28},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/2465.2468},
	doi = {10.1145/2465.2468},
	abstract = {The Manchester project has developed a powerful dataflow processor based on dynamic tagging. This processor is large enough to tackle realistic applications and exhibits impressive speedup for programs with sufficient parallelism.},
	number = {1},
	urldate = {2018-04-11},
	journal = {Commun. ACM},
	author = {Gurd, J. R and Kirkham, C. C and Watson, I.},
	month = jan,
	year = {1985},
	pages = {34--52},
	file = {Gurd et al_1985_The Manchester Prototype Dataflow Computer.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gurd et al_1985_The Manchester Prototype Dataflow Computer.pdf:application/pdf}
}

@inproceedings{sampson_expressing_2014,
	address = {New York, NY, USA},
	series = {{PLDI} '14},
	title = {Expressing and {Verifying} {Probabilistic} {Assertions}},
	isbn = {978-1-4503-2784-8},
	url = {http://doi.acm.org/10.1145/2594291.2594294},
	doi = {10.1145/2594291.2594294},
	abstract = {Traditional assertions express correctness properties that must hold on every program execution. However, many applications have probabilistic outcomes and consequently their correctness properties are also probabilistic (e.g., they identify faces in images, consume sensor data, or run on unreliable hardware). Traditional assertions do not capture these correctness properties. This paper proposes that programmers express probabilistic correctness properties with probabilistic assertions and describes a new probabilistic evaluation approach to efficiently verify these assertions. Probabilistic assertions are Boolean expressions that express the probability that a property will be true in a given execution rather than asserting that the property must always be true. Given either specific inputs or distributions on the input space, probabilistic evaluation verifies probabilistic assertions by first performing distribution extraction to represent the program as a Bayesian network. Probabilistic evaluation then uses statistical properties to simplify this representation to efficiently compute assertion probabilities directly or with sampling. Our approach is a mix of both static and dynamic analysis: distribution extraction statically builds and optimizes the Bayesian network representation and sampling dynamically interprets this representation. We implement our approach in a tool called Mayhap for C and C++ programs. We evaluate expressiveness, correctness, and performance of Mayhap on programs that use sensors, perform approximate computation, and obfuscate data for privacy. Our case studies demonstrate that probabilistic assertions describe useful correctness properties and that Mayhap efficiently verifies them.},
	urldate = {2018-04-11},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Sampson, Adrian and Panchekha, Pavel and Mytkowicz, Todd and McKinley, Kathryn S. and Grossman, Dan and Ceze, Luis},
	year = {2014},
	keywords = {approximate computing, symbolic execution, probabilistic programming, data obfuscation, differential privacy, sensors},
	pages = {112--122},
	file = {Sampson et al_2014_Expressing and Verifying Probabilistic Assertions.pdf:/home/michael/Dropbox/zotero-pdfs/S/Sampson et al_2014_Expressing and Verifying Probabilistic Assertions.pdf:application/pdf}
}

@inproceedings{elliott_push-pull_2009,
	address = {New York, NY, USA},
	series = {Haskell '09},
	title = {Push-pull {Functional} {Reactive} {Programming}},
	isbn = {978-1-60558-508-6},
	url = {http://doi.acm.org/10.1145/1596638.1596643},
	doi = {10.1145/1596638.1596643},
	abstract = {Functional reactive programming (FRP) has simple and powerful semantics, but has resisted efficient implementation. In particular, most past implementations have used demand-driven sampling, which accommodates FRP's continuous time semantics and fits well with the nature of functional programming. Consequently, values are wastefully recomputed even when inputs don't change, and reaction latency can be as high as the sampling period. This paper presents a way to implement FRP that combines data- and demand-driven evaluation, in which values are recomputed only when necessary, and reactions are nearly instantaneous. The implementation is rooted in a new simple formulation of FRP and its semantics and so is easy to understand and reason about. On the road to a new implementation, we'll meet some old friends (monoids, functors, applicative functors, monads, morphisms, and improving values) and make some new friends (functional future values, reactive normal form, and concurrent "unambiguous choice").},
	urldate = {2018-04-12},
	booktitle = {Proceedings of the 2Nd {ACM} {SIGPLAN} {Symposium} on {Haskell}},
	publisher = {ACM},
	author = {Elliott, Conal M.},
	year = {2009},
	keywords = {concurrency, functional reactive programming, semantics, FROM-BEN, data-driven, demand-driven},
	pages = {25--36},
	file = {Elliott_2009_Push-pull Functional Reactive Programming.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elliott_2009_Push-pull Functional Reactive Programming.pdf:application/pdf}
}

@inproceedings{krishnaswami_higher-order_2013,
	address = {New York, NY, USA},
	series = {{ICFP} '13},
	title = {Higher-order {Functional} {Reactive} {Programming} {Without} {Spacetime} {Leaks}},
	isbn = {978-1-4503-2326-0},
	url = {http://doi.acm.org/10.1145/2500365.2500588},
	doi = {10.1145/2500365.2500588},
	abstract = {Functional reactive programming (FRP) is an elegant approach to declaratively specify reactive systems. However, the powerful abstractions of FRP have historically made it difficult to predict and control the resource usage of programs written in this style. In this paper, we give a new language for higher-order reactive programming. Our language generalizes and simplifies prior type systems for reactive programming, by supporting the use of streams of streams, first-class functions, and higher-order operations. We also support many temporal operations beyond streams, such as terminatable streams, events, and even resumptions with first-class schedulers. Furthermore, our language supports an efficient implementation strategy permitting us to eagerly deallocate old values and statically rule out spacetime leaks, a notorious source of inefficiency in reactive programs. Furthermore, these memory guarantees are achieved without the use of a complex substructural type discipline. We also show that our implementation strategy of eager deallocation is safe, by showing the soundness of our type system with a novel step-indexed Kripke logical relation.},
	urldate = {2018-04-12},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Krishnaswami, Neelakantan R.},
	year = {2013},
	keywords = {capabilities, functional reactive programming, FROM-BEN, temporal logic, comonads, dataflow, guarded recursion, kripke logical relations},
	pages = {221--232},
	file = {Krishnaswami_2013_Higher-order Functional Reactive Programming Without Spacetime Leaks.pdf:/home/michael/Dropbox/zotero-pdfs/K/Krishnaswami_2013_Higher-order Functional Reactive Programming Without Spacetime Leaks.pdf:application/pdf}
}

@inproceedings{hudak_arrows_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Arrows, {Robots}, and {Functional} {Reactive} {Programming}},
	isbn = {978-3-540-40132-2 978-3-540-44833-4},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-44833-4_6},
	doi = {10.1007/978-3-540-44833-4_6},
	abstract = {Functional reactive programming},
	language = {en},
	urldate = {2018-04-12},
	booktitle = {Advanced {Functional} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Hudak, Paul and Courtney, Antony and Nilsson, Henrik and Peterson, John},
	month = aug,
	year = {2002},
	keywords = {FROM-BEN},
	pages = {159--187},
	file = {Hudak et al_2002_Arrows, Robots, and Functional Reactive Programming.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hudak et al_2002_Arrows, Robots, and Functional Reactive Programming.pdf:application/pdf}
}

@inproceedings{wan_functional_2000,
	address = {New York, NY, USA},
	series = {{PLDI} '00},
	title = {Functional {Reactive} {Programming} from {First} {Principles}},
	isbn = {978-1-58113-199-4},
	url = {http://doi.acm.org/10.1145/349299.349331},
	doi = {10.1145/349299.349331},
	abstract = {Functional Reactive Programming, or FRP, is a general framework for programming hybrid systems in a high-level, declarative manner. The key ideas in FRP are its notions of behaviors and events. Behaviors are time-varying, reactive values, while events are time-ordered sequences of discrete-time event occurrences. FRP is the essence of Fran, a domain-specific language embedded in Haskell for programming reactive animations, but FRP is now also being used in vision, robotics and other control systems applications. 
In this paper we explore the formal semantics of FRP and how it
relates to an implementation based on streams that represent (and therefore only approximate) continuous behaviors. We show that, in the limit as the sampling interval goes to zero, the implementation is faithful to the formal, continuous semantics, but only when certain constraints on behaviors are observed. We explore the nature of these constraints, which vary amongst the FRP primitives. Our results show both the power and limitations of this approach to language design and implementation. As an example of a limitation, we show that streams are incapable of representing instantaneous predicate events over behaviors.},
	urldate = {2018-04-12},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2000 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Wan, Zhanyong and Hudak, Paul},
	year = {2000},
	keywords = {FROM-BEN},
	pages = {242--252},
	file = {Wan_Hudak_2000_Functional Reactive Programming from First Principles.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wan_Hudak_2000_Functional Reactive Programming from First Principles.pdf:application/pdf}
}

@article{hughes_generalising_2000,
	title = {Generalising monads to arrows},
	volume = {37},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642399000234},
	doi = {10.1016/S0167-6423(99)00023-4},
	abstract = {Monads have become very popular for structuring functional programs since Wadler introduced their use in 1990. In particular, libraries of combinators are often based on a monadic type. Such libraries share (in part) a common interface, from which numerous benefits flow, such as the possibility to write generic code which works together with any library. But, several interesting and useful libraries are fundamentally incompatible with the monadic interface. In this paper I propose a generalisation of monads, which I call arrows, with significantly wider applicability. The paper shows how many of the techniques of monadic programming generalise to the new setting, and gives examples to show that the greater generality is useful. In particular, three non-monadic libraries for efficient parsing, building graphical user interfaces, and programming active web pages fit naturally into the new framework.},
	number = {1},
	urldate = {2018-04-12},
	journal = {Science of Computer Programming},
	author = {Hughes, John},
	month = may,
	year = {2000},
	pages = {67--111},
	file = {Hughes_2000_Generalising monads to arrows.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hughes_2000_Generalising monads to arrows.pdf:application/pdf}
}

@inproceedings{elliott_functional_1997,
	address = {New York, NY, USA},
	series = {{ICFP} '97},
	title = {Functional {Reactive} {Animation}},
	isbn = {978-0-89791-918-0},
	url = {http://doi.acm.org/10.1145/258948.258973},
	doi = {10.1145/258948.258973},
	abstract = {Fran (Functional Reactive Animation) is a collection of data types and functions for composing richly interactive, multimedia animations. The key ideas in Fran are its notions of behaviors and events. Behaviors are time-varying, reactive values, while events are sets of arbitrarily complex conditions, carrying possibly rich information. Most traditional values can be treated as behaviors, and when images are thus treated, they become animations. Although these notions are captured as data types rather than a programming language, we provide them with a denotational semantics, including a proper treatment of real time, to guide reasoning and implementation. A method to effectively and efficiently perform event detection using interval analysis is also described, which relies on the partial information structure on the domain of event times. Fran has been implemented in Hugs, yielding surprisingly good performance for an interpreter-based system. Several examples are given, including the ability to describe physical phenomena involving gravity, springs, velocity, acceleration, etc. using ordinary differential equations.},
	urldate = {2018-04-12},
	booktitle = {Proceedings of the {Second} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Elliott, Conal and Hudak, Paul},
	year = {1997},
	pages = {263--273},
	file = {Elliott_Hudak_1997_Functional Reactive Animation.pdf:/home/michael/Dropbox/zotero-pdfs/E/Elliott_Hudak_1997_Functional Reactive Animation.pdf:application/pdf}
}

@inproceedings{schuster_reactive_2016,
	address = {New York, NY, USA},
	series = {{MODULARITY} {Companion} 2016},
	title = {Reactive {Programming} with {Reactive} {Variables}},
	isbn = {978-1-4503-4033-5},
	url = {http://doi.acm.org/10.1145/2892664.2892666},
	doi = {10.1145/2892664.2892666},
	abstract = {Reactive Programming enables declarative definitions of time-varying values (signals) and their dependencies in a way that changes are automatically propagated. In order to use reactive programming in an imperative object-oriented language, signals are usually modelled as objects. However, computations on primitive values then have to lifted to signals which usually involves a verbose notation. Moreover, it is important to avoid cycles in the dependency graph and glitches, both of which can result from changes to mutable global state during change propagation. This paper introduces reactive variables as extension to imperative languages. Changes to reactive variables are automatically propagated to other reactive variables but, in contrast to signals, reactive variables cannot be reified and used as values. Instead, references to reactive variables always denote their latest values. This enables computation without explicit lifting and limits the dependents of a reactive variable to the lexical scope of its declaration. The dependency graph is therefore topologically ordered and acyclic. Additionally, reactive updates are prevented from mutating global state to ensure consistency. We present a working prototype implementation in JavaScript based on the sweet.js macro system and a formalism for integration with general imperative languages.},
	urldate = {2018-04-13},
	booktitle = {Companion {Proceedings} of the 15th {International} {Conference} on {Modularity}},
	publisher = {ACM},
	author = {Schuster, Christopher and Flanagan, Cormac},
	year = {2016},
	keywords = {FROM-BEN, JavaScript, Reactive Programming, Syntax Extension},
	pages = {29--33},
	file = {Schuster_Flanagan_2016_Reactive Programming with Reactive Variables.pdf:/home/michael/Dropbox/zotero-pdfs/S/Schuster_Flanagan_2016_Reactive Programming with Reactive Variables.pdf:application/pdf}
}

@article{park_probabilistic_2008,
	title = {A {Probabilistic} {Language} {Based} on {Sampling} {Functions}},
	volume = {31},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/1452044.1452048},
	doi = {10.1145/1452044.1452048},
	abstract = {As probabilistic computations play an increasing role in solving various problems, researchers have designed probabilistic languages which treat probability distributions as primitive datatypes. Most probabilistic languages, however, focus only on discrete distributions and have limited expressive power. This article presents a probabilistic language, called λ○, whose expressive power is beyond discrete distributions. Rich expressiveness of λ○ is due to its use of sampling functions, that is, mappings from the unit interval (0.0,1.0] to probability domains, in specifying probability distributions. As such, λ○ enables programmers to formally express and reason about sampling methods developed in simulation theory. The use of λ○ is demonstrated with three applications in robotics: robot localization, people tracking, and robotic mapping. All experiments have been carried out with real robots.},
	number = {1},
	urldate = {2018-04-13},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Park, Sungwoo and Pfenning, Frank and Thrun, Sebastian},
	month = dec,
	year = {2008},
	keywords = {Probabilistic language, probability distribution, robotics, sampling function},
	pages = {4:1--4:46},
	file = {Park et al_2008_A Probabilistic Language Based on Sampling Functions.pdf:/home/michael/Dropbox/zotero-pdfs/P/Park et al_2008_A Probabilistic Language Based on Sampling Functions.pdf:application/pdf}
}

@inproceedings{ramsey_stochastic_2002,
	address = {New York, NY, USA},
	series = {{POPL} '02},
	title = {Stochastic {Lambda} {Calculus} and {Monads} of {Probability} {Distributions}},
	isbn = {978-1-58113-450-6},
	url = {http://doi.acm.org/10.1145/503272.503288},
	doi = {10.1145/503272.503288},
	abstract = {Probability distributions are useful for expressing the meanings of probabilistic languages, which support formal modeling of and reasoning about uncertainty. Probability distributions form a monad, and the monadic definition leads to a simple, natural semantics for a stochastic lambda calculus, as well as simple, clean implementations of common queries. But the monadic implementation of the expectation query can be much less efficient than current best practices in probabilistic modeling. We therefore present a language of measure terms, which can not only denote discrete probability distributions but can also support the best known modeling techniques. We give a translation of stochastic lambda calculus into measure terms. Whether one translates into the probability monad or into measure terms, the results of the translations denote the same probability distribution.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 29th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Ramsey, Norman and Pfeffer, Avi},
	year = {2002},
	pages = {154--165},
	file = {Ramsey_Pfeffer_2002_Stochastic Lambda Calculus and Monads of Probability Distributions.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ramsey_Pfeffer_2002_Stochastic Lambda Calculus and Monads of Probability Distributions.pdf:application/pdf}
}

@inproceedings{felgentreff_babelsberg/js_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Babelsberg/{JS}},
	isbn = {978-3-662-44201-2 978-3-662-44202-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-662-44202-9_17},
	doi = {10.1007/978-3-662-44202-9_17},
	abstract = {Constraints provide a useful technique for ensuring that desired properties hold in an application. As a result, they have been used in a wide range of applications, including graphical layout, simulation, scheduling, and problem-solving. We describe the design and implementation of an Object Constraint Programming language, an object-oriented language that cleanly integrates constraints with the underlying language in a way that respects encapsulation and standard object-oriented programming techniques, and that runs in browser-based applications. Prior work on Object Constraint Programming languages has relied on modifying the underlying Virtual Machine, but that is not an option for web-based applications, which have become increasingly prominent. In this paper, we present an approach to implementing Object Constraint Programming without Virtual Machine support, along with an implementation as a JavaScript extension. We demonstrate the resulting language, Babelsberg/JS, on a number of applications and provide performance measurements. Programs without constraints in Babelsberg/JS run at the same speed as pure JavaScript versions, while programs that do have constraints can still be run efficiently. Our design and implementation also incorporate incremental re-solving to support interaction, as well as a cooperating solvers architecture that allows multiple solvers to work together to solve more difficult problems.},
	language = {en},
	urldate = {2018-04-13},
	booktitle = {{ECOOP} 2014 – {Object}-{Oriented} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Felgentreff, Tim and Borning, Alan and Hirschfeld, Robert and Lincke, Jens and Ohshima, Yoshiki and Freudenberg, Bert and Krahn, Robert},
	month = jul,
	year = {2014},
	pages = {411--436},
	file = {Felgentreff et al_2014_Babelsberg-JS.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felgentreff et al_2014_Babelsberg-JS.pdf:application/pdf}
}

@inproceedings{edwards_coherent_2009,
	address = {New York, NY, USA},
	series = {{OOPSLA} '09},
	title = {Coherent {Reaction}},
	isbn = {978-1-60558-768-4},
	url = {http://doi.acm.org/10.1145/1639950.1640058},
	doi = {10.1145/1639950.1640058},
	abstract = {Side effects are both the essence and bane of imperative programming. The programmer must carefully coordinate actions to manage their side effects upon each other. Such coordination is complex, error-prone, and fragile. Coherent reaction is a new model of change-driven computation that coordinates effects automatically. State changes trigger events called reactions that in turn change other states. A coherent execution order is one in which each reaction executes before any others that are affected by its changes. A coherent order is discovered iteratively by detecting incoherencies as they occur and backtracking their effects. Unlike alternative solutions, much of the power of imperative programming is retained, as is the common sense notion of mutable state. Automatically coordinating actions lets the programmer express what to do, not when to do it. Coherent reactions are embodied in the Coherence language, which is specialized for interactive applications like those common on the desktop and web. The fundamental building block of Coherence is the dynamically typed mutable tree. The fundamental abstraction mechanism is the virtual tree, whose value is lazily computed, and whose behavior is generated by coherent reactions.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 24th {ACM} {SIGPLAN} {Conference} {Companion} on {Object} {Oriented} {Programming} {Systems} {Languages} and {Applications}},
	publisher = {ACM},
	author = {Edwards, Jonathan},
	year = {2009},
	keywords = {functional reactive programming, reactive systems, bidirectional functions, interactive systems, synchronous reactive programming, trees},
	pages = {925--932},
	file = {Edwards_2009_Coherent Reaction.pdf:/home/michael/Dropbox/zotero-pdfs/E/Edwards_2009_Coherent Reaction.pdf:application/pdf}
}

@inproceedings{mcdirmid_programming_2014,
	address = {New York, NY, USA},
	series = {Onward! 2014},
	title = {Programming with {Managed} {Time}},
	isbn = {978-1-4503-3210-1},
	url = {http://doi.acm.org/10.1145/2661136.2661145},
	doi = {10.1145/2661136.2661145},
	abstract = {Most languages expose the computer's ability to globally read and write memory at any time. Programmers must then choreograph control flow so all reads and writes occur in correct relative orders, which can be difficult particularly when dealing with initialization, reactivity, and concurrency. Just as many languages now manage memory to unburden us from properly freeing memory, they should also manage time to automatically order memory accesses for us in the interests of comprehensibility, correctness, and simplicity. Time management is a general language feature with a large design space that is largely unexplored; we offer this perspective to relate prior work and guide future research. We introduce Glitch as a form of managed time that replays code for an appearance of simultaneous memory updates, avoiding the need for manual order. The key to such replay reaching consistent program states is an ability to reorder and rollback updates as needed, restricting the imperative model while retaining the basic concepts of memory access and control flow. This approach can also handle code to enable live programming that incrementally revises program executions in an IDE under arbitrary code changes.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} \& {Software}},
	publisher = {ACM},
	author = {McDirmid, Sean and Edwards, Jonathan},
	year = {2014},
	keywords = {live programming, programming models},
	pages = {1--10},
	file = {McDirmid_Edwards_2014_Programming with Managed Time.pdf:/home/michael/Dropbox/zotero-pdfs/M/McDirmid_Edwards_2014_Programming with Managed Time.pdf:application/pdf}
}

@inproceedings{meyerovich_flapjax:_2009,
	address = {New York, NY, USA},
	series = {{OOPSLA} '09},
	title = {Flapjax: {A} {Programming} {Language} for {Ajax} {Applications}},
	isbn = {978-1-60558-766-0},
	shorttitle = {Flapjax},
	url = {http://doi.acm.org/10.1145/1640089.1640091},
	doi = {10.1145/1640089.1640091},
	abstract = {This paper presents Flapjax, a language designed for contemporary Web applications. These applications communicate with servers and have rich, interactive interfaces. Flapjax provides two key features that simplify writing these applications. First, it provides event streams, a uniform abstraction for communication within a program as well as with external Web services. Second, the language itself is reactive: it automatically tracks data dependencies and propagates updates along those dataflows. This allows developers to write reactive interfaces in a declarative and compositional style. Flapjax is built on top of JavaScript. It runs on unmodified browsers and readily interoperates with existing JavaScript code. It is usable as either a programming language (that is compiled to JavaScript) or as a JavaScript library, and is designed for both uses. This paper presents the language, its design decisions, and illustrative examples drawn from several working Flapjax applications.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 24th {ACM} {SIGPLAN} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} and {Applications}},
	publisher = {ACM},
	author = {Meyerovich, Leo A. and Guha, Arjun and Baskin, Jacob and Cooper, Gregory H. and Greenberg, Michael and Bromfield, Aleks and Krishnamurthi, Shriram},
	year = {2009},
	keywords = {javascript, functional reactive programming, web programming},
	pages = {1--20},
	file = {Meyerovich et al_2009_Flapjax - A Programming Language for Ajax Applications.pdf:/home/michael/Dropbox/zotero-pdfs/M/Meyerovich et al_2009_Flapjax - A Programming Language for Ajax Applications.pdf:application/pdf}
}

@inproceedings{cooper_embedding_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Embedding {Dynamic} {Dataflow} in a {Call}-by-{Value} {Language}},
	isbn = {978-3-540-33095-0 978-3-540-33096-7},
	url = {https://link.springer.com/chapter/10.1007/11693024_20},
	doi = {10.1007/11693024_20},
	abstract = {This paper describes FrTime, an extension of Scheme designed for writing interactive applications. Inspired by functional reactive programming, the language embeds dynamic dataflow within a call-by-value functional language. The essence of the embedding is to make program expressions evaluate to nodes in a dataflow graph. This strategy eases importation of legacy code and permits incremental program construction. We have integrated FrTime with the DrScheme programming environment and have used it to develop several novel applications. We describe FrTime’s design and implementation in detail and present a formal semantics of its evaluation model.},
	language = {en},
	urldate = {2018-04-13},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Cooper, Gregory H. and Krishnamurthi, Shriram},
	month = mar,
	year = {2006},
	pages = {294--308},
	file = {Cooper_Krishnamurthi_2006_Embedding Dynamic Dataflow in a Call-by-Value Language.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cooper_Krishnamurthi_2006_Embedding Dynamic Dataflow in a Call-by-Value Language.pdf:application/pdf}
}

@inproceedings{goodman_church:_2008,
	title = {Church: {A} language for generative models},
	shorttitle = {Church},
	abstract = {Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite PCFGs, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques. 1},
	booktitle = {In {UAI}},
	author = {Goodman, Noah D. and Mansinghka, Vikash K. and Roy, Daniel M. and Bonawitz, Keith and Tenenbaum, Joshua B.},
	year = {2008},
	pages = {220--229},
	file = {Goodman et al_2008_Church - A language for generative models.pdf:/home/michael/Dropbox/zotero-pdfs/G/Goodman et al_2008_Church - A language for generative models.pdf:application/pdf}
}

@inproceedings{pfeffer_ibal:_2001,
	title = {{IBAL}: {A} {Probabilistic} {Rational} {Programming} {Language}},
	shorttitle = {{IBAL}},
	abstract = {In a rational programming language, a program  specifies a situation faced by an agent; evaluating  the program amounts to computing what a rational  agent would believe or do in the situation.  This paper presents IBAL, a rational programming  language for probabilistic and decision-theoretic  agents. IBAL provides a rich declarative language  for describing probabilistic models. The expression  language allows the description of arbitrarily  complex generative models. In addition, IBAL's  observation language makes it possible to express  and compose rejective models that result from conditioning  on the observations. IBAL also integrates  Bayesian parameter estimation and decisiontheoretic  utility maximization thoroughly into the  framework. All these are packaged together into a  programming language that has a rich type system  and built-in extensibility. This paper presents a detailed  account of the syntax and semantics of IBAL,  as well as an overview of the implementation.  1},
	booktitle = {In {Proc}. 17th {IJCAI}},
	publisher = {Morgan Kaufmann Publishers},
	author = {Pfeffer, Avi},
	year = {2001},
	pages = {733--740},
	file = {Pfeffer_2001_IBAL - A Probabilistic Rational Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pfeffer_2001_IBAL - A Probabilistic Rational Programming Language.pdf:application/pdf}
}

@article{gilks_language_1994,
	title = {A {Language} and {Program} for {Complex} {Bayesian} {Modelling}},
	volume = {43},
	issn = {00390526},
	url = {http://www.jstor.org/stable/10.2307/2348941?origin=crossref},
	doi = {10.2307/2348941},
	abstract = {Gibbs sampling has enormous potential for analysing complex data sets. However, routine use of Gibbs sampling has been hampered by the lack of general purpose software for its implementation. Until now all applications have involved writing one-off computer code in low or intermediate level languages such as C or Fortran. We describe some general purpose software that we are currently developing for implementing Gibbs sampling: BUGS (Bayesian inference using Gibbs sampling). The BUGS system comprises three components: first, a natural language for specifying complex models; second, an 'expert system' for deciding appropriate methods for obtaining samples required by the Gibbs sampler; third, a sampling module containing numerical routines to perform the sampling. S objects are used for data input and output. BUGS is written in Modula-2 and runs under both DOS and UNIX.},
	language = {en},
	number = {1},
	urldate = {2018-04-13},
	journal = {The Statistician},
	author = {Gilks, W. R. and Thomas, A. and Spiegelhalter, D. J.},
	year = {1994},
	pages = {169},
	file = {Gilks et al_1994_A Language and Program for Complex Bayesian Modelling.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gilks et al_1994_A Language and Program for Complex Bayesian Modelling.pdf:application/pdf}
}

@inproceedings{bhat_type_2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {A {Type} {Theory} for {Probability} {Density} {Functions}},
	isbn = {978-1-4503-1083-3},
	url = {http://doi.acm.org/10.1145/2103656.2103721},
	doi = {10.1145/2103656.2103721},
	abstract = {There has been great interest in creating probabilistic programming languages to simplify the coding of statistical tasks; however, there still does not exist a formal language that simultaneously provides (1) continuous probability distributions, (2) the ability to naturally express custom probabilistic models, and (3) probability density functions (PDFs). This collection of features is necessary for mechanizing fundamental statistical techniques. We formalize the first probabilistic language that exhibits these features, and it serves as a foundational framework for extending the ideas to more general languages. Particularly novel are our type system for absolutely continuous (AC) distributions (those which permit PDFs) and our PDF calculation procedure, which calculates PDF s for a large class of AC distributions. Our formalization paves the way toward the rigorous encoding of powerful statistical reformulations.},
	urldate = {2018-04-13},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Bhat, Sooraj and Agarwal, Ashish and Vuduc, Richard and Gray, Alexander},
	year = {2012},
	keywords = {continuous probability, probability density functions},
	pages = {545--556},
	file = {Bhat et al_2012_A Type Theory for Probability Density Functions.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bhat et al_2012_A Type Theory for Probability Density Functions.pdf:application/pdf}
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information {Science} and {Statistics}},
	title = {Pattern {Recognition} and {Machine} {Learning}},
	isbn = {978-0-387-31073-2},
	url = {//www.springer.com/us/book/9780387310732},
	abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. Christopher M. Bishop is Deputy Director of Microsoft Research Cambridge, and holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, a Fellow of the Royal Academy of Engineering, and a Fellow of the Royal Society of Edinburgh. His previous textbook "Neural Networks for Pattern Recognition" has been widely adopted. Coming soon: *For students, worked solutions to a subset of exercises available on a public web site (for exercises marked "www" in the text) *For instructors, worked solutions to remaining exercises from the Springer web site *Lecture slides to accompany each chapter *Data sets available for download},
	language = {en},
	urldate = {2018-04-13},
	publisher = {Springer-Verlag},
	author = {Bishop, Christopher},
	year = {2006}
}

@book{nelson_systems_1991,
	address = {Upper Saddle River, NJ, USA},
	title = {Systems {Programming} with {Modula}-3},
	isbn = {978-0-13-590464-0},
	publisher = {Prentice-Hall, Inc.},
	editor = {Nelson, Greg},
	year = {1991}
}

@article{kim_towards_2006,
	title = {Towards a {Resilient} {Operating} {System} for {Wireless} {Sensor} {Networks}},
	abstract = {Active research has recently been conducted on large scale wireless sensor networks, especially network management and maintenance, but the technique for managing application errors on MMU-less sensor node devices has not been seriously considered. This paper presents a resilient operating system mechanism for wireless sensor networks. The proposed mechanism separates the kernel from the user execution area via dual mode operation, and the access violation of applications is controlled by static/dynamic code checking. The experiment results on a common sensor node show that the proposed mechanisms effectively protect the system from errant applications.},
	language = {en},
	author = {Kim, Hyoseung and Cha, Hojung},
	year = {2006},
	pages = {6},
	file = {Kim_Cha_2006_Towards a Resilient Operating System for Wireless Sensor Networks.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kim_Cha_2006_Towards a Resilient Operating System for Wireless Sensor Networks.pdf:application/pdf}
}

@article{lee_synchronous_1987,
	title = {Synchronous data flow},
	volume = {75},
	issn = {0018-9219},
	doi = {10.1109/PROC.1987.13876},
	abstract = {Data flow is a natural paradigm for describing DSP applications for concurrent implementation on parallel hardware. Data flow programs for signal processing are directed graphs where each node represents a function and each arc represents a signal path. Synchronous data flow (SDF) is a special case of data flow (either atomic or large grain) in which the number of data samples produced or consumed by each node on each invocation is specified a priori. Nodes can be scheduled statically (at compile time) onto single or parallel programmable processors so the run-time overhead usually associated with data flow evaporates. Multiple sample rates within the same system are easily and naturally handled. Conditions for correctness of SDF graph are explained and scheduling algorithms are described for homogeneous parallel processors sharing memory. A preliminary SDF software system for automatically generating assembly language code for DSP microcomputers is described. Two new efficiency techniques are introduced, static buffering and an extension to SDF to efficiently implement conditionals.},
	number = {9},
	journal = {Proceedings of the IEEE},
	author = {Lee, E. A. and Messerschmitt, D. G.},
	month = sep,
	year = {1987},
	keywords = {Runtime, Hardware, Signal processing, Software systems, Processor scheduling, Assembly systems, Digital signal processing, Flow graphs, Microcomputers, Scheduling algorithm},
	pages = {1235--1245},
	file = {Lee_Messerschmitt_1987_Synchronous data flow.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee_Messerschmitt_1987_Synchronous data flow.pdf:application/pdf}
}

@article{baker_use-once_1995,
	title = {“{Use}-once” {Variables} and {Linear} {Objects}: {Storage} {Management}, {Reflection} and {Multi}-threading},
	volume = {30},
	issn = {0362-1340},
	shorttitle = {“{Use}-once” {Variables} and {Linear} {Objects}},
	url = {http://doi.acm.org/10.1145/199818.199860},
	doi = {10.1145/199818.199860},
	abstract = {Programming languages should have 'use-once' variables in addition to the usual 'multiple-use' variables. 'Use-once' variables are bound to linear (unshared, unaliased, or singly-referenced) objects. Linear objects are cheap to access and manage, because they require no synchronization or tracing garbage collection. Linear objects can elegantly and efficiently solve otherwise difficult problems of functional/mostly-functional systems---e.g., in-place updating and the efficient initialization of functional objects. Use-once variables are ideal for directly manipulating resources which are inherently linear such as freelists and 'engine ticks' in reflective languages.A 'use-once' variable must be dynamically referenced exactly once within its scope. Unreferenced use-once variables must be explicitly killed, and multiply-referenced use-once variables must be explicitly copied; this duplication and deletion is subject to the constraint that some linear datatypes do not support duplication and deletion methods. Use-once variables are bound only to linear objects, which may reference other linear or non-linear objects. Non-linear objects can reference other non-linear objects, but can reference a linear object only in a way that ensures mutual exclusion.Although implementations have long had implicit use-once variables and linear objects, most languages do not provide the programmer any help for their utilization. For example, use-once variables allow for the safe/controlled use of reified language implementation objects like single-use continuations.Linear objects and use-once variables map elegantly into dataflow models of concurrent computation, and the graphical representations of dataflow models make an appealing visual linear programming language.},
	number = {1},
	urldate = {2018-04-18},
	journal = {SIGPLAN Not.},
	author = {Baker, Henry G.},
	month = jan,
	year = {1995},
	pages = {45--52},
	file = {Baker_1995_“Use-once” Variables and Linear Objects.pdf:/home/michael/Dropbox/zotero-pdfs/B/Baker_1995_“Use-once” Variables and Linear Objects.pdf:application/pdf}
}

@techreport{ansi_iso/iec_2012,
	title = {{ISO}/{IEC} 9899-2011 {C} {Standard}},
	institution = {ANSI},
	author = {ANSI},
	month = may,
	year = {2012},
	pages = {702},
	file = {ANSI_2012_ISO-IEC 9899-2011 C Standard.pdf:/home/michael/Dropbox/zotero-pdfs/A/ANSI_2012_ISO-IEC 9899-2011 C Standard.pdf:application/pdf}
}

@misc{raymond_lost_2018,
	title = {The {Lost} {Art} of {C} {Structure} {Packing}},
	url = {http://www.catb.org/esr/structure-packing/},
	urldate = {2018-04-19},
	author = {Raymond, Eric S.},
	year = {2018},
	file = {Raymond_2018_The Lost Art of C Structure Packing.pdf:/home/michael/Dropbox/zotero-pdfs/R/Raymond_2018_The Lost Art of C Structure Packing.pdf:application/pdf}
}

@inproceedings{boyland_checking_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Checking {Interference} with {Fractional} {Permissions}},
	isbn = {978-3-540-40325-8 978-3-540-44898-3},
	url = {https://link.springer.com/chapter/10.1007/3-540-44898-5_4},
	doi = {10.1007/3-540-44898-5_4},
	abstract = {We describe a type system for checking interference using the concept of linear capabilities (which we call “permissions”). Our innovations include the concept of “fractional” permissions: reads can be permitted with fractional permissions whereas writes require complete permissions. This distinction expresses the fact that reads on the same state do not conflict with each other. One may give shared read access at one point while still retaining write permission afterwards. We give an operational semantics of a simple imperative language with structured parallelism and prove that the permission system enables parallelism to proceed with deterministic results.},
	language = {en},
	urldate = {2018-04-28},
	booktitle = {Static {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Boyland, John},
	month = jun,
	year = {2003},
	pages = {55--72},
	file = {Boyland_2003_Checking Interference with Fractional Permissions.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyland_2003_Checking Interference with Fractional Permissions.pdf:application/pdf}
}

@incollection{gregor_making_2003,
	series = {{IFIP} — {The} {International} {Federation} for {Information} {Processing}},
	title = {Making the {Usage} of {STL} {Safe}},
	isbn = {978-1-4757-5320-2 978-0-387-35672-3},
	url = {https://link.springer.com/chapter/10.1007/978-0-387-35672-3_7},
	abstract = {The use of the C++ Standard Template Library has many advantages, but comes with a unique set of problems that have not been addressed by compilers or development tools. Many of these problems are due to misuses of the STL components and algorithms that are syntactically correct but semantically flawed. We motivate the case for the use of static analysis to diagnose such problems and describe our approach to checking STL usage with an STL-aware static analysis.},
	language = {en},
	urldate = {2018-04-28},
	booktitle = {Generic {Programming}},
	publisher = {Springer, Boston, MA},
	author = {Gregor, Douglas and Schupp, Sibylle},
	year = {2003},
	doi = {10.1007/978-0-387-35672-3_7},
	pages = {127--140},
	file = {Gregor_Schupp_2003_Making the Usage of STL Safe.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gregor_Schupp_2003_Making the Usage of STL Safe.pdf:application/pdf}
}

@article{talpin_polymorphic_1992,
	title = {Polymorphic {Type}, {Region} and {Effect} {Inference}},
	volume = {2},
	abstract = {We present a new static system that reconstructs the types, regions and effects of expressions in an implicitly typed functional language that supports imperative operations on reference values. Just as types structurally abstract collections of concrete values,  regions represent sets of possibly aliased reference values and effects represent approximations of the imperative behavior on regions. We introduce a static semantics for inferring types, regions and effects and prove that it is consistent with respect to the dynamic semantics of the language. We present a reconstruction algorithm that computes the types and effects of expressions and assigns regions to reference values. We prove the correctness of the reconstruction algorithm with respect to the static semantics. Finally, we discuss potential applications of our system to automatic stack allocation and parallel code generation.  1 Introduction  Type and effect reconstruction is the process that automatically determines the t...},
	journal = {Journal of Functional Programming},
	author = {Talpin, Jean-Pierre and Jouvelot, Pierre},
	year = {1992},
	pages = {245--271},
	file = {Talpin_Jouvelot_1992_Polymorphic Type, Region and Effect Inference.pdf:/home/michael/Dropbox/zotero-pdfs/T/Talpin_Jouvelot_1992_Polymorphic Type, Region and Effect Inference.pdf:application/pdf}
}

@incollection{noauthor_uncertainy_nodate,
	title = {Uncertainy and {Time} {Series}},
	file = {Uncertainy and Time Series.pdf:/home/michael/Dropbox/zotero-pdfs/_/Uncertainy and Time Series.pdf:application/pdf}
}

@article{fong_seven_2018,
	title = {Seven {Sketches} in {Compositionality}: {An} {Invitation} to {Applied} {Category} {Theory}},
	shorttitle = {Seven {Sketches} in {Compositionality}},
	url = {http://arxiv.org/abs/1803.05316},
	abstract = {This book is an invitation to discover advanced topics in category theory through concrete, real-world examples. It aims to give a tour: a gentle, quick introduction to guide later exploration. The tour takes place over seven sketches, each pairing an evocative application, such as databases, electric circuits, or dynamical systems, with the exploration of a categorical structure, such as adjoint functors, enriched categories, or toposes. No prior knowledge of category theory is assumed.},
	urldate = {2018-05-03},
	journal = {arXiv:1803.05316 [math]},
	author = {Fong, Brendan and Spivak, David I.},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.05316},
	keywords = {Mathematics - Category Theory, 18-01},
	file = {Fong_Spivak_2018_Seven Sketches in Compositionality.pdf:/home/michael/Dropbox/zotero-pdfs/F/Fong_Spivak_2018_Seven Sketches in Compositionality.pdf:application/pdf}
}

@techreport{kozen_language-based_1999,
	address = {Ithaca, NY, USA},
	title = {Language-{Based} {Security}},
	abstract = {Security of mobile code is a major issue in today''s global computing environment. When you download a program from an untrusted source, how can you be sure it will not do something undesirable? In this paper I will discuss a particular approach to this problem called language-based security. In this approach, security information is derived from a program written in a high-level language during the compilation process and is included in the compiled object. This extra security information can take the form of a formal proof, a type annotation, or some other form of certificate or annotation. It can be downloaded along with the object code and automatically verified before running the code locally, giving some assurance against certain types of failure or unauthorized activity. The verifier must be trusted, but the compiler, code, and certificate need not be. Java bytecode verification is an example of this approach. I will give an overview of some recent work in this area, including a particular effort in which we are trying to make the production of certificates and the verification as efficient and invisible as possible.},
	institution = {Cornell University},
	author = {Kozen, Dexter},
	year = {1999},
	file = {Kozen_1999_Language-Based Security.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kozen_1999_Language-Based Security.pdf:application/pdf}
}

@inproceedings{bocic_data_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Data {Model} {Bugs}},
	isbn = {978-3-319-17523-2 978-3-319-17524-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-17524-9_27},
	doi = {10.1007/978-3-319-17524-9_27},
	abstract = {In today’s internet-centric world, web applications have replaced desktop applications. Cloud systems are frequently used to store and manage user data. Given the complexity inherent in web applications, it is imperative to ensure that this data is never corrupted. We overview existing techniques for data model verification in web applications, list bugs discovered by these tools, and discuss the impact, difficulty of detection, and prevention of these bugs.},
	language = {en},
	urldate = {2018-05-04},
	booktitle = {{NASA} {Formal} {Methods}},
	publisher = {Springer, Cham},
	author = {Bocić, Ivan and Bultan, Tevfik},
	month = apr,
	year = {2015},
	pages = {393--399},
	file = {Bocic_Bultan_2015_Data Model Bugs.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bocic_Bultan_2015_Data Model Bugs.pdf:application/pdf}
}

@book{bultan_string_2017,
	title = {String {Analysis} for {Software} {Verification} and {Security}},
	isbn = {978-3-319-68668-4},
	url = {//www.springer.com/us/book/9783319686684},
	abstract = {This book discusses automated string-analysis techniques, focusing particularly on automata-based static string analysis. It covers the following topics: automata-bases string analysis, computing pre and post-conditions of basic string operations using automata, symbolic representation of automata, forward and backward string analysis using symbolic automata representation, constraint-based string analysis, string constraint solvers, relational string analysis, vulnerability detection using string analysis, string abstractions, differential string analysis, and automated sanitization synthesis using string analysis. String manipulation is a crucial part of modern software systems; for example, it is used extensively in input validation and sanitization and in dynamic code and query generation. The goal of string-analysis techniques and this book is to determine the set of values that string expressions can take during program execution. String analysis can be used to solve many problems in modern software systems that relate to string manipulation, such as: (1) Identifying security vulnerabilities by checking if a security sensitive function can receive an input string that contains an exploit; (2) Identifying possible behaviors of a program by identifying possible values for dynamically generated code; (3) Identifying html generation errors by computing the html code generated by web applications; (4) Identifying the set of queries that are sent to back-end database by analyzing the code that generates the SQL queries; (5) Patching input validation and sanitization functions by automatically synthesizing repairs illustrated in this book. Like many other program-analysis problems, it is not possible to solve the string analysis problem precisely (i.e., it is not possible to precisely determine the set of string values that can reach a program point). However, one can compute over- or under-approximations of possible string values. If the approximations are precise enough, they can enable developers to demonstrate existence or absence of bugs in string manipulating code. String analysis has been an active research area in the last decade, resulting in a wide variety of string-analysis techniques. This book will primarily target researchers and professionals working in computer security, software verification, formal methods, software engineering and program analysis. Advanced level students or instructors teaching or studying courses in computer security, software verification or program analysis will find this book useful as a secondary text.},
	language = {en},
	urldate = {2018-05-04},
	publisher = {Springer International Publishing},
	author = {Bultan, Tevfik and Yu, Fang and Alkhalaf, Muath and Aydin, Abdulbaki},
	year = {2017},
	file = {Bultan et al_2017_String Analysis for Software Verification and Security.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bultan et al_2017_String Analysis for Software Verification and Security.pdf:application/pdf}
}

@article{cardelli_typeful_1991,
	title = {Typeful {Programming}},
	journal = {Formal Description of Programming Concepts},
	author = {Cardelli, Luca},
	year = {1991},
	file = {Cardelli_1991_Typeful Programming.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli_1991_Typeful Programming.pdf:application/pdf}
}

@article{cardelli_basic_1987-1,
	title = {Basic polymorphic typechecking},
	volume = {8},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/0167642387900190},
	doi = {10.1016/0167-6423(87)90019-0},
	number = {2},
	urldate = {2018-05-04},
	journal = {Science of Computer Programming},
	author = {Cardelli, Luca},
	month = apr,
	year = {1987},
	pages = {147--172},
	file = {Cardelli_1987_Basic polymorphic typechecking.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli_1987_Basic polymorphic typechecking2.pdf:application/pdf}
}

@incollection{barendregt_lambda_1992,
	address = {New York, NY, USA},
	title = {Lambda calculi with types},
	isbn = {978-0-19-853761-8},
	url = {http://dl.acm.org/citation.cfm?id=162552.162561},
	urldate = {2018-05-04},
	booktitle = {Handbook of logic in computer science},
	publisher = {Oxford University Press, Inc.},
	author = {Barendregt, H. P.},
	editor = {Abramsky, S. and Gabbay, Dov M. and Maibaum, S. E.},
	year = {1992},
	pages = {117--309},
	file = {Barendregt_1992_Lambda calculi with types.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barendregt_1992_Lambda calculi with types.pdf:application/pdf}
}

@article{jones_functional_1989,
	title = {Functional programming and operating systems},
	volume = {32},
	url = {https://www.stir.ac.uk/research/hub/publication/7073},
	language = {en},
	number = {2},
	urldate = {2018-05-04},
	journal = {The Computer Journal},
	author = {Jones, S and Sinclair, A},
	year = {1989},
	file = {Jones_Sinclair_1989_Functional programming and operating systems.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_Sinclair_1989_Functional programming and operating systems.pdf:application/pdf}
}

@book{levy_capability-based_1984,
	address = {Newton, MA, USA},
	title = {Capability-{Based} {Computer} {Systems}},
	isbn = {978-0-932376-22-0},
	publisher = {Butterworth-Heinemann},
	author = {Levy, Henry M.},
	year = {1984},
	file = {Levy_1984_Capability-Based Computer Systems.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levy_1984_Capability-Based Computer Systems.pdf:application/pdf}
}

@inproceedings{steele_debunking_1977,
	address = {New York, NY, USA},
	series = {{ACM} '77},
	title = {Debunking the “{Expensive} {Procedure} {Call}” {Myth} or, {Procedure} {Call} {Implementations} {Considered} {Harmful} or, {LAMBDA}: {The} {Ultimate} {GOTO}},
	isbn = {978-1-4503-3921-6},
	shorttitle = {Debunking the “{Expensive} {Procedure} {Call}” {Myth} or, {Procedure} {Call} {Implementations} {Considered} {Harmful} or, {LAMBDA}},
	url = {http://doi.acm.org/10.1145/800179.810196},
	doi = {10.1145/800179.810196},
	abstract = {Folklore states that GOTO statements are “cheap”, while procedure calls are “expensive”. This myth is largely a result of poorly designed language implementations. The historical growth of this myth is considered. Both theoretical ideas and an existing implementation are discussed which debunk this myth. It is shown that the unrestricted use of procedure calls permits great stylistic freedom. In particular, any flowchart can be written as a “structured” program without introducing extra variables. The difficulty with the GOTO statement and the procedure call is characterized as a conflict between abstract programming concepts and concrete language constructs.},
	urldate = {2018-05-04},
	booktitle = {Proceedings of the 1977 {Annual} {Conference}},
	publisher = {ACM},
	author = {Steele, Jr., Guy Lewis},
	year = {1977},
	pages = {153--162},
	file = {Steele_1977_Debunking the “Expensive Procedure Call” Myth or, Procedure Call.pdf:/home/michael/Dropbox/zotero-pdfs/S/Steele_1977_Debunking the “Expensive Procedure Call” Myth or, Procedure Call.pdf:application/pdf}
}

@article{plotkin_lcf_1977-1,
	title = {{LCF} considered as a programming language},
	volume = {5},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	doi = {10.1016/0304-3975(77)90044-5},
	abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on LCF. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called “fully abstract”. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
	number = {3},
	urldate = {2018-05-04},
	journal = {Theoretical Computer Science},
	author = {Plotkin, G. D.},
	month = dec,
	year = {1977},
	pages = {223--255},
	file = {Plotkin_1977_LCF considered as a programming language.pdf:/home/michael/Dropbox/zotero-pdfs/P/Plotkin_1977_LCF considered as a programming language2.pdf:application/pdf}
}

@inproceedings{launchbury_natural_1993-1,
	address = {New York, NY, USA},
	series = {{POPL} '93},
	title = {A {Natural} {Semantics} for {Lazy} {Evaluation}},
	isbn = {978-0-89791-560-1},
	url = {http://doi.acm.org/10.1145/158511.158618},
	doi = {10.1145/158511.158618},
	abstract = {We define an operational semantics for lazy evaluation which provides an accurate model for sharing. The only computational structure we introduce is a set of bindings which corresponds closely to a heap. The semantics is set at a considerably higher level of abstraction than operational semantics for particular abstract machines, so is more suitable for a variety of proofs. Furthermore, because a heap is explicitly modelled, the semantics provides a suitable framework for studies about space behaviour of terms under lazy evaluation.},
	urldate = {2018-05-04},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Launchbury, John},
	year = {1993},
	pages = {144--154},
	file = {Launchbury_1993_A Natural Semantics for Lazy Evaluation.pdf:/home/michael/Dropbox/zotero-pdfs/L/Launchbury_1993_A Natural Semantics for Lazy Evaluation3.pdf:application/pdf}
}

@inproceedings{kahn_natural_1987,
	address = {London, UK, UK},
	title = {Natural {Semantics}},
	isbn = {978-0-387-17219-4},
	url = {http://dl.acm.org/citation.cfm?id=28220.28222},
	urldate = {2018-05-04},
	booktitle = {4th {Annual} {Symposium} on {Theoretical} {Aspects} of {Computer} {Sciences} on {STACS} 87},
	publisher = {Springer-Verlag},
	author = {Kahn, G.},
	year = {1987},
	pages = {22--39},
	file = {Kahn_1987_Natural Semantics.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kahn_1987_Natural Semantics.pdf:application/pdf}
}

@article{josephs_semantics_1989-1,
	title = {The semantics of lazy functional languages},
	volume = {68},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397589901229},
	doi = {10.1016/0304-3975(89)90122-9},
	abstract = {A denotational semantics for the λ-calculus is described. The semantics is continuation-based, and so reflects the order in which expressions are evaluated. It provides a means by which lazy functional languages can be better understood.},
	number = {1},
	urldate = {2018-05-04},
	journal = {Theoretical Computer Science},
	author = {Josephs, Mark B.},
	month = oct,
	year = {1989},
	pages = {105--111},
	file = {Josephs_1989_The semantics of lazy functional languages.pdf:/home/michael/Dropbox/zotero-pdfs/J/Josephs_1989_The semantics of lazy functional languages2.pdf:application/pdf}
}

@misc{noauthor_tr44:_nodate,
	title = {{TR}44: {CONS} should not {Evaluate} its {Arguments}},
	url = {https://www.cs.indiana.edu/cgi-bin/techreports/TRNNN.cgi?trnum=TR44},
	urldate = {2018-05-04},
	file = {TR44 - CONS should not Evaluate its Arguments.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/TR44 - CONS should not Evaluate its Arguments.pdf:application/pdf}
}

@article{steele_art_1978,
	title = {The {Art} of the {Interpreter} of the {Modularity} {Complex} ({Parts} {Zero}, {One}, and {Two})},
	url = {http://dspace.mit.edu/handle/1721.1/6094},
	abstract = {We examine the effects of various language  design decisions on theprogramming styles  available to a user of the language, with  particular emphasis on the ability to  incrementally construct modular systems. At  each step we exhibit an interactive meta-circular interpreter for the language under  consideration. Each new interpreter is the  result of an incremental change to a previous  interpreter. We explore the consequences of  various variable binding disciplines and the  introduction of side effects. We find that  dynamic scoping is unsuitable for  constructing procedural abstractions, but has  another role as agent of modularity, being a  structured form of side effect. More general  side effects are also found to be necessary to  promote modular style. We find that the notion  of side effect and the notion of equality (object  identity) are mutually constraining; to define  one is to define the other. The interpreters we exhibit are all written in a simple dialect of  LISP, and all implement LISP-like languages.  A subset of these interpreters constitute a  partial historical reconstruction of the actual  evaluation of LISP.},
	language = {en\_US},
	urldate = {2018-05-04},
	author = {Steele, Guy Lewis and Sussman, Gerald Jay},
	month = may,
	year = {1978},
	file = {Steele_Sussman_1978_The Art of the Interpreter of the Modularity Complex (Parts Zero, One, and Two).pdf:/home/michael/Dropbox/zotero-pdfs/S/Steele_Sussman_1978_The Art of the Interpreter of the Modularity Complex (Parts Zero, One, and Two).pdf:application/pdf}
}

@book{church_introduction_1956,
	title = {Introduction to {Mathematical} {Logic} ({PMS}-13), {Volume} 1},
	url = {https://press.princeton.edu/titles/291.html},
	abstract = {Logic is sometimes called the foundation of mathematics: the logician studies the kinds of reasoning used in the individual steps of a proof. Alonzo Church was a pioneer in the field of mathematical logic, whose contributions to number theory and the theories of algorithms and computability laid the theoretical foundations of computer science. His first Princeton book, The Calculi of Lambda-Conversion (1941), established an invaluable tool that computer scientists still use today.  Even beyond the accomplishment of that book, however, his second Princeton book, Introduction to Mathematical Logic, defined its subject for a generation. Originally published in Princeton's Annals of Mathematics Studies series, this book was revised in 1956 and reprinted a third time, in 1996, in the Princeton Landmarks in Mathematics series. Although new results in mathematical logic have been developed and other textbooks have been published, it remains, sixty years later, a basic source for understanding formal logic.  Church was one of the principal founders of the Association for Symbolic Logic; he founded the Journal of Symbolic Logic in 1936 and remained an editor until 1979 At his death in 1995, Church was still regarded as the greatest mathematical logician in the world.},
	language = {en},
	urldate = {2018-05-04},
	author = {Church, Alonzo},
	year = {1956},
	file = {Church_1956_Introduction to Mathematical Logic (PMS-13), Volume 1.pdf:/home/michael/Dropbox/zotero-pdfs/C/Church_1956_Introduction to Mathematical Logic (PMS-13), Volume 1.pdf:application/pdf}
}

@misc{schonfinkel_buidling_1924,
	title = {On the buidling blocks of mathematical logic},
	author = {Schonfinkel, Moses},
	year = {1924},
	file = {Schonfinkel_1924_On the buidling blocks of mathematical logic.pdf:/home/michael/Dropbox/zotero-pdfs/S/Schonfinkel_1924_On the buidling blocks of mathematical logic.pdf:application/pdf}
}

@incollection{howard_formulae-as-types_1995,
	title = {The {Formulæ}-as-{Types} {Notion} of {Construction}},
	booktitle = {The {Curry}-{Howard} {Isomorphism}},
	publisher = {Academia},
	author = {Howard, W. A.},
	editor = {Groote, Philippe De},
	year = {1995},
	file = {Howard_1995_The Formulae-as-Types Notion of Construction.pdf:/home/michael/Dropbox/zotero-pdfs/H/Howard_1995_The Formulae-as-Types Notion of Construction.pdf:application/pdf}
}

@book{gordon_edinburgh_1979,
	title = {Edinburgh {LCF}: {A} {Mechanized} {Logic} of {Computation}},
	publisher = {Springer-Verlag},
	author = {Gordon, Michael and Milner, Arthur and Wadsworth, Christopher},
	year = {1979},
	file = {Gordon et al_1979_Edinburgh LCF - A Mechanized Logic of Computation.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gordon et al_1979_Edinburgh LCF - A Mechanized Logic of Computation.pdf:application/pdf}
}

@phdthesis{felleisen_calculi_1987,
	address = {Indianapolis, IN, USA},
	type = {{PhD} {Thesis}},
	title = {The {Calculi} of {Lambda}-nu-cs {Conversion}: {A} {Syntactic} {Theory} of {Control} and {State} in {Imperative} {Higher}-order {Programming} {Languages}},
	shorttitle = {The {Calculi} of {Lambda}-nu-cs {Conversion}},
	school = {Indiana University},
	author = {Felleisen, Matthias},
	year = {1987},
	file = {Felleisen_1987_The Calculi of Lambda-nu-cs Conversion - A Syntactic Theory of Control and State.pdf:/home/michael/Dropbox/zotero-pdfs/F/Felleisen_1987_The Calculi of Lambda-nu-cs Conversion - A Syntactic Theory of Control and State.pdf:application/pdf}
}

@misc{barendregt_introduction_2000,
	title = {Introduction to {Lambda} {Calculus}},
	author = {Barendregt, H and Barendsen, Erik},
	year = {2000},
	file = {Barendregt_Barendsen_2000_Introduction to Lambda Calculus.pdf:/home/michael/Dropbox/zotero-pdfs/B/Barendregt_Barendsen_2000_Introduction to Lambda Calculus.pdf:application/pdf}
}

@inproceedings{garrigue_relaxing_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Relaxing the {Value} {Restriction}},
	isbn = {978-3-540-21402-1 978-3-540-24754-8},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-24754-8_15},
	doi = {10.1007/978-3-540-24754-8_15},
	abstract = {Restricting polymorphism to values is now the standard way to obtain soundness in ML-like programming languages with imperative features. While this solution has undeniable advantages over previous approaches, it forbids polymorphism in many cases where it would be sound. We use a subtyping based approach to recover part of this lost polymorphism, without changing the type algebra itself, and this has significant applications.},
	language = {en},
	urldate = {2018-05-04},
	booktitle = {Functional and {Logic} {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Garrigue, Jacques},
	month = apr,
	year = {2004},
	pages = {196--213},
	file = {Garrigue_2004_Relaxing the Value Restriction.pdf:/home/michael/Dropbox/zotero-pdfs/G/Garrigue_2004_Relaxing the Value Restriction.pdf:application/pdf}
}

@misc{claessen_beginners_nodate,
	title = {A beginner's guide to {SSA}},
	author = {Claessen, David and Groth, Andreas},
	file = {Claessen_Groth_A beginner's guide to SSA.pdf:/home/michael/Dropbox/zotero-pdfs/C/Claessen_Groth_A beginner's guide to SSA.pdf:application/pdf}
}

@inproceedings{levis_mate:_2002,
	address = {New York, NY, USA},
	series = {{ASPLOS} {X}},
	title = {{MatÉ}: {A} {Tiny} {Virtual} {Machine} for {Sensor} {Networks}},
	isbn = {978-1-58113-574-9},
	shorttitle = {{MatÉ}},
	url = {http://doi.acm.org/10.1145/605397.605407},
	doi = {10.1145/605397.605407},
	abstract = {Composed of tens of thousands of tiny devices with very limited resources ("motes"), sensor networks are subject to novel systems problems and constraints. The large number of motes in a sensor network means that there will often be some failing nodes; networks must be easy to repopulate. Often there is no feasible method to recharge motes, so energy is a precious resource. Once deployed, a network must be reprogrammable although physically unreachable, and this reprogramming can be a significant energy cost.We present Maté, a tiny communication-centric virtual machine designed for sensor networks. Maté's high-level interface allows complex programs to be very short (under 100 bytes), reducing the energy cost of transmitting new programs. Code is broken up into small capsules of 24 instructions, which can self-replicate through the network. Packet sending and reception capsules enable the deployment of ad-hoc routing and data aggregation algorithms. Maté's concise, high-level program representation simplifies programming and allows large networks to be frequently reprogrammed in an energy-efficient manner; in addition, its safe execution environment suggests a use of virtual machines to provide the user/kernel boundary on motes that have no hardware protection mechanisms.},
	urldate = {2018-05-05},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Levis, Philip and Culler, David},
	year = {2002},
	pages = {85--95},
	file = {Levis_Culler_2002_MatE.pdf:/home/michael/Dropbox/zotero-pdfs/L/Levis_Culler_2002_MatE.pdf:application/pdf}
}

@inproceedings{necula_cil:_2002,
	title = {{CIL}: {Intermediate} language and tools for analysis and transformation of {C} programs},
	shorttitle = {{CIL}},
	abstract = {Abstract. This paper describes the CIntermediate Language: a highlevel representation along with a set of tools that permit easy analysis and source-to-source transformation of C programs. Compared to C, CIL has fewer constructs. It breaks down certain complicated constructs of C into simpler ones, and thus it works at a lower level than abstract-syntax trees. But CIL is also more high-level than typical intermediate languages (e.g., three-address code) designed for compilation. As a result, what we have is a representation that makes it easy to analyze and manipulate C programs, and emit them in a form that resembles the original source. Moreover, it comes with a front-end that translates to CIL not only ANSI C programs but also those using Microsoft C or GNU C extensions. We describe the structure of CIL with a focus on how it disambiguates those features of C that we found to be most confusing for program analysis and transformation. We also describe a whole-program merger based on structural type equality, allowing a complete project to be viewed as a single compilation unit. As a representative application of CIL, we show a transformation aimed at making code immune to stack-smashing attacks. We are currently using CIL as part of a system that analyzes and instruments C programs with run-time checks to ensure type safety. CIL has served us very well in this project, and we believe it can usefully be applied in other situations as well. 1},
	booktitle = {In {International} {Conference} on {Compiler} {Construction}},
	author = {Necula, George C. and Mcpeak, Scott and Rahul, Shree P. and Weimer, Westley},
	year = {2002},
	pages = {213--228},
	file = {Necula et al_2002_CIL.pdf:/home/michael/Dropbox/zotero-pdfs/N/Necula et al_2002_CIL.pdf:application/pdf}
}

@inproceedings{milner_functions_1990,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Functions as processes},
	isbn = {978-3-540-52826-5 978-3-540-47159-2},
	url = {https://link.springer.com/chapter/10.1007/BFb0032030},
	doi = {10.1007/BFb0032030},
	abstract = {This paper exhibits accurate encodings of the λ-calculus in the π-calculus. The former is canonical for calculation with functions, while the latter is a recent step [15] towards a canonical treatment of concurrent processes. With quite simple encodings, two λ-calculus reduction strategies are simulated very closely; each reduction in λ-calculus is mimicked by a short sequence of reductions in π-calculus. Abramsky's precongruence of applicative simulation [1] over λ-calculus is compared with that induced by the encoding of the lazy λ-calculus into π-calculus; a similar comparison is made for call-by-value λ-calculus.The part of π-calculus which is needed for the encoding is formulated in a new way, inspired by Berry's and Boudol's Chemical Abstract Machine [5].},
	language = {en},
	urldate = {2018-05-05},
	booktitle = {Automata, {Languages} and {Programming}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Milner, Robin},
	month = jul,
	year = {1990},
	pages = {167--180},
	file = {Milner_1990_Functions as processes.pdf:/home/michael/Dropbox/zotero-pdfs/M/Milner_1990_Functions as processes.pdf:application/pdf}
}

@inproceedings{lattner_automatic_2005,
	address = {New York, NY, USA},
	series = {{PLDI} '05},
	title = {Automatic {Pool} {Allocation}: {Improving} {Performance} by {Controlling} {Data} {Structure} {Layout} in the {Heap}},
	isbn = {978-1-59593-056-9},
	shorttitle = {Automatic {Pool} {Allocation}},
	url = {http://doi.acm.org/10.1145/1065010.1065027},
	doi = {10.1145/1065010.1065027},
	abstract = {This paper describes Automatic Pool Allocation, a transformation framework that segregates distinct instances of heap-based data structures into seperate memory pools and allows heuristics to be used to partially control the internal layout of those data structures. The primary goal of this work is performance improvement, not automatic memory management, and the paper makes several new contributions. The key contribution is a new compiler algorithm for partitioning heap objects in imperative programs based on a context-sensitive pointer analysis, including a novel strategy for correct handling of indirect (and potentially unsafe) function calls. The transformation does not require type safe programs and works for the full generality of C and C++. Second, the paper describes several optimizations that exploit data structure partitioning to further improve program performance. Third, the paper evaluates how memory hierarchy behavior and overall program performance are impacted by the new transformations. Using a number of benchmarks and a few applications, we find that compilation times are extremely low, and overall running times for heap intensive programs speed up by 10-25\% in many cases, about 2x in two cases, and more than 10x in two small benchmarks. Overall, we believe this work provides a new framework for optimizing pointer intensive programs by segregating and controlling the layout of heap-based data structures.},
	urldate = {2018-05-07},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Lattner, Chris and Adve, Vikram},
	year = {2005},
	keywords = {static analysis, cache, data layout, pool allocation, recursive data structure},
	pages = {129--142},
	file = {Lattner_Adve_2005_Automatic Pool Allocation - Improving Performance by Controlling Data Structure.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lattner_Adve_2005_Automatic Pool Allocation - Improving Performance by Controlling Data Structure.pdf:application/pdf}
}

@misc{walls_ee_2014,
	title = {{EE} {Times} - {Embedded} {Systems} {Programming} {Languages}},
	url = {https://www.eetimes.com/author.asp?section_id=36&doc_id=1323907&print=yes},
	abstract = {Specialized languages have been developed to address the unique requirements of embedded developers, but none have found universal acceptance.},
	urldate = {2018-05-10},
	journal = {EE Times},
	author = {Walls, Colin},
	month = sep,
	year = {2014},
	file = {Walls_2014_EE Times - Embedded Systems Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/W/Walls_2014_EE Times - Embedded Systems Programming Languages.pdf:application/pdf}
}

@inproceedings{choi_application-centric_2006,
	title = {Application-{Centric} {Networking} {Framework} for {Wireless} {Sensor} {Nodes}},
	doi = {10.1109/MOBIQ.2006.340439},
	abstract = {Wireless sensor network technology has found diverse applications in numerous fields. As the networking technology is refined in many ways, the need for system modulation with effective performance becomes essential. A multitude of architectures, which includes system abstraction and layering, has been proposed to solve the need at the operating system level. However, previous efforts do not qualify for networking architecture required by sensor networking, since they are aimed at hardware abstraction or protocol-based layering. In this paper, we classify developers into kernel, network and application developers and propose a network architecture that enables those developers to program independently. Network stack is separated into three different layers; MLL, NSL, DNL. This three-layered architecture provides an effective programming environment to sensor network developers by minimizing modification of other layers and maximizing reusability of the networking module. To validate the proposed mechanism, we implemented and assessed the performance with a few network algorithms and applications, based on the RETOS, which supports a dynamic loadable kernel module},
	booktitle = {2006 {Third} {Annual} {International} {Conference} on {Mobile} and {Ubiquitous} {Systems}: {Networking} {Services}},
	author = {Choi, S. and Cha, H.},
	month = jul,
	year = {2006},
	keywords = {Application software, Computer science, Operating systems, Hardware, Kernel, operating system kernels, Libraries, wireless sensor networks, Wireless sensor networks, access protocols, DNL, dynamic loadable kernel module, dynamic network layer, MAC-data link layer, Marine technology, Media Access Protocol, MLL, network architecture, network stack, networking support layer, NSL, operating system level, Programming environments, RETOS, system abstraction, system modulation, wireless sensor network, WSN technology},
	pages = {1--8},
	file = {Choi_Cha_2006_Application-Centric Networking Framework for Wireless Sensor Nodes.pdf:/home/michael/Dropbox/zotero-pdfs/C/Choi_Cha_2006_Application-Centric Networking Framework for Wireless Sensor Nodes.pdf:application/pdf}
}

@inproceedings{andersen_enabling_2016,
	title = {Enabling {Synergy} in {IoT}: {Platform} to {Service} and {Beyond}},
	shorttitle = {Enabling {Synergy} in {IoT}},
	doi = {10.1109/IoTDI.2015.45},
	abstract = {To enable a prosperous Internet of Things, devices and services must be extensible and adapt to changes in the environment or user interaction patterns. These requirements manifest as a set of design principles for each of the layers in an IoT ecosystem, from hardware to cloud services. This paper gives concrete guidelines learned from building a full-stack Synergistic IoT platform.},
	booktitle = {2016 {IEEE} {First} {International} {Conference} on {Internet}-of-{Things} {Design} and {Implementation} ({IoTDI})},
	author = {Andersen, M. P. and Fierro, G. and Culler, D. E.},
	month = apr,
	year = {2016},
	keywords = {Complexity theory, Hardware, Context, wireless sensor networks, Wireless sensor networks, Protocols, IEEE 802.15 Standard, Internet of Things, IoT synergy, Metadata, Sensor motes, Software, synergistic IoT platform, user interaction pattern},
	pages = {1--12},
	file = {Andersen et al_2016_Enabling Synergy in IoT.pdf:/home/michael/Dropbox/zotero-pdfs/A/Andersen et al_2016_Enabling Synergy in IoT.pdf:application/pdf}
}

@article{chisnall_c_2018,
	title = {C {Is} {Not} a {Low}-level {Language} - {ACM} {Queue}},
	url = {https://queue.acm.org/detail.cfm?id=3212479},
	urldate = {2018-05-08},
	journal = {ACM Queue},
	author = {Chisnall, David},
	month = apr,
	year = {2018},
	pages = {13},
	file = {Chisnall_2018_C Is Not a Low-level Language - ACM Queue.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chisnall_2018_C Is Not a Low-level Language - ACM Queue.pdf:application/pdf}
}

@inproceedings{cha_retos:_2007,
	address = {New York, NY, USA},
	series = {{IPSN} '07},
	title = {{RETOS}: {Resilient}, {Expandable}, and {Threaded} {Operating} {System} for {Wireless} {Sensor} {Networks}},
	isbn = {978-1-59593-638-7},
	shorttitle = {{RETOS}},
	url = {http://doi.acm.org/10.1145/1236360.1236381},
	doi = {10.1145/1236360.1236381},
	abstract = {This paper presents the design principles, implementation, and evaluation of the RETOS operating system which is specifically developed for micro sensor nodes. RETOS has four distinct objectives, which are to provide (1) a multithreaded programming interface, (2) system resiliency, (3) kernel extensibility with dynamic reconfiguration, and (4) WSN-oriented network abstraction. RETOS is a multithreaded operating system, hence it provides the commonly used thread model of programming interface to developers. We have used various implementation techniques to optimize the performance and resource usage of multithreading. RETOS also provides software solutions to separate kernel from user applications, and supports their robust execution on MMU-less hardware. The RETOS kernel can be dynamically reconfigured, via loadable kernel framework, so a application-optimized and resource-efficient kernel is constructed. Finally, the networking architecture in RETOS is designed with a layering concept to provide WSN-specific network abstraction. RETOS currently supports Atmel ATmega128, TI MSP430, and Chipcon CC2430 family of microcontrollers. Several real-world WSN applications are developed for RETOS and the overall evaluation of the systems is described in the paper.},
	urldate = {2018-05-10},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Information} {Processing} in {Sensor} {Networks}},
	publisher = {ACM},
	author = {Cha, Hojung and Choi, Sukwon and Jung, Inuk and Kim, Hyoseung and Shin, Hyojeong and Yoo, Jaehyun and Yoon, Chanmin},
	year = {2007},
	keywords = {operating systems, multithreading, wireless sensor network},
	pages = {148--157},
	file = {Cha et al_2007_RETOS.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cha et al_2007_RETOS.pdf:application/pdf}
}

@article{maeng_alpaca:_2017,
	title = {Alpaca: {Intermittent} {Execution} {Without} {Checkpoints}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {Alpaca},
	url = {http://doi.acm.org/10.1145/3133920},
	doi = {10.1145/3133920},
	abstract = {The emergence of energy harvesting devices creates the potential for batteryless sensing and computing devices. Such devices operate only intermittently, as energy is available, presenting a number of challenges for software developers. Programmers face a complex design space requiring reasoning about energy, memory consistency, and forward progress. This paper introduces Alpaca, a low-overhead programming model for intermittent computing on energy-harvesting devices. Alpaca programs are composed of a sequence of user-defined tasks. The Alpaca runtime preserves execution progress at the granularity of a task. The key insight in Alpaca is the privatization of data shared between tasks. Shared values written in a task are detected using idempotence analysis and copied into a buffer private to the task. At the end of the task, modified values from the private buffer are atomically committed to main memory, ensuring that data remain consistent despite power failures. Alpaca provides a familiar programming interface, a highly efficient runtime model, and places fewer restrictions on a target device's hardware architecture. We implemented a prototype of Alpaca as an extension to C with an LLVM compiler pass. We evaluated Alpaca, and directly compared to two systems from prior work. Alpaca eliminates checkpoints, which improves performance up to 15x, and avoids static multi-versioning, which improves memory consumption by up to 5.5x.},
	number = {OOPSLA},
	urldate = {2018-05-14},
	journal = {Proc. ACM Program. Lang.},
	author = {Maeng, Kiwan and Colin, Alexei and Lucia, Brandon},
	month = oct,
	year = {2017},
	keywords = {energy-harvesting, intermittent computing},
	pages = {96:1--96:30},
	file = {Maeng et al_2017_Alpaca - Intermittent Execution Without Checkpoints.pdf:/home/michael/Dropbox/zotero-pdfs/M/Maeng et al_2017_Alpaca - Intermittent Execution Without Checkpoints.pdf:application/pdf}
}

@article{hoare_communicating_1978-1,
	title = {Communicating {Sequential} {Processes}},
	volume = {21},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359576.359585},
	doi = {10.1145/359576.359585},
	abstract = {This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions of a variety of a familiar programming exercises.},
	number = {8},
	urldate = {2018-05-15},
	journal = {Commun. ACM},
	author = {Hoare, C. A. R.},
	month = aug,
	year = {1978},
	keywords = {concurrency, monitors, programming languages, programming, classes, conditional critical regions, coroutines, data representations, guarded commands, input, iterative arrays, multiple entries, multiple exits, nondeterminacy, output, parallel programming, procedures, program structures, programming primitives, recursion},
	pages = {666--677},
	file = {Hoare_1978_Communicating Sequential Processes.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hoare_1978_Communicating Sequential Processes2.pdf:application/pdf}
}

@article{armstrong_making_nodate,
	title = {Making reliable distributed systems in the presence of sodware errors},
	language = {en},
	author = {Armstrong, Joe},
	pages = {295},
	file = {Armstrong - Making reliable distributed systems in the presenc.pdf:/home/michael/Zotero/storage/8NKWGCGZ/Armstrong - Making reliable distributed systems in the presenc.pdf:application/pdf}
}

@techreport{ericsson_erlang/otp_2018,
	title = {Erlang/{OTP} {System} {Documentation}},
	url = {http://erlang.org/doc/pdf/otp-system-documentation.pdf},
	number = {9.3},
	urldate = {2018-05-16},
	institution = {Ericsson AB},
	author = {Ericsson, AB},
	month = mar,
	year = {2018},
	pages = {371},
	file = {Ericsson_2018_Erlang-OTP System Documentation.pdf:/home/michael/Dropbox/zotero-pdfs/E/Ericsson_2018_Erlang-OTP System Documentation.pdf:application/pdf}
}

@article{gene_archipelago:_2008,
	title = {Archipelago: {Trading} {Address} {Space} for {Reliability} and {Security}},
	abstract = {Memory errors are a notorious source of security vulnerabilities that can lead to service interruptions, information leakage and unauthorized access. Because such errors are also difﬁcult to debug, the absence of timely patches can leave users vulnerable to attack for long periods of time. A variety of approaches have been introduced to combat these errors, but these often incur large runtime overheads and generally abort on errors, threatening availability.},
	language = {en},
	author = {Gene, Vitaliy B Lvin and Berger, Emery D and Zorn, Benjamin G},
	year = {2008},
	pages = {10},
	file = {Gene et al_2008_Archipelago.pdf:/home/michael/Dropbox/zotero-pdfs/G/Gene et al_2008_Archipelago.pdf:application/pdf}
}

@inproceedings{bacon_metronome:_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Metronome}: {A} {Simpler} {Approach} to {Garbage} {Collection} in {Real}-{Time} {Systems}},
	isbn = {978-3-540-20494-7 978-3-540-39962-9},
	shorttitle = {The {Metronome}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-39962-9_52},
	doi = {10.1007/978-3-540-39962-9_52},
	abstract = {With the wide-spread adoption of Java, there is significant interest in using the language for programming real-time systems. The community has generally viewed a truly real-time garbage collector as being impossible to build, and has instead focused its efforts on adding manual memory management mechanisms to Java. Unfortunately, these mechanisms are an awkward fit for the language: they introduce significant run-time overhead, introduce run-time memory access exceptions, and greatly complicate the development of library code. In recent work we have shown that it is possible to build a real-time collector for Java with highly regular CPU utilization and greatly reduced memory footprint. The system currently achieves 6 ms pause times with 50\% CPU utilization (MMU) and virtually no “tail” in the distribution. We show how this work can be incorporated into a general real-time framework, and extended to systems with higher task frequencies. We argue that the community should focus more effort on such a simple, orthogonal solution that is true to the spirit of the Java language.},
	language = {en},
	urldate = {2018-05-18},
	booktitle = {On {The} {Move} to {Meaningful} {Internet} {Systems} 2003: {OTM} 2003 {Workshops}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Bacon, David F. and Cheng, Perry and Rajan, V. T.},
	month = nov,
	year = {2003},
	pages = {466--478},
	file = {Bacon et al_2003_The Metronome.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bacon et al_2003_The Metronome.pdf:application/pdf}
}

@inproceedings{naden_type_2012,
	address = {New York, NY, USA},
	series = {{POPL} '12},
	title = {A {Type} {System} for {Borrowing} {Permissions}},
	isbn = {978-1-4503-1083-3},
	url = {http://doi.acm.org/10.1145/2103656.2103722},
	doi = {10.1145/2103656.2103722},
	abstract = {In object-oriented programming, unique permissions to object references are useful for checking correctness properties such as consistency of typestate and noninterference of concurrency. To be usable, unique permissions must be borrowed --- for example, one must be able to read a unique reference out of a field, use it for something, and put it back. While one can null out the field and later reassign it, this paradigm is ungainly and requires unnecessary writes, potentially hurting cache performance. Therefore, in practice borrowing must occur in the type system, without requiring memory updates. Previous systems support borrowing with external alias analysis and/or explicit programmer management of fractional permissions. While these approaches are powerful, they are also awkward and difficult for programmers to understand. We present an integrated language and type system with unique, immutable, and shared permissions, together with new local permissions that say that a reference may not be stored to the heap. Our system also includes change permissions such as unique{\textgreater}{\textgreater}unique and unique{\textgreater}{\textgreater}none that describe how permissions flow in and out of method formal parameters. Together, these features support common patterns of borrowing, including borrowing multiple local permissions from a unique reference and recovering the unique reference when the local permissions go out of scope, without any explicit management of fractions in the source language. All accounting of fractional permissions is done by the type system "under the hood." We present the syntax and static and dynamic semantics of a formal core language and state soundness results. We also illustrate the utility and practicality of our design by using it to express several realistic examples.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the 39th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Naden, Karl and Bocchino, Robert and Aldrich, Jonathan and Bierhoff, Kevin},
	year = {2012},
	keywords = {types, borrowing, immutability, permissions, uniqueness},
	pages = {557--570},
	file = {Naden et al_2012_A Type System for Borrowing Permissions.pdf:/home/michael/Dropbox/zotero-pdfs/N/Naden et al_2012_A Type System for Borrowing Permissions.pdf:application/pdf}
}

@inproceedings{hogg_islands:_1991,
	address = {New York, NY, USA},
	series = {{OOPSLA} '91},
	title = {Islands: {Aliasing} {Protection} in {Object}-oriented {Languages}},
	isbn = {978-0-201-55417-5},
	shorttitle = {Islands},
	url = {http://doi.acm.org/10.1145/117954.117975},
	doi = {10.1145/117954.117975},
	urldate = {2018-05-18},
	booktitle = {Conference {Proceedings} on {Object}-oriented {Programming} {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Hogg, John},
	year = {1991},
	pages = {271--285},
	file = {Hogg_1991_Islands.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hogg_1991_Islands.pdf:application/pdf}
}

@inproceedings{boyapati_ownership_2003,
	address = {New York, NY, USA},
	series = {{PLDI} '03},
	title = {Ownership {Types} for {Safe} {Region}-based {Memory} {Management} in {Real}-time {Java}},
	isbn = {978-1-58113-662-3},
	url = {http://doi.acm.org/10.1145/781131.781168},
	doi = {10.1145/781131.781168},
	abstract = {The Real Time Specification for Java (RTSJ) allows a program to create real-time threads with hard real-time constraints. Real-time threads use region-based memory management to avoid unbounded pauses caused by interference from the garbage collector. The RTSJ uses runtime checks to ensure that deleting a region does not create dangling references and that real-time threads do not access references to objects allocated in the garbage-collected heap. This paper presents a static type system that guarantees that these runtime checks will never fail for well-typed programs. Our type system therefore 1) provides an important safety guarantee for real-time programs and 2) makes it possible to eliminate the runtime checks and their associated overhead.Our system also makes several contributions over previous work on region types. For object-oriented programs, it combines the benefits of region types and ownership types in a unified type system framework. For multithreaded programs, it allows long-lived threads to share objects without using the heap and without memory leaks. For real-time programs, it ensures that real-time threads do not interfere with the garbage collector. Our experience indicates that our type system is sufficiently expressive and requires little programming overhead, and that eliminating the RTSJ runtime checks using a static type system can significantly decrease the execution time of real-time programs.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2003 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Boyapati, Chandrasekhar and Salcianu, Alexandru and Beebee, Jr., William and Rinard, Martin},
	year = {2003},
	keywords = {encapsulation, ownership types, regions, real-time},
	pages = {324--337},
	file = {Boyapati et al_2003_Ownership Types for Safe Region-based Memory Management in Real-time Java.pdf:/home/michael/Dropbox/zotero-pdfs/B/Boyapati et al_2003_Ownership Types for Safe Region-based Memory Management in Real-time Java.pdf:application/pdf}
}

@inproceedings{stata_type_1998,
	address = {New York, NY, USA},
	series = {{POPL} '98},
	title = {A {Type} {System} for {Java} {Bytecode} {Subroutines}},
	isbn = {978-0-89791-979-1},
	url = {http://doi.acm.org/10.1145/268946.268959},
	doi = {10.1145/268946.268959},
	abstract = {Java is typically compiled into an intermediate language, JVML, that is interpreted by the Java Virtual Machine. Because mobile JVML code is not always trusted, a bytecode verifier enforces static constraints that prevent various dynamic errors. Given the importance of the bytecode verifier for security, its current descriptions are inadequate. This paper proposes using typing rules to describe the bytecode verifier because they are more precise than prose, clearer than code, and easier to reason about than either.JVML has a subroutine construct used for the compilation of Java's try-finally statement. Subroutines are a major source of complexity for the bytecode verifier because they are not obviously last-in/first-out and because they require a kind of polymorphism. Focusing on subroutines, we isolate an interesting, small subset of JVML. We give typing rules for this subset and prove their correctness. Our type system constitutes a sound basis for bytecode verification and a rational reconstruction of a delicate part of Sun's bytecode verifier.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the 25th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Stata, Raymie and Abadi, Martín},
	year = {1998},
	pages = {149--160},
	file = {Stata_Abadi_1998_A Type System for Java Bytecode Subroutines.pdf:/home/michael/Dropbox/zotero-pdfs/S/Stata_Abadi_1998_A Type System for Java Bytecode Subroutines.pdf:application/pdf}
}

@inproceedings{foster_flow-sensitive_2002,
	address = {New York, NY, USA},
	series = {{PLDI} '02},
	title = {Flow-sensitive {Type} {Qualifiers}},
	isbn = {978-1-58113-463-6},
	url = {http://doi.acm.org/10.1145/512529.512531},
	doi = {10.1145/512529.512531},
	abstract = {We present a system for extending standard type systems with flow-sensitive type qualifiers. Users annotate their programs with type qualifiers, and inference checks that the annotations are correct. In our system only the type qualifiers are modeled flow-sensitively---the underlying standard types are unchanged, which allows us to obtain an efficient constraint-based inference algorithm that integrates flow-insensitive alias analysis, effect inference, and ideas from linear type systems to support strong updates. We demonstrate the usefulness of flow-sensitive type qualifiers by finding a number of new locking bugs in the Linux kernel.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2002 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Foster, Jeffrey S. and Terauchi, Tachio and Aiken, Alex},
	year = {2002},
	keywords = {types, alias analysis, constraints, effect inference, flow-sensitivity, linux kernel, locking, restrict, type qualifiers},
	pages = {1--12},
	file = {Foster et al_2002_Flow-sensitive Type Qualifiers.pdf:/home/michael/Dropbox/zotero-pdfs/F/Foster et al_2002_Flow-sensitive Type Qualifiers2.pdf:application/pdf}
}

@inproceedings{neamtiu_practical_2006,
	address = {New York, NY, USA},
	series = {{PLDI} '06},
	title = {Practical {Dynamic} {Software} {Updating} for {C}},
	isbn = {978-1-59593-320-1},
	url = {http://doi.acm.org/10.1145/1133981.1133991},
	doi = {10.1145/1133981.1133991},
	abstract = {Software updates typically require stopping and restarting an application, but many systems cannot afford to halt service, or would prefer not to. Dynamic software updating (DSU) addresses this difficulty by permitting programs to be updated while they run. DSU is appealing compared to other approaches for on-line upgrades because it is quite general and requires no redundant hardware. The challenge is in making DSU practical: it should be flexible, and yet safe, efficient, and easy to use.In this paper, we present Ginseng, a DSU implementation for C that aims to meet this challenge. We compile programs specially so that they can be dynamically patched, and generate most of a dynamic patch automatically. Ginseng performs a series of analyses that when combined with some simple runtime support ensure that an update will not violate type-safety while guaranteeing that data is kept up-to-date. We have used Ginseng to construct and dynamically apply patches to three substantial open-source server programs---Very Secure FTP daemon, OpenSSH sshd daemon, and GNU Zebra. In total, we dynamically patched each program with three years' worth of releases. Though the programs changed substantially, the majority of updates were easy to generate. Performance experiments show that all patches could be applied in less than 5 ms, and that the overhead on application throughput due to updating support ranged from 0 to at most 32\%.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the 27th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Neamtiu, Iulian and Hicks, Michael and Stoyle, Gareth and Oriol, Manuel},
	year = {2006},
	keywords = {dynamic software updating, function indirection, loop extraction, type wrapping},
	pages = {72--83},
	file = {Neamtiu et al_2006_Practical Dynamic Software Updating for C.pdf:/home/michael/Dropbox/zotero-pdfs/N/Neamtiu et al_2006_Practical Dynamic Software Updating for C.pdf:application/pdf}
}

@inproceedings{reynolds_syntactic_1978,
	address = {New York, NY, USA},
	series = {{POPL} '78},
	title = {Syntactic {Control} of {Interference}},
	url = {http://doi.acm.org/10.1145/512760.512766},
	doi = {10.1145/512760.512766},
	abstract = {In programming languages which permit both assignment and procedures, distinct identifiers can represent data structures which share storage or procedures with interfering side effects. In addition to being a direct source of programming errors, this phenomenon, which we call interference can impact type structure and parallelism. We show how to eliminate these difficulties by imposing syntactic restrictions, without prohibiting the kind of constructive interference which occurs with higher-order procedures or SIMULA classes. The basic idea is to prohibit interference between identifiers, but to permit interference among components of collections named by single identifiers.},
	urldate = {2018-05-18},
	booktitle = {Proceedings of the 5th {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Reynolds, John C.},
	year = {1978},
	pages = {39--46},
	file = {Reynolds_1978_Syntactic Control of Interference.pdf:/home/michael/Dropbox/zotero-pdfs/R/Reynolds_1978_Syntactic Control of Interference.pdf:application/pdf}
}

@article{tofte_type_1990,
	title = {Type inference for polymorphic references},
	volume = {89},
	issn = {0890-5401},
	url = {http://www.sciencedirect.com/science/article/pii/089054019090018D},
	doi = {10.1016/0890-5401(90)90018-D},
	abstract = {The Hindley/Milner discipline for polymorphic type inference in functional programming languages is not sound if used on functions that can create and update references (pointers). We have found that the reason is a simple technical point concerning the capture of free type variables in store typings. We present a modified type inference system and prove its soundness using operational semantics. It is decidable whether, given an expression e, any type can be inferred for e. If some type can be inferred for e then a principal type can be inferred. Principal types are found using unification. The ideas extend to polymorphic exceptions and have been adopted in the definition of the programming language Standard ML.},
	number = {1},
	urldate = {2018-05-17},
	journal = {Information and Computation},
	author = {Tofte, Mads},
	month = nov,
	year = {1990},
	pages = {1--34},
	file = {Tofte_1990_Type inference for polymorphic references.pdf:/home/michael/Dropbox/zotero-pdfs/T/Tofte_1990_Type inference for polymorphic references.pdf:application/pdf}
}

@techreport{noauthor_proceedings_1981,
	title = {Proceedings of the 4th {Seminar} on the {DOD} {Computer} {Security} {Initiative}},
	institution = {National Bureau of Standards},
	month = aug,
	year = {1981},
	file = {1981_Proceedings of the 4th Seminar on the DOD Computer Security Initiative.pdf:/home/michael/Dropbox/zotero-pdfs/undefined/1981_Proceedings of the 4th Seminar on the DOD Computer Security Initiative.pdf:application/pdf}
}

@misc{noauthor_alpha-draft.pdf_nodate,
	title = {alpha-draft.pdf},
	url = {https://www.cis.upenn.edu/~aarthur/alpha-draft.pdf},
	urldate = {2017-11-20},
	file = {alpha-draft.pdf:/home/michael/Dropbox/zotero-pdfs/_/alpha-draft.pdf:application/pdf}
}

@article{neumann_software_1976,
	title = {Software {Development} and {Proofs} of {Multi}-{Level} {Security}},
	journal = {ICSE},
	author = {Neumann, Peter and Feiertag, Richard and Levitt, Karl and Robinson, Lawrence},
	year = {1976},
	file = {Neumann et al_1976_Software Development and Proofs of Multi-Level Security.pdf:/home/michael/Dropbox/zotero-pdfs/N/Neumann et al_1976_Software Development and Proofs of Multi-Level Security.pdf:application/pdf}
}

@article{patil_low-cost_1997,
	title = {Low-cost, {Concurrent} {Checking} of {Pointer} and {Array} {Accesses} in {C} {Programs}},
	volume = {27},
	copyright = {Copyright © 1997 John Wiley \& Sons, Ltd.},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-024X%28199701%2927%3A1%3C87%3A%3AAID-SPE78%3E3.0.CO%3B2-P},
	doi = {10.1002/(SICI)1097-024X(199701)27:1<87::AID-SPE78>3.0.CO;2-P},
	abstract = {Illegal pointer and array accesses are a major cause of failure for C programs. We present a technique called ‘guarding’ to catch illegal array and pointer accesses. Our implementation of guarding for C programs works as a source-to-source translator. Auxiliary objects called guards are added to a user program to monitor pointer and array accesses at run time. Guards maintain attributes to catch out of bounds array accesses and accesses to deallocated memory. Our system has found a number of previously unreported errors in widely-used Unix utilities and SPEC92 benchmarks. Many commonly used programs have bugs which may not always manifest themselves as a program crash, but may instead produce a subtly wrong answer. These programs are not routinely checked for run-time errors because the increase in execution time due to run-time checking can be very high. We present two techniques to handle the high cost of run-time checking of pointer and array accesses in C programs: ‘customization’ and ‘shadow processing’. Customization works by decoupling run-time checking from original computation. A user program is customized for guarding by throwing away computation not relevant for guarding. We have explored using program slicing for customization. Customization can cut the overhead of guarding by up to half. Shadow processing uses idle processors in multiprocessor workstations to perform run-time checking in the background. A user program is instrumented to obtain a ‘main process’ and a ‘shadow process’. The main process performs computations from the orignal program, occasionally communicating a few key values to the shadow process. The shadow process follows the main process, checking pointer and array accesses. The overhead to the main process which the user sees is very low – almost always less than 10\%. © 1997 by John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2018-05-20},
	journal = {Software: Practice and Experience},
	author = {Patil, Harish and Fischer, Charles},
	month = jan,
	year = {1997},
	keywords = {memory access checking, multiprocessor workstations, program slicing},
	pages = {87--110},
	file = {Patil_Fischer_1997_Low-cost, Concurrent Checking of Pointer and Array Accesses in C Programs.pdf:/home/michael/Dropbox/zotero-pdfs/P/Patil_Fischer_1997_Low-cost, Concurrent Checking of Pointer and Array Accesses in C Programs.pdf:application/pdf}
}

@inproceedings{rondon_liquid_2008,
	address = {New York, NY, USA},
	series = {{PLDI} '08},
	title = {Liquid {Types}},
	isbn = {978-1-59593-860-2},
	url = {http://doi.acm.org/10.1145/1375581.1375602},
	doi = {10.1145/1375581.1375602},
	abstract = {We present Logically Qualified Data Types, abbreviated to Liquid Types, a system that combines Hindley-Milner type inference with Predicate Abstraction to automatically infer dependent types precise enough to prove a variety of safety properties. Liquid types allow programmers to reap many of the benefits of dependent types, namely static verification of critical properties and the elimination of expensive run-time checks, without the heavy price of manual annotation. We have implemented liquid type inference in DSOLVE, which takes as input an OCAML program and a set of logical qualifiers and infers dependent types for the expressions in the OCAML program. To demonstrate the utility of our approach, we describe experiments using DSOLVE to statically verify the safety of array accesses on a set of OCAML benchmarks that were previously annotated with dependent types as part of the DML project. We show that when used in conjunction with a fixed set of array bounds checking qualifiers, DSOLVE reduces the amount of manual annotation required for proving safety from 31\% of program text to under 1\%.},
	urldate = {2018-05-22},
	booktitle = {Proceedings of the 29th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Rondon, Patrick M. and Kawaguci, Ming and Jhala, Ranjit},
	year = {2008},
	keywords = {type inference, dependent types, hindley-milner, predicate abstraction},
	pages = {159--169},
	file = {Rondon et al_2008_Liquid Types.pdf:/home/michael/Dropbox/zotero-pdfs/R/Rondon et al_2008_Liquid Types.pdf:application/pdf}
}

@inproceedings{nguyen_automated_2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Automated {Verification} of {Shape} and {Size} {Properties} {Via} {Separation} {Logic}},
	isbn = {978-3-540-69735-0 978-3-540-69738-1},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-69738-1_18},
	doi = {10.1007/978-3-540-69738-1_18},
	abstract = {Despite their popularity and importance, pointer-based programs remain a major challenge for program verification. In this paper, we propose an automated verification system that is concise, precise and expressive for ensuring the safety of pointer-based programs. Our approach uses user-definable shape predicates to allow programmers to describe a wide range of data structures with their associated size properties. To support automatic verification, we design a new entailment checking procedure that can handle well-founded inductive predicates using unfold/fold reasoning. We have proven the soundness and termination of our verification system, and have built a prototype system.},
	language = {en},
	urldate = {2018-05-22},
	booktitle = {Verification, {Model} {Checking}, and {Abstract} {Interpretation}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Nguyen, Huu Hai and David, Cristina and Qin, Shengchao and Chin, Wei-Ngan},
	month = jan,
	year = {2007},
	pages = {251--266},
	file = {Nguyen et al_2007_Automated Verification of Shape and Size Properties Via Separation Logic.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nguyen et al_2007_Automated Verification of Shape and Size Properties Via Separation Logic.pdf:application/pdf}
}

@article{martin-lof_constructive_1984,
	title = {Constructive mathematics and computer programming},
	volume = {312},
	copyright = {Scanned images copyright © 2017, Royal Society},
	issn = {0080-4614, 2054-0272},
	url = {http://rsta.royalsocietypublishing.org/content/312/1522/501},
	doi = {10.1098/rsta.1984.0073},
	abstract = {If programming is understood not as the writing of instructions for this or that computing machine but as the design of methods of computation that it is the computer’s duty to execute (a difference that Dijkstra has referred to as the difference between computer science and computing science), then it no longer seems possible to distinguish the discipline of programming from constructive mathematics. This explains why the intuitionistic theory of types (Martin-Lof 1975 In Logic Colloquium 1973 (ed. H. E. Rose \& J. C. Shepherdson), pp. 73- 118. Amsterdam: North-Holland), which was originally developed as a symbolism for the precise codification of constructive mathematics, may equally well be viewed as a programming language. As such it provides a precise notation not only, like other programming languages, for the programs themselves but also for the tasks that the programs are supposed to perform. Moreover, the inference rules of the theory of types, which are again completely formal, appear as rules of correct program synthesis. Thus the correctness of a program written in the theory of types is proved formally at the same time as it is being synthesized.},
	language = {en},
	number = {1522},
	urldate = {2018-05-23},
	journal = {Phil. Trans. R. Soc. Lond. A},
	author = {Martin-Lof, P.},
	month = oct,
	year = {1984},
	pages = {501--518},
	file = {Martin-Lof_1984_Constructive mathematics and computer programming.pdf:/home/michael/Dropbox/zotero-pdfs/M/Martin-Lof_1984_Constructive mathematics and computer programming.pdf:application/pdf}
}

@article{de_araujo_tyr:_2016,
	series = {{WEIT} 2015, the {Third} {Workshop}-{School} on {Theoretical} {Computer} {Science}},
	title = {Týr: {A} {Dependent} {Type} {System} for {Spatial} {Memory} {Safety} in {LLVM}},
	volume = {324},
	issn = {1571-0661},
	shorttitle = {Týr},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066116300469},
	doi = {10.1016/j.entcs.2016.09.003},
	abstract = {This work proposes a dependent type system for the LLVM Intermediate Representation language for keeping track of pointer bounds information. The system employs a combination of static analysis and runtime checks to avoid spatial memory safety violations, such as buffer overflows. By working on LLVM IR, the system serves a foundation for ensuring spatial memory safety in languages which can be compiled to LLVM, such as C and C++.},
	urldate = {2018-05-25},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {De Araújo, Vítor Bujés Ubatuba and Moreira, Álvaro Freitas and Machado, Rodrigo},
	month = sep,
	year = {2016},
	keywords = {type safety, dependent types, LLVM, Spatial memory},
	pages = {3--13},
	file = {De Araujo et al_2016_Tyr.pdf:/home/michael/Dropbox/zotero-pdfs/D/De Araujo et al_2016_Tyr.pdf:application/pdf}
}

@techreport{jay_shape_1997,
	title = {Shape {Checking} of {Array} {Programs}},
	abstract = {Shape theory provides a framework for the study of data types in which shape and data can be manipulated separately. This paper is concerned with shape checking, i.e. the detection of shape errors, such as array bound errors, without handling the data stored within. It can be seen as a form of partial evaluation in which data computations are ignored.  We construct a simply-typed lambda-calculus that supports a vector type constructor, whose iteration yields types of arrays. It is expressive enough to construct all of the usual linear algebra operations. All shape errors in a term t can be detected by evaluating its shape \#t. Evaluation of \#t will terminate if that of t does.  Keywords shape analysis, partial evaluation, arrays, higher-order.  1 Introduction  Shape theory explores the consequences of manipulating shape and data separately (Jay [14]). Shape refers to the data structure in which the data is stored. For example, the shape of a three-dimensional regular array is a tuple of...},
	institution = {In Computing: the Australasian Theory Seminar, Proceedings},
	author = {Jay, C. Barry and Sekanina, Milan},
	year = {1997},
	file = {Jay_Sekanina_1997_Shape Checking of Array Programs.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jay_Sekanina_1997_Shape Checking of Array Programs.pdf:application/pdf}
}

@techreport{davies_practical_1997,
	title = {Practical {Refinement}-{Type} {Checking}},
	abstract = {Refinement types allow many more properties of programs to be expressed and statically checked than conventional type systems. We present a practical algorithm for refinement-type checking in a -calculus enriched with refinement-type annotations. We prove that our basic algorithm is sound and complete, and show that every term which has a refinement type can be annotated as required by our algorithm. Our positive experience with an implementation of an extension of this algorithm to the full core language of Standard ML demonstrates that refinement types can be a practical program development tool in a realistic programming language. The required refinement type definitions and annotations are not much of a burden and serve as formal, machine-checked explanations of code invariants which otherwise would remain implicit. 1 Introduction  The advantages of statically-typed programming languages are well known, and have been described many times (e.g. see [Car97]). However, conventional ty...},
	author = {Davies, Rowan and Pfenning, Frank},
	year = {1997},
	file = {Davies_Pfenning_1997_Practical Refinement-Type Checking.pdf:/home/michael/Dropbox/zotero-pdfs/D/Davies_Pfenning_1997_Practical Refinement-Type Checking.pdf:application/pdf}
}

@inproceedings{amani_cogent:_2016,
	address = {New York, NY, USA},
	series = {{ASPLOS} '16},
	title = {Cogent: {Verifying} {High}-{Assurance} {File} {System} {Implementations}},
	isbn = {978-1-4503-4091-5},
	shorttitle = {Cogent},
	url = {http://doi.acm.org/10.1145/2872362.2872404},
	doi = {10.1145/2872362.2872404},
	abstract = {We present an approach to writing and formally verifying high-assurance file-system code in a restricted language called Cogent, supported by a certifying compiler that produces C code, high-level specification of Cogent, and translation correctness proofs. The language is strongly typed and guarantees absence of a number of common file system implementation errors. We show how verification effort is drastically reduced for proving higher-level properties of the file system implementation by reasoning about the generated formal specification rather than its low-level C code. We use the framework to write two Linux file systems, and compare their performance with their native C implementations.},
	urldate = {2018-05-29},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Architectural} {Support} for {Programming} {Languages} and {Operating} {Systems}},
	publisher = {ACM},
	author = {Amani, Sidney and Hixon, Alex and Chen, Zilin and Rizkallah, Christine and Chubb, Peter and O'Connor, Liam and Beeren, Joel and Nagashima, Yutaka and Lim, Japheth and Sewell, Thomas and Tuong, Joseph and Keller, Gabriele and Murray, Toby and Klein, Gerwin and Heiser, Gernot},
	year = {2016},
	keywords = {verification, file systems, isabelle/hol, domain-specific languages, co-generation},
	pages = {175--188},
	file = {Amani et al_2016_Cogent.pdf:/home/michael/Dropbox/zotero-pdfs/A/Amani et al_2016_Cogent.pdf:application/pdf}
}

@inproceedings{chen_toward_2016,
	address = {New York, NY, USA},
	series = {{PLDI} '16},
	title = {Toward {Compositional} {Verification} of {Interruptible} {OS} {Kernels} and {Device} {Drivers}},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908101},
	doi = {10.1145/2908080.2908101},
	abstract = {An operating system (OS) kernel forms the lowest level of any system software stack. The correctness of the OS kernel is the basis for the correctness of the entire system. Recent efforts have demonstrated the feasibility of building formally verified general-purpose kernels, but it is unclear how to extend their work to verify the functional correctness of device drivers, due to the non-local effects of interrupts. In this paper, we present a novel compositional framework for building certified interruptible OS kernels with device drivers. We provide a general device model that can be instantiated with various hardware devices, and a realistic formal model of interrupts, which can be used to reason about interruptible code. We have realized this framework in the Coq proof assistant. To demonstrate the effectiveness of our new approach, we have successfully extended an existing verified non-interruptible kernel with our framework and turned it into an interruptible kernel with verified device drivers. To the best of our knowledge, this is the first verified interruptible operating system with device drivers.},
	urldate = {2018-05-29},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Chen, Hao and Wu, Xiongnan (Newman) and Shao, Zhong and Lockerman, Joshua and Gu, Ronghui},
	year = {2016},
	keywords = {Abstraction Layer, Certified OS Kernels, Device Drivers, Interrupts, Modularity, Program Verification},
	pages = {431--447},
	file = {Chen et al_2016_Toward Compositional Verification of Interruptible OS Kernels and Device Drivers.pdf:/home/michael/Dropbox/zotero-pdfs/C/Chen et al_2016_Toward Compositional Verification of Interruptible OS Kernels and Device Drivers.pdf:application/pdf}
}

@inproceedings{greenaway_dont_2014,
	address = {New York, NY, USA},
	series = {{PLDI} '14},
	title = {Don'{T} {Sweat} the {Small} {Stuff}: {Formal} {Verification} of {C} {Code} {Without} the {Pain}},
	isbn = {978-1-4503-2784-8},
	shorttitle = {Don'{T} {Sweat} the {Small} {Stuff}},
	url = {http://doi.acm.org/10.1145/2594291.2594296},
	doi = {10.1145/2594291.2594296},
	abstract = {We present an approach for automatically generating provably correct abstractions from C source code that are useful for practical implementation verification. The abstractions are easier for a human verification engineer to reason about than the implementation and increase the productivity of interactive code proof. We guarantee soundness by automatically generating proofs that the abstractions are correct. In particular, we show two key abstractions that are critical for verifying systems-level C code: automatically turning potentially overflowing machine-word arithmetic into ideal integers, and transforming low-level C pointer reasoning into separate abstract heaps. Previous work carrying out such transformations has either done so using unverified translations, or required significant proof engineering effort. We implement these abstractions in an existing proof-producing specification transformation framework named AutoCorres, developed in Isabelle/HOL, and demonstrate its effectiveness in a number of case studies. We show scalability on multiple OS microkernels, and we show how our changes to AutoCorres improve productivity for total correctness by porting an existing high-level verification of the Schorr-Waite algorithm to a low-level C implementation with minimal effort.},
	urldate = {2018-05-29},
	booktitle = {Proceedings of the 35th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Greenaway, David and Lim, Japheth and Andronick, June and Klein, Gerwin},
	year = {2014},
	keywords = {Isabelle/HOL, C verification},
	pages = {429--439},
	file = {Greenaway et al_2014_Don'T Sweat the Small Stuff.pdf:/home/michael/Dropbox/zotero-pdfs/G/Greenaway et al_2014_Don'T Sweat the Small Stuff.pdf:application/pdf}
}

@inproceedings{swamy_dependent_2016,
	title = {Dependent types and multi-monadic effects in {F}*},
	isbn = {978-1-4503-3549-2},
	url = {http://dl.acm.org/citation.cfm?doid=2837614.2837655},
	doi = {10.1145/2837614.2837655},
	abstract = {We present a new, completely redesigned, version of F⋆, a language that works both as a proof assistant as well as a general-purpose, veriﬁcation-oriented, effectful programming language. In support of these complementary roles, F⋆ is a dependently typed, higher-order, call-by-value language with primitive effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F⋆ uses this to efﬁciently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F⋆ is a language of pure functions used to write speciﬁcations and proof terms—its consistency is maintained by a semantic termination check based on a well-founded order.},
	language = {en},
	urldate = {2018-05-29},
	publisher = {ACM Press},
	author = {Swamy, Nikhil and Kohlweiss, Markulf and Zinzindohoue, Jean-Karim and Zanella-Béguelin, Santiago and Hriţcu, Cătălin and Keller, Chantal and Rastogi, Aseem and Delignat-Lavaud, Antoine and Forest, Simon and Bhargavan, Karthikeyan and Fournet, Cédric and Strub, Pierre-Yves},
	year = {2016},
	pages = {256--270},
	file = {Swamy et al_2016_Dependent types and multi-monadic effects in F.pdf:/home/michael/Dropbox/zotero-pdfs/S/Swamy et al_2016_Dependent types and multi-monadic effects in F.pdf:application/pdf}
}

@article{diatchki_high-level_2005,
	title = {High-level {Views} on {Low}-level {Representations}},
	abstract = {This paper explains how the high-level treatment of datatypes in functional languages—using features like constructor functions and pattern matching—can be made to coexist with bitdata. We use this term to describe the bit-level representations of data that are required in the construction of many different applications, including operating systems, device drivers, and assemblers. We explain our approach as a combination of two language extensions, each of which could potentially be adapted to any modern functional language. The ﬁrst adds simple and elegant constructs for manipulating raw bitﬁeld values, while the second provides a view-like mechanism for deﬁning distinct new bitdata types with ﬁne-control over the underlying representation. Our design leverages polymorphic type inference, as well as techniques for improvement of qualiﬁed types, to track both the type and the width of bitdata structures. We have implemented our extensions in a small functional language interpreter, and used it to show that our approach can handle a wide range of practical bitdata types.},
	language = {en},
	author = {Diatchki, Iavor S and Jones, Mark P and Leslie, Rebekah},
	year = {2005},
	pages = {12},
	file = {Diatchki et al_2005_High-level Views on Low-level Representations.pdf:/home/michael/Dropbox/zotero-pdfs/D/Diatchki et al_2005_High-level Views on Low-level Representations.pdf:application/pdf}
}

@book{massalin_synthesis:_1992,
	title = {Synthesis: {An} {Efficient} {Implementation} of {Fundamental} {Operating} {System} {Services}},
	shorttitle = {Synthesis},
	abstract = {This dissertation shows that operating systems can provide fundamental services an order of magnitude more efficiently than traditional implementations. It describes the implementation of a new operating system kernel, Synthesis, that achieves this level of performance. The Synthesis kernel combines several new techniques to provide high performance without sacrificing the expressive power or security of the system. The new ideas include: ffl Run-time code synthesis --- a systematic way of creating executable machine code at runtime to optimize frequently-used kernel routines --- queues, buffers, context switchers, interrupt handlers, and system call dispatchers --- for specific situations, greatly reducing their execution time. ffl Fine-grain scheduling --- a new process-scheduling technique based on the idea of feedback that performs frequent scheduling actions and policy adjustments (at submillisecond intervals) resulting in an adaptive, self-tuning system that can support real-ti...},
	author = {Massalin, Henry and Massalin, Henry},
	year = {1992},
	file = {Massalin_Massalin_1992_Synthesis.pdf:/home/michael/Dropbox/zotero-pdfs/M/Massalin_Massalin_1992_Synthesis.pdf:application/pdf}
}

@article{lattner_llvm:_2002,
	title = {{LLVM}: {AN} {INFRASTRUCTURE} {FOR} {MULTI}-{STAGE} {OPTIMIZATION}},
	language = {en},
	author = {LATTNER, CHRIS ARTHUR},
	year = {2002},
	pages = {68},
	file = {LATTNER - LLVM AN INFRASTRUCTURE FOR MULTI-STAGE OPTIMIZATI.pdf:/home/michael/Zotero/storage/9SHB7BRC/LATTNER - LLVM AN INFRASTRUCTURE FOR MULTI-STAGE OPTIMIZATI.pdf:application/pdf}
}

@article{sift_program_1996,
	title = {Program {Generalization} for {Software} {Reuse}: {From} {C} to {C} + +},
	abstract = {We consider the problem of software generalization: Given a program component C, create a parameterized program component C ° such that C o is usable in a wider variety of syntactic contexts than C. Furthermore, C o should be a semantically meaningful generalization of C; namely, there must exist an instantiation of C {\textasciitilde}that is equivalent in functionality to C.},
	language = {en},
	author = {Sift, Michael and Reps, Thomas},
	year = {1996},
	pages = {12},
	file = {Sift and Reps - Program Generalization for Software Reuse From C .pdf:/home/michael/Zotero/storage/YYC8DB4Z/Sift and Reps - Program Generalization for Software Reuse From C .pdf:application/pdf}
}

@article{ancona_behavioral_2016,
	title = {Behavioral {Types} in {Programming} {Languages}},
	volume = {3},
	issn = {2325-1107, 2325-1131},
	url = {https://www.nowpublishers.com/article/Details/PGL-031},
	doi = {10.1561/2500000031},
	abstract = {Behavioral Types in Programming Languages},
	language = {English},
	number = {2-3},
	urldate = {2018-05-29},
	journal = {Foundations and Trends® in Programming Languages},
	author = {Ancona, Davide and Bono, Viviana and Bravetti, Mario and Campos, Joana and Castagna, Giuseppe and Deniélou, Pierre-Malo and Gay, Simon J. and Gesbert, Nils and Giachino, Elena and Hu, Raymond and Johnsen, Einar Broch and Martins, Francisco and Mascardi, Viviana and Montesi, Fabrizio and Neykova, Rumyana and Ng, Nicholas and Padovani, Luca and Vasconcelos, Vasco T. and Yoshida, Nobuko},
	month = jul,
	year = {2016},
	pages = {95--230},
	file = {Ancona et al_2016_Behavioral Types in Programming Languages.pdf:/home/michael/Dropbox/zotero-pdfs/A/Ancona et al_2016_Behavioral Types in Programming Languages.pdf:application/pdf}
}

@inproceedings{ferraiuolo_secure_2017-1,
	title = {Secure information flow verification with mutable dependent types},
	doi = {10.1145/3061639.3062316},
	abstract = {This paper presents a novel secure hardware description language (HDL) that uses an information flow type system to ensure that hardware is secure at design time. The novelty of this HDL lies in its ability to securely share hardware modules and storage elements across multiple security levels. Unlike previous secure HDLs, the new HDL enables secure sharing at a fine granularity and without implicitly adding hardware for security enforcement; this is important because the implicitly added hardware can break functionality and harm efficiency. The new HDL enables practical hardware designs that are secure, correct, and efficient. We demonstrate the practicality of the new HDL by using it to design and type-check a synthesizable pipelined processor implementation that support protection rings and instructions that change modes.},
	booktitle = {2017 54th {ACM}/{EDAC}/{IEEE} {Design} {Automation} {Conference} ({DAC})},
	author = {Ferraiuolo, A. and Hua, Weizhe and Myers, A. C. and Suh, G. E.},
	month = jun,
	year = {2017},
	keywords = {security of data, formal verification, Ground penetrating radar, Security, Registers, Hardware, Pipelines, hardware description languages, peer-to-peer computing, Hardware design languages, Clocks, information flow type system, multiple security levels, mutable dependent types, secure hardware description language, secure HDL, secure information flow verification, secure sharing},
	pages = {1--6},
	file = {Ferraiuolo et al_2017_Secure information flow verification with mutable dependent types.pdf:/home/michael/Dropbox/zotero-pdfs/F/Ferraiuolo et al_2017_Secure information flow verification with mutable dependent types2.pdf:application/pdf}
}

@article{wagner_elastic_2017,
	title = {Elastic {Program} {Transformations}: {Automatically} {Optimizing} the {Reliability}/{Performance} {Trade}-off in {Systems} {Software}},
	language = {en},
	author = {Wagner, Jonas Benedict},
	year = {2017},
	pages = {151},
	file = {Wagner - Elastic Program Transformations Automatically Opt.pdf:/home/michael/Zotero/storage/7ICT3WYS/Wagner - Elastic Program Transformations Automatically Opt.pdf:application/pdf}
}

@article{ruef_checked_2017,
	title = {Checked {C} for {Safety}, {Gradually}},
	abstract = {This paper presents Checked C, an extension to C designed to support spatial safety, implemented in Clang and LLVM. Checked C’s design is distinguished by its focus on backwardcompatibility, developer usability, and enabling highly performant code. Like past approaches to a safer C, Checked C employs a form of checked pointer whose accesses can be statically or dynamically verified. New to Checked C is the notion of a checked region. Inspired by the blame theorem from gradual typing, checked regions can be held blameless as the source of a safety violation, meaning it must have arisen from unchecked code. We formalize and prove this property using the Coq proof assistant. To assist programmers in migrating legacy code to Checked C, we have implemented a porting tool that introduces the use of checked pointers, where safe. Experiments on standard benchmarks and some legacy programs show that Checked C generates efficient code, and that the porting tool is useful.},
	language = {en},
	author = {Ruef, Andrew and Elliott, Archibald Samuel and Sweet, Ian and Hicks, Michael and Tarditi, David},
	year = {2017},
	pages = {18},
	file = {Ruef et al_2017_Checked C for Safety, Gradually.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ruef et al_2017_Checked C for Safety, Gradually.pdf:application/pdf}
}

@article{harrison_survey_2013,
	title = {A {Survey} of {Automated} {Theorem} {Proving}},
	language = {en},
	author = {Harrison, John},
	year = {2013},
	pages = {216},
	file = {Harrison - A Survey of Automated Theorem Proving.pdf:/home/michael/Zotero/storage/6UR4UKKE/Harrison - A Survey of Automated Theorem Proving.pdf:application/pdf}
}

@inproceedings{steensgaard_points-analysis_1996-1,
	address = {London, UK, UK},
	series = {{CC} '96},
	title = {Points-to {Analysis} by {Type} {Inference} of {Programs} with {Structures} and {Unions}},
	isbn = {978-3-540-61053-3},
	url = {http://dl.acm.org/citation.cfm?id=647473.727458},
	urldate = {2018-05-29},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Compiler} {Construction}},
	publisher = {Springer-Verlag},
	author = {Steensgaard, Bjarne},
	year = {1996},
	pages = {136--150}
}

@article{cardelli_understanding_1985,
	title = {On {Understanding} {Types}, {Data} {Abstraction}, and {Polymorphism}},
	volume = {17},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/6041.6042},
	doi = {10.1145/6041.6042},
	abstract = {Our objective is to understand the notion of type in programming languages, present a model of typed, polymorphic programming languages that reflects recent research in type theory, and examine the relevance of recent research to the design of practical programming languages.
Object-oriented languages provide both a framework and a motivation for exploring the interaction among the concepts of type, data abstraction, and polymorphism, since they extend the notion of type to data abstraction and since type inheritance is an important form of polymorphism. We develop a \&lgr;-calculus-based model for type systems that allows us to explore these interactions in a simple setting, unencumbered by complexities of production programming languages.
The evolution of languages from untyped universes to monomorphic and then polymorphic type systems is reviewed. Mechanisms for polymorphism such as overloading, coercion, subtyping, and parameterization are examined. A unifying framework for polymorphic type systems is developed in terms of the typed \&lgr;-calculus augmented to include binding of types by quantification as well as binding of values by abstraction.
The typed \&lgr;-calculus is augmented by universal quantification to model generic functions with type parameters, existential quantification and packaging (information hiding) to model abstract data types, and bounded quantification to model subtypes and type inheritance. In this way we obtain a simple and precise characterization of a powerful type system that includes abstract data types, parametric polymorphism, and multiple inheritance in a single consistent framework. The mechanisms for type checking for the augmented \&lgr;-calculus are discussed.
The augmented typed \&lgr;-calculus is used as a programming language for a variety of illustrative examples. We christen this language Fun because fun instead of \&lgr; is the functional abstraction keyword and because it is pleasant to deal with.
Fun is mathematically simple and can serve as a basis for the design and implementation of real programming languages with type facilities that are more powerful and expressive than those of existing programming languages. In particular, it provides a basis for the design of strongly typed object-oriented languages.},
	number = {4},
	urldate = {2018-05-29},
	journal = {ACM Comput. Surv.},
	author = {Cardelli, Luca and Wegner, Peter},
	month = dec,
	year = {1985},
	pages = {471--523},
	file = {Cardelli_Wegner_1985_On Understanding Types, Data Abstraction, and Polymorphism.pdf:/home/michael/Dropbox/zotero-pdfs/C/Cardelli_Wegner_1985_On Understanding Types, Data Abstraction, and Polymorphism.pdf:application/pdf}
}

@article{bodik_abcd:_2002,
	title = {{ABCD}: {Eliminating} {Array} {Bounds} {Checks} on {Demand}},
	abstract = {To guarantee typesafe execution, Java and other strongly typed languages require bounds checking of array accesses. Because arraybounds checks may raise exceptions, they block code motion of instructions with side effects, thus preventing many useful code optimizations, such as partial redundancy elimination or instruction scheduling of memory operations. Furthermore, because it is not expressible at bytecode level, the elimination of bounds checks can only be performed at run time, after the bytecode program is loaded. Using existing powerful bounds-check optimizers at run time is not feasible, however, because they are too heavyweight for the dynamic compilation setting.},
	language = {en},
	author = {Bodık, Rastislav and Gupta, Rajiv and Sarkar, Vivek},
	year = {2002},
	pages = {13},
	file = {Bodik et al_2002_ABCD.pdf:/home/michael/Dropbox/zotero-pdfs/B/Bodik et al_2002_ABCD.pdf:application/pdf}
}

@inproceedings{petroni_automated_2007,
	address = {New York, NY, USA},
	series = {{CCS} '07},
	title = {Automated {Detection} of {Persistent} {Kernel} {Control}-flow {Attacks}},
	isbn = {978-1-59593-703-2},
	url = {http://doi.acm.org/10.1145/1315245.1315260},
	doi = {10.1145/1315245.1315260},
	abstract = {This paper presents a new approach to dynamically monitoring operating system kernel integrity, based on a property called state-based control-flow integrity (SBCFI). Violations of SBCFI signal a persistent, unexpected modification of the kernel's control-flow graph. We performed a thorough analysis of 25 Linux rootkits and found that 24 (96\%) employ persistent control-flow modifications; an informal study of Windows rootkits yielded similar results. We have implemented SBCFI enforcement as part of the Xen and VMware virtual machine monitors. Our implementation detected all the control-flow modifying rootkits we could install, while imposing unnoticeable overhead for both a typical web server workload and CPU-intensive workloads when operating at 10 second intervals.},
	urldate = {2018-05-29},
	booktitle = {Proceedings of the 14th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Petroni, Jr., Nick L. and Hicks, Michael},
	year = {2007},
	keywords = {CFI, virtualization, integrity, kernel, rootkit},
	pages = {103--115},
	file = {Petroni_Hicks_2007_Automated Detection of Persistent Kernel Control-flow Attacks.pdf:/home/michael/Dropbox/zotero-pdfs/P/Petroni_Hicks_2007_Automated Detection of Persistent Kernel Control-flow Attacks.pdf:application/pdf}
}

@article{harper_framework_1993,
	title = {A {Framework} for {Defining} {Logics}},
	volume = {40},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/138027.138060},
	doi = {10.1145/138027.138060},
	abstract = {The Edinburgh Logical Framework (LF) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed \&lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-Lo¨f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in LF via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.},
	number = {1},
	urldate = {2018-05-29},
	journal = {J. ACM},
	author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon},
	month = jan,
	year = {1993},
	keywords = {interactive theorem proving, formal systems, proof checking, typed lambda calculus},
	pages = {143--184},
	file = {Harper et al_1993_A Framework for Defining Logics.pdf:/home/michael/Dropbox/zotero-pdfs/H/Harper et al_1993_A Framework for Defining Logics.pdf:application/pdf}
}

@techreport{leroy_compcert_2012,
	type = {report},
	title = {The {CompCert} {Memory} {Model}, {Version} 2},
	url = {https://hal.inria.fr/hal-00703441/document},
	abstract = {A memory model is an important component of the formal semantics of imperative programming languages: it specifies the behavior of operations over memory states, such as reads and writes. The formally verified CompCert C compiler uses a sophisticated memory model that is shared between the semantics of its source language (the CompCert subset of C) and intermediate languages. The algebraic properties of this memory model play an important role in the proofs of semantic preservation for the compiler. The initial design of the CompCert memory model is described in an article by Leroy and Blazy (J. Autom. Reasoning 2008). The present research report describes version 2 of this memory model, improving over the main limitations of version 1. The first improvement is to expose the byte-level, in-memory representation of integers and floats, while preserving desirable opaqueness properties of pointer values. The second improvement is the integration of a fine-grained mechanism of permissions (access rights), which supports more aggressive optimizations over read-only data, and paves the way towards shared-memory, data-race-free concurrency in the style of Appel's Verified Software Toolchain project.},
	language = {en},
	urldate = {2018-05-30},
	institution = {INRIA},
	author = {Leroy, Xavier and Appel, Andrew and Blazy, Sandrine and Stewart, Gordon},
	month = jun,
	year = {2012},
	pages = {26},
	file = {Leroy et al_2012_The CompCert Memory Model, Version 2.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leroy et al_2012_The CompCert Memory Model, Version 2.pdf:application/pdf}
}

@article{leroy_formal_2009,
	title = {Formal {Verification} of a {Realistic} {Compiler}},
	volume = {52},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1538788.1538814},
	doi = {10.1145/1538788.1538814},
	abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
	number = {7},
	urldate = {2018-05-30},
	journal = {Commun. ACM},
	author = {Leroy, Xavier},
	month = jul,
	year = {2009},
	pages = {107--115},
	file = {Leroy_2009_Formal Verification of a Realistic Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/L/Leroy_2009_Formal Verification of a Realistic Compiler.pdf:application/pdf}
}

@inproceedings{szekeres_sok:_2013,
	title = {{SoK}: {Eternal} {War} in {Memory}},
	shorttitle = {{SoK}},
	doi = {10.1109/SP.2013.13},
	abstract = {Memory corruption bugs in software written in low-level languages like C or C++ are one of the oldest problems in computer security. The lack of safety in these languages allows attackers to alter the program's behavior or take full control over it by hijacking its control flow. This problem has existed for more than 30 years and a vast number of potential solutions have been proposed, yet memory corruption attacks continue to pose a serious threat. Real world exploits show that all currently deployed protections can be defeated. This paper sheds light on the primary reasons for this by describing attacks that succeed on today's systems. We systematize the current knowledge about various protection techniques by setting up a general model for memory corruption attacks. Using this model we show what policies can stop which attacks. The model identifies weaknesses of currently deployed techniques, as well as other proposed protections enforcing stricter policies. We analyze the reasons why protection mechanisms implementing stricter polices are not deployed. To achieve wide adoption, protection mechanisms must support a multitude of features and must satisfy a host of requirements. Especially important is performance, as experience shows that only solutions whose overhead is in reasonable bounds get deployed. A comparison of different enforceable policies helps designers of new protection mechanisms in finding the balance between effectiveness (security) and efficiency. We identify some open research problems, and provide suggestions on improving the adoption of newer techniques.},
	booktitle = {2013 {IEEE} {Symposium} on {Security} and {Privacy}},
	author = {Szekeres, L. and Payer, M. and Wei, T. and Song, D.},
	month = may,
	year = {2013},
	keywords = {Memory management, security of data, Security, Programming, Arrays, Aerospace electronics, Computer bugs, Safety, storage management, software reliability, computer security, memory corruption attacks, memory corruption bugs, program debugging, protection mechanisms, protection techniques, SoK},
	pages = {48--62},
	file = {Szekeres et al_2013_SoK.pdf:/home/michael/Dropbox/zotero-pdfs/S/Szekeres et al_2013_SoK.pdf:application/pdf}
}

@inproceedings{zhou_safedrive:_2006,
	address = {Berkeley, CA, USA},
	series = {{OSDI} '06},
	title = {{SafeDrive}: {Safe} and {Recoverable} {Extensions} {Using} {Language}-based {Techniques}},
	isbn = {978-1-931971-47-8},
	shorttitle = {{SafeDrive}},
	url = {http://dl.acm.org/citation.cfm?id=1298455.1298461},
	abstract = {We present SafeDrive, a system for detecting and recovering from type safety violations in software extensions. SafeDrive has low overhead and requires minimal changes to existing source code. To achieve this result, SafeDrive uses a novel type system that provides fine-grained isolation for existing extensions written in C. In addition, SafeDrive tracks invariants using simple wrappers for the host system API and restores them when recovering from a violation. This approach achieves fine-grained memory error detection and recovery with few code changes and at a significantly lower performance cost than existing solutions based on hardware-enforced domains, such as Nooks [33], L4 [21], and Xen [13], or software-enforced domains, such as SFI [35]. The principles used in SafeDrive can be applied to any large system with loadable, error-prone extension modules. In this paper we describe our experience using SafeDrive for protection and recovery of a variety of Linux device drivers. In order to apply SafeDrive to these device drivers, we had to change less than 4\% of the source code. SafeDrive recovered from all 44 crashes due to injected faults in a network card driver. In experiments with 6 different drivers, we observed increases in kernel CPU utilization of 4--23\% with no noticeable degradation in end-to-end performance.},
	urldate = {2018-05-30},
	booktitle = {Proceedings of the 7th {Symposium} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Zhou, Feng and Condit, Jeremy and Anderson, Zachary and Bagrak, Ilya and Ennals, Rob and Harren, Matthew and Necula, George and Brewer, Eric},
	year = {2006},
	pages = {45--60},
	file = {Zhou et al_2006_SafeDrive.pdf:/home/michael/Dropbox/zotero-pdfs/Z/Zhou et al_2006_SafeDrive.pdf:application/pdf}
}

@inproceedings{oiwa_implementation_2009,
	address = {New York, NY, USA},
	series = {{PLDI} '09},
	title = {Implementation of the {Memory}-safe {Full} {ANSI}-{C} {Compiler}},
	isbn = {978-1-60558-392-1},
	url = {http://doi.acm.org/10.1145/1542476.1542505},
	doi = {10.1145/1542476.1542505},
	abstract = {This paper describes a completely memory-safe compiler for C language programs that is fully compatible with the ANSI C specification. Programs written in C often suffer from nasty errors due to dangling pointers and buffer overflow. Such errors in Internet server programs are often exploited by malicious attackers to crack an entire system. The origin of these errors is usually corruption of in-memory data structures caused by out-of-bound array accesses. Usual C compilers do not provide any protection against such out-of-bound access, although many other languages such as Java and ML do provide such protection. There have been several proposals for preventing such memory corruption from various aspects: runtime buffer overrun detectors, designs for new C-like languages, and compilers for (subsets of) the C language. However, as far as we know, none of them have achieved full memory protection and full compatibility with the C language specification at the same time. We propose the most powerful solution to this problem ever presented. We have developed Fail-Safe C, a memory-safe implementation of the full ANSI C language. It detects and disallows all unsafe operations, yet conforms to the full ANSI C standard (including casts and unions). This paper introduces several techniques--both compile-time and runtime--to reduce the overhead of runtime checks, while still maintaining 100\% memory safety. This compiler lets programmers easily make their programs safe without heavy rewriting or porting of their code. It also supports many of the "dirty tricks" commonly used in many existing C programs, which do not strictly conform to the standard specification. In this paper, we demonstrate several real-world server programs that can be processed by our compiler and present technical details and benchmark results for it.},
	urldate = {2018-05-30},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Oiwa, Yutaka},
	year = {2009},
	keywords = {memory safety, c language},
	pages = {259--269},
	file = {Oiwa_2009_Implementation of the Memory-safe Full ANSI-C Compiler.pdf:/home/michael/Dropbox/zotero-pdfs/O/Oiwa_2009_Implementation of the Memory-safe Full ANSI-C Compiler.pdf:application/pdf}
}

@inproceedings{kendall_bcc:_1983,
	address = {Berkeley, CA, USA},
	title = {Bcc: runtime checking for {C} programs},
	url = {https://www.doc.ic.ac.uk/~afd/rarepapers/KendallBccRuntimeCheckingsforC.pdf},
	urldate = {2018-05-30},
	publisher = {USENIX Association},
	author = {Kendall, Samuel},
	year = {1983},
	file = {Kendall_1983_Bcc.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kendall_1983_Bcc.pdf:application/pdf}
}

@article{steffen_adding_1992,
	title = {Adding run-time checking to the portable {C} compiler},
	volume = {22},
	copyright = {Copyright © 1992 John Wiley \& Sons, Ltd},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380220403},
	doi = {10.1002/spe.4380220403},
	abstract = {Run-time checking of array subscripts and pointer bounds was added to the Portable C Compiler (PCC). Memory overwrite bugs are then caught as they happen instead of when the overwritten memory is used later in the program execution. The run-time checking compiler is used both to find the true cause of a core dump and to eliminate run-time errors as the cause of unexpected program behavior. On average, it takes about 40 percent longer to compile, the generated code is about three times larger, and it runs about ten times slower. This performance may seem slow, but it typically reduces days of debugging to less than an hour. The implementation described herein can be adapted to any C compiler as it describes how to generate run-time checking code in a machine/compiler independent way by changing the intermediate expression trees. In four years of use it has found latent bugs and the cause of intermittent core dumps in programs used for many years by thousands of people.},
	language = {en},
	number = {4},
	urldate = {2018-05-30},
	journal = {Software: Practice and Experience},
	author = {Steffen, Joseph L.},
	year = {1992},
	keywords = {Error checking, PCC, Range checking},
	pages = {305--316},
	file = {Steffen_1992_Adding run-time checking to the portable C compiler.pdf:/home/michael/Dropbox/zotero-pdfs/S/Steffen_1992_Adding run-time checking to the portable C compiler.pdf:application/pdf}
}

@article{serebryany_addresssanitizer:_2012,
	title = {{AddressSanitizer}: {A} {Fast} {Address} {Sanity} {Checker}},
	abstract = {Memory access bugs, including buffer overﬂows and uses of freed heap memory, remain a serious problem for programming languages like C and C++. Many memory error detectors exist, but most of them are either slow or detect a limited set of bugs, or both.},
	language = {en},
	author = {Serebryany, Konstantin and Bruening, Derek and Potapenko, Alexander and Vyukov, Dmitry},
	year = {2012},
	pages = {10},
	file = {Serebryany et al_2012_AddressSanitizer - A Fast Address Sanity Checker.pdf:/home/michael/Dropbox/zotero-pdfs/S/Serebryany et al_2012_AddressSanitizer - A Fast Address Sanity Checker.pdf:application/pdf}
}

@inproceedings{wadler_well-typed_2009,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Well-{Typed} {Programs} {Can}’t {Be} {Blamed}},
	isbn = {978-3-642-00589-3 978-3-642-00590-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-00590-9_1},
	doi = {10.1007/978-3-642-00590-9_1},
	abstract = {We introduce the blame calculus, which adds the notion of blame from Findler and Felleisen’s contracts to a system similar to Siek and Taha’s gradual types and Flanagan’s hybrid types. We characterise where positive and negative blame can arise by decomposing the usual notion of subtype into positive and negative subtypes, and show that these recombine to yield naive subtypes. Naive subtypes previously appeared in type systems that are unsound, but we believe this is the first time naive subtypes play a role in establishing type soundness.},
	language = {en},
	urldate = {2018-05-30},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Wadler, Philip and Findler, Robert Bruce},
	month = mar,
	year = {2009},
	pages = {1--16},
	file = {Wadler_Findler_2009_Well-Typed Programs Can’t Be Blamed.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wadler_Findler_2009_Well-Typed Programs Can’t Be Blamed.pdf:application/pdf}
}

@article{hickey_formal_1996,
	title = {Formal {Objects} in {Type} {Theory} {Using} {Very} {Dependent} {Types}},
	abstract = {In this paper we present an extension to basic type theory to allow a uniform construction of abstract data types  ADTs  having many of the properties of objects, including abstraction, subtyping, and inheritance. The extension relies on allowing type dependencies for function types to range over a well-founded domain. Using the propositions as types correspondence, abstract data types can be identi ed with logical theories, and proofs of the theories are the objects that inhabit the corresponding ADT.},
	language = {en},
	author = {Hickey, Jason J},
	year = {1996},
	pages = {16},
	file = {Hickey_1996_Formal Objects in Type Theory Using Very Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hickey_1996_Formal Objects in Type Theory Using Very Dependent Types.pdf:application/pdf}
}

@inproceedings{mitchell_javaos:_1996,
	address = {New York, NY, USA},
	series = {{OSDI} '96},
	title = {{JavaOS}: {Back} to the {Future}},
	isbn = {978-1-880446-82-9},
	shorttitle = {{JavaOS}},
	url = {http://doi.acm.org/10.1145/238721.238731},
	doi = {10.1145/238721.238731},
	urldate = {2018-05-30},
	booktitle = {Proceedings of the {Second} {USENIX} {Symposium} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Mitchell, James G.},
	year = {1996},
	pages = {1--}
}

@article{back_java_2003,
	title = {Java {Operating} {Systems}: {Design} and {Implementation}},
	shorttitle = {Java {Operating} {Systems}},
	abstract = {Language-based extensible systems such as Java use type safety to provide memory safety in a single address space. Memory safety alone, however, is not sufficient to protect different applications from each other. Such systems must support a process model that enables the control and management of computational resources. In particular, language-based extensible systems must support resource control mechanisms analogous to those in standard operating systems. They must support the separation of processes and limit their use of resources, but still support safe and efficient interprocess communication.},
	author = {Back, Godmar and Tullmann, Patrick and Stoller, Leigh and Hsieh, Wilson and Lepreau, Jay},
	month = aug,
	year = {2003},
	file = {Back et al_2003_Java Operating Systems.pdf:/home/michael/Dropbox/zotero-pdfs/B/Back et al_2003_Java Operating Systems.pdf:application/pdf}
}

@inproceedings{back_techniques_2000,
	address = {Berkeley, CA, USA},
	series = {{ATEC} '00},
	title = {Techniques for the {Design} of {Java} {Operating} {Systems}},
	url = {http://dl.acm.org/citation.cfm?id=1267724.1267741},
	abstract = {Language-based extensible systems, such as Java Virtual Machines and SPIN, use type safety to provide memory safety in a single address space. By using software to provide safety, they can support more efficient IPC. Memory safety alone, however, is not sufficient to protect different applications from each other. Such systems need to support a process model that enables the control and management of computational resources. In particular, language-based extensible systems should support resource control mechanisms analogous to those in standard operating systems. They need to support the separation of processes and limit their use of resources, but still support safe and efficient IPC. We demonstrate how this challenge is being addressed in several Java-based systems. First, we lay out the design choices when implementing a process model in Java. Second, we compare the solutions that have been explored in several projects: Alta, K0, and the J-Kernel. Alta closely models the Fluke operating system; K0 is similar to a traditional monolithic kernel; and the J-Kernel resembles a microkernel-based system. We compare how these systems support resource control, and explore the tradeoffs between the various designs.},
	urldate = {2018-05-30},
	booktitle = {Proceedings of the {Annual} {Conference} on {USENIX} {Annual} {Technical} {Conference}},
	publisher = {USENIX Association},
	author = {Back, Godmar and Tullmann, Patrick and Stoller, Leigh and Hsieh, Wilson C. and Lepreau, Jay},
	year = {2000},
	pages = {17--17}
}

@inproceedings{detlefs_overview_1995,
	title = {An {Overview} of the {Extended} {Static} {Checking} {System}},
	abstract = {this paper is organized as follows. Section 2 presents some related work. Section 3 describes the organization of the system. Section 4 briefly describes the specification language, including some interesting issues that arise when multiple levels of abstraction are present in the system. Section 5 describes the theorem prover. Section 6 describes some of the uses to which ESC has been put. Finally, section 7 presents conclusions and future directions.},
	booktitle = {In {Proceedings} of the {First} {Workshop} on {Formal} {Methods} in {Software} {Practice}},
	author = {Detlefs, David L.},
	year = {1995},
	pages = {1--9},
	file = {Detlefs_1995_An Overview of the Extended Static Checking System.pdf:/home/michael/Dropbox/zotero-pdfs/D/Detlefs_1995_An Overview of the Extended Static Checking System.pdf:application/pdf}
}

@inproceedings{flanagan_extended_2002,
	address = {New York, NY, USA},
	series = {{PLDI} '02},
	title = {Extended {Static} {Checking} for {Java}},
	isbn = {978-1-58113-463-6},
	url = {http://doi.acm.org/10.1145/512529.512558},
	doi = {10.1145/512529.512558},
	abstract = {Software development and maintenance are costly endeavors. The cost can be reduced if more software defects are detected earlier in the development cycle. This paper introduces the Extended Static Checker for Java (ESC/Java), an experimental compile-time program checker that finds common programming errors. The checker is powered by verification-condition generation and automatic theorem-proving techniques. It provides programmers with a simple annotation language with which programmer design decisions can be expressed formally. ESC/Java examines the annotated software and warns of inconsistencies between the design decisions recorded in the annotations and the actual code, and also warns of potential runtime errors in the code. This paper gives an overview of the checker architecture and annotation language and describes our experience applying the checker to tens of thousands of lines of Java programs.},
	urldate = {2018-05-30},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2002 {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Flanagan, Cormac and Leino, K. Rustan M. and Lillibridge, Mark and Nelson, Greg and Saxe, James B. and Stata, Raymie},
	year = {2002},
	keywords = {compile-time, checking, program},
	pages = {234--245},
	file = {Flanagan et al_2002_Extended Static Checking for Java.pdf:/home/michael/Dropbox/zotero-pdfs/F/Flanagan et al_2002_Extended Static Checking for Java.pdf:application/pdf}
}

@book{detlefs_extended_1998,
	title = {Extended {Static} {Checking}},
	abstract = {The paper describes a mechanical checker for software that catches many common programming errors, in particular array index bounds errors, nil dereference errors, and synchronization errors in multi-threaded programs. The checking is performed at compile-time. The checker uses an automatic theorem-prover to reason about the semantics of conditional statements, loops, procedure and method calls, and exceptions. The checker has been implemented for Modula-3. It has been applied to thousands of lines of code, including mature systems code as well as fresh untested code, and it has found a number of errors.},
	author = {Detlefs, David L. and Leino, K. Rustan M. and Nelson, Greg and Saxe, James B.},
	year = {1998},
	file = {Detlefs et al_1998_Extended Static Checking.pdf:/home/michael/Dropbox/zotero-pdfs/D/Detlefs et al_1998_Extended Static Checking.pdf:application/pdf}
}

@book{dijkstra_discipline_1976,
	title = {A discipline of programming},
	volume = {1},
	publisher = {prentice-hall Englewood Cliffs},
	author = {Dijkstra, Edsger Wybe and Dijkstra, Edsger Wybe and Dijkstra, Edsger Wybe and Informaticien, Etats-Unis and Dijkstra, Edsger Wybe},
	year = {1976}
}

@article{oconnor_cogent:_2016,
	title = {{COGENT}: {Certified} {Compilation} for a {Functional} {Systems} {Language}},
	shorttitle = {{COGENT}},
	url = {http://arxiv.org/abs/1601.05520},
	abstract = {We present a self-certifying compiler for the COGENT systems language. COGENT is a restricted, polymorphic, higher-order, and purely functional language with linear types and without the need for a trusted runtime or garbage collector. It compiles to efficient C code that is designed to interoperate with existing C functions. The language is suited for layered systems code with minimal sharing such as file systems or network protocol control code. For a well-typed COGENT program, the compiler produces C code, a high-level shallow embedding of its semantics in Isabelle/HOL, and a proof that the C code correctly implements this embedding. The aim is for proof engineers to reason about the full semantics of real-world systems code productively and equationally, while retaining the interoperability and leanness of C. We describe the formal verification stages of the compiler, which include automated formal refinement calculi, a switch from imperative update semantics to functional value semantics formally justified by the linear type system, and a number of standard compiler phases such as type checking and monomorphisation. The compiler certificate is a series of language-level meta proofs and per-program translation validation phases, combined into one coherent top-level theorem in Isabelle/HOL.},
	urldate = {2018-05-31},
	journal = {arXiv:1601.05520 [cs]},
	author = {O'Connor, Liam and Rizkallah, Christine and Chen, Zilin and Amani, Sidney and Lim, Japheth and Nagashima, Yutaka and Sewell, Thomas and Hixon, Alex and Keller, Gabriele and Murray, Toby and Klein, Gerwin},
	month = jan,
	year = {2016},
	note = {arXiv: 1601.05520},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	file = {O'Connor et al_2016_COGENT.pdf:/home/michael/Dropbox/zotero-pdfs/O/O'Connor et al_2016_COGENT.pdf:application/pdf}
}

@inproceedings{pike_programming_2014,
	title = {Programming languages for high-assurance autonomous vehicles: extended abstract},
	isbn = {978-1-4503-2567-7},
	shorttitle = {Programming languages for high-assurance autonomous vehicles},
	url = {http://dl.acm.org/citation.cfm?doid=2541568.2541570},
	doi = {10.1145/2541568.2541570},
	abstract = {We brieﬂy describe the use of embedded domain-speciﬁc languages to improve programmer productivity and increase software assurance in the context of building a fully-featured autopilot for unpiloted aircraft.},
	language = {en},
	urldate = {2018-05-31},
	publisher = {ACM Press},
	author = {Pike, Lee and Hickey, Patrick and Bielman, James and Elliott, Trevor and DuBuisson, Thomas and Launchbury, John},
	year = {2014},
	pages = {1--2},
	file = {Pike et al_2014_Programming languages for high-assurance autonomous vehicles.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pike et al_2014_Programming languages for high-assurance autonomous vehicles.pdf:application/pdf}
}

@techreport{noauthor_habit_2010,
	address = {Portland, Oregon},
	title = {The {Habit} {Programming} {Language}: {The} {Revisted} {Preliminary} {Report}},
	url = {http://hasp.cs.pdx.edu/habit-report-Nov2010.pdf},
	urldate = {2018-05-31},
	institution = {Portland State University},
	month = nov,
	year = {2010},
	pages = {95},
	file = {2010_The Habit Programming Language.pdf:/home/michael/Dropbox/zotero-pdfs/_/2010_The Habit Programming Language.pdf:application/pdf}
}

@misc{noauthor_home_nodate,
	title = {Home - {D} {Programming} {Language}},
	url = {https://dlang.org/},
	abstract = {D is a general-purpose programming language with static typing, systems-level access, and C-like syntax.},
	language = {en-US},
	urldate = {2018-05-31}
}

@book{moon_lisp_1983,
	title = {Lisp machine manual},
	publisher = {MIT Artificial Intelligence Laboratory,},
	author = {Moon, David and Stallman, Richard and Weinreb, Daniel},
	year = {1983}
}

@inproceedings{diatchki_strongly_2006,
	address = {New York, NY, USA},
	series = {Haskell '06},
	title = {Strongly {Typed} {Memory} {Areas} {Programming} {Systems}-level {Data} {Structures} in a {Functional} {Language}},
	isbn = {978-1-59593-489-5},
	url = {http://doi.acm.org/10.1145/1159842.1159851},
	doi = {10.1145/1159842.1159851},
	abstract = {Modern functional languages offer several attractive features to support development of reliable and secure software. However, in our efforts to use Haskell for systems programming tasks-including device driver and operating system construction-we have also encountered some significant gaps in functionality. As a result, we have been forced, either to code some non-trivial components in more traditional but unsafe languages like C or assembler, or else to adopt aspects of the foreign function interface that compromise on strong typing and type safety.In this paper, we describe how we have filled one of these gaps by extending a Haskell-like language with facilities for working directly with low-level, memory-based data structures. Using this extension, we are able to program a wide range of examples, including hardware interfaces, kernel data structures, and operating system APIs. Our design allows us to address concerns about representation, alignment, and placement (in virtual or physical address spaces) that are critical in some systems applications, but clearly beyond the scope of most existing functional languages.Our approach leverages type system features that are wellknown and widely supported in existing Haskell implementations, including kinds, multiple parameter type classes, functional dependencies, and improvement. One interesting feature is the use of a syntactic abbreviation that makes it easy to define and work with functions at the type level.},
	urldate = {2018-05-31},
	booktitle = {Proceedings of the 2006 {ACM} {SIGPLAN} {Workshop} on {Haskell}},
	publisher = {ACM},
	author = {Diatchki, Iavor S. and Jones, Mark P.},
	year = {2006},
	keywords = {data representation, systems programming, improvement, memory areas, memory manipulation, qualified types},
	pages = {72--83},
	file = {Diatchki_Jones_2006_Strongly Typed Memory Areas Programming Systems-level Data Structures in a.pdf:/home/michael/Dropbox/zotero-pdfs/D/Diatchki_Jones_2006_Strongly Typed Memory Areas Programming Systems-level Data Structures in a.pdf:application/pdf}
}

@inproceedings{yorgey_giving_2012,
	title = {Giving {Haskell} a promotion},
	isbn = {978-1-4503-1120-5},
	url = {http://dl.acm.org/citation.cfm?doid=2103786.2103795},
	doi = {10.1145/2103786.2103795},
	abstract = {Static type systems strive to be richly expressive while still being simple enough for programmers to use. We describe an experiment that enriches Haskell’s kind system with two features promoted from its type system: data types and polymorphism. The new system has a very good power-to-weight ratio: it offers a signiﬁcant improvement in expressiveness, but, by re-using concepts that programmers are already familiar with, the system is easy to understand and implement.},
	language = {en},
	urldate = {2018-05-31},
	publisher = {ACM Press},
	author = {Yorgey, Brent A. and Weirich, Stephanie and Cretin, Julien and Peyton Jones, Simon and Vytiniotis, Dimitrios and Magalhães, José Pedro},
	year = {2012},
	pages = {53},
	file = {Yorgey et al. - 2012 - Giving Haskell a promotion.pdf:/home/michael/Zotero/storage/HQ7NVIRA/Yorgey et al. - 2012 - Giving Haskell a promotion.pdf:application/pdf}
}

@article{geschke_early_1977,
	title = {Early {Experience} with {Mesa}},
	volume = {20},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359763.359771},
	doi = {10.1145/359763.359771},
	abstract = {The experiences of Mesa's first users—primarily its implementers—are discussed, and some implications for Mesa and similar programming languages are suggested. The specific topics addressed are: module structure and its use in defining abstractions, data-structuring facilities in Mesa, an equivalence algorithm for types and type coercions, the benefits of the type system and why it is breached occasionally, and the difficulty of making the treatment of variant records safe.},
	number = {8},
	urldate = {2018-06-01},
	journal = {Commun. ACM},
	author = {Geschke, Charles M. and Morris, Jr., James H. and Satterthwaite, Edwin H.},
	month = aug,
	year = {1977},
	keywords = {programming languages, systems programming, types, modules, data structures},
	pages = {540--553},
	file = {Geschke et al_1977_Early Experience with Mesa.pdf:/home/michael/Dropbox/zotero-pdfs/G/Geschke et al_1977_Early Experience with Mesa.pdf:application/pdf}
}

@article{redell_pilot:_1980,
	title = {Pilot: {An} {Operating} {System} for a {Personal} {Computer}},
	volume = {23},
	abstract = {The Pilot operating system provides a single-user, single-language environment for higher level software on a powerful personal computer. Its features include virtual memory, a large “flat” file system, streams, network communication facilities, and concurrent programming support. Pilot thus provides rather more powerful facilities than are normally associated with personal computers. The exact facilities provided display interesting similarities to and differences from corresponding facilities provided in large multi-user systems. Pilot is implemented entirely in Mesa, a highlevel system programming language. The modularization of the implementation displays some interesting aspects in terms of both the static structure and dynamic interactions of the various components.},
	language = {en},
	number = {2},
	author = {Redell, David D and Dalal, Yogen K and Horsley, Thomas R and Lauer, Hugh C and Lynch, William C and McJones, Paul R and Murray, Hal G and Purcell, Stephen C},
	year = {1980},
	pages = {12},
	file = {Redell et al_1980_Pilot.pdf:/home/michael/Dropbox/zotero-pdfs/R/Redell et al_1980_Pilot.pdf:application/pdf}
}

@article{hanson_fast_1990,
	title = {Fast {Allocation} and {Deallocation} of {Memory} {Based} on {Object} {Lifetimes}},
	volume = {20},
	issn = {0038-0644},
	url = {http://dx.doi.org/10.1002/spe.4380200104},
	doi = {10.1002/spe.4380200104},
	number = {1},
	urldate = {2018-06-02},
	journal = {Softw. Pract. Exper.},
	author = {Hanson, D. R.},
	month = jan,
	year = {1990},
	pages = {5--12},
	file = {Hanson_1990_Fast Allocation and Deallocation of Memory Based on Object Lifetimes.pdf:/home/michael/Dropbox/zotero-pdfs/H/Hanson_1990_Fast Allocation and Deallocation of Memory Based on Object Lifetimes.pdf:application/pdf}
}

@book{meyer_eiffel:_1992,
	address = {Upper Saddle River, NJ, USA},
	title = {Eiffel: {The} {Language}},
	isbn = {978-0-13-247925-7},
	shorttitle = {Eiffel},
	publisher = {Prentice-Hall, Inc.},
	author = {Meyer, Bertrand},
	year = {1992}
}

@book{meyer_object-oriented_1997,
	address = {Upper Saddle River, NJ, USA},
	title = {Object-oriented {Software} {Construction} (2nd {Ed}.)},
	isbn = {978-0-13-629155-8},
	publisher = {Prentice-Hall, Inc.},
	author = {Meyer, Bertrand},
	year = {1997}
}

@book{jones_qualified_1994,
	address = {Cambridge},
	title = {Qualified {Types}: {Theory} and {Practice}},
	isbn = {978-0-511-66308-6},
	shorttitle = {Qualified {Types}},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511663086},
	abstract = {This thesis describes ({\textbackslash} type system that combines ML-style polymorphism with a general approach to overloading. The central idea is to use qualified types that include predicates and restrict the set of types at which an object can be used to particular instances of a polymorphic type. Different applications of qualified types can be obtained by changing the underlying system of predicates. We illustrate this with examples including type classes, explicit subtyping and extensible records.},
	language = {en},
	urldate = {2018-06-02},
	publisher = {Cambridge University Press},
	author = {Jones, Mark P.},
	year = {1994},
	doi = {10.1017/CBO9780511663086},
	file = {Jones_1994_Qualified Types.pdf:/home/michael/Dropbox/zotero-pdfs/J/Jones_1994_Qualified Types.pdf:application/pdf}
}

@inproceedings{ruwase_practical_2004,
	title = {A {Practical} {Dynamic} {Buffer} {Overflow} {Detector}},
	abstract = {Despite previous efforts in auditing software manually and automatically, buffer overruns are still being discovered in programs in use. A dynamic bounds checker detects buffer overruns in erroneous software before it occurs and thereby prevents attacks from corrupting the integrity of the system. Dynamic buffer},
	booktitle = {In {Proceedings} of the 11th {Annual} {Network} and {Distributed} {System} {Security} {Symposium}},
	author = {Ruwase, Olatunji and Lam, Monica S.},
	year = {2004},
	pages = {159--169},
	file = {Ruwase_Lam_2004_A Practical Dynamic Buffer Overflow Detector.pdf:/home/michael/Dropbox/zotero-pdfs/R/Ruwase_Lam_2004_A Practical Dynamic Buffer Overflow Detector.pdf:application/pdf}
}

@inproceedings{arora_architectural_2006,
	title = {Architectural support for safe software execution on embedded processors},
	isbn = {978-1-59593-370-6},
	url = {http://portal.acm.org/citation.cfm?doid=1176254.1176281},
	doi = {10.1145/1176254.1176281},
	abstract = {The lack of memory safety in many popular programming languages, including C and C++, has been a cause for great concern in the realm of software reliability, veriﬁcation, and more recently, system security. Despite their limitations, the ﬂexibility, performance, and ease of use of these languages have made them the choice of most embedded software developers. Researchers have proposed various techniques to enhance programs for memory safety; however, they are all subject to severe performance penalties, making their use impractical in most scenarios. In this paper, we present architectural enhancements to enable eﬃcient, memory-safe execution of software on embedded processors. The key insight behind our approach is to extend embedded processors with hardware that signiﬁcantly accelerates the execution of the additional computations involved in memory-safe execution. Speciﬁcally, we design custom instructions to perform various kinds of memory-safety checks and augment the instruction set of a state-of-the-art extensible processor (Xtensa from Tensilica, Inc.) to implement them. We demonstrate the application of the proposed architectural enhancements using CCured, an existing tool for type-safe retroﬁtting of C programs. The tool uses a type-inferencing engine that is built around strong type-safety theory and is provably safe. Simulations of memory-safe versions of popular embedded benchmarks on a cycle-accurate simulator modeling a typical embedded system conﬁguration indicate an average performance improvement of 2.3×, and a maximum of 4.6×, when using the proposed architecture. These enhancements entail minimal (less than 10\%) hardware overhead to the base processor. Our approach is completely automated, and applicable to any C program, making it a promising and practical approach for addressing the growing security and reliability concerns in embedded software.},
	language = {en},
	urldate = {2018-06-02},
	publisher = {ACM Press},
	author = {Arora, Divya and Raghunathan, Anand and Ravi, Srivaths and Jha, Niraj K.},
	year = {2006},
	pages = {106},
	file = {Arora et al_2006_Architectural support for safe software execution on embedded processors.pdf:/home/michael/Dropbox/zotero-pdfs/A/Arora et al_2006_Architectural support for safe software execution on embedded processors.pdf:application/pdf}
}

@inproceedings{wagner_first_2000,
	title = {A {First} {Step} {Towards} {Automated} {Detection} of {Buffer} {Overrun} {Vulnerabilities}},
	abstract = {We describe a new technique for finding potential buffer overrun vulnerabilities in security-critical C code. The key to success is to use static analysis: we formulate detection of buffer overruns as an integer range analysis problem. One major advantage of static analysis is that security bugs can be eliminated before code is deployed. We have implemented our design and used our prototype to find new remotely-exploitable vulnerabilities in a large, widely deployed software package. An earlier hand audit missed these bugs.  1. Introduction  Buffer overrun vulnerabilities have plagued security architects for at least a decade. In November 1988, the infamous Internet worm infected thousands or tens of thousands of network-connected hosts and fragmented much of the known net [17]. One of the primary replication mechanisms was exploitation of a buffer overrun vulnerability in the fingerd daemon.  Since then, buffer overruns have been a serious, continuing menace to system security. If any...},
	booktitle = {In {Network} and {Distributed} {System} {Security} {Symposium}},
	author = {Wagner, David and Foster, Jeffrey S. and Brewer, Eric A. and Aiken, Alexander},
	year = {2000},
	pages = {3--17},
	file = {Wagner et al_2000_A First Step Towards Automated Detection of Buffer Overrun Vulnerabilities.pdf:/home/michael/Dropbox/zotero-pdfs/W/Wagner et al_2000_A First Step Towards Automated Detection of Buffer Overrun Vulnerabilities.pdf:application/pdf}
}

@inproceedings{larochelle_statically_2001,
	address = {Berkeley, CA, USA},
	series = {{SSYM}'01},
	title = {Statically {Detecting} {Likely} {Buffer} {Overflow} {Vulnerabilities}},
	url = {http://dl.acm.org/citation.cfm?id=1251327.1251341},
	abstract = {The abstract has been removed at the request of one of the authors.},
	urldate = {2018-06-03},
	booktitle = {Proceedings of the 10th {Conference} on {USENIX} {Security} {Symposium} - {Volume} 10},
	publisher = {USENIX Association},
	author = {Larochelle, David and Evans, David},
	year = {2001},
	file = {Larochelle_Evans_2001_Statically Detecting Likely Buffer Overflow Vulnerabilities.pdf:/home/michael/Dropbox/zotero-pdfs/L/Larochelle_Evans_2001_Statically Detecting Likely Buffer Overflow Vulnerabilities.pdf:application/pdf}
}

@article{dor_cssv:_2003,
	title = {{CSSV}: {Towards} a {Realistic} {Tool} for {Statically} {Detecting} {All} {Buffer} {Overﬂows} in {C}},
	abstract = {Erroneous string manipulations are a major source of software defects in C programs yielding vulnerabilities which are exploited by software viruses. We present C String Static Verifyer (CSSV), a tool that statically uncovers all string manipulation errors. Being a conservative tool, it reports all such errors at the expense of sometimes generating false alarms. Fortunately, only a small number of false alarms are reported, thereby proving that statically reducing software vulnerability is achievable. CSSV handles large programs by analyzing each procedure separately. To this end procedure contracts are allowed which are veriﬁed by the tool.},
	language = {en},
	author = {Dor, Nurit and Rodeh, Michael and Sagiv, Mooly},
	year = {2003},
	pages = {13},
	file = {Dor et al_2003_CSSV.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dor et al_2003_CSSV.pdf:application/pdf}
}

@inproceedings{ganapathy_buffer_2003,
	address = {New York, NY, USA},
	series = {{CCS} '03},
	title = {Buffer {Overrun} {Detection} {Using} {Linear} {Programming} and {Static} {Analysis}},
	isbn = {978-1-58113-738-5},
	url = {http://doi.acm.org/10.1145/948109.948155},
	doi = {10.1145/948109.948155},
	abstract = {This paper addresses the issue of identifying buffer overrun vulnerabilities by statically analyzing C source code. We demonstrate a light-weight analysis based on modeling C string manipulations as a linear program. We also present fast, scalable solvers based on linear programming, and demonstrate techniques to make the program analysis context sensitive. Based on these techniques, we built a prototype and used it to identify several vulnerabilities in popular security critical applications.},
	urldate = {2018-06-03},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Ganapathy, Vinod and Jha, Somesh and Chandler, David and Melski, David and Vitek, David},
	year = {2003},
	keywords = {static analysis, buffer overruns, linear programming},
	pages = {345--354},
	file = {Ganapathy et al_2003_Buffer Overrun Detection Using Linear Programming and Static Analysis.pdf:/home/michael/Dropbox/zotero-pdfs/G/Ganapathy et al_2003_Buffer Overrun Detection Using Linear Programming and Static Analysis.pdf:application/pdf}
}

@inproceedings{xie_archer:_2003,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE}-11},
	title = {{ARCHER}: {Using} {Symbolic}, {Path}-sensitive {Analysis} to {Detect} {Memory} {Access} {Errors}},
	isbn = {978-1-58113-743-9},
	shorttitle = {{ARCHER}},
	url = {http://doi.acm.org/10.1145/940071.940115},
	doi = {10.1145/940071.940115},
	abstract = {Memory corruption errors lead to non-deterministic, elusive crashes. This paper describes ARCHER (ARray CHeckER) a static, effective memory access checker. ARCHER uses path-sensitive, interprocedural symbolic analysis to bound the values of both variables and memory sizes. It evaluates known values using a constraint solver at every array access, pointer dereference, or call to a function that expects a size parameter. Accesses that violate constraints are flagged as errors. Those that are exploitable by malicious attackers are marked as security holes.Memory corruption errors lead to non-deterministic, elusive crashes. This paper describes ARCHER (ARray CHeckER) a static, effective memory access checker. ARCHER uses path-sensitive, interprocedural symbolic analysis to bound the values of both variables and memory sizes. It evaluates known values using a constraint solver at every array access, pointer dereference, or call to a function that expects a size parameter. Accesses that violate constraints are flagged as errors. Those that are exploitable by malicious attackers are marked as security holes.We carefully designed ARCHER to work well on large bodies of source code. It requires no annotations to use (though it can use them). Its solver has been built to be powerful in the ways that real code requires, while backing off on the places that were irrelevant. Selective power allows it to gain efficiency while avoiding classes of false positives that arise when a complex analysis interacts badly with statically undecidable program properties. ARCHER uses statistical code analysis to automatically infer the set of functions that it should track --- this inference serves as a robust guard against omissions, especially in large systems which can have hundreds of such functions.In practice ARCHER is effective: it finds many errors; its analysis scales to systems of millions of lines of code and the average false positive rate of our results is below 35\%. We have run ARCHER over several large open source software projects --- such as Linux, OpenBSD, Sendmail, and PostgreSQL --- and have found errors in all of them (118 in the case of Linux, including 21 security holes).},
	urldate = {2018-06-03},
	booktitle = {Proceedings of the 9th {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 11th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Xie, Yichen and Chou, Andy and Engler, Dawson},
	year = {2003},
	keywords = {security, static analysis, buffer overflow, buffer overrun, error detection, memory access errors},
	pages = {327--336},
	file = {Xie et al_2003_ARCHER.pdf:/home/michael/Dropbox/zotero-pdfs/X/Xie et al_2003_ARCHER.pdf:application/pdf}
}

@inproceedings{kroes_delta_2018,
	address = {New York, NY, USA},
	series = {{EuroSys} '18},
	title = {Delta {Pointers}: {Buffer} {Overflow} {Checks} {Without} the {Checks}},
	isbn = {978-1-4503-5584-1},
	shorttitle = {Delta {Pointers}},
	url = {http://doi.acm.org/10.1145/3190508.3190553},
	doi = {10.1145/3190508.3190553},
	abstract = {Despite decades of research, buffer overflows still rank among the most dangerous vulnerabilities in unsafe languages such as C and C++. Compared to other memory corruption vulnerabilities, buffer overflows are both common and typically easy to exploit. Yet, they have proven so challenging to detect in real-world programs that existing solutions either yield very poor performance, or introduce incompatibilities with the C/C++ language standard. We present Delta Pointers, a new solution for buffer overflow detection based on efficient pointer tagging. By carefully altering the pointer representation, without violating language specifications, Delta Pointers use existing hardware features to detect both contiguous and non-contiguous overflows on dereferences, without a single check incurring extra branch or memory access operations. By focusing on buffer overflows rather than other vulnerabilities (e.g., underflows), Delta Pointers offer a unique checkless design to provide high performance while still maintaining compatibility. We show that Delta Pointers are effective in detecting arbitrary buffer overflows and, at 35\% overhead on SPEC, offer much better performance than competing solutions.},
	urldate = {2018-06-03},
	booktitle = {Proceedings of the {Thirteenth} {EuroSys} {Conference}},
	publisher = {ACM},
	author = {Kroes, Taddeus and Koning, Koen and van der Kouwe, Erik and Bos, Herbert and Giuffrida, Cristiano},
	year = {2018},
	keywords = {memory safety, bounds checking, LLVM, pointer tagging},
	pages = {22:1--22:14},
	file = {Kroes et al_2018_Delta Pointers.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kroes et al_2018_Delta Pointers.pdf:application/pdf}
}

@inproceedings{dhurjati_efficiently_2006,
	title = {Efficiently {Detecting} {All} {Dangling} {Pointer} {Uses} in {Production} {Servers}},
	doi = {10.1109/DSN.2006.31},
	abstract = {In this paper, we propose a novel technique to detect all dangling pointer uses at run-time that is efficient enough for production use in server codes. One idea (previously used by electric fence, PageHeap) is to use a new virtual page for each allocation of the program and rely on page protection mechanisms to check dangling pointer accesses. This naive approach has two limitations that make it impractical to use in production software: increased physical memory usage and increased address space usage. We propose two key improvements that alleviate both these problems. First, we use a new virtual page for each allocation of the program but map it to the same physical page as the original allocator. This allows using nearly identical physical memory as the original program while still retaining the dangling pointer detection capability. We also show how to implement this idea without requiring any changes to the underlying memory allocator. Our second idea alleviates the problem of virtual address space exhaustion by using a previously developed compiler transformation called automatic pool allocation to reuse many virtual pages. The transformation partitions the memory of the program based on their lifetimes and allows us to reuse virtual pages when portions of memory become inaccessible. Experimentally we find that the run-time overhead for five Unix servers is less than 4\%, for other Unix utilities less than 15\%. However, in case of allocation intensive benchmarks, we find our overheads are much worse (up to 11x slowdown)},
	booktitle = {International {Conference} on {Dependable} {Systems} and {Networks} ({DSN}'06)},
	author = {Dhurjati, D. and Adve, V.},
	month = jun,
	year = {2006},
	keywords = {Protection, Runtime, memory allocation, automatic pool allocation, storage allocation, Production, Embedded system, Buffer overflow, compiler transformation, Debugging, Electric fences, Embedded software, Engineering profession, page protection mechanism, paged storage, physical memory usage, pointer detection, production server, Software performance, software reusability, virtual address space exhaustion, virtual page},
	pages = {269--280},
	file = {Dhurjati_Adve_2006_Efficiently Detecting All Dangling Pointer Uses in Production Servers.pdf:/home/michael/Dropbox/zotero-pdfs/D/Dhurjati_Adve_2006_Efficiently Detecting All Dangling Pointer Uses in Production Servers.pdf:application/pdf}
}

@article{kowshik_safecode:_2006,
	title = {{SAFECode}: {Enforcing} {Alias} {Analysis} for {Weakly} {Typed} {Languages} ∗},
	abstract = {Static analysis of programs in weakly typed languages such as C and C++ is generally not sound because of possible memory errors due to dangling pointer references, uninitialized pointers, and array bounds overﬂow. We describe a compilation strategy for standard C programs that guarantees that aggressive interprocedural pointer analysis (or less precise ones), a call graph, and type information for a subset of memory, are never invalidated by any possible memory errors. We formalize our approach as a new type system with the necessary run-time checks in operational semantics and prove the correctness of our approach for a subset of C. Our semantics provide the foundation for other sophisticated static analyses to be applied to C programs with a guarantee of soundness. Our work builds on a previously published transformation called Automatic Pool Allocation to ensure that hard-to-detect memory errors (dangling pointer references and certain array bounds errors) cannot invalidate the call graph, points-to information or type information. The key insight behind our approach is that pool allocation can be used to create a run-time partitioning of memory that matches the compile-time memory partitioning in a points-to graph, and efﬁcient checks can be used to isolate the run-time partitions. Furthermore, we show that the sound analysis information enables static checking techniques that eliminate many run-time checks. Our approach requires no source code changes, allows memory to be managed explicitly, and does not use meta-data on pointers or individual tag bits for memory. Using several benchmarks and system codes, we show experimentally that the run-time overheads are low (less than 10\% in nearly all cases and 30\% in the worst case we have seen). We also show the effectiveness of static analyses in eliminating run-time checks.},
	language = {en},
	author = {Kowshik, Dinakar Dhurjati Sumant and Adve, Vikram},
	year = {2006},
	pages = {14},
	file = {Kowshik_Adve_2006_SAFECode.pdf:/home/michael/Dropbox/zotero-pdfs/K/Kowshik_Adve_2006_SAFECode.pdf:application/pdf}
}

@article{nagarakatte_everything_2015,
	title = {Everything {You} {Want} to {Know} {About} {Pointer}-{Based} {Checking}},
	doi = {10.4230/lipics.snapl.2015.190},
	abstract = {Lack of memory safety in C/C++ has resulted in numerous security vulnerabilities and serious bugs in large software systems. This paper highlights the challenges in enforcing memory safety for C/C++ programs and progress made as part of the SoftBoundCETS project. We have been exploring memory safety enforcement at various levels – in hardware, in the compiler, and as a hardware-compiler hybrid – in this project. Our research has identiﬁed that maintaining metadata with pointers in a disjoint metadata space and performing bounds and use-after-free checking can provide comprehensive memory safety. We describe the rationale behind the design decisions and its ramiﬁcations on various dimensions, our experience with the various variants that we explored in this project, and the lessons learned in the process. We also describe and analyze the forthcoming Intel Memory Protection Extensions (MPX) that provides hardware acceleration for disjoint metadata and pointer checking in mainstream hardware, which is expected to be available later this year.},
	language = {en},
	author = {Nagarakatte, Santosh and Martin, Milo M. K. and Zdancewic, Steve},
	editor = {Herbstritt, Marc},
	year = {2015},
	file = {Nagarakatte et al_2015_Everything You Want to Know About Pointer-Based Checking.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nagarakatte et al_2015_Everything You Want to Know About Pointer-Based Checking.pdf:application/pdf}
}

@inproceedings{akritidis_baggy_2009,
	address = {Berkeley, CA, USA},
	series = {{SSYM}'09},
	title = {Baggy {Bounds} {Checking}: {An} {Efficient} and {Backwards}-compatible {Defense} {Against} {Out}-of-bounds {Errors}},
	shorttitle = {Baggy {Bounds} {Checking}},
	url = {http://dl.acm.org/citation.cfm?id=1855768.1855772},
	abstract = {Attacks that exploit out-of-bounds errors in C and C++ programs are still prevalent despite many years of research on bounds checking. Previous backwards compatible bounds checking techniques, which can be applied to unmodified C and C++ programs, maintain a data structure with the bounds for each allocated object and perform lookups in this data structure to check if pointers remain within bounds. This data structure can grow large and the lookups are expensive. In this paper we present a backwards compatible bounds checking technique that substantially reduces performance overhead. The key insight is to constrain the sizes of allocated memory regions and their alignment to enable efficient bounds lookups and hence efficient bounds checks at runtime. Our technique has low overhead in practice--only 8\% throughput decrease for Apache-- and is more than two times faster than the fastest previous technique and about five times faster--using less memory--than recording object bounds using a splay tree.},
	urldate = {2018-06-03},
	booktitle = {Proceedings of the 18th {Conference} on {USENIX} {Security} {Symposium}},
	publisher = {USENIX Association},
	author = {Akritidis, Periklis and Costa, Manuel and Castro, Miguel and Hand, Steven},
	year = {2009},
	pages = {51--66},
	file = {Akritidis et al_2009_Baggy Bounds Checking.pdf:/home/michael/Dropbox/zotero-pdfs/A/Akritidis et al_2009_Baggy Bounds Checking.pdf:application/pdf}
}

@article{cowan_stackguard:_1998,
	title = {{StackGuard}: {Automatic} {Adaptive} {Detection} and {Prevention} of {Buffer}-{Overflow} {Attacks}},
	language = {en},
	author = {Cowan, Crispan and Pu, Calton and Maier, Dave and Walpole, Jonathan and Bakke, Peat},
	year = {1998},
	pages = {16},
	file = {Cowan et al. - StackGuard Automatic Adaptive Detection and Preve.pdf:/home/michael/Zotero/storage/8GPBGQ4W/Cowan et al. - StackGuard Automatic Adaptive Detection and Preve.pdf:application/pdf}
}

@inproceedings{brunink_boundless_2011,
	title = {Boundless memory allocations for memory safety and high availability},
	doi = {10.1109/DSN.2011.5958203},
	abstract = {Spatial memory errors (like buffer overflows) are still a major threat for applications written in C. Most recent work focuses on memory safety - when a memory error is detected at runtime, the application is aborted. Our goal is not only to increase the memory safety of applications but also to increase the application's availability. Therefore, we need to tolerate spatial memory errors at runtime. We have implemented a compiler extension, Boundless, that automatically adds the tolerance feature to C applications at compile time. We show that this can increase the availability of applications. Our measurements also indicate that Boundless has a lower performance overhead than SoftBound, a state-of-the-art approach to detect spatial memory errors. Our performance gains result from a novel way to represent pointers. Nevertheless, Boundless is compatible with existing C code. Additionally, Boundless provides a trade-off to reduce the runtime overhead even further: We introduce vulnerability specific patching for spatial memory errors to tolerate only known vulnerabilities. Vulnerability specific patching has an even lower runtime overhead than full tolerance.},
	booktitle = {2011 {IEEE}/{IFIP} 41st {International} {Conference} on {Dependable} {Systems} {Networks} ({DSN})},
	author = {Brünink, M. and Süßkraut, M. and Fetzer, C.},
	month = jun,
	year = {2011},
	keywords = {security of data, Runtime, C language, program compilers, Arrays, Availability, Safety, Fault tolerance, storage allocation, boundless memory allocations, Bounds checking, C applications, compiler extension, Compiler transformation, Instruments, Random access memory, Resource management, Software safety, spatial memory errors, vulnerability specific patching},
	pages = {13--24},
	file = {Brunink et al_2011_Boundless memory allocations for memory safety and high availability.pdf:/home/michael/Dropbox/zotero-pdfs/B/Brunink et al_2011_Boundless memory allocations for memory safety and high availability.pdf:application/pdf}
}

@article{simpson_memsafe:_2013,
	title = {{MemSafe}: ensuring the spatial and temporal memory safety of {C} at runtime},
	volume = {43},
	issn = {1097-024X},
	shorttitle = {{MemSafe}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2105},
	doi = {10.1002/spe.2105},
	abstract = {Memory access violations are a leading source of unreliability in C programs. As evidence of this problem, a variety of methods exist that retrofit C with software checks to detect memory errors at runtime. However, these methods generally suffer from one or more drawbacks including the inability to detect all errors, the use of incompatible metadata, the need for manual code modifications, and high runtime overheads. This paper presents a compiler analysis and transformation for ensuring the memory safety of C called MemSafe. MemSafe makes several novel contributions that improve upon previous work and lower the cost of safety. These include (i) a method for modeling temporal errors as spatial errors, (ii) a metadata representation that combines features of both object-based and pointer-based approaches, and (iii) a dataflow representation that simplifies optimizations for removing unneeded checks. MemSafe is capable of detecting real errors with lower overheads than previous efforts. Experimental results show that MemSafe detects all memory errors in six programs with known violations as well as two large and widely used open source applications. Finally, MemSafe ensures complete safety with an average overhead of 88\% on 30 programs commonly used for evaluating the performance of error detection tools. Copyright © 2012 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2018-06-03},
	journal = {Software: Practice and Experience},
	author = {Simpson, Matthew S. and Barua, Rajeev K.},
	year = {2013},
	keywords = {memory safety, programming languages, verification, reliability},
	pages = {93--128},
	file = {Simpson_Barua_2013_MemSafe.pdf:/home/michael/Dropbox/zotero-pdfs/S/Simpson_Barua_2013_MemSafe.pdf:application/pdf}
}

@article{wadler_propositions_2015,
	title = {Propositions as types},
	volume = {58},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2847579.2699407},
	doi = {10.1145/2699407},
	language = {en},
	number = {12},
	urldate = {2018-06-07},
	journal = {Communications of the ACM},
	author = {Wadler, Philip},
	month = nov,
	year = {2015},
	pages = {75--84},
	file = {Wadler - 2015 - Propositions as types.pdf:/home/michael/Zotero/storage/6C29G2BB/Wadler - 2015 - Propositions as types.pdf:application/pdf}
}

@article{pincus_beyond_2004,
	title = {Beyond stack smashing: recent advances in exploiting buffer overruns},
	volume = {2},
	issn = {1540-7993},
	shorttitle = {Beyond stack smashing},
	doi = {10.1109/MSP.2004.36},
	abstract = {Security vulnerabilities related to buffer overruns account for the largest share of CERT advisories, as well as high-profile worms - from the original Internet Worm in 1987 through Blaster's appearance in 2003. When malicious crackers discover a vulnerability, they devise exploits that take advantage of the vulnerability to attack a system. The article describes three powerful general-purpose families of exploits for buffer overruns: arc injection, pointer subterfuge, and heap smashing. These new techniques go beyond the traditional "stack smashing" attack and invalidate traditional assumptions about buffer overruns.},
	number = {4},
	journal = {IEEE Security Privacy},
	author = {Pincus, J. and Baker, B.},
	month = jul,
	year = {2004},
	keywords = {Privacy, Java, computer crime, storage management, buffer overruns, 65, arc injection, attacking systems, CERT advisories, Computer hacking, Computer security, Computer worms, exploits, heap smashing, high-profile worms, Lab-on-a-chip, malicious crackers, Payloads, pointer subterfuge, Power system security, Runtime environment, security vulnerabilities, stack smashing},
	pages = {20--27},
	file = {Pincus_Baker_2004_Beyond stack smashing.pdf:/home/michael/Dropbox/zotero-pdfs/P/Pincus_Baker_2004_Beyond stack smashing.pdf:application/pdf}
}

@inproceedings{delozier_ironclad_2013,
	address = {New York, NY, USA},
	series = {{OOPSLA} '13},
	title = {Ironclad {C}++: {A} {Library}-augmented {Type}-safe {Subset} of {C}++},
	isbn = {978-1-4503-2374-1},
	shorttitle = {Ironclad {C}++},
	url = {http://doi.acm.org/10.1145/2509136.2509550},
	doi = {10.1145/2509136.2509550},
	abstract = {The C++ programming language remains widely used, despite inheriting many unsafe features from C---features that often lead to failures of type or memory safety that manifest as buffer overflows, use-after-free vulnerabilities, or abstraction violations. Malicious attackers can exploit such violations to compromise application and system security. This paper introduces Ironclad C++, an approach to bringing the benefits of type and memory safety to C++. Ironclad C++ is, in essence, a library-augmented, type-safe subset of C++. All Ironclad C++ programs are valid C++ programs that can be compiled using standard, off-the-shelf C++ compilers. However, not all valid C++ programs are valid Ironclad C++ programs: a syntactic source-code validator statically prevents the use of unsafe C++ features. To enforce safety properties that are difficult to check statically, Ironclad C++ applies dynamic checks via templated ``smart pointer'' classes. Using a semi-automatic refactoring tool, we have ported nearly 50K lines of code to Ironclad C++. These benchmarks incur a performance overhead of 12\% on average, compared to the original unsafe C++ code.},
	urldate = {2018-06-07},
	booktitle = {Proceedings of the 2013 {ACM} {SIGPLAN} {International} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} \& {Applications}},
	publisher = {ACM},
	author = {DeLozier, Christian and Eisenberg, Richard and Nagarakatte, Santosh and Osera, Peter-Michael and Martin, Milo M.K. and Zdancewic, Steve},
	year = {2013},
	keywords = {memory safety, c++, local pointers, type-safety},
	pages = {287--304},
	file = {DeLozier et al_2013_Ironclad C++.pdf:/home/michael/Dropbox/zotero-pdfs/D/DeLozier et al_2013_Ironclad C++.pdf:application/pdf}
}

@book{lee_preventing_2015,
	title = {Preventing {Use}-after-free with {Dangling} {Pointers} {Nullification}},
	abstract = {Abstract—Many system components and network applications are written in languages that are prone to memory corruption vulnerabilities. There have been countless cases where simple mistakes by developers resulted in memory corruption vulnera-bilities and consequently security exploits. While there have been tremendous research efforts to mitigate these vulnerabilities, use-after-free still remains one of the most critical and popular attack vectors because existing proposals have not adequately addressed the challenging program analysis and runtime performance issues. In this paper we present DANGNULL, a system that detects temporal memory safety violations—in particular, use-after-free and double-free—during runtime. DANGNULL relies on the key observation that the root cause of these violations is that pointers are not nullified after the target object is freed. Based on this observation, DANGNULL automatically traces the object’s rela-tionships via pointers and automatically nullifies all pointers when the target object is freed. DANGNULL offers several benefits. First, DANGNULL addresses the root cause of temporal memory safety violations. It does not rely on the side effects of violations, which can vary and may be masked by attacks. Thus, DANGNULL is ef-fective against even the most sophisticated exploitation techniques. Second, DANGNULL checks object relationship information using runtime object range analysis on pointers, and thus is able to keep track of pointer semantics more robustly even in complex and large scale software. Lastly, DANGNULL does not require numerous explicit sanity checks on memory accesses because it can detect a violation with implicit exception handling, and thus its detection capabilities only incur moderate performance overhead. I.},
	author = {Lee, Byoungyoung and Song, Chengyu and Jang, Yeongjin and Wang, Tielei and Kim, Taesoo and Lu, Long and Lee, Wenke},
	year = {2015},
	file = {Lee et al_2015_Preventing Use-after-free with Dangling Pointers Nullification.pdf:/home/michael/Dropbox/zotero-pdfs/L/Lee et al_2015_Preventing Use-after-free with Dangling Pointers Nullification.pdf:application/pdf}
}

@inproceedings{ye_wpbound:_2014,
	title = {{WPBOUND}: {Enforcing} {Spatial} {Memory} {Safety} {Efficiently} at {Runtime} with {Weakest} {Preconditions}},
	shorttitle = {{WPBOUND}},
	doi = {10.1109/ISSRE.2014.20},
	abstract = {Spatial errors (e.g., Buffer overflows) continue to be one of the dominant threats to software reliability and security in C/C++ programs. Presently, the software industry typically enforces spatial memory safety by instrumentation. Due to high overheads incurred in bounds checking at runtime, many program inputs cannot be exercised, causing some input-specific spatial errors to go undetected in today's commercial software. This paper introduces a new compile-time optimisation for reducing bounds checking overheads based on the notion of Weakest Precondition (WP). The basic idea is to guard a bounds check at a pointer dereference inside a loop, where the WP-based guard is hoisted outside the loop, so that its falsehood implies the absence of out-of-bounds errors at the dereference, thereby avoiding the corresponding bounds check inside the loop. This WP-based optimisation is applicable to any spatial-error detection approach (in software or hardware or both). To evaluate the effectiveness of our optimisation, we take SOFTBOUND, a compile-time tool with an open-source implementation in LLVM, as our baseline. SOFTBOUND adopts a pointer-based checking approach with disjoint metadata, making it a state-of-the-art tool in providing compatible and complete spatial safety for C. Our new tool, called WPBOUND, is a refined version of SOFTBOUND, also implemented in LLVM, by incorporating our WP-based optimisation. For a set of 12 SPEC C benchmarks evaluated, WPBOUND reduces the average (geometric mean) slowdown of SOFTBOUND from 71\% to 45\% (by a reduction of 37\%), with small code size increases.},
	booktitle = {2014 {IEEE} 25th {International} {Symposium} on {Software} {Reliability} {Engineering}},
	author = {Ye, D. and Su, Y. and Sui, Y. and Xue, J.},
	month = nov,
	year = {2014},
	keywords = {Runtime, TO-READ, LLVM, program verification, Hardware, Safety, software reliability, Software, Instruments, bounds checking overheads, buffer overflows, C/C++ programs, C++ language, compile-time optimisation, compile-time tool, disjoint metadata, dominant threats, input-specific spatial errors, meta data, open-source implementation, optimisation, optimising compilers, Optimization, out-of-bounds errors, pointer dereference, pointer-based checking approach, safety-critical software, SOFTBOUND, software fault tolerance, software industry, software security, spatial memory safety, spatial-error detection approach, Upper bound, weakest preconditions, WP-based guard, WP-based optimisation, WPBOUND},
	pages = {88--99},
	file = {Ye et al_2014_WPBOUND.pdf:/home/michael/Dropbox/zotero-pdfs/Y/Ye et al_2014_WPBOUND.pdf:application/pdf}
}

@inproceedings{nagarakatte_watchdoglite:_2014,
	address = {New York, NY, USA},
	series = {{CGO} '14},
	title = {{WatchdogLite}: {Hardware}-{Accelerated} {Compiler}-{Based} {Pointer} {Checking}},
	isbn = {978-1-4503-2670-4},
	shorttitle = {{WatchdogLite}},
	url = {http://doi.acm.org/10.1145/2544137.2544147},
	doi = {10.1145/2544137.2544147},
	abstract = {Lack of memory safety in C is the root cause of a multitude of serious bugs and security vulnerabilities. Numerous software-only and hardware-based schemes have been proposed to enforce memory safety. Among these approaches, pointer-based checking, which maintains per-pointer metadata in a disjoint metadata space, has been recognized as providing comprehensive memory safety. Software approaches for pointer-based checking have high performance overheads. In contrast, hardware approaches introduce a myriad of hardware structures and widgets to mitigate those performance overheads. This paper proposes WatchdogLite, an ISA extension that provides hardware acceleration for a compiler implementation of pointer-based checking. This division of labor between the compiler and the hardware allows for hardware acceleration while using only preexisting architectural registers. By leveraging the compiler to identify pointers, perform check elimination, and insert the new instructions, this approach attains performance similar to prior hardware-intensive approaches without adding any hardware structures for tracking metadata.},
	urldate = {2018-06-07},
	booktitle = {Proceedings of {Annual} {IEEE}/{ACM} {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {ACM},
	author = {Nagarakatte, Santosh and Martin, Milo M. K. and Zdancewic, Steve},
	year = {2014},
	keywords = {memory safety, bounds checking, spatial safety, temporal safety, use-after-free checking},
	pages = {175:175--175:184},
	file = {Nagarakatte et al_2014_WatchdogLite.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nagarakatte et al_2014_WatchdogLite.pdf:application/pdf}
}

@inproceedings{nagarakatte_watchdog:_2012,
	address = {Washington, DC, USA},
	series = {{ISCA} '12},
	title = {Watchdog: {Hardware} for {Safe} and {Secure} {Manual} {Memory} {Management} and {Full} {Memory} {Safety}},
	isbn = {978-1-4503-1642-2},
	shorttitle = {Watchdog},
	url = {http://dl.acm.org/citation.cfm?id=2337159.2337181},
	abstract = {Languages such as C and C++ use unsafe manual memory management, allowing simple bugs (i.e., accesses to an object after deallocation) to become the root cause of exploitable security vulnerabilities. This paper proposes Watchdog, a hardware-based approach for ensuring safe and secure manual memory management. Inspired by prior software-only proposals, Watchdog generates a unique identifier for each memory allocation, associates these identifiers with pointers, and checks to ensure that the identifier is still valid on every memory access. This use of identifiers and checks enables Watchdog to detect errors even in the presence of reallocations. Watchdog stores these pointer identifiers in a disjoint shadow space to provide comprehensive protection and ensure compatibility with existing code. To streamline the implementation and reduce runtime overhead: Watchdog (1) uses micro-ops to access metadata and perform checks, (2) eliminates metadata copies among registers via modified register renaming, and (3) uses a dedicated metadata cache to reduce checking overhead. Furthermore, this paper extends Watchdog's mechanisms to detect bounds errors, thereby providing full hardware-enforced memory safety at low overheads.},
	urldate = {2018-06-07},
	booktitle = {Proceedings of the 39th {Annual} {International} {Symposium} on {Computer} {Architecture}},
	publisher = {IEEE Computer Society},
	author = {Nagarakatte, Santosh and Martin, Milo M. K. and Zdancewic, Steve},
	year = {2012},
	pages = {189--200},
	file = {Nagarakatte et al_2012_Watchdog.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nagarakatte et al_2012_Watchdog.pdf:application/pdf}
}

@inproceedings{akritidis_cling:_2010,
	address = {Berkeley, CA, USA},
	series = {{USENIX} {Security}'10},
	title = {Cling: {A} {Memory} {Allocator} to {Mitigate} {Dangling} {Pointers}},
	shorttitle = {Cling},
	url = {http://dl.acm.org/citation.cfm?id=1929820.1929836},
	abstract = {Use-after-free vulnerabilities exploiting so-called dangling pointers to deallocated objects are just as dangerous as buffer overflows: they may enable arbitrary code execution. Unfortunately, state-of-the-art defenses against use-after-free vulnerabilities require compiler support, pervasive source code modifications, or incur high performance overheads. This paper presents and evaluates Cling, a memory allocator designed to thwart these attacks at runtime. Cling utilizes more address space, a plentiful resource on modern machines, to prevent type-unsafe address space reuse among objects of different types. It infers type information about allocated objects at runtime by inspecting the call stack of memory allocation routines. Cling disrupts a large class of attacks against use-after-free vulnerabilities, notably including those hijacking the C++ virtual function dispatch mechanism, with low CPU and physical memory overhead even for allocation intensive applications.},
	urldate = {2018-06-08},
	booktitle = {Proceedings of the 19th {USENIX} {Conference} on {Security}},
	publisher = {USENIX Association},
	author = {Akritidis, Periklis},
	year = {2010},
	pages = {12--12},
	file = {Akritidis_2010_Cling.pdf:/home/michael/Dropbox/zotero-pdfs/A/Akritidis_2010_Cling.pdf:application/pdf}
}

@article{eigler_mudflap:_2003,
	title = {Mudflap: {Pointer} {Use} {Checking} {C}/{C}++},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.9896&rep=rep1&type=pdf#page=57},
	urldate = {2018-06-08},
	journal = {Proceedings of the First Annual GCC Developers’ Summit},
	author = {Eigler, Frank},
	year = {2003},
	pages = {57--70},
	file = {Eigler_2003_Mudflap.pdf:/home/michael/Dropbox/zotero-pdfs/E/Eigler_2003_Mudflap.pdf:application/pdf}
}

@inproceedings{nagarakatte_cets:_2010,
	address = {New York, NY, USA},
	series = {{ISMM} '10},
	title = {{CETS}: {Compiler} {Enforced} {Temporal} {Safety} for {C}},
	isbn = {978-1-4503-0054-4},
	shorttitle = {{CETS}},
	url = {http://doi.acm.org/10.1145/1806651.1806657},
	doi = {10.1145/1806651.1806657},
	abstract = {Temporal memory safety errors, such as dangling pointer dereferences and double frees, are a prevalent source of software bugs in unmanaged languages such as C. Existing schemes that attempt to retrofit temporal safety for such languages have high runtime overheads and/or are incomplete, thereby limiting their effectiveness as debugging aids. This paper presents CETS, a compile-time transformation for detecting all violations of temporal safety in C programs. Inspired by existing approaches, CETS maintains a unique identifier with each object, associates this metadata with the pointers in a disjoint metadata space to retain memory layout compatibility, and checks that the object is still allocated on pointer dereferences. A formal proof shows that this is sufficient to provide temporal safety even in the presence of arbitrary casts if the program contains no spatial safety violations. Our CETS prototype employs both temporal check removal optimizations and traditional compiler optimizations to achieve a runtime overhead of just 48\% on average. When combined with a spatial-checking system, the average overall overhead is 116\% for complete memory safety},
	urldate = {2018-06-08},
	booktitle = {Proceedings of the 2010 {International} {Symposium} on {Memory} {Management}},
	publisher = {ACM},
	author = {Nagarakatte, Santosh and Zhao, Jianzhou and Martin, Milo M.K. and Zdancewic, Steve},
	year = {2010},
	keywords = {memory safety, c, dangling pointers, temporal errors},
	pages = {31--40},
	file = {Nagarakatte et al_2010_CETS.pdf:/home/michael/Dropbox/zotero-pdfs/N/Nagarakatte et al_2010_CETS.pdf:application/pdf}
}

@inproceedings{akritidis_preventing_2008,
	title = {Preventing {Memory} {Error} {Exploits} with {WIT}},
	doi = {10.1109/SP.2008.30},
	abstract = {Attacks often exploit memory errors to gain control over the execution of vulnerable programs. These attacks remain a serious problem despite previous research on techniques to prevent them. We present write integrity testing (WIT), a new technique that provides practical protection from these attacks. WIT uses points-to analysis at compile time to compute the control-flow graph and the set of objects that can be written by each instruction in the program. Then it generates code instrumented to prevent instructions from modifying objects that are not in the set computed by the static analysis, and to ensure that indirect control transfers are allowed by the control-flow graph. To improve coverage where the analysis is not precise enough, WIT inserts small guards between the original program objects. We describe an efficient implementation with optimizations to reduce space and time overhead. This implementation can be used in practice because it compiles C and C++ programs without modifications, it has high coverage with no false positives, and it has low overhead. WIT's average runtime overhead is only 7\% across a set of CPU intensive benchmarks and it is negligible when IO is the bottleneck.},
	booktitle = {2008 {IEEE} {Symposium} on {Security} and {Privacy} (sp 2008)},
	author = {Akritidis, P. and Cadar, C. and Raiciu, C. and Costa, M. and Castro, M.},
	month = may,
	year = {2008},
	keywords = {Privacy, security of data, Protection, static analysis, program diagnostics, Runtime, Security, program compilers, Error correction, Testing, instrumentation, C program, Instruments, attack detection, C++ program, Color, Computer aided instruction, control-flow graph, data flow graphs, Gain control, memory error exploit prevention, memory errors, points-to analysis, program compilation, program control structures, program testing, vulnerable program execution control, write integrity testing},
	pages = {263--277}
}

@incollection{ou_dynamic_2004,
	series = {{IFIP} {International} {Federation} for {Information} {Processing}},
	title = {Dynamic {Typing} with {Dependent} {Types}},
	isbn = {978-1-4020-8140-8 978-1-4020-8141-5},
	url = {https://link.springer.com/chapter/10.1007/1-4020-8141-3_34},
	abstract = {Dependent type systems are promising tools programmers can use to increase the reliability and security of their programs. Unfortunately, dependently-typed programming languages require programmers to annotate their programs with many typing specifications to help guide the type checker. This paper shows how to make the process of programming with dependent types more palatable by defining a language in which programmers have fine-grained control over the trade-off between the number of dependent typing annotations they must place on programs and the degree of compile-time safety. More specifically, certain program fragments are marked dependent, in which case the programmer annotates them in detail and a dependent type checker verifies them at compile time. Other fragments are marked simple, in which case they may be annotation-free and dependent constraints are verified at run time.},
	language = {en},
	urldate = {2018-06-09},
	booktitle = {Exploring {New} {Frontiers} of {Theoretical} {Informatics}},
	publisher = {Springer, Boston, MA},
	author = {Ou, Xinming and Tan, Gang and Mandelbaum, Yitzhak and Walker, David},
	year = {2004},
	doi = {10.1007/1-4020-8141-3_34},
	pages = {437--450},
	file = {Ou et al_2004_Dynamic Typing with Dependent Types.pdf:/home/michael/Dropbox/zotero-pdfs/O/Ou et al_2004_Dynamic Typing with Dependent Types.pdf:application/pdf}
}
